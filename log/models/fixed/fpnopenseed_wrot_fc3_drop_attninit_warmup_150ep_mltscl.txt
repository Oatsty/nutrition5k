[2023-06-25 02:39:02,612] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 02:39:03,378] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 02:39:06,083] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,085] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,085] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,092] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,092] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,098] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,098] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,100] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,100] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,106] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,106] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,112] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,112] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,114] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,114] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,120] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,120] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,126] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,126] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,127] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,127] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,133] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,134] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,140] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,140] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,142] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,142] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,148] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,148] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,154] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,154] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,156] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,156] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,162] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,162] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,168] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,168] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,170] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,170] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,176] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,176] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,182] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,182] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,183] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,183] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,190] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,190] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,196] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,196] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,198] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,198] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,204] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,204] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,210] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,210] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,212] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,212] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,218] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,218] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,224] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,224] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,226] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,226] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,232] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,232] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,238] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,238] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,239] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,240] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,246] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,246] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:39:06,252] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,900] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,901] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,902] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,902] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,902] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,902] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,903] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,903] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,904] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,905] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,906] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:39:06,906] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,907] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,907] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,907] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:39:06,907] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,907] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:39:06,907] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,907] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,907] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,908] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:39:06,908] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:39:06,908] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,909] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,910] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,911] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,912] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,913] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,914] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,915] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,916] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,917] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,918] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,919] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,920] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,921] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,922] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,923] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,924] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,925] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,926] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,927] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,928] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,929] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,930] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:39:06,931] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,932] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,933] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,934] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,935] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,936] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,937] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,938] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,939] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:39:06,940] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:39:06,941] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:39:06,941] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:39:06,941] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:39:06,941] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:39:08,147] Epoch 1/150
[2023-06-25 02:41:34,928] train loss: 3.8095
[2023-06-25 02:41:34,929] cal loss: 168.1488
[2023-06-25 02:41:34,929] cal percent loss: 0.6594
[2023-06-25 02:41:34,929] mass loss: 131.2096
[2023-06-25 02:41:34,929] mass percent loss: 0.6019
[2023-06-25 02:41:34,929] fat loss: 10.6488
[2023-06-25 02:41:34,930] fat percent loss: 0.8385
[2023-06-25 02:41:34,930] carb loss: 12.8542
[2023-06-25 02:41:34,930] carb percent loss: 0.6660
[2023-06-25 02:41:34,930] protein loss: 17.6254
[2023-06-25 02:41:34,930] protein percent loss: 0.9738
[2023-06-25 02:41:34,930] Epoch 1/150
[2023-06-25 02:42:01,101] test loss: 3.8740
[2023-06-25 02:42:01,102] cal loss: 167.6990
[2023-06-25 02:42:01,103] cal percent loss: 0.6576
[2023-06-25 02:42:01,103] mass loss: 132.1906
[2023-06-25 02:42:01,103] mass percent loss: 0.6064
[2023-06-25 02:42:01,103] fat loss: 11.2198
[2023-06-25 02:42:01,103] fat percent loss: 0.8834
[2023-06-25 02:42:01,103] carb loss: 13.6363
[2023-06-25 02:42:01,103] carb percent loss: 0.7065
[2023-06-25 02:42:01,103] protein loss: 17.2799
[2023-06-25 02:42:01,103] protein percent loss: 0.9547
[2023-06-25 02:42:01,103] Epoch 2/150
[2023-06-25 02:44:30,704] train loss: 3.5258
[2023-06-25 02:44:30,705] cal loss: 164.5154
[2023-06-25 02:44:30,705] cal percent loss: 0.6452
[2023-06-25 02:44:30,705] mass loss: 121.5146
[2023-06-25 02:44:30,705] mass percent loss: 0.5574
[2023-06-25 02:44:30,705] fat loss: 9.9134
[2023-06-25 02:44:30,706] fat percent loss: 0.7806
[2023-06-25 02:44:30,706] carb loss: 12.3856
[2023-06-25 02:44:30,706] carb percent loss: 0.6417
[2023-06-25 02:44:30,706] protein loss: 14.9613
[2023-06-25 02:44:30,706] protein percent loss: 0.8266
[2023-06-25 02:44:30,706] Epoch 2/150
[2023-06-25 02:44:54,285] test loss: 3.4698
[2023-06-25 02:44:54,286] cal loss: 164.4731
[2023-06-25 02:44:54,286] cal percent loss: 0.6450
[2023-06-25 02:44:54,286] mass loss: 111.5933
[2023-06-25 02:44:54,287] mass percent loss: 0.5119
[2023-06-25 02:44:54,287] fat loss: 9.9514
[2023-06-25 02:44:54,287] fat percent loss: 0.7836
[2023-06-25 02:44:54,287] carb loss: 13.2743
[2023-06-25 02:44:54,287] carb percent loss: 0.6878
[2023-06-25 02:44:54,287] protein loss: 14.2016
[2023-06-25 02:44:54,287] protein percent loss: 0.7846
[2023-06-25 02:44:54,288] Epoch 3/150
[2023-06-25 02:47:24,777] train loss: 3.4174
[2023-06-25 02:47:24,778] cal loss: 159.9693
[2023-06-25 02:47:24,778] cal percent loss: 0.6273
[2023-06-25 02:47:24,778] mass loss: 115.1630
[2023-06-25 02:47:24,779] mass percent loss: 0.5283
[2023-06-25 02:47:24,779] fat loss: 9.6936
[2023-06-25 02:47:24,779] fat percent loss: 0.7633
[2023-06-25 02:47:24,779] carb loss: 12.3100
[2023-06-25 02:47:24,779] carb percent loss: 0.6378
[2023-06-25 02:47:24,779] protein loss: 14.3748
[2023-06-25 02:47:24,779] protein percent loss: 0.7942
[2023-06-25 02:47:24,779] Epoch 3/150
[2023-06-25 02:47:50,048] test loss: 3.3804
[2023-06-25 02:47:50,048] cal loss: 155.4134
[2023-06-25 02:47:50,048] cal percent loss: 0.6095
[2023-06-25 02:47:50,049] mass loss: 109.7970
[2023-06-25 02:47:50,049] mass percent loss: 0.5037
[2023-06-25 02:47:50,049] fat loss: 9.7473
[2023-06-25 02:47:50,049] fat percent loss: 0.7675
[2023-06-25 02:47:50,049] carb loss: 13.5348
[2023-06-25 02:47:50,049] carb percent loss: 0.7013
[2023-06-25 02:47:50,049] protein loss: 13.5176
[2023-06-25 02:47:50,050] protein percent loss: 0.7468
[2023-06-25 02:47:50,050] Epoch 4/150
[2023-06-25 02:50:20,582] train loss: 3.2672
[2023-06-25 02:50:20,583] cal loss: 151.6979
[2023-06-25 02:50:20,583] cal percent loss: 0.5949
[2023-06-25 02:50:20,583] mass loss: 107.7373
[2023-06-25 02:50:20,583] mass percent loss: 0.4942
[2023-06-25 02:50:20,583] fat loss: 9.3319
[2023-06-25 02:50:20,583] fat percent loss: 0.7348
[2023-06-25 02:50:20,583] carb loss: 11.9787
[2023-06-25 02:50:20,583] carb percent loss: 0.6207
[2023-06-25 02:50:20,583] protein loss: 13.8614
[2023-06-25 02:50:20,583] protein percent loss: 0.7658
[2023-06-25 02:50:20,583] Epoch 4/150
[2023-06-25 02:50:49,437] test loss: 3.1144
[2023-06-25 02:50:49,438] cal loss: 145.2827
[2023-06-25 02:50:49,438] cal percent loss: 0.5697
[2023-06-25 02:50:49,438] mass loss: 92.1315
[2023-06-25 02:50:49,438] mass percent loss: 0.4226
[2023-06-25 02:50:49,438] fat loss: 9.0307
[2023-06-25 02:50:49,438] fat percent loss: 0.7111
[2023-06-25 02:50:49,438] carb loss: 13.0911
[2023-06-25 02:50:49,438] carb percent loss: 0.6783
[2023-06-25 02:50:49,438] protein loss: 12.7417
[2023-06-25 02:50:49,438] protein percent loss: 0.7040
[2023-06-25 02:50:49,439] Epoch 5/150
[2023-06-25 02:53:18,547] train loss: 3.1158
[2023-06-25 02:53:18,548] cal loss: 143.7393
[2023-06-25 02:53:18,548] cal percent loss: 0.5637
[2023-06-25 02:53:18,548] mass loss: 102.5778
[2023-06-25 02:53:18,548] mass percent loss: 0.4705
[2023-06-25 02:53:18,548] fat loss: 8.8318
[2023-06-25 02:53:18,548] fat percent loss: 0.6954
[2023-06-25 02:53:18,548] carb loss: 11.8329
[2023-06-25 02:53:18,548] carb percent loss: 0.6131
[2023-06-25 02:53:18,548] protein loss: 13.0572
[2023-06-25 02:53:18,549] protein percent loss: 0.7214
[2023-06-25 02:53:18,549] Epoch 5/150
[2023-06-25 02:53:46,717] test loss: 3.8932
[2023-06-25 02:53:46,719] cal loss: 180.6341
[2023-06-25 02:53:46,719] cal percent loss: 0.7084
[2023-06-25 02:53:46,719] mass loss: 132.8312
[2023-06-25 02:53:46,719] mass percent loss: 0.6093
[2023-06-25 02:53:46,719] fat loss: 11.1667
[2023-06-25 02:53:46,719] fat percent loss: 0.8793
[2023-06-25 02:53:46,719] carb loss: 14.3322
[2023-06-25 02:53:46,720] carb percent loss: 0.7426
[2023-06-25 02:53:46,720] protein loss: 15.8556
[2023-06-25 02:53:46,720] protein percent loss: 0.8760
[2023-06-25 02:53:46,720] Epoch 6/150
[2023-06-25 02:56:11,774] train loss: 3.1903
[2023-06-25 02:56:11,775] cal loss: 146.2908
[2023-06-25 02:56:11,775] cal percent loss: 0.5737
[2023-06-25 02:56:11,775] mass loss: 106.8970
[2023-06-25 02:56:11,775] mass percent loss: 0.4904
[2023-06-25 02:56:11,775] fat loss: 9.0159
[2023-06-25 02:56:11,776] fat percent loss: 0.7099
[2023-06-25 02:56:11,776] carb loss: 11.9002
[2023-06-25 02:56:11,776] carb percent loss: 0.6166
[2023-06-25 02:56:11,776] protein loss: 13.4554
[2023-06-25 02:56:11,776] protein percent loss: 0.7434
[2023-06-25 02:56:11,776] Epoch 6/150
[2023-06-25 02:56:36,239] test loss: 2.9163
[2023-06-25 02:56:36,240] cal loss: 127.4083
[2023-06-25 02:56:36,240] cal percent loss: 0.4996
[2023-06-25 02:56:36,240] mass loss: 87.7443
[2023-06-25 02:56:36,240] mass percent loss: 0.4025
[2023-06-25 02:56:36,241] fat loss: 8.6749
[2023-06-25 02:56:36,241] fat percent loss: 0.6831
[2023-06-25 02:56:36,241] carb loss: 12.5984
[2023-06-25 02:56:36,241] carb percent loss: 0.6528
[2023-06-25 02:56:36,241] protein loss: 11.9016
[2023-06-25 02:56:36,241] protein percent loss: 0.6575
[2023-06-25 02:56:36,241] Epoch 7/150
[2023-06-25 02:59:02,967] train loss: 2.9194
[2023-06-25 02:59:02,968] cal loss: 133.5914
[2023-06-25 02:59:02,968] cal percent loss: 0.5239
[2023-06-25 02:59:02,968] mass loss: 90.5874
[2023-06-25 02:59:02,968] mass percent loss: 0.4155
[2023-06-25 02:59:02,968] fat loss: 8.5174
[2023-06-25 02:59:02,968] fat percent loss: 0.6707
[2023-06-25 02:59:02,968] carb loss: 11.4840
[2023-06-25 02:59:02,968] carb percent loss: 0.5950
[2023-06-25 02:59:02,969] protein loss: 12.2925
[2023-06-25 02:59:02,969] protein percent loss: 0.6791
[2023-06-25 02:59:02,969] Epoch 7/150
[2023-06-25 02:59:28,021] test loss: 2.8876
[2023-06-25 02:59:28,021] cal loss: 126.9237
[2023-06-25 02:59:28,022] cal percent loss: 0.4977
[2023-06-25 02:59:28,022] mass loss: 88.6802
[2023-06-25 02:59:28,022] mass percent loss: 0.4068
[2023-06-25 02:59:28,022] fat loss: 8.6341
[2023-06-25 02:59:28,022] fat percent loss: 0.6798
[2023-06-25 02:59:28,022] carb loss: 12.1501
[2023-06-25 02:59:28,022] carb percent loss: 0.6295
[2023-06-25 02:59:28,022] protein loss: 11.7163
[2023-06-25 02:59:28,023] protein percent loss: 0.6473
[2023-06-25 02:59:28,023] Epoch 8/150
[2023-06-25 03:02:01,283] train loss: 2.9166
[2023-06-25 03:02:01,283] cal loss: 132.8287
[2023-06-25 03:02:01,284] cal percent loss: 0.5209
[2023-06-25 03:02:01,284] mass loss: 91.4272
[2023-06-25 03:02:01,284] mass percent loss: 0.4194
[2023-06-25 03:02:01,284] fat loss: 8.5124
[2023-06-25 03:02:01,284] fat percent loss: 0.6703
[2023-06-25 03:02:01,284] carb loss: 11.3352
[2023-06-25 03:02:01,284] carb percent loss: 0.5873
[2023-06-25 03:02:01,285] protein loss: 12.3439
[2023-06-25 03:02:01,285] protein percent loss: 0.6820
[2023-06-25 03:02:01,285] Epoch 8/150
[2023-06-25 03:02:26,240] test loss: 2.8993
[2023-06-25 03:02:26,240] cal loss: 133.1552
[2023-06-25 03:02:26,240] cal percent loss: 0.5222
[2023-06-25 03:02:26,240] mass loss: 82.2747
[2023-06-25 03:02:26,240] mass percent loss: 0.3774
[2023-06-25 03:02:26,240] fat loss: 8.4964
[2023-06-25 03:02:26,240] fat percent loss: 0.6690
[2023-06-25 03:02:26,240] carb loss: 13.1385
[2023-06-25 03:02:26,240] carb percent loss: 0.6808
[2023-06-25 03:02:26,241] protein loss: 11.4907
[2023-06-25 03:02:26,241] protein percent loss: 0.6348
[2023-06-25 03:02:26,241] Epoch 9/150
[2023-06-25 03:04:52,812] train loss: 2.7928
[2023-06-25 03:04:52,812] cal loss: 127.2412
[2023-06-25 03:04:52,813] cal percent loss: 0.4990
[2023-06-25 03:04:52,813] mass loss: 84.3731
[2023-06-25 03:04:52,813] mass percent loss: 0.3870
[2023-06-25 03:04:52,813] fat loss: 8.2649
[2023-06-25 03:04:52,813] fat percent loss: 0.6508
[2023-06-25 03:04:52,813] carb loss: 11.2807
[2023-06-25 03:04:52,814] carb percent loss: 0.5845
[2023-06-25 03:04:52,814] protein loss: 11.6505
[2023-06-25 03:04:52,814] protein percent loss: 0.6437
[2023-06-25 03:04:52,814] Epoch 9/150
[2023-06-25 03:05:18,421] test loss: 3.0695
[2023-06-25 03:05:18,421] cal loss: 134.1514
[2023-06-25 03:05:18,421] cal percent loss: 0.5261
[2023-06-25 03:05:18,421] mass loss: 101.1274
[2023-06-25 03:05:18,422] mass percent loss: 0.4639
[2023-06-25 03:05:18,422] fat loss: 8.7581
[2023-06-25 03:05:18,422] fat percent loss: 0.6896
[2023-06-25 03:05:18,422] carb loss: 12.9556
[2023-06-25 03:05:18,422] carb percent loss: 0.6713
[2023-06-25 03:05:18,422] protein loss: 12.2722
[2023-06-25 03:05:18,422] protein percent loss: 0.6780
[2023-06-25 03:05:18,422] Epoch 10/150
[2023-06-25 03:07:24,278] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 03:07:25,050] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 03:07:27,738] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,740] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,740] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,747] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,747] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,753] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,753] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,754] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,754] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,761] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,761] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,766] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,767] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,768] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,768] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,774] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,774] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,780] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,780] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,782] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,782] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,788] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,788] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,794] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,794] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,796] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,796] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,802] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,802] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,808] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,808] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,810] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,810] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,816] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,816] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,822] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,822] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,823] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,823] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,829] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,829] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,835] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,835] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,837] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,837] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,843] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,843] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,849] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,849] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,851] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,851] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,857] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,857] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,863] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,863] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,865] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,865] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,871] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,871] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,877] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,877] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,879] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,879] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,885] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,885] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,891] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,891] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,892] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,892] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,899] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:27,899] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:07:27,905] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,535] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,536] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,536] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,537] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,537] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,538] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,539] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,540] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,541] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,541] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,541] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,541] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,541] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,541] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:07:28,542] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,542] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,542] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,542] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:07:28,542] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,542] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:07:28,542] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,542] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,542] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,542] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:07:28,542] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 03:07:28,542] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,543] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,544] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,545] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,546] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,547] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,548] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,549] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,550] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,551] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,552] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,553] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,554] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,555] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,556] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,557] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,558] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,559] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,560] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,561] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:07:28,562] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:07:28,563] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,564] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,565] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,566] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,567] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,568] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,569] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,570] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,571] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,572] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,573] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,574] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,575] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:07:28,575] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:07:28,575] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 03:07:28,575] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:07:28,575] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:07:30,353] Epoch 1/150
[2023-06-25 03:08:21,965] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 03:08:22,792] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 03:08:35,214] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,217] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,217] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,225] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,225] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,231] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,231] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,233] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,233] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,239] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,239] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,245] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,245] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,246] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,246] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,252] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,252] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,258] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,258] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,260] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,260] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,266] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,266] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,272] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,272] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,274] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,274] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,280] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,280] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,285] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,286] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,287] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,287] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,293] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,293] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,299] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,299] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,301] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,301] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,307] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,307] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,313] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,313] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,314] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,314] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,320] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,320] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,326] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,326] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,328] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,328] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,334] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,334] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,340] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,340] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,342] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,342] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,348] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,348] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,354] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,354] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,355] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,355] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,361] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,361] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,367] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,367] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,369] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,369] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,375] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:35,375] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:08:35,381] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:08:36,057] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 03:08:36,058] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,059] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,060] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,060] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,060] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,060] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,061] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:08:36,062] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,063] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:08:36,063] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,064] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,064] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,064] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,064] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,064] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:08:36,064] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,065] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:08:36,065] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,065] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,065] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,065] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,065] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:08:36,065] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 03:08:36,065] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,065] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,065] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 03:08:36,065] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,065] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,066] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,067] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,068] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,069] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,070] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,071] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,072] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,073] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,074] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,075] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,076] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,077] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,078] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,079] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,080] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,081] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,082] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,083] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,084] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,085] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,086] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,087] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,088] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,089] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,090] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:08:36,091] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,092] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,095] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,096] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,097] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,098] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,099] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,100] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:08:36,101] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:08:36,101] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 03:08:36,101] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:08:36,101] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:08:38,308] Epoch 1/150
[2023-06-25 03:11:08,522] train loss: 3.8584
[2023-06-25 03:11:08,523] cal loss: 174.9677
[2023-06-25 03:11:08,523] cal percent loss: 0.6861
[2023-06-25 03:11:08,523] mass loss: 132.3848
[2023-06-25 03:11:08,523] mass percent loss: 0.6073
[2023-06-25 03:11:08,523] fat loss: 10.4949
[2023-06-25 03:11:08,524] fat percent loss: 0.8264
[2023-06-25 03:11:08,524] carb loss: 13.1507
[2023-06-25 03:11:08,524] carb percent loss: 0.6814
[2023-06-25 03:11:08,524] protein loss: 17.8089
[2023-06-25 03:11:08,524] protein percent loss: 0.9839
[2023-06-25 03:11:08,524] Epoch 1/150
[2023-06-25 03:11:35,199] test loss: 3.8507
[2023-06-25 03:11:35,199] cal loss: 170.6540
[2023-06-25 03:11:35,200] cal percent loss: 0.6692
[2023-06-25 03:11:35,200] mass loss: 131.7558
[2023-06-25 03:11:35,200] mass percent loss: 0.6044
[2023-06-25 03:11:35,200] fat loss: 10.8061
[2023-06-25 03:11:35,200] fat percent loss: 0.8509
[2023-06-25 03:11:35,200] carb loss: 13.5660
[2023-06-25 03:11:35,200] carb percent loss: 0.7029
[2023-06-25 03:11:35,200] protein loss: 17.2787
[2023-06-25 03:11:35,201] protein percent loss: 0.9546
[2023-06-25 03:11:35,201] Epoch 2/150
[2023-06-25 03:14:09,459] train loss: 3.4666
[2023-06-25 03:14:09,460] cal loss: 162.4268
[2023-06-25 03:14:09,460] cal percent loss: 0.6370
[2023-06-25 03:14:09,460] mass loss: 117.2112
[2023-06-25 03:14:09,460] mass percent loss: 0.5377
[2023-06-25 03:14:09,461] fat loss: 9.6696
[2023-06-25 03:14:09,461] fat percent loss: 0.7614
[2023-06-25 03:14:09,461] carb loss: 12.5649
[2023-06-25 03:14:09,461] carb percent loss: 0.6510
[2023-06-25 03:14:09,461] protein loss: 14.6961
[2023-06-25 03:14:09,461] protein percent loss: 0.8119
[2023-06-25 03:14:09,461] Epoch 2/150
[2023-06-25 03:14:33,399] test loss: 3.3341
[2023-06-25 03:14:33,400] cal loss: 161.5998
[2023-06-25 03:14:33,400] cal percent loss: 0.6337
[2023-06-25 03:14:33,401] mass loss: 100.9666
[2023-06-25 03:14:33,401] mass percent loss: 0.4631
[2023-06-25 03:14:33,401] fat loss: 9.4664
[2023-06-25 03:14:33,401] fat percent loss: 0.7454
[2023-06-25 03:14:33,401] carb loss: 13.5795
[2023-06-25 03:14:33,401] carb percent loss: 0.7036
[2023-06-25 03:14:33,401] protein loss: 13.4955
[2023-06-25 03:14:33,401] protein percent loss: 0.7456
[2023-06-25 03:14:33,402] Epoch 3/150
[2023-06-25 03:17:07,614] train loss: 3.1260
[2023-06-25 03:17:07,614] cal loss: 146.0298
[2023-06-25 03:17:07,614] cal percent loss: 0.5727
[2023-06-25 03:17:07,614] mass loss: 99.7475
[2023-06-25 03:17:07,615] mass percent loss: 0.4576
[2023-06-25 03:17:07,615] fat loss: 8.9594
[2023-06-25 03:17:07,615] fat percent loss: 0.7055
[2023-06-25 03:17:07,615] carb loss: 11.9640
[2023-06-25 03:17:07,615] carb percent loss: 0.6199
[2023-06-25 03:17:07,615] protein loss: 13.0921
[2023-06-25 03:17:07,615] protein percent loss: 0.7233
[2023-06-25 03:17:07,615] Epoch 3/150
[2023-06-25 03:17:33,664] test loss: 2.9410
[2023-06-25 03:17:33,665] cal loss: 143.1012
[2023-06-25 03:17:33,665] cal percent loss: 0.5612
[2023-06-25 03:17:33,665] mass loss: 81.3646
[2023-06-25 03:17:33,665] mass percent loss: 0.3732
[2023-06-25 03:17:33,665] fat loss: 8.7061
[2023-06-25 03:17:33,665] fat percent loss: 0.6855
[2023-06-25 03:17:33,665] carb loss: 12.4028
[2023-06-25 03:17:33,666] carb percent loss: 0.6426
[2023-06-25 03:17:33,666] protein loss: 11.8872
[2023-06-25 03:17:33,666] protein percent loss: 0.6568
[2023-06-25 03:17:33,666] Epoch 4/150
[2023-06-25 03:20:08,165] train loss: 2.8770
[2023-06-25 03:20:08,165] cal loss: 132.7932
[2023-06-25 03:20:08,165] cal percent loss: 0.5208
[2023-06-25 03:20:08,165] mass loss: 85.6056
[2023-06-25 03:20:08,166] mass percent loss: 0.3927
[2023-06-25 03:20:08,166] fat loss: 8.6380
[2023-06-25 03:20:08,166] fat percent loss: 0.6802
[2023-06-25 03:20:08,166] carb loss: 11.3267
[2023-06-25 03:20:08,166] carb percent loss: 0.5869
[2023-06-25 03:20:08,166] protein loss: 12.0873
[2023-06-25 03:20:08,166] protein percent loss: 0.6678
[2023-06-25 03:20:08,166] Epoch 4/150
[2023-06-25 03:20:37,369] test loss: 3.2926
[2023-06-25 03:20:37,370] cal loss: 139.0066
[2023-06-25 03:20:37,370] cal percent loss: 0.5451
[2023-06-25 03:20:37,370] mass loss: 125.0815
[2023-06-25 03:20:37,370] mass percent loss: 0.5738
[2023-06-25 03:20:37,371] fat loss: 9.3104
[2023-06-25 03:20:37,371] fat percent loss: 0.7331
[2023-06-25 03:20:37,371] carb loss: 12.5379
[2023-06-25 03:20:37,371] carb percent loss: 0.6496
[2023-06-25 03:20:37,371] protein loss: 12.9123
[2023-06-25 03:20:37,371] protein percent loss: 0.7134
[2023-06-25 03:20:37,372] Epoch 5/150
[2023-06-25 03:23:10,928] train loss: 2.8181
[2023-06-25 03:23:10,929] cal loss: 129.0871
[2023-06-25 03:23:10,929] cal percent loss: 0.5062
[2023-06-25 03:23:10,929] mass loss: 82.9705
[2023-06-25 03:23:10,929] mass percent loss: 0.3806
[2023-06-25 03:23:10,929] fat loss: 8.4802
[2023-06-25 03:23:10,930] fat percent loss: 0.6677
[2023-06-25 03:23:10,930] carb loss: 11.2687
[2023-06-25 03:23:10,930] carb percent loss: 0.5839
[2023-06-25 03:23:10,930] protein loss: 11.8528
[2023-06-25 03:23:10,930] protein percent loss: 0.6549
[2023-06-25 03:23:10,930] Epoch 5/150
[2023-06-25 03:23:39,189] test loss: 2.7082
[2023-06-25 03:23:39,190] cal loss: 119.0580
[2023-06-25 03:23:39,190] cal percent loss: 0.4669
[2023-06-25 03:23:39,190] mass loss: 71.0174
[2023-06-25 03:23:39,190] mass percent loss: 0.3258
[2023-06-25 03:23:39,190] fat loss: 8.4150
[2023-06-25 03:23:39,191] fat percent loss: 0.6626
[2023-06-25 03:23:39,191] carb loss: 11.7920
[2023-06-25 03:23:39,191] carb percent loss: 0.6110
[2023-06-25 03:23:39,191] protein loss: 11.6559
[2023-06-25 03:23:39,191] protein percent loss: 0.6440
[2023-06-25 03:23:39,191] Epoch 6/150
[2023-06-25 03:26:07,989] train loss: 2.7266
[2023-06-25 03:26:07,990] cal loss: 125.2569
[2023-06-25 03:26:07,990] cal percent loss: 0.4912
[2023-06-25 03:26:07,990] mass loss: 77.8940
[2023-06-25 03:26:07,991] mass percent loss: 0.3573
[2023-06-25 03:26:07,991] fat loss: 8.2979
[2023-06-25 03:26:07,991] fat percent loss: 0.6534
[2023-06-25 03:26:07,991] carb loss: 11.0450
[2023-06-25 03:26:07,991] carb percent loss: 0.5723
[2023-06-25 03:26:07,991] protein loss: 11.4626
[2023-06-25 03:26:07,991] protein percent loss: 0.6333
[2023-06-25 03:26:07,991] Epoch 6/150
[2023-06-25 03:26:32,961] test loss: 2.6352
[2023-06-25 03:26:32,962] cal loss: 116.8546
[2023-06-25 03:26:32,962] cal percent loss: 0.4583
[2023-06-25 03:26:32,962] mass loss: 68.5581
[2023-06-25 03:26:32,962] mass percent loss: 0.3145
[2023-06-25 03:26:32,962] fat loss: 8.2530
[2023-06-25 03:26:32,962] fat percent loss: 0.6498
[2023-06-25 03:26:32,962] carb loss: 11.5425
[2023-06-25 03:26:32,962] carb percent loss: 0.5981
[2023-06-25 03:26:32,962] protein loss: 11.1568
[2023-06-25 03:26:32,962] protein percent loss: 0.6164
[2023-06-25 03:26:32,962] Epoch 7/150
[2023-06-25 03:29:03,062] train loss: 2.6056
[2023-06-25 03:29:03,063] cal loss: 117.0768
[2023-06-25 03:29:03,063] cal percent loss: 0.4591
[2023-06-25 03:29:03,063] mass loss: 73.4150
[2023-06-25 03:29:03,063] mass percent loss: 0.3368
[2023-06-25 03:29:03,063] fat loss: 8.1003
[2023-06-25 03:29:03,063] fat percent loss: 0.6378
[2023-06-25 03:29:03,063] carb loss: 10.8157
[2023-06-25 03:29:03,063] carb percent loss: 0.5604
[2023-06-25 03:29:03,063] protein loss: 10.8267
[2023-06-25 03:29:03,064] protein percent loss: 0.5982
[2023-06-25 03:29:03,064] Epoch 7/150
[2023-06-25 03:29:28,563] test loss: 2.7599
[2023-06-25 03:29:28,563] cal loss: 114.7520
[2023-06-25 03:29:28,563] cal percent loss: 0.4500
[2023-06-25 03:29:28,564] mass loss: 69.3787
[2023-06-25 03:29:28,564] mass percent loss: 0.3183
[2023-06-25 03:29:28,564] fat loss: 8.3223
[2023-06-25 03:29:28,564] fat percent loss: 0.6553
[2023-06-25 03:29:28,564] carb loss: 11.5037
[2023-06-25 03:29:28,564] carb percent loss: 0.5960
[2023-06-25 03:29:28,564] protein loss: 13.6980
[2023-06-25 03:29:28,565] protein percent loss: 0.7568
[2023-06-25 03:29:28,565] Epoch 8/150
[2023-06-25 03:32:05,705] train loss: 2.5361
[2023-06-25 03:32:05,705] cal loss: 114.8099
[2023-06-25 03:32:05,705] cal percent loss: 0.4502
[2023-06-25 03:32:05,706] mass loss: 69.0419
[2023-06-25 03:32:05,706] mass percent loss: 0.3167
[2023-06-25 03:32:05,706] fat loss: 7.9879
[2023-06-25 03:32:05,706] fat percent loss: 0.6290
[2023-06-25 03:32:05,706] carb loss: 10.6278
[2023-06-25 03:32:05,706] carb percent loss: 0.5507
[2023-06-25 03:32:05,706] protein loss: 10.5098
[2023-06-25 03:32:05,706] protein percent loss: 0.5807
[2023-06-25 03:32:05,706] Epoch 8/150
[2023-06-25 03:32:31,326] test loss: 2.6229
[2023-06-25 03:32:31,326] cal loss: 121.4053
[2023-06-25 03:32:31,327] cal percent loss: 0.4761
[2023-06-25 03:32:31,327] mass loss: 61.8436
[2023-06-25 03:32:31,327] mass percent loss: 0.2837
[2023-06-25 03:32:31,327] fat loss: 8.9224
[2023-06-25 03:32:31,327] fat percent loss: 0.7026
[2023-06-25 03:32:31,327] carb loss: 11.5212
[2023-06-25 03:32:31,327] carb percent loss: 0.5970
[2023-06-25 03:32:31,327] protein loss: 10.3346
[2023-06-25 03:32:31,328] protein percent loss: 0.5710
[2023-06-25 03:32:31,328] Epoch 9/150
[2023-06-25 03:35:01,446] train loss: 2.5605
[2023-06-25 03:35:01,447] cal loss: 115.7510
[2023-06-25 03:35:01,447] cal percent loss: 0.4539
[2023-06-25 03:35:01,447] mass loss: 71.8691
[2023-06-25 03:35:01,447] mass percent loss: 0.3297
[2023-06-25 03:35:01,447] fat loss: 8.1296
[2023-06-25 03:35:01,447] fat percent loss: 0.6401
[2023-06-25 03:35:01,447] carb loss: 10.4451
[2023-06-25 03:35:01,447] carb percent loss: 0.5412
[2023-06-25 03:35:01,448] protein loss: 10.5197
[2023-06-25 03:35:01,448] protein percent loss: 0.5812
[2023-06-25 03:35:01,448] Epoch 9/150
[2023-06-25 03:35:27,584] test loss: 3.1062
[2023-06-25 03:35:27,584] cal loss: 141.0474
[2023-06-25 03:35:27,585] cal percent loss: 0.5531
[2023-06-25 03:35:27,585] mass loss: 97.5043
[2023-06-25 03:35:27,585] mass percent loss: 0.4473
[2023-06-25 03:35:27,585] fat loss: 9.3690
[2023-06-25 03:35:27,585] fat percent loss: 0.7377
[2023-06-25 03:35:27,585] carb loss: 12.1930
[2023-06-25 03:35:27,585] carb percent loss: 0.6318
[2023-06-25 03:35:27,585] protein loss: 12.6020
[2023-06-25 03:35:27,585] protein percent loss: 0.6962
[2023-06-25 03:35:27,586] Epoch 10/150
[2023-06-25 03:38:01,554] train loss: 2.5269
[2023-06-25 03:38:01,555] cal loss: 112.7204
[2023-06-25 03:38:01,555] cal percent loss: 0.4420
[2023-06-25 03:38:01,555] mass loss: 71.0187
[2023-06-25 03:38:01,556] mass percent loss: 0.3258
[2023-06-25 03:38:01,556] fat loss: 8.0116
[2023-06-25 03:38:01,556] fat percent loss: 0.6308
[2023-06-25 03:38:01,556] carb loss: 10.3717
[2023-06-25 03:38:01,556] carb percent loss: 0.5374
[2023-06-25 03:38:01,556] protein loss: 10.4672
[2023-06-25 03:38:01,556] protein percent loss: 0.5783
[2023-06-25 03:38:01,556] Epoch 10/150
[2023-06-25 03:38:27,087] test loss: 2.4577
[2023-06-25 03:38:27,087] cal loss: 108.5017
[2023-06-25 03:38:27,087] cal percent loss: 0.4255
[2023-06-25 03:38:27,087] mass loss: 60.5549
[2023-06-25 03:38:27,088] mass percent loss: 0.2778
[2023-06-25 03:38:27,088] fat loss: 8.2029
[2023-06-25 03:38:27,088] fat percent loss: 0.6459
[2023-06-25 03:38:27,088] carb loss: 10.7233
[2023-06-25 03:38:27,088] carb percent loss: 0.5556
[2023-06-25 03:38:27,088] protein loss: 10.1457
[2023-06-25 03:38:27,088] protein percent loss: 0.5605
[2023-06-25 03:38:27,088] Epoch 11/150
[2023-06-25 03:40:57,293] train loss: 2.5058
[2023-06-25 03:40:57,294] cal loss: 112.8265
[2023-06-25 03:40:57,294] cal percent loss: 0.4425
[2023-06-25 03:40:57,294] mass loss: 69.4844
[2023-06-25 03:40:57,294] mass percent loss: 0.3187
[2023-06-25 03:40:57,294] fat loss: 7.8677
[2023-06-25 03:40:57,295] fat percent loss: 0.6195
[2023-06-25 03:40:57,295] carb loss: 10.3994
[2023-06-25 03:40:57,295] carb percent loss: 0.5388
[2023-06-25 03:40:57,295] protein loss: 10.4142
[2023-06-25 03:40:57,295] protein percent loss: 0.5754
[2023-06-25 03:40:57,295] Epoch 11/150
[2023-06-25 03:41:24,052] test loss: 2.6394
[2023-06-25 03:41:24,052] cal loss: 116.6401
[2023-06-25 03:41:24,053] cal percent loss: 0.4574
[2023-06-25 03:41:24,053] mass loss: 60.6188
[2023-06-25 03:41:24,053] mass percent loss: 0.2781
[2023-06-25 03:41:24,053] fat loss: 9.2092
[2023-06-25 03:41:24,053] fat percent loss: 0.7251
[2023-06-25 03:41:24,053] carb loss: 11.4226
[2023-06-25 03:41:24,053] carb percent loss: 0.5918
[2023-06-25 03:41:24,053] protein loss: 10.9131
[2023-06-25 03:41:24,053] protein percent loss: 0.6029
[2023-06-25 03:41:24,054] Epoch 12/150
[2023-06-25 03:43:57,474] train loss: 2.4465
[2023-06-25 03:43:57,474] cal loss: 109.5031
[2023-06-25 03:43:57,474] cal percent loss: 0.4294
[2023-06-25 03:43:57,474] mass loss: 65.5740
[2023-06-25 03:43:57,474] mass percent loss: 0.3008
[2023-06-25 03:43:57,475] fat loss: 7.9417
[2023-06-25 03:43:57,475] fat percent loss: 0.6253
[2023-06-25 03:43:57,475] carb loss: 10.0310
[2023-06-25 03:43:57,475] carb percent loss: 0.5197
[2023-06-25 03:43:57,475] protein loss: 10.2254
[2023-06-25 03:43:57,475] protein percent loss: 0.5649
[2023-06-25 03:43:57,475] Epoch 12/150
[2023-06-25 03:44:22,070] test loss: 3.5401
[2023-06-25 03:44:22,071] cal loss: 150.5429
[2023-06-25 03:44:22,071] cal percent loss: 0.5904
[2023-06-25 03:44:22,071] mass loss: 152.3354
[2023-06-25 03:44:22,071] mass percent loss: 0.6988
[2023-06-25 03:44:22,072] fat loss: 8.6601
[2023-06-25 03:44:22,072] fat percent loss: 0.6819
[2023-06-25 03:44:22,072] carb loss: 11.1296
[2023-06-25 03:44:22,072] carb percent loss: 0.5767
[2023-06-25 03:44:22,072] protein loss: 15.7362
[2023-06-25 03:44:22,072] protein percent loss: 0.8694
[2023-06-25 03:44:22,072] Epoch 13/150
[2023-06-25 03:46:58,869] train loss: 2.4893
[2023-06-25 03:46:58,869] cal loss: 112.3449
[2023-06-25 03:46:58,869] cal percent loss: 0.4406
[2023-06-25 03:46:58,869] mass loss: 68.3998
[2023-06-25 03:46:58,870] mass percent loss: 0.3138
[2023-06-25 03:46:58,870] fat loss: 7.8918
[2023-06-25 03:46:58,870] fat percent loss: 0.6214
[2023-06-25 03:46:58,870] carb loss: 10.1766
[2023-06-25 03:46:58,870] carb percent loss: 0.5273
[2023-06-25 03:46:58,870] protein loss: 10.4241
[2023-06-25 03:46:58,870] protein percent loss: 0.5759
[2023-06-25 03:46:58,870] Epoch 13/150
[2023-06-25 03:47:23,286] test loss: 2.5012
[2023-06-25 03:47:23,287] cal loss: 105.4027
[2023-06-25 03:47:23,287] cal percent loss: 0.4133
[2023-06-25 03:47:23,287] mass loss: 68.4355
[2023-06-25 03:47:23,288] mass percent loss: 0.3139
[2023-06-25 03:47:23,288] fat loss: 8.3415
[2023-06-25 03:47:23,288] fat percent loss: 0.6568
[2023-06-25 03:47:23,288] carb loss: 10.1931
[2023-06-25 03:47:23,288] carb percent loss: 0.5281
[2023-06-25 03:47:23,288] protein loss: 10.6009
[2023-06-25 03:47:23,288] protein percent loss: 0.5857
[2023-06-25 03:47:23,288] Epoch 14/150
[2023-06-25 03:49:59,859] train loss: 2.4042
[2023-06-25 03:49:59,860] cal loss: 109.0067
[2023-06-25 03:49:59,860] cal percent loss: 0.4275
[2023-06-25 03:49:59,860] mass loss: 62.8273
[2023-06-25 03:49:59,860] mass percent loss: 0.2882
[2023-06-25 03:49:59,860] fat loss: 7.7816
[2023-06-25 03:49:59,861] fat percent loss: 0.6127
[2023-06-25 03:49:59,861] carb loss: 9.9100
[2023-06-25 03:49:59,861] carb percent loss: 0.5135
[2023-06-25 03:49:59,861] protein loss: 10.1072
[2023-06-25 03:49:59,861] protein percent loss: 0.5584
[2023-06-25 03:49:59,861] Epoch 14/150
[2023-06-25 03:50:24,100] test loss: 2.5458
[2023-06-25 03:50:24,101] cal loss: 117.2591
[2023-06-25 03:50:24,101] cal percent loss: 0.4598
[2023-06-25 03:50:24,101] mass loss: 57.1186
[2023-06-25 03:50:24,101] mass percent loss: 0.2620
[2023-06-25 03:50:24,101] fat loss: 8.9227
[2023-06-25 03:50:24,101] fat percent loss: 0.7026
[2023-06-25 03:50:24,101] carb loss: 9.9694
[2023-06-25 03:50:24,101] carb percent loss: 0.5165
[2023-06-25 03:50:24,101] protein loss: 11.1469
[2023-06-25 03:50:24,102] protein percent loss: 0.6159
[2023-06-25 03:50:24,102] Epoch 15/150
[2023-06-25 03:52:53,731] train loss: 2.3875
[2023-06-25 03:52:53,731] cal loss: 107.3900
[2023-06-25 03:52:53,731] cal percent loss: 0.4211
[2023-06-25 03:52:53,732] mass loss: 63.6315
[2023-06-25 03:52:53,732] mass percent loss: 0.2919
[2023-06-25 03:52:53,732] fat loss: 7.8349
[2023-06-25 03:52:53,732] fat percent loss: 0.6169
[2023-06-25 03:52:53,732] carb loss: 9.6488
[2023-06-25 03:52:53,733] carb percent loss: 0.4999
[2023-06-25 03:52:53,733] protein loss: 9.9758
[2023-06-25 03:52:53,733] protein percent loss: 0.5512
[2023-06-25 03:52:53,733] Epoch 15/150
[2023-06-25 03:53:19,207] test loss: 2.9622
[2023-06-25 03:53:19,208] cal loss: 169.5164
[2023-06-25 03:53:19,208] cal percent loss: 0.6648
[2023-06-25 03:53:19,208] mass loss: 63.3638
[2023-06-25 03:53:19,209] mass percent loss: 0.2907
[2023-06-25 03:53:19,209] fat loss: 9.5380
[2023-06-25 03:53:19,209] fat percent loss: 0.7510
[2023-06-25 03:53:19,209] carb loss: 11.5749
[2023-06-25 03:53:19,209] carb percent loss: 0.5997
[2023-06-25 03:53:19,209] protein loss: 11.6260
[2023-06-25 03:53:19,210] protein percent loss: 0.6423
[2023-06-25 03:53:19,210] Epoch 16/150
[2023-06-25 03:55:09,130] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 03:55:09,935] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 03:55:12,984] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,001] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,001] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,026] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,026] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,049] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,052] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,081] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,081] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,102] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,102] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,140] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,140] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,148] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,149] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,185] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,186] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,201] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,201] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,237] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,237] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,265] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,265] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,272] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,273] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,275] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,275] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,282] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,282] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,289] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,289] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,291] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,291] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,297] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,298] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,304] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,304] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,306] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,306] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,312] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,312] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,318] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,318] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,320] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,320] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,326] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,326] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,332] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,332] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,334] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,334] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,340] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,340] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,346] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,346] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,348] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,348] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,354] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,354] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,360] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,360] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,362] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,362] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,368] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,368] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,374] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,375] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,376] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,376] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,382] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:13,382] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 03:55:13,388] => init bias of Linear/Conv2d to zeros
[2023-06-25 03:55:14,114] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 03:55:14,115] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,116] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,116] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,117] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,117] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,118] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,119] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 03:55:14,120] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,120] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:55:14,120] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:55:14,120] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,121] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,121] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,122] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,122] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 03:55:14,122] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,122] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 03:55:14,122] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,122] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,122] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,122] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,122] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 03:55:14,122] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,122] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,123] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,124] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,125] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,126] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,127] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,128] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,129] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,130] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,131] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,132] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,133] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,134] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,135] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,136] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,137] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,138] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,139] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,140] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,141] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,142] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,143] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,144] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,145] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,147] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,148] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,149] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,150] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,151] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,152] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 03:55:14,153] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 03:55:14,154] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 03:55:14,154] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 03:55:14,154] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:55:14,154] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 03:55:16,126] Epoch 1/150
[2023-06-25 03:57:44,428] train loss: 3.6573
[2023-06-25 03:57:44,429] cal loss: 169.9856
[2023-06-25 03:57:44,429] cal percent loss: 0.6666
[2023-06-25 03:57:44,429] mass loss: 123.4016
[2023-06-25 03:57:44,429] mass percent loss: 0.5661
[2023-06-25 03:57:44,430] fat loss: 10.3187
[2023-06-25 03:57:44,430] fat percent loss: 0.8125
[2023-06-25 03:57:44,430] carb loss: 12.4530
[2023-06-25 03:57:44,430] carb percent loss: 0.6452
[2023-06-25 03:57:44,430] protein loss: 16.2123
[2023-06-25 03:57:44,430] protein percent loss: 0.8957
[2023-06-25 03:57:44,430] Epoch 1/150
[2023-06-25 03:58:10,652] test loss: 3.6922
[2023-06-25 03:58:10,653] cal loss: 168.9193
[2023-06-25 03:58:10,653] cal percent loss: 0.6624
[2023-06-25 03:58:10,653] mass loss: 120.8865
[2023-06-25 03:58:10,654] mass percent loss: 0.5545
[2023-06-25 03:58:10,654] fat loss: 10.7350
[2023-06-25 03:58:10,654] fat percent loss: 0.8453
[2023-06-25 03:58:10,654] carb loss: 13.4293
[2023-06-25 03:58:10,654] carb percent loss: 0.6958
[2023-06-25 03:58:10,654] protein loss: 15.8142
[2023-06-25 03:58:10,654] protein percent loss: 0.8737
[2023-06-25 03:58:10,654] Epoch 2/150
[2023-06-25 04:00:42,635] train loss: 3.1114
[2023-06-25 04:00:42,635] cal loss: 142.8415
[2023-06-25 04:00:42,635] cal percent loss: 0.5602
[2023-06-25 04:00:42,635] mass loss: 100.4396
[2023-06-25 04:00:42,635] mass percent loss: 0.4607
[2023-06-25 04:00:42,635] fat loss: 8.9739
[2023-06-25 04:00:42,635] fat percent loss: 0.7066
[2023-06-25 04:00:42,636] carb loss: 11.7431
[2023-06-25 04:00:42,636] carb percent loss: 0.6085
[2023-06-25 04:00:42,636] protein loss: 13.1814
[2023-06-25 04:00:42,636] protein percent loss: 0.7283
[2023-06-25 04:00:42,636] Epoch 2/150
[2023-06-25 04:01:05,682] test loss: 2.7746
[2023-06-25 04:01:05,683] cal loss: 123.3669
[2023-06-25 04:01:05,683] cal percent loss: 0.4838
[2023-06-25 04:01:05,683] mass loss: 76.0126
[2023-06-25 04:01:05,684] mass percent loss: 0.3487
[2023-06-25 04:01:05,684] fat loss: 8.6097
[2023-06-25 04:01:05,684] fat percent loss: 0.6779
[2023-06-25 04:01:05,684] carb loss: 11.7924
[2023-06-25 04:01:05,684] carb percent loss: 0.6110
[2023-06-25 04:01:05,685] protein loss: 11.6912
[2023-06-25 04:01:05,685] protein percent loss: 0.6459
[2023-06-25 04:01:05,685] Epoch 3/150
[2023-06-25 04:03:37,699] train loss: 2.4761
[2023-06-25 04:03:37,699] cal loss: 109.8999
[2023-06-25 04:03:37,700] cal percent loss: 0.4310
[2023-06-25 04:03:37,700] mass loss: 72.1774
[2023-06-25 04:03:37,700] mass percent loss: 0.3311
[2023-06-25 04:03:37,700] fat loss: 7.5962
[2023-06-25 04:03:37,700] fat percent loss: 0.5981
[2023-06-25 04:03:37,700] carb loss: 10.3891
[2023-06-25 04:03:37,700] carb percent loss: 0.5383
[2023-06-25 04:03:37,700] protein loss: 10.1653
[2023-06-25 04:03:37,700] protein percent loss: 0.5616
[2023-06-25 04:03:37,700] Epoch 3/150
[2023-06-25 04:04:02,734] test loss: 2.3010
[2023-06-25 04:04:02,735] cal loss: 97.1752
[2023-06-25 04:04:02,735] cal percent loss: 0.3811
[2023-06-25 04:04:02,735] mass loss: 58.7501
[2023-06-25 04:04:02,736] mass percent loss: 0.2695
[2023-06-25 04:04:02,736] fat loss: 7.7024
[2023-06-25 04:04:02,736] fat percent loss: 0.6065
[2023-06-25 04:04:02,736] carb loss: 9.9632
[2023-06-25 04:04:02,736] carb percent loss: 0.5162
[2023-06-25 04:04:02,736] protein loss: 9.6824
[2023-06-25 04:04:02,736] protein percent loss: 0.5349
[2023-06-25 04:04:02,736] Epoch 4/150
[2023-06-25 04:06:34,732] train loss: 2.1582
[2023-06-25 04:06:34,733] cal loss: 91.9947
[2023-06-25 04:06:34,733] cal percent loss: 0.3608
[2023-06-25 04:06:34,733] mass loss: 61.1245
[2023-06-25 04:06:34,733] mass percent loss: 0.2804
[2023-06-25 04:06:34,734] fat loss: 6.9509
[2023-06-25 04:06:34,734] fat percent loss: 0.5473
[2023-06-25 04:06:34,734] carb loss: 9.2773
[2023-06-25 04:06:34,734] carb percent loss: 0.4807
[2023-06-25 04:06:34,734] protein loss: 8.7295
[2023-06-25 04:06:34,734] protein percent loss: 0.4823
[2023-06-25 04:06:34,734] Epoch 4/150
[2023-06-25 04:07:03,338] test loss: 2.1690
[2023-06-25 04:07:03,339] cal loss: 92.3172
[2023-06-25 04:07:03,339] cal percent loss: 0.3620
[2023-06-25 04:07:03,339] mass loss: 58.3080
[2023-06-25 04:07:03,339] mass percent loss: 0.2675
[2023-06-25 04:07:03,339] fat loss: 7.0174
[2023-06-25 04:07:03,339] fat percent loss: 0.5525
[2023-06-25 04:07:03,339] carb loss: 10.3004
[2023-06-25 04:07:03,339] carb percent loss: 0.5337
[2023-06-25 04:07:03,339] protein loss: 8.2414
[2023-06-25 04:07:03,339] protein percent loss: 0.4553
[2023-06-25 04:07:03,340] Epoch 5/150
[2023-06-25 04:09:34,132] train loss: 2.0182
[2023-06-25 04:09:34,133] cal loss: 86.7081
[2023-06-25 04:09:34,133] cal percent loss: 0.3400
[2023-06-25 04:09:34,133] mass loss: 54.9667
[2023-06-25 04:09:34,134] mass percent loss: 0.2521
[2023-06-25 04:09:34,134] fat loss: 6.6268
[2023-06-25 04:09:34,134] fat percent loss: 0.5218
[2023-06-25 04:09:34,134] carb loss: 8.8966
[2023-06-25 04:09:34,134] carb percent loss: 0.4610
[2023-06-25 04:09:34,134] protein loss: 7.9813
[2023-06-25 04:09:34,134] protein percent loss: 0.4410
[2023-06-25 04:09:34,134] Epoch 5/150
[2023-06-25 04:10:01,587] test loss: 2.0166
[2023-06-25 04:10:01,587] cal loss: 91.1560
[2023-06-25 04:10:01,588] cal percent loss: 0.3575
[2023-06-25 04:10:01,588] mass loss: 45.3061
[2023-06-25 04:10:01,588] mass percent loss: 0.2078
[2023-06-25 04:10:01,588] fat loss: 7.3454
[2023-06-25 04:10:01,588] fat percent loss: 0.5784
[2023-06-25 04:10:01,588] carb loss: 8.3091
[2023-06-25 04:10:01,588] carb percent loss: 0.4305
[2023-06-25 04:10:01,588] protein loss: 8.1892
[2023-06-25 04:10:01,589] protein percent loss: 0.4524
[2023-06-25 04:10:01,589] Epoch 6/150
[2023-06-25 04:12:27,936] train loss: 1.8656
[2023-06-25 04:12:27,936] cal loss: 80.5904
[2023-06-25 04:12:27,937] cal percent loss: 0.3160
[2023-06-25 04:12:27,937] mass loss: 48.5683
[2023-06-25 04:12:27,937] mass percent loss: 0.2228
[2023-06-25 04:12:27,937] fat loss: 6.1940
[2023-06-25 04:12:27,937] fat percent loss: 0.4877
[2023-06-25 04:12:27,937] carb loss: 8.0856
[2023-06-25 04:12:27,937] carb percent loss: 0.4189
[2023-06-25 04:12:27,937] protein loss: 7.6392
[2023-06-25 04:12:27,937] protein percent loss: 0.4221
[2023-06-25 04:12:27,938] Epoch 6/150
[2023-06-25 04:12:52,372] test loss: 2.2420
[2023-06-25 04:12:52,373] cal loss: 90.8059
[2023-06-25 04:12:52,373] cal percent loss: 0.3561
[2023-06-25 04:12:52,373] mass loss: 66.5043
[2023-06-25 04:12:52,373] mass percent loss: 0.3051
[2023-06-25 04:12:52,373] fat loss: 7.1441
[2023-06-25 04:12:52,373] fat percent loss: 0.5625
[2023-06-25 04:12:52,374] carb loss: 8.0895
[2023-06-25 04:12:52,374] carb percent loss: 0.4191
[2023-06-25 04:12:52,374] protein loss: 10.6498
[2023-06-25 04:12:52,374] protein percent loss: 0.5884
[2023-06-25 04:12:52,374] Epoch 7/150
[2023-06-25 04:15:20,141] train loss: 1.8203
[2023-06-25 04:15:20,142] cal loss: 78.2310
[2023-06-25 04:15:20,142] cal percent loss: 0.3068
[2023-06-25 04:15:20,142] mass loss: 49.2772
[2023-06-25 04:15:20,143] mass percent loss: 0.2260
[2023-06-25 04:15:20,143] fat loss: 5.8672
[2023-06-25 04:15:20,143] fat percent loss: 0.4620
[2023-06-25 04:15:20,143] carb loss: 7.9846
[2023-06-25 04:15:20,143] carb percent loss: 0.4137
[2023-06-25 04:15:20,143] protein loss: 7.4351
[2023-06-25 04:15:20,143] protein percent loss: 0.4108
[2023-06-25 04:15:20,143] Epoch 7/150
[2023-06-25 04:15:45,140] test loss: 2.2302
[2023-06-25 04:15:45,141] cal loss: 117.9905
[2023-06-25 04:15:45,142] cal percent loss: 0.4627
[2023-06-25 04:15:45,142] mass loss: 42.4954
[2023-06-25 04:15:45,142] mass percent loss: 0.1949
[2023-06-25 04:15:45,142] fat loss: 6.9983
[2023-06-25 04:15:45,142] fat percent loss: 0.5511
[2023-06-25 04:15:45,142] carb loss: 7.7711
[2023-06-25 04:15:45,142] carb percent loss: 0.4026
[2023-06-25 04:15:45,142] protein loss: 11.4107
[2023-06-25 04:15:45,143] protein percent loss: 0.6304
[2023-06-25 04:15:45,143] Epoch 8/150
[2023-06-25 04:18:20,305] train loss: 1.7433
[2023-06-25 04:18:20,306] cal loss: 75.2630
[2023-06-25 04:18:20,307] cal percent loss: 0.2951
[2023-06-25 04:18:20,307] mass loss: 44.3041
[2023-06-25 04:18:20,308] mass percent loss: 0.2032
[2023-06-25 04:18:20,308] fat loss: 5.7772
[2023-06-25 04:18:20,309] fat percent loss: 0.4549
[2023-06-25 04:18:20,309] carb loss: 7.3597
[2023-06-25 04:18:20,310] carb percent loss: 0.3813
[2023-06-25 04:18:20,311] protein loss: 7.4704
[2023-06-25 04:18:20,311] protein percent loss: 0.4127
[2023-06-25 04:18:20,312] Epoch 8/150
[2023-06-25 04:18:45,002] test loss: 1.6157
[2023-06-25 04:18:45,003] cal loss: 62.9910
[2023-06-25 04:18:45,003] cal percent loss: 0.2470
[2023-06-25 04:18:45,003] mass loss: 43.3673
[2023-06-25 04:18:45,003] mass percent loss: 0.1989
[2023-06-25 04:18:45,003] fat loss: 5.3673
[2023-06-25 04:18:45,004] fat percent loss: 0.4226
[2023-06-25 04:18:45,004] carb loss: 7.6607
[2023-06-25 04:18:45,004] carb percent loss: 0.3969
[2023-06-25 04:18:45,004] protein loss: 6.4750
[2023-06-25 04:18:45,004] protein percent loss: 0.3577
[2023-06-25 04:18:45,005] Epoch 9/150
[2023-06-25 04:21:13,095] train loss: 1.6316
[2023-06-25 04:21:13,095] cal loss: 70.5183
[2023-06-25 04:21:13,095] cal percent loss: 0.2765
[2023-06-25 04:21:13,096] mass loss: 42.4680
[2023-06-25 04:21:13,096] mass percent loss: 0.1948
[2023-06-25 04:21:13,096] fat loss: 5.4320
[2023-06-25 04:21:13,096] fat percent loss: 0.4277
[2023-06-25 04:21:13,096] carb loss: 7.0168
[2023-06-25 04:21:13,096] carb percent loss: 0.3636
[2023-06-25 04:21:13,096] protein loss: 6.7060
[2023-06-25 04:21:13,096] protein percent loss: 0.3705
[2023-06-25 04:21:13,096] Epoch 9/150
[2023-06-25 04:21:38,655] test loss: 1.8009
[2023-06-25 04:21:38,656] cal loss: 81.3458
[2023-06-25 04:21:38,656] cal percent loss: 0.3190
[2023-06-25 04:21:38,656] mass loss: 53.8306
[2023-06-25 04:21:38,656] mass percent loss: 0.2469
[2023-06-25 04:21:38,656] fat loss: 4.7416
[2023-06-25 04:21:38,656] fat percent loss: 0.3734
[2023-06-25 04:21:38,656] carb loss: 8.8861
[2023-06-25 04:21:38,656] carb percent loss: 0.4604
[2023-06-25 04:21:38,656] protein loss: 7.0746
[2023-06-25 04:21:38,656] protein percent loss: 0.3909
[2023-06-25 04:21:38,657] Epoch 10/150
[2023-06-25 04:24:10,182] train loss: 1.6170
[2023-06-25 04:24:10,183] cal loss: 71.5917
[2023-06-25 04:24:10,183] cal percent loss: 0.2808
[2023-06-25 04:24:10,183] mass loss: 41.7416
[2023-06-25 04:24:10,183] mass percent loss: 0.1915
[2023-06-25 04:24:10,183] fat loss: 5.2138
[2023-06-25 04:24:10,183] fat percent loss: 0.4105
[2023-06-25 04:24:10,184] carb loss: 6.9779
[2023-06-25 04:24:10,184] carb percent loss: 0.3616
[2023-06-25 04:24:10,184] protein loss: 6.7673
[2023-06-25 04:24:10,184] protein percent loss: 0.3739
[2023-06-25 04:24:10,184] Epoch 10/150
[2023-06-25 04:24:34,944] test loss: 1.6845
[2023-06-25 04:24:34,945] cal loss: 78.4732
[2023-06-25 04:24:34,945] cal percent loss: 0.3077
[2023-06-25 04:24:34,945] mass loss: 39.9483
[2023-06-25 04:24:34,945] mass percent loss: 0.1832
[2023-06-25 04:24:34,945] fat loss: 5.1135
[2023-06-25 04:24:34,945] fat percent loss: 0.4026
[2023-06-25 04:24:34,946] carb loss: 7.7165
[2023-06-25 04:24:34,946] carb percent loss: 0.3998
[2023-06-25 04:24:34,946] protein loss: 7.2059
[2023-06-25 04:24:34,946] protein percent loss: 0.3981
[2023-06-25 04:24:34,946] Epoch 11/150
[2023-06-25 04:27:02,567] train loss: 1.5803
[2023-06-25 04:27:02,567] cal loss: 66.9974
[2023-06-25 04:27:02,568] cal percent loss: 0.2627
[2023-06-25 04:27:02,568] mass loss: 41.1448
[2023-06-25 04:27:02,568] mass percent loss: 0.1887
[2023-06-25 04:27:02,568] fat loss: 5.1565
[2023-06-25 04:27:02,568] fat percent loss: 0.4060
[2023-06-25 04:27:02,568] carb loss: 6.9960
[2023-06-25 04:27:02,568] carb percent loss: 0.3625
[2023-06-25 04:27:02,568] protein loss: 6.5885
[2023-06-25 04:27:02,568] protein percent loss: 0.3640
[2023-06-25 04:27:02,568] Epoch 11/150
[2023-06-25 04:27:28,714] test loss: 1.6706
[2023-06-25 04:27:28,715] cal loss: 70.7117
[2023-06-25 04:27:28,715] cal percent loss: 0.2773
[2023-06-25 04:27:28,715] mass loss: 47.9173
[2023-06-25 04:27:28,715] mass percent loss: 0.2198
[2023-06-25 04:27:28,715] fat loss: 5.3074
[2023-06-25 04:27:28,716] fat percent loss: 0.4179
[2023-06-25 04:27:28,716] carb loss: 7.1290
[2023-06-25 04:27:28,716] carb percent loss: 0.3694
[2023-06-25 04:27:28,716] protein loss: 6.8862
[2023-06-25 04:27:28,716] protein percent loss: 0.3805
[2023-06-25 04:27:28,716] Epoch 12/150
[2023-06-25 04:30:00,596] train loss: 1.6093
[2023-06-25 04:30:00,597] cal loss: 69.9927
[2023-06-25 04:30:00,597] cal percent loss: 0.2745
[2023-06-25 04:30:00,597] mass loss: 43.8176
[2023-06-25 04:30:00,597] mass percent loss: 0.2010
[2023-06-25 04:30:00,597] fat loss: 5.0767
[2023-06-25 04:30:00,597] fat percent loss: 0.3997
[2023-06-25 04:30:00,598] carb loss: 6.8580
[2023-06-25 04:30:00,598] carb percent loss: 0.3553
[2023-06-25 04:30:00,598] protein loss: 6.8159
[2023-06-25 04:30:00,598] protein percent loss: 0.3766
[2023-06-25 04:30:00,598] Epoch 12/150
[2023-06-25 04:30:24,992] test loss: 1.7777
[2023-06-25 04:30:24,993] cal loss: 55.7136
[2023-06-25 04:30:24,993] cal percent loss: 0.2185
[2023-06-25 04:30:24,993] mass loss: 74.7750
[2023-06-25 04:30:24,993] mass percent loss: 0.3430
[2023-06-25 04:30:24,993] fat loss: 4.6060
[2023-06-25 04:30:24,993] fat percent loss: 0.3627
[2023-06-25 04:30:24,994] carb loss: 7.0102
[2023-06-25 04:30:24,994] carb percent loss: 0.3632
[2023-06-25 04:30:24,994] protein loss: 8.2573
[2023-06-25 04:30:24,994] protein percent loss: 0.4562
[2023-06-25 04:30:24,994] Epoch 13/150
[2023-06-25 04:33:00,120] train loss: 1.5603
[2023-06-25 04:33:00,120] cal loss: 66.8144
[2023-06-25 04:33:00,120] cal percent loss: 0.2620
[2023-06-25 04:33:00,120] mass loss: 40.2326
[2023-06-25 04:33:00,120] mass percent loss: 0.1846
[2023-06-25 04:33:00,120] fat loss: 5.2657
[2023-06-25 04:33:00,121] fat percent loss: 0.4146
[2023-06-25 04:33:00,121] carb loss: 6.7037
[2023-06-25 04:33:00,121] carb percent loss: 0.3473
[2023-06-25 04:33:00,121] protein loss: 6.4150
[2023-06-25 04:33:00,121] protein percent loss: 0.3544
[2023-06-25 04:33:00,121] Epoch 13/150
[2023-06-25 04:33:24,001] test loss: 1.4681
[2023-06-25 04:33:24,002] cal loss: 62.8810
[2023-06-25 04:33:24,002] cal percent loss: 0.2466
[2023-06-25 04:33:24,002] mass loss: 35.1153
[2023-06-25 04:33:24,002] mass percent loss: 0.1611
[2023-06-25 04:33:24,002] fat loss: 4.5832
[2023-06-25 04:33:24,002] fat percent loss: 0.3609
[2023-06-25 04:33:24,002] carb loss: 7.0606
[2023-06-25 04:33:24,002] carb percent loss: 0.3658
[2023-06-25 04:33:24,003] protein loss: 6.2513
[2023-06-25 04:33:24,003] protein percent loss: 0.3454
[2023-06-25 04:33:24,003] Epoch 14/150
[2023-06-25 04:35:58,528] train loss: 1.4807
[2023-06-25 04:35:58,529] cal loss: 63.0439
[2023-06-25 04:35:58,529] cal percent loss: 0.2472
[2023-06-25 04:35:58,529] mass loss: 37.7909
[2023-06-25 04:35:58,529] mass percent loss: 0.1734
[2023-06-25 04:35:58,529] fat loss: 4.8056
[2023-06-25 04:35:58,529] fat percent loss: 0.3784
[2023-06-25 04:35:58,530] carb loss: 6.5741
[2023-06-25 04:35:58,530] carb percent loss: 0.3406
[2023-06-25 04:35:58,530] protein loss: 6.2660
[2023-06-25 04:35:58,530] protein percent loss: 0.3462
[2023-06-25 04:35:58,530] Epoch 14/150
[2023-06-25 04:36:22,402] test loss: 1.8818
[2023-06-25 04:36:22,403] cal loss: 82.0541
[2023-06-25 04:36:22,403] cal percent loss: 0.3218
[2023-06-25 04:36:22,403] mass loss: 67.7751
[2023-06-25 04:36:22,403] mass percent loss: 0.3109
[2023-06-25 04:36:22,404] fat loss: 5.2055
[2023-06-25 04:36:22,404] fat percent loss: 0.4099
[2023-06-25 04:36:22,404] carb loss: 7.2975
[2023-06-25 04:36:22,404] carb percent loss: 0.3781
[2023-06-25 04:36:22,404] protein loss: 7.6550
[2023-06-25 04:36:22,404] protein percent loss: 0.4229
[2023-06-25 04:36:22,404] Epoch 15/150
[2023-06-25 04:38:49,806] train loss: 1.5611
[2023-06-25 04:38:49,807] cal loss: 67.0618
[2023-06-25 04:38:49,807] cal percent loss: 0.2630
[2023-06-25 04:38:49,807] mass loss: 40.6704
[2023-06-25 04:38:49,807] mass percent loss: 0.1866
[2023-06-25 04:38:49,807] fat loss: 5.2451
[2023-06-25 04:38:49,807] fat percent loss: 0.4130
[2023-06-25 04:38:49,807] carb loss: 6.5836
[2023-06-25 04:38:49,807] carb percent loss: 0.3411
[2023-06-25 04:38:49,807] protein loss: 6.4935
[2023-06-25 04:38:49,807] protein percent loss: 0.3588
[2023-06-25 04:38:49,808] Epoch 15/150
[2023-06-25 04:39:14,737] test loss: 1.6692
[2023-06-25 04:39:14,738] cal loss: 75.8990
[2023-06-25 04:39:14,738] cal percent loss: 0.2976
[2023-06-25 04:39:14,738] mass loss: 39.8374
[2023-06-25 04:39:14,738] mass percent loss: 0.1827
[2023-06-25 04:39:14,738] fat loss: 5.4659
[2023-06-25 04:39:14,738] fat percent loss: 0.4304
[2023-06-25 04:39:14,738] carb loss: 7.2737
[2023-06-25 04:39:14,738] carb percent loss: 0.3769
[2023-06-25 04:39:14,738] protein loss: 7.0157
[2023-06-25 04:39:14,738] protein percent loss: 0.3876
[2023-06-25 04:39:14,738] Epoch 16/150
[2023-06-25 04:41:47,223] train loss: 1.4520
[2023-06-25 04:41:47,224] cal loss: 63.7725
[2023-06-25 04:41:47,224] cal percent loss: 0.2501
[2023-06-25 04:41:47,224] mass loss: 36.8312
[2023-06-25 04:41:47,224] mass percent loss: 0.1690
[2023-06-25 04:41:47,225] fat loss: 4.8035
[2023-06-25 04:41:47,225] fat percent loss: 0.3782
[2023-06-25 04:41:47,225] carb loss: 6.1611
[2023-06-25 04:41:47,225] carb percent loss: 0.3192
[2023-06-25 04:41:47,225] protein loss: 6.1144
[2023-06-25 04:41:47,225] protein percent loss: 0.3378
[2023-06-25 04:41:47,225] Epoch 16/150
[2023-06-25 04:42:12,907] test loss: 1.7680
[2023-06-25 04:42:12,908] cal loss: 92.6630
[2023-06-25 04:42:12,908] cal percent loss: 0.3634
[2023-06-25 04:42:12,908] mass loss: 40.2035
[2023-06-25 04:42:12,908] mass percent loss: 0.1844
[2023-06-25 04:42:12,908] fat loss: 5.5511
[2023-06-25 04:42:12,908] fat percent loss: 0.4371
[2023-06-25 04:42:12,908] carb loss: 7.3141
[2023-06-25 04:42:12,909] carb percent loss: 0.3790
[2023-06-25 04:42:12,909] protein loss: 7.2685
[2023-06-25 04:42:12,909] protein percent loss: 0.4016
[2023-06-25 04:42:12,909] Epoch 17/150
[2023-06-25 04:44:46,244] train loss: 1.5195
[2023-06-25 04:44:46,246] cal loss: 66.3934
[2023-06-25 04:44:46,247] cal percent loss: 0.2604
[2023-06-25 04:44:46,247] mass loss: 40.7299
[2023-06-25 04:44:46,247] mass percent loss: 0.1868
[2023-06-25 04:44:46,247] fat loss: 4.7809
[2023-06-25 04:44:46,248] fat percent loss: 0.3764
[2023-06-25 04:44:46,248] carb loss: 6.5486
[2023-06-25 04:44:46,248] carb percent loss: 0.3393
[2023-06-25 04:44:46,248] protein loss: 6.4394
[2023-06-25 04:44:46,248] protein percent loss: 0.3558
[2023-06-25 04:44:46,248] Epoch 17/150
[2023-06-25 04:45:10,909] test loss: 2.1107
[2023-06-25 04:45:10,910] cal loss: 100.8868
[2023-06-25 04:45:10,910] cal percent loss: 0.3956
[2023-06-25 04:45:10,910] mass loss: 70.8304
[2023-06-25 04:45:10,910] mass percent loss: 0.3249
[2023-06-25 04:45:10,910] fat loss: 5.8221
[2023-06-25 04:45:10,910] fat percent loss: 0.4584
[2023-06-25 04:45:10,910] carb loss: 8.5922
[2023-06-25 04:45:10,910] carb percent loss: 0.4452
[2023-06-25 04:45:10,910] protein loss: 8.0775
[2023-06-25 04:45:10,910] protein percent loss: 0.4463
[2023-06-25 04:45:10,910] Epoch 18/150
[2023-06-25 04:47:46,215] train loss: 1.4678
[2023-06-25 04:47:46,215] cal loss: 64.2034
[2023-06-25 04:47:46,215] cal percent loss: 0.2518
[2023-06-25 04:47:46,215] mass loss: 40.7208
[2023-06-25 04:47:46,215] mass percent loss: 0.1868
[2023-06-25 04:47:46,216] fat loss: 4.6634
[2023-06-25 04:47:46,216] fat percent loss: 0.3672
[2023-06-25 04:47:46,216] carb loss: 6.2565
[2023-06-25 04:47:46,216] carb percent loss: 0.3242
[2023-06-25 04:47:46,216] protein loss: 6.0369
[2023-06-25 04:47:46,216] protein percent loss: 0.3335
[2023-06-25 04:47:46,216] Epoch 18/150
[2023-06-25 04:48:10,491] test loss: 1.5527
[2023-06-25 04:48:10,492] cal loss: 62.8229
[2023-06-25 04:48:10,492] cal percent loss: 0.2464
[2023-06-25 04:48:10,492] mass loss: 39.1236
[2023-06-25 04:48:10,492] mass percent loss: 0.1795
[2023-06-25 04:48:10,492] fat loss: 5.3020
[2023-06-25 04:48:10,492] fat percent loss: 0.4175
[2023-06-25 04:48:10,492] carb loss: 6.8960
[2023-06-25 04:48:10,492] carb percent loss: 0.3573
[2023-06-25 04:48:10,493] protein loss: 6.5348
[2023-06-25 04:48:10,493] protein percent loss: 0.3610
[2023-06-25 04:48:10,493] Epoch 19/150
[2023-06-25 04:50:36,492] train loss: 1.4984
[2023-06-25 04:50:36,493] cal loss: 65.5554
[2023-06-25 04:50:36,493] cal percent loss: 0.2571
[2023-06-25 04:50:36,493] mass loss: 40.2492
[2023-06-25 04:50:36,493] mass percent loss: 0.1846
[2023-06-25 04:50:36,493] fat loss: 5.0033
[2023-06-25 04:50:36,493] fat percent loss: 0.3940
[2023-06-25 04:50:36,493] carb loss: 6.1250
[2023-06-25 04:50:36,493] carb percent loss: 0.3174
[2023-06-25 04:50:36,493] protein loss: 6.1963
[2023-06-25 04:50:36,493] protein percent loss: 0.3423
[2023-06-25 04:50:36,494] Epoch 19/150
[2023-06-25 04:51:02,999] test loss: 1.6517
[2023-06-25 04:51:03,000] cal loss: 75.7359
[2023-06-25 04:51:03,000] cal percent loss: 0.2970
[2023-06-25 04:51:03,000] mass loss: 38.4813
[2023-06-25 04:51:03,000] mass percent loss: 0.1765
[2023-06-25 04:51:03,000] fat loss: 5.5760
[2023-06-25 04:51:03,001] fat percent loss: 0.4391
[2023-06-25 04:51:03,001] carb loss: 6.9826
[2023-06-25 04:51:03,001] carb percent loss: 0.3618
[2023-06-25 04:51:03,001] protein loss: 6.9427
[2023-06-25 04:51:03,001] protein percent loss: 0.3836
[2023-06-25 04:51:03,001] Epoch 20/150
[2023-06-25 04:53:35,354] train loss: 1.4087
[2023-06-25 04:53:35,355] cal loss: 60.3697
[2023-06-25 04:53:35,355] cal percent loss: 0.2367
[2023-06-25 04:53:35,355] mass loss: 38.6660
[2023-06-25 04:53:35,355] mass percent loss: 0.1774
[2023-06-25 04:53:35,356] fat loss: 4.6178
[2023-06-25 04:53:35,356] fat percent loss: 0.3636
[2023-06-25 04:53:35,356] carb loss: 5.9751
[2023-06-25 04:53:35,356] carb percent loss: 0.3096
[2023-06-25 04:53:35,356] protein loss: 5.7723
[2023-06-25 04:53:35,356] protein percent loss: 0.3189
[2023-06-25 04:53:35,356] Epoch 20/150
[2023-06-25 04:53:58,955] test loss: 1.3804
[2023-06-25 04:53:58,956] cal loss: 53.0776
[2023-06-25 04:53:58,956] cal percent loss: 0.2081
[2023-06-25 04:53:58,956] mass loss: 45.0929
[2023-06-25 04:53:58,956] mass percent loss: 0.2068
[2023-06-25 04:53:58,956] fat loss: 4.1301
[2023-06-25 04:53:58,956] fat percent loss: 0.3252
[2023-06-25 04:53:58,956] carb loss: 6.3816
[2023-06-25 04:53:58,956] carb percent loss: 0.3307
[2023-06-25 04:53:58,956] protein loss: 5.4383
[2023-06-25 04:53:58,956] protein percent loss: 0.3005
[2023-06-25 04:53:58,956] Epoch 21/150
[2023-06-25 04:56:31,557] train loss: 1.3827
[2023-06-25 04:56:31,558] cal loss: 58.0273
[2023-06-25 04:56:31,558] cal percent loss: 0.2276
[2023-06-25 04:56:31,558] mass loss: 38.1862
[2023-06-25 04:56:31,558] mass percent loss: 0.1752
[2023-06-25 04:56:31,558] fat loss: 4.5006
[2023-06-25 04:56:31,558] fat percent loss: 0.3544
[2023-06-25 04:56:31,558] carb loss: 5.9349
[2023-06-25 04:56:31,559] carb percent loss: 0.3075
[2023-06-25 04:56:31,559] protein loss: 5.7335
[2023-06-25 04:56:31,559] protein percent loss: 0.3168
[2023-06-25 04:56:31,559] Epoch 21/150
[2023-06-25 04:56:57,085] test loss: 1.6199
[2023-06-25 04:56:57,086] cal loss: 60.6597
[2023-06-25 04:56:57,086] cal percent loss: 0.2379
[2023-06-25 04:56:57,086] mass loss: 49.8075
[2023-06-25 04:56:57,086] mass percent loss: 0.2285
[2023-06-25 04:56:57,086] fat loss: 4.4557
[2023-06-25 04:56:57,087] fat percent loss: 0.3508
[2023-06-25 04:56:57,087] carb loss: 8.3781
[2023-06-25 04:56:57,087] carb percent loss: 0.4341
[2023-06-25 04:56:57,087] protein loss: 6.6991
[2023-06-25 04:56:57,087] protein percent loss: 0.3701
[2023-06-25 04:56:57,087] Epoch 22/150
[2023-06-25 04:59:32,454] train loss: 1.3284
[2023-06-25 04:59:32,455] cal loss: 58.1092
[2023-06-25 04:59:32,455] cal percent loss: 0.2279
[2023-06-25 04:59:32,455] mass loss: 34.3405
[2023-06-25 04:59:32,455] mass percent loss: 0.1575
[2023-06-25 04:59:32,456] fat loss: 4.3200
[2023-06-25 04:59:32,456] fat percent loss: 0.3402
[2023-06-25 04:59:32,456] carb loss: 5.7433
[2023-06-25 04:59:32,456] carb percent loss: 0.2976
[2023-06-25 04:59:32,456] protein loss: 5.5528
[2023-06-25 04:59:32,456] protein percent loss: 0.3068
[2023-06-25 04:59:32,456] Epoch 22/150
[2023-06-25 04:59:56,518] test loss: 1.6889
[2023-06-25 04:59:56,519] cal loss: 78.5154
[2023-06-25 04:59:56,519] cal percent loss: 0.3079
[2023-06-25 04:59:56,519] mass loss: 42.1880
[2023-06-25 04:59:56,519] mass percent loss: 0.1935
[2023-06-25 04:59:56,520] fat loss: 5.7062
[2023-06-25 04:59:56,520] fat percent loss: 0.4493
[2023-06-25 04:59:56,520] carb loss: 7.3255
[2023-06-25 04:59:56,520] carb percent loss: 0.3796
[2023-06-25 04:59:56,520] protein loss: 6.4736
[2023-06-25 04:59:56,520] protein percent loss: 0.3577
[2023-06-25 04:59:56,520] Epoch 23/150
[2023-06-25 05:02:30,572] train loss: 1.3514
[2023-06-25 05:02:30,573] cal loss: 57.0183
[2023-06-25 05:02:30,573] cal percent loss: 0.2236
[2023-06-25 05:02:30,573] mass loss: 36.7514
[2023-06-25 05:02:30,573] mass percent loss: 0.1686
[2023-06-25 05:02:30,573] fat loss: 4.3553
[2023-06-25 05:02:30,573] fat percent loss: 0.3429
[2023-06-25 05:02:30,573] carb loss: 5.8720
[2023-06-25 05:02:30,573] carb percent loss: 0.3042
[2023-06-25 05:02:30,573] protein loss: 5.6476
[2023-06-25 05:02:30,573] protein percent loss: 0.3120
[2023-06-25 05:02:30,574] Epoch 23/150
[2023-06-25 05:02:54,832] test loss: 1.4718
[2023-06-25 05:02:54,833] cal loss: 70.1125
[2023-06-25 05:02:54,833] cal percent loss: 0.2750
[2023-06-25 05:02:54,833] mass loss: 34.2213
[2023-06-25 05:02:54,833] mass percent loss: 0.1570
[2023-06-25 05:02:54,833] fat loss: 4.3179
[2023-06-25 05:02:54,833] fat percent loss: 0.3400
[2023-06-25 05:02:54,833] carb loss: 7.3751
[2023-06-25 05:02:54,833] carb percent loss: 0.3821
[2023-06-25 05:02:54,834] protein loss: 5.8910
[2023-06-25 05:02:54,834] protein percent loss: 0.3255
[2023-06-25 05:02:54,834] Epoch 24/150
[2023-06-25 05:05:23,848] train loss: 1.2902
[2023-06-25 05:05:23,849] cal loss: 55.2305
[2023-06-25 05:05:23,849] cal percent loss: 0.2166
[2023-06-25 05:05:23,849] mass loss: 33.8894
[2023-06-25 05:05:23,849] mass percent loss: 0.1555
[2023-06-25 05:05:23,849] fat loss: 4.2635
[2023-06-25 05:05:23,849] fat percent loss: 0.3357
[2023-06-25 05:05:23,849] carb loss: 5.6708
[2023-06-25 05:05:23,849] carb percent loss: 0.2938
[2023-06-25 05:05:23,849] protein loss: 5.2496
[2023-06-25 05:05:23,850] protein percent loss: 0.2900
[2023-06-25 05:05:23,850] Epoch 24/150
[2023-06-25 05:05:49,116] test loss: 1.3640
[2023-06-25 05:05:49,117] cal loss: 52.0464
[2023-06-25 05:05:49,117] cal percent loss: 0.2041
[2023-06-25 05:05:49,117] mass loss: 34.1803
[2023-06-25 05:05:49,117] mass percent loss: 0.1568
[2023-06-25 05:05:49,117] fat loss: 4.2951
[2023-06-25 05:05:49,118] fat percent loss: 0.3382
[2023-06-25 05:05:49,118] carb loss: 6.2638
[2023-06-25 05:05:49,118] carb percent loss: 0.3245
[2023-06-25 05:05:49,118] protein loss: 6.4105
[2023-06-25 05:05:49,118] protein percent loss: 0.3542
[2023-06-25 05:05:49,118] Epoch 25/150
[2023-06-25 05:08:18,596] train loss: 1.2995
[2023-06-25 05:08:18,596] cal loss: 55.8183
[2023-06-25 05:08:18,596] cal percent loss: 0.2189
[2023-06-25 05:08:18,596] mass loss: 33.4277
[2023-06-25 05:08:18,596] mass percent loss: 0.1533
[2023-06-25 05:08:18,597] fat loss: 4.1665
[2023-06-25 05:08:18,597] fat percent loss: 0.3281
[2023-06-25 05:08:18,597] carb loss: 5.8334
[2023-06-25 05:08:18,597] carb percent loss: 0.3022
[2023-06-25 05:08:18,597] protein loss: 5.4415
[2023-06-25 05:08:18,597] protein percent loss: 0.3006
[2023-06-25 05:08:18,597] Epoch 25/150
[2023-06-25 05:08:44,731] test loss: 1.7281
[2023-06-25 05:08:44,732] cal loss: 83.3136
[2023-06-25 05:08:44,732] cal percent loss: 0.3267
[2023-06-25 05:08:44,732] mass loss: 48.0438
[2023-06-25 05:08:44,732] mass percent loss: 0.2204
[2023-06-25 05:08:44,732] fat loss: 4.7074
[2023-06-25 05:08:44,732] fat percent loss: 0.3707
[2023-06-25 05:08:44,733] carb loss: 7.4581
[2023-06-25 05:08:44,733] carb percent loss: 0.3864
[2023-06-25 05:08:44,733] protein loss: 7.4866
[2023-06-25 05:08:44,733] protein percent loss: 0.4136
[2023-06-25 05:08:44,733] Epoch 26/150
[2023-06-25 05:11:21,653] train loss: 1.3646
[2023-06-25 05:11:21,653] cal loss: 61.0193
[2023-06-25 05:11:21,653] cal percent loss: 0.2393
[2023-06-25 05:11:21,653] mass loss: 36.9240
[2023-06-25 05:11:21,653] mass percent loss: 0.1694
[2023-06-25 05:11:21,653] fat loss: 4.4092
[2023-06-25 05:11:21,653] fat percent loss: 0.3472
[2023-06-25 05:11:21,654] carb loss: 5.6445
[2023-06-25 05:11:21,654] carb percent loss: 0.2925
[2023-06-25 05:11:21,654] protein loss: 5.6514
[2023-06-25 05:11:21,654] protein percent loss: 0.3122
[2023-06-25 05:11:21,654] Epoch 26/150
[2023-06-25 05:11:44,782] test loss: 1.3179
[2023-06-25 05:11:44,783] cal loss: 53.3517
[2023-06-25 05:11:44,783] cal percent loss: 0.2092
[2023-06-25 05:11:44,784] mass loss: 37.2066
[2023-06-25 05:11:44,784] mass percent loss: 0.1707
[2023-06-25 05:11:44,784] fat loss: 3.8324
[2023-06-25 05:11:44,784] fat percent loss: 0.3018
[2023-06-25 05:11:44,784] carb loss: 6.4060
[2023-06-25 05:11:44,784] carb percent loss: 0.3319
[2023-06-25 05:11:44,784] protein loss: 5.5546
[2023-06-25 05:11:44,784] protein percent loss: 0.3069
[2023-06-25 05:11:44,785] Epoch 27/150
[2023-06-25 05:14:18,439] train loss: 1.1983
[2023-06-25 05:14:18,440] cal loss: 50.6315
[2023-06-25 05:14:18,440] cal percent loss: 0.1986
[2023-06-25 05:14:18,440] mass loss: 32.4764
[2023-06-25 05:14:18,440] mass percent loss: 0.1490
[2023-06-25 05:14:18,440] fat loss: 3.8478
[2023-06-25 05:14:18,440] fat percent loss: 0.3030
[2023-06-25 05:14:18,440] carb loss: 5.3185
[2023-06-25 05:14:18,440] carb percent loss: 0.2756
[2023-06-25 05:14:18,440] protein loss: 4.9352
[2023-06-25 05:14:18,441] protein percent loss: 0.2727
[2023-06-25 05:14:18,441] Epoch 27/150
[2023-06-25 05:14:43,451] test loss: 1.9001
[2023-06-25 05:14:43,452] cal loss: 90.3866
[2023-06-25 05:14:43,452] cal percent loss: 0.3545
[2023-06-25 05:14:43,453] mass loss: 62.3241
[2023-06-25 05:14:43,453] mass percent loss: 0.2859
[2023-06-25 05:14:43,453] fat loss: 4.7877
[2023-06-25 05:14:43,453] fat percent loss: 0.3770
[2023-06-25 05:14:43,453] carb loss: 8.4102
[2023-06-25 05:14:43,453] carb percent loss: 0.4358
[2023-06-25 05:14:43,453] protein loss: 7.5616
[2023-06-25 05:14:43,453] protein percent loss: 0.4178
[2023-06-25 05:14:43,454] Epoch 28/150
[2023-06-25 05:17:09,398] train loss: 1.5026
[2023-06-25 05:17:09,399] cal loss: 65.4989
[2023-06-25 05:17:09,399] cal percent loss: 0.2569
[2023-06-25 05:17:09,399] mass loss: 46.2156
[2023-06-25 05:17:09,399] mass percent loss: 0.2120
[2023-06-25 05:17:09,399] fat loss: 4.4424
[2023-06-25 05:17:09,399] fat percent loss: 0.3498
[2023-06-25 05:17:09,400] carb loss: 6.3571
[2023-06-25 05:17:09,400] carb percent loss: 0.3294
[2023-06-25 05:17:09,400] protein loss: 6.1825
[2023-06-25 05:17:09,400] protein percent loss: 0.3416
[2023-06-25 05:17:09,400] Epoch 28/150
[2023-06-25 05:17:35,931] test loss: 1.5030
[2023-06-25 05:17:35,932] cal loss: 67.5773
[2023-06-25 05:17:35,932] cal percent loss: 0.2650
[2023-06-25 05:17:35,932] mass loss: 41.2505
[2023-06-25 05:17:35,932] mass percent loss: 0.1892
[2023-06-25 05:17:35,932] fat loss: 4.6807
[2023-06-25 05:17:35,932] fat percent loss: 0.3686
[2023-06-25 05:17:35,933] carb loss: 6.4588
[2023-06-25 05:17:35,933] carb percent loss: 0.3347
[2023-06-25 05:17:35,933] protein loss: 6.1644
[2023-06-25 05:17:35,933] protein percent loss: 0.3406
[2023-06-25 05:17:35,933] Epoch 29/150
[2023-06-25 05:20:04,163] train loss: 1.3060
[2023-06-25 05:20:04,164] cal loss: 57.6475
[2023-06-25 05:20:04,164] cal percent loss: 0.2261
[2023-06-25 05:20:04,164] mass loss: 34.4679
[2023-06-25 05:20:04,164] mass percent loss: 0.1581
[2023-06-25 05:20:04,164] fat loss: 4.2316
[2023-06-25 05:20:04,164] fat percent loss: 0.3332
[2023-06-25 05:20:04,165] carb loss: 5.5156
[2023-06-25 05:20:04,165] carb percent loss: 0.2858
[2023-06-25 05:20:04,165] protein loss: 5.4663
[2023-06-25 05:20:04,165] protein percent loss: 0.3020
[2023-06-25 05:20:04,165] Epoch 29/150
[2023-06-25 05:20:30,531] test loss: 1.3742
[2023-06-25 05:20:30,532] cal loss: 55.1342
[2023-06-25 05:20:30,532] cal percent loss: 0.2162
[2023-06-25 05:20:30,532] mass loss: 35.7015
[2023-06-25 05:20:30,532] mass percent loss: 0.1638
[2023-06-25 05:20:30,532] fat loss: 4.1727
[2023-06-25 05:20:30,533] fat percent loss: 0.3286
[2023-06-25 05:20:30,533] carb loss: 6.6808
[2023-06-25 05:20:30,533] carb percent loss: 0.3462
[2023-06-25 05:20:30,533] protein loss: 5.9534
[2023-06-25 05:20:30,533] protein percent loss: 0.3289
[2023-06-25 05:20:30,533] Epoch 30/150
[2023-06-25 05:23:08,738] train loss: 1.2344
[2023-06-25 05:23:08,739] cal loss: 51.4752
[2023-06-25 05:23:08,739] cal percent loss: 0.2019
[2023-06-25 05:23:08,739] mass loss: 34.1315
[2023-06-25 05:23:08,740] mass percent loss: 0.1566
[2023-06-25 05:23:08,740] fat loss: 4.0876
[2023-06-25 05:23:08,740] fat percent loss: 0.3219
[2023-06-25 05:23:08,740] carb loss: 5.1613
[2023-06-25 05:23:08,740] carb percent loss: 0.2674
[2023-06-25 05:23:08,740] protein loss: 5.1635
[2023-06-25 05:23:08,740] protein percent loss: 0.2853
[2023-06-25 05:23:08,740] Epoch 30/150
[2023-06-25 05:23:32,648] test loss: 1.4044
[2023-06-25 05:23:32,649] cal loss: 59.3050
[2023-06-25 05:23:32,649] cal percent loss: 0.2326
[2023-06-25 05:23:32,649] mass loss: 37.3326
[2023-06-25 05:23:32,649] mass percent loss: 0.1713
[2023-06-25 05:23:32,649] fat loss: 4.4630
[2023-06-25 05:23:32,649] fat percent loss: 0.3514
[2023-06-25 05:23:32,650] carb loss: 5.9858
[2023-06-25 05:23:32,650] carb percent loss: 0.3101
[2023-06-25 05:23:32,650] protein loss: 6.1714
[2023-06-25 05:23:32,650] protein percent loss: 0.3410
[2023-06-25 05:23:32,650] Epoch 31/150
[2023-06-25 05:26:04,157] train loss: 1.2330
[2023-06-25 05:26:04,157] cal loss: 53.6877
[2023-06-25 05:26:04,157] cal percent loss: 0.2105
[2023-06-25 05:26:04,157] mass loss: 34.0042
[2023-06-25 05:26:04,158] mass percent loss: 0.1560
[2023-06-25 05:26:04,158] fat loss: 4.0302
[2023-06-25 05:26:04,158] fat percent loss: 0.3173
[2023-06-25 05:26:04,158] carb loss: 5.2575
[2023-06-25 05:26:04,158] carb percent loss: 0.2724
[2023-06-25 05:26:04,158] protein loss: 4.9477
[2023-06-25 05:26:04,158] protein percent loss: 0.2734
[2023-06-25 05:26:04,158] Epoch 31/150
[2023-06-25 05:26:30,609] test loss: 1.3421
[2023-06-25 05:26:30,610] cal loss: 54.0457
[2023-06-25 05:26:30,610] cal percent loss: 0.2119
[2023-06-25 05:26:30,610] mass loss: 40.9736
[2023-06-25 05:26:30,610] mass percent loss: 0.1880
[2023-06-25 05:26:30,610] fat loss: 4.0703
[2023-06-25 05:26:30,610] fat percent loss: 0.3205
[2023-06-25 05:26:30,610] carb loss: 6.2916
[2023-06-25 05:26:30,611] carb percent loss: 0.3260
[2023-06-25 05:26:30,611] protein loss: 5.2575
[2023-06-25 05:26:30,611] protein percent loss: 0.2905
[2023-06-25 05:26:30,611] Epoch 32/150
[2023-06-25 05:29:02,121] train loss: 1.2103
[2023-06-25 05:29:02,122] cal loss: 52.1459
[2023-06-25 05:29:02,122] cal percent loss: 0.2045
[2023-06-25 05:29:02,122] mass loss: 33.8251
[2023-06-25 05:29:02,122] mass percent loss: 0.1552
[2023-06-25 05:29:02,122] fat loss: 3.9191
[2023-06-25 05:29:02,122] fat percent loss: 0.3086
[2023-06-25 05:29:02,122] carb loss: 5.2175
[2023-06-25 05:29:02,122] carb percent loss: 0.2703
[2023-06-25 05:29:02,122] protein loss: 4.8569
[2023-06-25 05:29:02,123] protein percent loss: 0.2683
[2023-06-25 05:29:02,123] Epoch 32/150
[2023-06-25 05:29:26,925] test loss: 1.3851
[2023-06-25 05:29:26,925] cal loss: 51.1777
[2023-06-25 05:29:26,926] cal percent loss: 0.2007
[2023-06-25 05:29:26,926] mass loss: 45.5269
[2023-06-25 05:29:26,926] mass percent loss: 0.2088
[2023-06-25 05:29:26,926] fat loss: 3.8625
[2023-06-25 05:29:26,926] fat percent loss: 0.3041
[2023-06-25 05:29:26,926] carb loss: 6.5203
[2023-06-25 05:29:26,927] carb percent loss: 0.3378
[2023-06-25 05:29:26,927] protein loss: 5.9298
[2023-06-25 05:29:26,927] protein percent loss: 0.3276
[2023-06-25 05:29:26,927] Epoch 33/150
[2023-06-25 05:32:01,596] train loss: 1.1692
[2023-06-25 05:32:01,597] cal loss: 50.2361
[2023-06-25 05:32:01,597] cal percent loss: 0.1970
[2023-06-25 05:32:01,597] mass loss: 31.9276
[2023-06-25 05:32:01,597] mass percent loss: 0.1465
[2023-06-25 05:32:01,597] fat loss: 3.7839
[2023-06-25 05:32:01,598] fat percent loss: 0.2979
[2023-06-25 05:32:01,598] carb loss: 5.1460
[2023-06-25 05:32:01,598] carb percent loss: 0.2666
[2023-06-25 05:32:01,598] protein loss: 4.7044
[2023-06-25 05:32:01,598] protein percent loss: 0.2599
[2023-06-25 05:32:01,598] Epoch 33/150
[2023-06-25 05:32:25,675] test loss: 1.4075
[2023-06-25 05:32:25,676] cal loss: 57.6725
[2023-06-25 05:32:25,676] cal percent loss: 0.2262
[2023-06-25 05:32:25,676] mass loss: 36.3232
[2023-06-25 05:32:25,676] mass percent loss: 0.1666
[2023-06-25 05:32:25,676] fat loss: 4.5116
[2023-06-25 05:32:25,677] fat percent loss: 0.3552
[2023-06-25 05:32:25,677] carb loss: 6.8935
[2023-06-25 05:32:25,677] carb percent loss: 0.3572
[2023-06-25 05:32:25,677] protein loss: 5.6132
[2023-06-25 05:32:25,677] protein percent loss: 0.3101
[2023-06-25 05:32:25,677] Epoch 34/150
[2023-06-25 05:35:01,642] train loss: 1.1325
[2023-06-25 05:35:01,643] cal loss: 48.4061
[2023-06-25 05:35:01,643] cal percent loss: 0.1898
[2023-06-25 05:35:01,643] mass loss: 30.5058
[2023-06-25 05:35:01,643] mass percent loss: 0.1399
[2023-06-25 05:35:01,643] fat loss: 3.6402
[2023-06-25 05:35:01,644] fat percent loss: 0.2866
[2023-06-25 05:35:01,644] carb loss: 4.8835
[2023-06-25 05:35:01,644] carb percent loss: 0.2530
[2023-06-25 05:35:01,644] protein loss: 4.7603
[2023-06-25 05:35:01,644] protein percent loss: 0.2630
[2023-06-25 05:35:01,644] Epoch 34/150
[2023-06-25 05:35:28,900] test loss: 1.2590
[2023-06-25 05:35:28,901] cal loss: 53.5535
[2023-06-25 05:35:28,901] cal percent loss: 0.2100
[2023-06-25 05:35:28,901] mass loss: 32.4053
[2023-06-25 05:35:28,901] mass percent loss: 0.1486
[2023-06-25 05:35:28,902] fat loss: 4.0370
[2023-06-25 05:35:28,902] fat percent loss: 0.3179
[2023-06-25 05:35:28,902] carb loss: 6.0308
[2023-06-25 05:35:28,902] carb percent loss: 0.3125
[2023-06-25 05:35:28,902] protein loss: 4.9716
[2023-06-25 05:35:28,902] protein percent loss: 0.2747
[2023-06-25 05:35:28,902] Epoch 35/150
[2023-06-25 05:38:07,284] train loss: 1.1243
[2023-06-25 05:38:07,285] cal loss: 47.4344
[2023-06-25 05:38:07,285] cal percent loss: 0.1860
[2023-06-25 05:38:07,285] mass loss: 30.9197
[2023-06-25 05:38:07,285] mass percent loss: 0.1418
[2023-06-25 05:38:07,285] fat loss: 3.6224
[2023-06-25 05:38:07,285] fat percent loss: 0.2852
[2023-06-25 05:38:07,285] carb loss: 4.9192
[2023-06-25 05:38:07,286] carb percent loss: 0.2549
[2023-06-25 05:38:07,286] protein loss: 4.6268
[2023-06-25 05:38:07,286] protein percent loss: 0.2556
[2023-06-25 05:38:07,286] Epoch 35/150
[2023-06-25 05:38:32,026] test loss: 1.2996
[2023-06-25 05:38:32,027] cal loss: 55.9122
[2023-06-25 05:38:32,027] cal percent loss: 0.2193
[2023-06-25 05:38:32,027] mass loss: 32.6957
[2023-06-25 05:38:32,027] mass percent loss: 0.1500
[2023-06-25 05:38:32,028] fat loss: 3.8366
[2023-06-25 05:38:32,028] fat percent loss: 0.3021
[2023-06-25 05:38:32,028] carb loss: 6.8157
[2023-06-25 05:38:32,028] carb percent loss: 0.3531
[2023-06-25 05:38:32,028] protein loss: 5.1332
[2023-06-25 05:38:32,028] protein percent loss: 0.2836
[2023-06-25 05:38:32,028] Epoch 36/150
[2023-06-25 05:41:06,759] train loss: 1.1136
[2023-06-25 05:41:06,760] cal loss: 47.3890
[2023-06-25 05:41:06,760] cal percent loss: 0.1858
[2023-06-25 05:41:06,760] mass loss: 31.3129
[2023-06-25 05:41:06,761] mass percent loss: 0.1436
[2023-06-25 05:41:06,761] fat loss: 3.5736
[2023-06-25 05:41:06,761] fat percent loss: 0.2814
[2023-06-25 05:41:06,761] carb loss: 4.9630
[2023-06-25 05:41:06,761] carb percent loss: 0.2571
[2023-06-25 05:41:06,761] protein loss: 4.3992
[2023-06-25 05:41:06,761] protein percent loss: 0.2431
[2023-06-25 05:41:06,761] Epoch 36/150
[2023-06-25 05:41:32,385] test loss: 1.2631
[2023-06-25 05:41:32,386] cal loss: 50.7574
[2023-06-25 05:41:32,386] cal percent loss: 0.1990
[2023-06-25 05:41:32,386] mass loss: 32.2081
[2023-06-25 05:41:32,386] mass percent loss: 0.1477
[2023-06-25 05:41:32,386] fat loss: 3.9313
[2023-06-25 05:41:32,386] fat percent loss: 0.3096
[2023-06-25 05:41:32,386] carb loss: 6.1394
[2023-06-25 05:41:32,386] carb percent loss: 0.3181
[2023-06-25 05:41:32,386] protein loss: 5.3966
[2023-06-25 05:41:32,387] protein percent loss: 0.2982
[2023-06-25 05:41:32,387] Epoch 37/150
[2023-06-25 05:44:08,844] train loss: 1.0830
[2023-06-25 05:44:08,845] cal loss: 45.7731
[2023-06-25 05:44:08,845] cal percent loss: 0.1795
[2023-06-25 05:44:08,845] mass loss: 30.2870
[2023-06-25 05:44:08,846] mass percent loss: 0.1389
[2023-06-25 05:44:08,846] fat loss: 3.4449
[2023-06-25 05:44:08,846] fat percent loss: 0.2713
[2023-06-25 05:44:08,846] carb loss: 4.7007
[2023-06-25 05:44:08,846] carb percent loss: 0.2436
[2023-06-25 05:44:08,846] protein loss: 4.4890
[2023-06-25 05:44:08,846] protein percent loss: 0.2480
[2023-06-25 05:44:08,846] Epoch 37/150
[2023-06-25 05:44:34,722] test loss: 1.3173
[2023-06-25 05:44:34,723] cal loss: 53.7704
[2023-06-25 05:44:34,723] cal percent loss: 0.2109
[2023-06-25 05:44:34,723] mass loss: 35.2973
[2023-06-25 05:44:34,723] mass percent loss: 0.1619
[2023-06-25 05:44:34,723] fat loss: 4.2216
[2023-06-25 05:44:34,723] fat percent loss: 0.3324
[2023-06-25 05:44:34,723] carb loss: 6.2767
[2023-06-25 05:44:34,723] carb percent loss: 0.3252
[2023-06-25 05:44:34,723] protein loss: 5.2714
[2023-06-25 05:44:34,724] protein percent loss: 0.2912
[2023-06-25 05:44:34,724] Epoch 38/150
[2023-06-25 05:47:07,150] train loss: 1.0420
[2023-06-25 05:47:07,151] cal loss: 43.8832
[2023-06-25 05:47:07,151] cal percent loss: 0.1721
[2023-06-25 05:47:07,151] mass loss: 28.3156
[2023-06-25 05:47:07,151] mass percent loss: 0.1299
[2023-06-25 05:47:07,151] fat loss: 3.4890
[2023-06-25 05:47:07,152] fat percent loss: 0.2747
[2023-06-25 05:47:07,152] carb loss: 4.4864
[2023-06-25 05:47:07,152] carb percent loss: 0.2325
[2023-06-25 05:47:07,152] protein loss: 4.2049
[2023-06-25 05:47:07,152] protein percent loss: 0.2323
[2023-06-25 05:47:07,152] Epoch 38/150
[2023-06-25 05:47:32,087] test loss: 1.3500
[2023-06-25 05:47:32,088] cal loss: 55.9588
[2023-06-25 05:47:32,088] cal percent loss: 0.2194
[2023-06-25 05:47:32,088] mass loss: 37.0320
[2023-06-25 05:47:32,089] mass percent loss: 0.1699
[2023-06-25 05:47:32,089] fat loss: 4.2420
[2023-06-25 05:47:32,089] fat percent loss: 0.3340
[2023-06-25 05:47:32,089] carb loss: 6.0357
[2023-06-25 05:47:32,089] carb percent loss: 0.3127
[2023-06-25 05:47:32,089] protein loss: 5.7029
[2023-06-25 05:47:32,089] protein percent loss: 0.3151
[2023-06-25 05:47:32,090] Epoch 39/150
[2023-06-25 05:50:04,255] train loss: 1.1238
[2023-06-25 05:50:04,255] cal loss: 48.2682
[2023-06-25 05:50:04,255] cal percent loss: 0.1893
[2023-06-25 05:50:04,256] mass loss: 31.9615
[2023-06-25 05:50:04,256] mass percent loss: 0.1466
[2023-06-25 05:50:04,256] fat loss: 3.5034
[2023-06-25 05:50:04,256] fat percent loss: 0.2759
[2023-06-25 05:50:04,256] carb loss: 4.7460
[2023-06-25 05:50:04,256] carb percent loss: 0.2459
[2023-06-25 05:50:04,256] protein loss: 4.7474
[2023-06-25 05:50:04,256] protein percent loss: 0.2623
[2023-06-25 05:50:04,256] Epoch 39/150
[2023-06-25 05:50:27,701] test loss: 1.2405
[2023-06-25 05:50:27,702] cal loss: 50.1462
[2023-06-25 05:50:27,702] cal percent loss: 0.1967
[2023-06-25 05:50:27,702] mass loss: 29.5538
[2023-06-25 05:50:27,702] mass percent loss: 0.1356
[2023-06-25 05:50:27,702] fat loss: 3.8872
[2023-06-25 05:50:27,703] fat percent loss: 0.3061
[2023-06-25 05:50:27,703] carb loss: 6.2042
[2023-06-25 05:50:27,703] carb percent loss: 0.3215
[2023-06-25 05:50:27,703] protein loss: 5.3323
[2023-06-25 05:50:27,703] protein percent loss: 0.2946
[2023-06-25 05:50:27,703] Epoch 40/150
[2023-06-25 05:52:59,466] train loss: 1.1012
[2023-06-25 05:52:59,467] cal loss: 48.4825
[2023-06-25 05:52:59,467] cal percent loss: 0.1901
[2023-06-25 05:52:59,467] mass loss: 29.5212
[2023-06-25 05:52:59,467] mass percent loss: 0.1354
[2023-06-25 05:52:59,467] fat loss: 3.4679
[2023-06-25 05:52:59,467] fat percent loss: 0.2731
[2023-06-25 05:52:59,467] carb loss: 4.8219
[2023-06-25 05:52:59,467] carb percent loss: 0.2498
[2023-06-25 05:52:59,467] protein loss: 4.5587
[2023-06-25 05:52:59,467] protein percent loss: 0.2519
[2023-06-25 05:52:59,468] Epoch 40/150
[2023-06-25 05:53:25,084] test loss: 1.2752
[2023-06-25 05:53:25,085] cal loss: 53.9046
[2023-06-25 05:53:25,085] cal percent loss: 0.2114
[2023-06-25 05:53:25,086] mass loss: 30.4323
[2023-06-25 05:53:25,086] mass percent loss: 0.1396
[2023-06-25 05:53:25,086] fat loss: 4.0246
[2023-06-25 05:53:25,086] fat percent loss: 0.3169
[2023-06-25 05:53:25,086] carb loss: 5.6057
[2023-06-25 05:53:25,086] carb percent loss: 0.2905
[2023-06-25 05:53:25,086] protein loss: 5.9166
[2023-06-25 05:53:25,087] protein percent loss: 0.3269
[2023-06-25 05:53:25,087] Epoch 41/150
[2023-06-25 05:55:59,617] train loss: 1.0475
[2023-06-25 05:55:59,617] cal loss: 44.2781
[2023-06-25 05:55:59,617] cal percent loss: 0.1736
[2023-06-25 05:55:59,617] mass loss: 29.1191
[2023-06-25 05:55:59,617] mass percent loss: 0.1336
[2023-06-25 05:55:59,617] fat loss: 3.3425
[2023-06-25 05:55:59,618] fat percent loss: 0.2632
[2023-06-25 05:55:59,618] carb loss: 4.5656
[2023-06-25 05:55:59,618] carb percent loss: 0.2366
[2023-06-25 05:55:59,618] protein loss: 4.3292
[2023-06-25 05:55:59,618] protein percent loss: 0.2392
[2023-06-25 05:55:59,618] Epoch 41/150
[2023-06-25 05:56:24,720] test loss: 1.5795
[2023-06-25 05:56:24,721] cal loss: 68.9854
[2023-06-25 05:56:24,721] cal percent loss: 0.2705
[2023-06-25 05:56:24,721] mass loss: 44.9367
[2023-06-25 05:56:24,721] mass percent loss: 0.2061
[2023-06-25 05:56:24,721] fat loss: 4.5821
[2023-06-25 05:56:24,721] fat percent loss: 0.3608
[2023-06-25 05:56:24,721] carb loss: 6.3072
[2023-06-25 05:56:24,721] carb percent loss: 0.3268
[2023-06-25 05:56:24,722] protein loss: 7.4118
[2023-06-25 05:56:24,722] protein percent loss: 0.4095
[2023-06-25 05:56:24,722] Epoch 42/150
[2023-06-25 05:58:53,571] train loss: 1.1897
[2023-06-25 05:58:53,571] cal loss: 50.4252
[2023-06-25 05:58:53,571] cal percent loss: 0.1977
[2023-06-25 05:58:53,571] mass loss: 32.6571
[2023-06-25 05:58:53,572] mass percent loss: 0.1498
[2023-06-25 05:58:53,572] fat loss: 3.8219
[2023-06-25 05:58:53,572] fat percent loss: 0.3009
[2023-06-25 05:58:53,572] carb loss: 5.0629
[2023-06-25 05:58:53,572] carb percent loss: 0.2623
[2023-06-25 05:58:53,572] protein loss: 5.0290
[2023-06-25 05:58:53,572] protein percent loss: 0.2778
[2023-06-25 05:58:53,572] Epoch 42/150
[2023-06-25 05:59:18,735] test loss: 1.4497
[2023-06-25 05:59:18,736] cal loss: 64.6904
[2023-06-25 05:59:18,736] cal percent loss: 0.2537
[2023-06-25 05:59:18,736] mass loss: 32.6573
[2023-06-25 05:59:18,736] mass percent loss: 0.1498
[2023-06-25 05:59:18,736] fat loss: 4.8312
[2023-06-25 05:59:18,736] fat percent loss: 0.3804
[2023-06-25 05:59:18,737] carb loss: 6.6873
[2023-06-25 05:59:18,737] carb percent loss: 0.3465
[2023-06-25 05:59:18,737] protein loss: 5.9830
[2023-06-25 05:59:18,737] protein percent loss: 0.3306
[2023-06-25 05:59:18,737] Epoch 43/150
[2023-06-25 06:01:55,729] train loss: 1.1041
[2023-06-25 06:01:55,729] cal loss: 48.3762
[2023-06-25 06:01:55,729] cal percent loss: 0.1897
[2023-06-25 06:01:55,729] mass loss: 29.3338
[2023-06-25 06:01:55,729] mass percent loss: 0.1346
[2023-06-25 06:01:55,730] fat loss: 3.6758
[2023-06-25 06:01:55,730] fat percent loss: 0.2894
[2023-06-25 06:01:55,730] carb loss: 4.8653
[2023-06-25 06:01:55,730] carb percent loss: 0.2521
[2023-06-25 06:01:55,730] protein loss: 4.2979
[2023-06-25 06:01:55,730] protein percent loss: 0.2375
[2023-06-25 06:01:55,730] Epoch 43/150
[2023-06-25 06:02:23,207] test loss: 1.2874
[2023-06-25 06:02:23,208] cal loss: 56.5740
[2023-06-25 06:02:23,208] cal percent loss: 0.2219
[2023-06-25 06:02:23,208] mass loss: 30.0051
[2023-06-25 06:02:23,208] mass percent loss: 0.1376
[2023-06-25 06:02:23,209] fat loss: 4.2925
[2023-06-25 06:02:23,209] fat percent loss: 0.3380
[2023-06-25 06:02:23,209] carb loss: 6.3882
[2023-06-25 06:02:23,209] carb percent loss: 0.3310
[2023-06-25 06:02:23,209] protein loss: 4.8592
[2023-06-25 06:02:23,209] protein percent loss: 0.2685
[2023-06-25 06:02:23,209] Epoch 44/150
[2023-06-25 06:04:53,232] train loss: 1.0476
[2023-06-25 06:04:53,232] cal loss: 44.8740
[2023-06-25 06:04:53,232] cal percent loss: 0.1760
[2023-06-25 06:04:53,232] mass loss: 28.0899
[2023-06-25 06:04:53,233] mass percent loss: 0.1289
[2023-06-25 06:04:53,233] fat loss: 3.4504
[2023-06-25 06:04:53,233] fat percent loss: 0.2717
[2023-06-25 06:04:53,233] carb loss: 4.6399
[2023-06-25 06:04:53,233] carb percent loss: 0.2404
[2023-06-25 06:04:53,233] protein loss: 4.1745
[2023-06-25 06:04:53,233] protein percent loss: 0.2306
[2023-06-25 06:04:53,233] Epoch 44/150
[2023-06-25 06:05:19,098] test loss: 1.3736
[2023-06-25 06:05:19,099] cal loss: 61.9238
[2023-06-25 06:05:19,099] cal percent loss: 0.2428
[2023-06-25 06:05:19,099] mass loss: 34.8478
[2023-06-25 06:05:19,099] mass percent loss: 0.1599
[2023-06-25 06:05:19,099] fat loss: 4.4201
[2023-06-25 06:05:19,099] fat percent loss: 0.3480
[2023-06-25 06:05:19,099] carb loss: 6.1393
[2023-06-25 06:05:19,099] carb percent loss: 0.3181
[2023-06-25 06:05:19,100] protein loss: 5.5432
[2023-06-25 06:05:19,100] protein percent loss: 0.3063
[2023-06-25 06:05:19,100] Epoch 45/150
[2023-06-25 06:07:50,636] train loss: 1.1373
[2023-06-25 06:07:50,639] cal loss: 49.5098
[2023-06-25 06:07:50,639] cal percent loss: 0.1942
[2023-06-25 06:07:50,639] mass loss: 31.4721
[2023-06-25 06:07:50,639] mass percent loss: 0.1444
[2023-06-25 06:07:50,639] fat loss: 3.6253
[2023-06-25 06:07:50,639] fat percent loss: 0.2855
[2023-06-25 06:07:50,640] carb loss: 4.7701
[2023-06-25 06:07:50,640] carb percent loss: 0.2472
[2023-06-25 06:07:50,640] protein loss: 4.7621
[2023-06-25 06:07:50,640] protein percent loss: 0.2631
[2023-06-25 06:07:50,640] Epoch 45/150
[2023-06-25 06:08:13,771] test loss: 1.4161
[2023-06-25 06:08:13,772] cal loss: 58.0670
[2023-06-25 06:08:13,772] cal percent loss: 0.2277
[2023-06-25 06:08:13,772] mass loss: 39.5277
[2023-06-25 06:08:13,772] mass percent loss: 0.1813
[2023-06-25 06:08:13,772] fat loss: 4.3659
[2023-06-25 06:08:13,772] fat percent loss: 0.3438
[2023-06-25 06:08:13,772] carb loss: 6.4979
[2023-06-25 06:08:13,773] carb percent loss: 0.3367
[2023-06-25 06:08:13,773] protein loss: 5.9312
[2023-06-25 06:08:13,773] protein percent loss: 0.3277
[2023-06-25 06:08:13,773] Epoch 46/150
[2023-06-25 06:10:45,767] train loss: 1.0168
[2023-06-25 06:10:45,768] cal loss: 43.5247
[2023-06-25 06:10:45,768] cal percent loss: 0.1707
[2023-06-25 06:10:45,768] mass loss: 27.9083
[2023-06-25 06:10:45,768] mass percent loss: 0.1280
[2023-06-25 06:10:45,768] fat loss: 3.3016
[2023-06-25 06:10:45,768] fat percent loss: 0.2600
[2023-06-25 06:10:45,768] carb loss: 4.3978
[2023-06-25 06:10:45,768] carb percent loss: 0.2279
[2023-06-25 06:10:45,768] protein loss: 4.1412
[2023-06-25 06:10:45,768] protein percent loss: 0.2288
[2023-06-25 06:10:45,769] Epoch 46/150
[2023-06-25 06:11:11,038] test loss: 1.3865
[2023-06-25 06:11:11,039] cal loss: 60.7809
[2023-06-25 06:11:11,039] cal percent loss: 0.2384
[2023-06-25 06:11:11,039] mass loss: 38.7590
[2023-06-25 06:11:11,039] mass percent loss: 0.1778
[2023-06-25 06:11:11,039] fat loss: 4.2145
[2023-06-25 06:11:11,040] fat percent loss: 0.3318
[2023-06-25 06:11:11,040] carb loss: 6.0505
[2023-06-25 06:11:11,040] carb percent loss: 0.3135
[2023-06-25 06:11:11,040] protein loss: 5.8149
[2023-06-25 06:11:11,040] protein percent loss: 0.3213
[2023-06-25 06:11:11,040] Epoch 47/150
[2023-06-25 06:13:43,209] train loss: 1.0308
[2023-06-25 06:13:43,210] cal loss: 43.0343
[2023-06-25 06:13:43,210] cal percent loss: 0.1688
[2023-06-25 06:13:43,210] mass loss: 29.0782
[2023-06-25 06:13:43,210] mass percent loss: 0.1334
[2023-06-25 06:13:43,210] fat loss: 3.4221
[2023-06-25 06:13:43,210] fat percent loss: 0.2695
[2023-06-25 06:13:43,210] carb loss: 4.3125
[2023-06-25 06:13:43,210] carb percent loss: 0.2234
[2023-06-25 06:13:43,211] protein loss: 4.2197
[2023-06-25 06:13:43,211] protein percent loss: 0.2331
[2023-06-25 06:13:43,211] Epoch 47/150
[2023-06-25 06:14:06,497] test loss: 1.3236
[2023-06-25 06:14:06,498] cal loss: 56.8537
[2023-06-25 06:14:06,498] cal percent loss: 0.2230
[2023-06-25 06:14:06,498] mass loss: 35.7413
[2023-06-25 06:14:06,498] mass percent loss: 0.1640
[2023-06-25 06:14:06,498] fat loss: 4.1174
[2023-06-25 06:14:06,498] fat percent loss: 0.3242
[2023-06-25 06:14:06,498] carb loss: 6.2254
[2023-06-25 06:14:06,498] carb percent loss: 0.3226
[2023-06-25 06:14:06,499] protein loss: 5.2656
[2023-06-25 06:14:06,499] protein percent loss: 0.2909
[2023-06-25 06:14:06,499] Epoch 48/150
[2023-06-25 06:16:36,736] train loss: 0.9855
[2023-06-25 06:16:36,737] cal loss: 41.9018
[2023-06-25 06:16:36,737] cal percent loss: 0.1643
[2023-06-25 06:16:36,737] mass loss: 27.9304
[2023-06-25 06:16:36,737] mass percent loss: 0.1281
[2023-06-25 06:16:36,737] fat loss: 3.1961
[2023-06-25 06:16:36,737] fat percent loss: 0.2517
[2023-06-25 06:16:36,737] carb loss: 4.3307
[2023-06-25 06:16:36,737] carb percent loss: 0.2244
[2023-06-25 06:16:36,737] protein loss: 3.8743
[2023-06-25 06:16:36,737] protein percent loss: 0.2141
[2023-06-25 06:16:36,738] Epoch 48/150
[2023-06-25 06:17:01,604] test loss: 1.3903
[2023-06-25 06:17:01,605] cal loss: 57.2542
[2023-06-25 06:17:01,605] cal percent loss: 0.2245
[2023-06-25 06:17:01,605] mass loss: 36.5672
[2023-06-25 06:17:01,605] mass percent loss: 0.1677
[2023-06-25 06:17:01,605] fat loss: 3.9230
[2023-06-25 06:17:01,606] fat percent loss: 0.3089
[2023-06-25 06:17:01,606] carb loss: 7.1859
[2023-06-25 06:17:01,606] carb percent loss: 0.3723
[2023-06-25 06:17:01,606] protein loss: 5.8972
[2023-06-25 06:17:01,606] protein percent loss: 0.3258
[2023-06-25 06:17:01,606] Epoch 49/150
[2023-06-25 06:19:38,584] train loss: 0.9825
[2023-06-25 06:19:38,585] cal loss: 41.3768
[2023-06-25 06:19:38,585] cal percent loss: 0.1623
[2023-06-25 06:19:38,585] mass loss: 28.5609
[2023-06-25 06:19:38,586] mass percent loss: 0.1310
[2023-06-25 06:19:38,586] fat loss: 3.0915
[2023-06-25 06:19:38,586] fat percent loss: 0.2434
[2023-06-25 06:19:38,586] carb loss: 4.2837
[2023-06-25 06:19:38,586] carb percent loss: 0.2220
[2023-06-25 06:19:38,586] protein loss: 3.9839
[2023-06-25 06:19:38,586] protein percent loss: 0.2201
[2023-06-25 06:19:38,586] Epoch 49/150
[2023-06-25 06:20:04,760] test loss: 1.3343
[2023-06-25 06:20:04,761] cal loss: 53.3360
[2023-06-25 06:20:04,761] cal percent loss: 0.2092
[2023-06-25 06:20:04,761] mass loss: 35.9289
[2023-06-25 06:20:04,761] mass percent loss: 0.1648
[2023-06-25 06:20:04,761] fat loss: 4.0541
[2023-06-25 06:20:04,761] fat percent loss: 0.3192
[2023-06-25 06:20:04,761] carb loss: 6.6248
[2023-06-25 06:20:04,761] carb percent loss: 0.3433
[2023-06-25 06:20:04,761] protein loss: 5.5133
[2023-06-25 06:20:04,762] protein percent loss: 0.3046
[2023-06-25 06:20:04,762] Epoch 50/150
[2023-06-25 06:22:30,982] train loss: 0.9716
[2023-06-25 06:22:30,983] cal loss: 41.4114
[2023-06-25 06:22:30,983] cal percent loss: 0.1624
[2023-06-25 06:22:30,983] mass loss: 27.9204
[2023-06-25 06:22:30,983] mass percent loss: 0.1281
[2023-06-25 06:22:30,984] fat loss: 3.0998
[2023-06-25 06:22:30,984] fat percent loss: 0.2441
[2023-06-25 06:22:30,984] carb loss: 4.2480
[2023-06-25 06:22:30,984] carb percent loss: 0.2201
[2023-06-25 06:22:30,984] protein loss: 3.8609
[2023-06-25 06:22:30,984] protein percent loss: 0.2133
[2023-06-25 06:22:30,984] Epoch 50/150
[2023-06-25 06:22:57,087] test loss: 1.2889
[2023-06-25 06:22:57,088] cal loss: 50.9383
[2023-06-25 06:22:57,088] cal percent loss: 0.1998
[2023-06-25 06:22:57,088] mass loss: 32.0647
[2023-06-25 06:22:57,088] mass percent loss: 0.1471
[2023-06-25 06:22:57,088] fat loss: 3.9634
[2023-06-25 06:22:57,088] fat percent loss: 0.3121
[2023-06-25 06:22:57,088] carb loss: 6.1958
[2023-06-25 06:22:57,088] carb percent loss: 0.3210
[2023-06-25 06:22:57,088] protein loss: 5.8200
[2023-06-25 06:22:57,089] protein percent loss: 0.3215
[2023-06-25 06:22:57,089] Epoch 51/150
[2023-06-25 06:25:29,532] train loss: 0.9550
[2023-06-25 06:25:29,532] cal loss: 40.4182
[2023-06-25 06:25:29,532] cal percent loss: 0.1585
[2023-06-25 06:25:29,532] mass loss: 27.2852
[2023-06-25 06:25:29,532] mass percent loss: 0.1252
[2023-06-25 06:25:29,532] fat loss: 3.0760
[2023-06-25 06:25:29,532] fat percent loss: 0.2422
[2023-06-25 06:25:29,532] carb loss: 4.1935
[2023-06-25 06:25:29,532] carb percent loss: 0.2173
[2023-06-25 06:25:29,532] protein loss: 3.7802
[2023-06-25 06:25:29,532] protein percent loss: 0.2089
[2023-06-25 06:25:29,532] Epoch 51/150
[2023-06-25 06:25:52,806] test loss: 1.2009
[2023-06-25 06:25:52,807] cal loss: 46.5484
[2023-06-25 06:25:52,807] cal percent loss: 0.1825
[2023-06-25 06:25:52,807] mass loss: 33.1248
[2023-06-25 06:25:52,807] mass percent loss: 0.1519
[2023-06-25 06:25:52,807] fat loss: 3.9246
[2023-06-25 06:25:52,808] fat percent loss: 0.3090
[2023-06-25 06:25:52,808] carb loss: 5.5083
[2023-06-25 06:25:52,808] carb percent loss: 0.2854
[2023-06-25 06:25:52,808] protein loss: 4.9931
[2023-06-25 06:25:52,808] protein percent loss: 0.2759
[2023-06-25 06:25:52,808] Epoch 52/150
[2023-06-25 06:28:26,474] train loss: 0.9272
[2023-06-25 06:28:26,474] cal loss: 39.5300
[2023-06-25 06:28:26,474] cal percent loss: 0.1550
[2023-06-25 06:28:26,475] mass loss: 26.0774
[2023-06-25 06:28:26,475] mass percent loss: 0.1196
[2023-06-25 06:28:26,475] fat loss: 3.0299
[2023-06-25 06:28:26,475] fat percent loss: 0.2386
[2023-06-25 06:28:26,475] carb loss: 4.0392
[2023-06-25 06:28:26,475] carb percent loss: 0.2093
[2023-06-25 06:28:26,475] protein loss: 3.6585
[2023-06-25 06:28:26,475] protein percent loss: 0.2021
[2023-06-25 06:28:26,475] Epoch 52/150
[2023-06-25 06:28:49,610] test loss: 1.3031
[2023-06-25 06:28:49,611] cal loss: 56.8685
[2023-06-25 06:28:49,611] cal percent loss: 0.2230
[2023-06-25 06:28:49,611] mass loss: 32.6430
[2023-06-25 06:28:49,612] mass percent loss: 0.1497
[2023-06-25 06:28:49,612] fat loss: 4.1159
[2023-06-25 06:28:49,612] fat percent loss: 0.3241
[2023-06-25 06:28:49,612] carb loss: 6.1883
[2023-06-25 06:28:49,612] carb percent loss: 0.3206
[2023-06-25 06:28:49,612] protein loss: 5.2696
[2023-06-25 06:28:49,612] protein percent loss: 0.2911
[2023-06-25 06:28:49,612] Epoch 53/150
[2023-06-25 06:31:25,510] train loss: 0.9299
[2023-06-25 06:31:25,510] cal loss: 39.0245
[2023-06-25 06:31:25,510] cal percent loss: 0.1530
[2023-06-25 06:31:25,511] mass loss: 25.7328
[2023-06-25 06:31:25,511] mass percent loss: 0.1180
[2023-06-25 06:31:25,511] fat loss: 3.0771
[2023-06-25 06:31:25,511] fat percent loss: 0.2423
[2023-06-25 06:31:25,511] carb loss: 4.1084
[2023-06-25 06:31:25,511] carb percent loss: 0.2129
[2023-06-25 06:31:25,511] protein loss: 3.6685
[2023-06-25 06:31:25,511] protein percent loss: 0.2027
[2023-06-25 06:31:25,511] Epoch 53/150
[2023-06-25 06:31:51,416] test loss: 1.4638
[2023-06-25 06:31:51,416] cal loss: 64.6726
[2023-06-25 06:31:51,416] cal percent loss: 0.2536
[2023-06-25 06:31:51,417] mass loss: 41.7202
[2023-06-25 06:31:51,417] mass percent loss: 0.1914
[2023-06-25 06:31:51,417] fat loss: 4.6860
[2023-06-25 06:31:51,417] fat percent loss: 0.3690
[2023-06-25 06:31:51,417] carb loss: 5.8102
[2023-06-25 06:31:51,417] carb percent loss: 0.3010
[2023-06-25 06:31:51,417] protein loss: 6.1608
[2023-06-25 06:31:51,417] protein percent loss: 0.3404
[2023-06-25 06:31:51,417] Epoch 54/150
[2023-06-25 06:34:20,012] train loss: 1.0927
[2023-06-25 06:34:20,012] cal loss: 47.5294
[2023-06-25 06:34:20,012] cal percent loss: 0.1864
[2023-06-25 06:34:20,013] mass loss: 30.9559
[2023-06-25 06:34:20,013] mass percent loss: 0.1420
[2023-06-25 06:34:20,014] fat loss: 3.5401
[2023-06-25 06:34:20,014] fat percent loss: 0.2787
[2023-06-25 06:34:20,014] carb loss: 4.5938
[2023-06-25 06:34:20,014] carb percent loss: 0.2380
[2023-06-25 06:34:20,014] protein loss: 4.3943
[2023-06-25 06:34:20,014] protein percent loss: 0.2428
[2023-06-25 06:34:20,014] Epoch 54/150
[2023-06-25 06:34:44,143] test loss: 1.3253
[2023-06-25 06:34:44,143] cal loss: 57.7104
[2023-06-25 06:34:44,144] cal percent loss: 0.2263
[2023-06-25 06:34:44,144] mass loss: 30.9438
[2023-06-25 06:34:44,144] mass percent loss: 0.1419
[2023-06-25 06:34:44,144] fat loss: 4.1677
[2023-06-25 06:34:44,144] fat percent loss: 0.3282
[2023-06-25 06:34:44,144] carb loss: 6.5711
[2023-06-25 06:34:44,145] carb percent loss: 0.3405
[2023-06-25 06:34:44,145] protein loss: 5.4271
[2023-06-25 06:34:44,145] protein percent loss: 0.2998
[2023-06-25 06:34:44,145] Epoch 55/150
[2023-06-25 06:37:24,416] train loss: 0.8922
[2023-06-25 06:37:24,417] cal loss: 38.1583
[2023-06-25 06:37:24,417] cal percent loss: 0.1496
[2023-06-25 06:37:24,417] mass loss: 24.4314
[2023-06-25 06:37:24,417] mass percent loss: 0.1121
[2023-06-25 06:37:24,418] fat loss: 2.9531
[2023-06-25 06:37:24,418] fat percent loss: 0.2325
[2023-06-25 06:37:24,418] carb loss: 3.8616
[2023-06-25 06:37:24,418] carb percent loss: 0.2001
[2023-06-25 06:37:24,418] protein loss: 3.5572
[2023-06-25 06:37:24,418] protein percent loss: 0.1965
[2023-06-25 06:37:24,418] Epoch 55/150
[2023-06-25 06:37:48,984] test loss: 1.2951
[2023-06-25 06:37:48,985] cal loss: 55.3837
[2023-06-25 06:37:48,985] cal percent loss: 0.2172
[2023-06-25 06:37:48,985] mass loss: 28.7555
[2023-06-25 06:37:48,985] mass percent loss: 0.1319
[2023-06-25 06:37:48,985] fat loss: 4.6335
[2023-06-25 06:37:48,986] fat percent loss: 0.3648
[2023-06-25 06:37:48,986] carb loss: 5.8270
[2023-06-25 06:37:48,986] carb percent loss: 0.3019
[2023-06-25 06:37:48,986] protein loss: 5.2717
[2023-06-25 06:37:48,986] protein percent loss: 0.2913
[2023-06-25 06:37:48,986] Epoch 56/150
[2023-06-25 06:40:21,329] train loss: 0.8965
[2023-06-25 06:40:21,330] cal loss: 38.3088
[2023-06-25 06:40:21,330] cal percent loss: 0.1502
[2023-06-25 06:40:21,330] mass loss: 24.6502
[2023-06-25 06:40:21,330] mass percent loss: 0.1131
[2023-06-25 06:40:21,331] fat loss: 2.9236
[2023-06-25 06:40:21,331] fat percent loss: 0.2302
[2023-06-25 06:40:21,331] carb loss: 3.8988
[2023-06-25 06:40:21,331] carb percent loss: 0.2020
[2023-06-25 06:40:21,331] protein loss: 3.6150
[2023-06-25 06:40:21,331] protein percent loss: 0.1997
[2023-06-25 06:40:21,331] Epoch 56/150
[2023-06-25 06:40:45,907] test loss: 1.3379
[2023-06-25 06:40:45,908] cal loss: 56.1736
[2023-06-25 06:40:45,908] cal percent loss: 0.2203
[2023-06-25 06:40:45,908] mass loss: 34.2230
[2023-06-25 06:40:45,908] mass percent loss: 0.1570
[2023-06-25 06:40:45,908] fat loss: 4.1974
[2023-06-25 06:40:45,908] fat percent loss: 0.3305
[2023-06-25 06:40:45,908] carb loss: 6.1574
[2023-06-25 06:40:45,909] carb percent loss: 0.3190
[2023-06-25 06:40:45,910] protein loss: 5.7454
[2023-06-25 06:40:45,910] protein percent loss: 0.3174
[2023-06-25 06:40:45,911] Epoch 57/150
[2023-06-25 06:43:15,655] train loss: 0.9381
[2023-06-25 06:43:15,656] cal loss: 40.6256
[2023-06-25 06:43:15,656] cal percent loss: 0.1593
[2023-06-25 06:43:15,656] mass loss: 26.4033
[2023-06-25 06:43:15,656] mass percent loss: 0.1211
[2023-06-25 06:43:15,656] fat loss: 3.0575
[2023-06-25 06:43:15,656] fat percent loss: 0.2407
[2023-06-25 06:43:15,656] carb loss: 3.9347
[2023-06-25 06:43:15,656] carb percent loss: 0.2039
[2023-06-25 06:43:15,657] protein loss: 3.7905
[2023-06-25 06:43:15,657] protein percent loss: 0.2094
[2023-06-25 06:43:15,657] Epoch 57/150
[2023-06-25 06:43:39,477] test loss: 1.2751
[2023-06-25 06:43:39,477] cal loss: 54.2821
[2023-06-25 06:43:39,478] cal percent loss: 0.2129
[2023-06-25 06:43:39,478] mass loss: 33.9779
[2023-06-25 06:43:39,478] mass percent loss: 0.1559
[2023-06-25 06:43:39,478] fat loss: 4.1334
[2023-06-25 06:43:39,478] fat percent loss: 0.3255
[2023-06-25 06:43:39,478] carb loss: 5.9421
[2023-06-25 06:43:39,478] carb percent loss: 0.3079
[2023-06-25 06:43:39,478] protein loss: 4.9715
[2023-06-25 06:43:39,479] protein percent loss: 0.2747
[2023-06-25 06:43:39,479] Epoch 58/150
[2023-06-25 06:46:11,661] train loss: 0.9945
[2023-06-25 06:46:11,661] cal loss: 44.0149
[2023-06-25 06:46:11,661] cal percent loss: 0.1726
[2023-06-25 06:46:11,662] mass loss: 28.0375
[2023-06-25 06:46:11,662] mass percent loss: 0.1286
[2023-06-25 06:46:11,662] fat loss: 3.2573
[2023-06-25 06:46:11,662] fat percent loss: 0.2565
[2023-06-25 06:46:11,662] carb loss: 4.1259
[2023-06-25 06:46:11,662] carb percent loss: 0.2138
[2023-06-25 06:46:11,662] protein loss: 3.9427
[2023-06-25 06:46:11,662] protein percent loss: 0.2178
[2023-06-25 06:46:11,662] Epoch 58/150
[2023-06-25 06:46:34,087] test loss: 1.3029
[2023-06-25 06:46:34,088] cal loss: 53.8841
[2023-06-25 06:46:34,088] cal percent loss: 0.2113
[2023-06-25 06:46:34,088] mass loss: 27.0775
[2023-06-25 06:46:34,088] mass percent loss: 0.1242
[2023-06-25 06:46:34,089] fat loss: 4.2631
[2023-06-25 06:46:34,089] fat percent loss: 0.3357
[2023-06-25 06:46:34,089] carb loss: 6.9705
[2023-06-25 06:46:34,089] carb percent loss: 0.3612
[2023-06-25 06:46:34,089] protein loss: 5.2974
[2023-06-25 06:46:34,089] protein percent loss: 0.2927
[2023-06-25 06:46:34,089] Epoch 59/150
[2023-06-25 06:48:59,784] train loss: 0.9411
[2023-06-25 06:48:59,785] cal loss: 39.6116
[2023-06-25 06:48:59,785] cal percent loss: 0.1553
[2023-06-25 06:48:59,785] mass loss: 24.9522
[2023-06-25 06:48:59,785] mass percent loss: 0.1145
[2023-06-25 06:48:59,786] fat loss: 3.0574
[2023-06-25 06:48:59,786] fat percent loss: 0.2407
[2023-06-25 06:48:59,786] carb loss: 4.2686
[2023-06-25 06:48:59,786] carb percent loss: 0.2212
[2023-06-25 06:48:59,786] protein loss: 3.8225
[2023-06-25 06:48:59,786] protein percent loss: 0.2112
[2023-06-25 06:48:59,786] Epoch 59/150
[2023-06-25 06:49:22,677] test loss: 1.2536
[2023-06-25 06:49:22,679] cal loss: 49.7919
[2023-06-25 06:49:22,679] cal percent loss: 0.1953
[2023-06-25 06:49:22,679] mass loss: 29.8087
[2023-06-25 06:49:22,679] mass percent loss: 0.1367
[2023-06-25 06:49:22,679] fat loss: 3.8459
[2023-06-25 06:49:22,679] fat percent loss: 0.3028
[2023-06-25 06:49:22,679] carb loss: 6.1186
[2023-06-25 06:49:22,679] carb percent loss: 0.3170
[2023-06-25 06:49:22,680] protein loss: 5.7371
[2023-06-25 06:49:22,680] protein percent loss: 0.3170
[2023-06-25 06:49:22,680] Epoch 60/150
[2023-06-25 06:51:51,143] train loss: 0.8864
[2023-06-25 06:51:51,143] cal loss: 37.7470
[2023-06-25 06:51:51,143] cal percent loss: 0.1480
[2023-06-25 06:51:51,143] mass loss: 24.6403
[2023-06-25 06:51:51,143] mass percent loss: 0.1130
[2023-06-25 06:51:51,144] fat loss: 2.8229
[2023-06-25 06:51:51,144] fat percent loss: 0.2223
[2023-06-25 06:51:51,144] carb loss: 4.0325
[2023-06-25 06:51:51,144] carb percent loss: 0.2089
[2023-06-25 06:51:51,144] protein loss: 3.4943
[2023-06-25 06:51:51,144] protein percent loss: 0.1931
[2023-06-25 06:51:51,144] Epoch 60/150
[2023-06-25 06:52:14,857] test loss: 1.2371
[2023-06-25 06:52:14,858] cal loss: 54.5054
[2023-06-25 06:52:14,858] cal percent loss: 0.2137
[2023-06-25 06:52:14,858] mass loss: 29.6002
[2023-06-25 06:52:14,858] mass percent loss: 0.1358
[2023-06-25 06:52:14,858] fat loss: 3.5568
[2023-06-25 06:52:14,858] fat percent loss: 0.2801
[2023-06-25 06:52:14,858] carb loss: 6.0383
[2023-06-25 06:52:14,858] carb percent loss: 0.3129
[2023-06-25 06:52:14,858] protein loss: 5.5077
[2023-06-25 06:52:14,858] protein percent loss: 0.3043
[2023-06-25 06:52:14,858] Epoch 61/150
[2023-06-25 06:54:43,627] train loss: 0.8954
[2023-06-25 06:54:43,627] cal loss: 38.3472
[2023-06-25 06:54:43,627] cal percent loss: 0.1504
[2023-06-25 06:54:43,627] mass loss: 24.5176
[2023-06-25 06:54:43,628] mass percent loss: 0.1125
[2023-06-25 06:54:43,628] fat loss: 2.9644
[2023-06-25 06:54:43,628] fat percent loss: 0.2334
[2023-06-25 06:54:43,628] carb loss: 3.8970
[2023-06-25 06:54:43,628] carb percent loss: 0.2019
[2023-06-25 06:54:43,628] protein loss: 3.5452
[2023-06-25 06:54:43,628] protein percent loss: 0.1959
[2023-06-25 06:54:43,629] Epoch 61/150
[2023-06-25 06:55:09,943] test loss: 1.2526
[2023-06-25 06:55:09,944] cal loss: 51.7047
[2023-06-25 06:55:09,944] cal percent loss: 0.2028
[2023-06-25 06:55:09,944] mass loss: 30.9221
[2023-06-25 06:55:09,945] mass percent loss: 0.1418
[2023-06-25 06:55:09,945] fat loss: 3.8410
[2023-06-25 06:55:09,945] fat percent loss: 0.3024
[2023-06-25 06:55:09,945] carb loss: 5.8875
[2023-06-25 06:55:09,945] carb percent loss: 0.3050
[2023-06-25 06:55:09,945] protein loss: 5.6221
[2023-06-25 06:55:09,945] protein percent loss: 0.3106
[2023-06-25 06:55:09,946] Epoch 62/150
[2023-06-25 06:57:42,444] train loss: 0.8859
[2023-06-25 06:57:42,445] cal loss: 38.8366
[2023-06-25 06:57:42,445] cal percent loss: 0.1523
[2023-06-25 06:57:42,445] mass loss: 25.0723
[2023-06-25 06:57:42,445] mass percent loss: 0.1150
[2023-06-25 06:57:42,445] fat loss: 2.8349
[2023-06-25 06:57:42,445] fat percent loss: 0.2232
[2023-06-25 06:57:42,445] carb loss: 3.7958
[2023-06-25 06:57:42,445] carb percent loss: 0.1967
[2023-06-25 06:57:42,446] protein loss: 3.5267
[2023-06-25 06:57:42,446] protein percent loss: 0.1948
[2023-06-25 06:57:42,446] Epoch 62/150
[2023-06-25 06:58:08,881] test loss: 1.3666
[2023-06-25 06:58:08,882] cal loss: 59.3426
[2023-06-25 06:58:08,882] cal percent loss: 0.2327
[2023-06-25 06:58:08,882] mass loss: 34.1031
[2023-06-25 06:58:08,883] mass percent loss: 0.1564
[2023-06-25 06:58:08,883] fat loss: 4.1085
[2023-06-25 06:58:08,883] fat percent loss: 0.3235
[2023-06-25 06:58:08,883] carb loss: 6.2273
[2023-06-25 06:58:08,883] carb percent loss: 0.3227
[2023-06-25 06:58:08,883] protein loss: 6.1206
[2023-06-25 06:58:08,883] protein percent loss: 0.3382
[2023-06-25 06:58:08,884] Epoch 63/150
[2023-06-25 07:00:46,870] train loss: 0.8413
[2023-06-25 07:00:46,870] cal loss: 35.5172
[2023-06-25 07:00:46,870] cal percent loss: 0.1393
[2023-06-25 07:00:46,870] mass loss: 24.0413
[2023-06-25 07:00:46,871] mass percent loss: 0.1103
[2023-06-25 07:00:46,871] fat loss: 2.7083
[2023-06-25 07:00:46,871] fat percent loss: 0.2133
[2023-06-25 07:00:46,871] carb loss: 3.7786
[2023-06-25 07:00:46,871] carb percent loss: 0.1958
[2023-06-25 07:00:46,871] protein loss: 3.2627
[2023-06-25 07:00:46,871] protein percent loss: 0.1803
[2023-06-25 07:00:46,872] Epoch 63/150
[2023-06-25 07:01:12,768] test loss: 1.2596
[2023-06-25 07:01:12,768] cal loss: 54.6313
[2023-06-25 07:01:12,769] cal percent loss: 0.2142
[2023-06-25 07:01:12,769] mass loss: 28.3918
[2023-06-25 07:01:12,769] mass percent loss: 0.1302
[2023-06-25 07:01:12,769] fat loss: 3.8393
[2023-06-25 07:01:12,769] fat percent loss: 0.3023
[2023-06-25 07:01:12,769] carb loss: 6.1137
[2023-06-25 07:01:12,769] carb percent loss: 0.3168
[2023-06-25 07:01:12,769] protein loss: 5.6063
[2023-06-25 07:01:12,769] protein percent loss: 0.3097
[2023-06-25 07:01:12,770] Epoch 64/150
[2023-06-25 07:03:42,455] train loss: 0.8234
[2023-06-25 07:03:42,456] cal loss: 34.8699
[2023-06-25 07:03:42,456] cal percent loss: 0.1367
[2023-06-25 07:03:42,456] mass loss: 22.9784
[2023-06-25 07:03:42,456] mass percent loss: 0.1054
[2023-06-25 07:03:42,456] fat loss: 2.6845
[2023-06-25 07:03:42,457] fat percent loss: 0.2114
[2023-06-25 07:03:42,457] carb loss: 3.6292
[2023-06-25 07:03:42,457] carb percent loss: 0.1880
[2023-06-25 07:03:42,457] protein loss: 3.2642
[2023-06-25 07:03:42,457] protein percent loss: 0.1803
[2023-06-25 07:03:42,457] Epoch 64/150
[2023-06-25 07:04:07,945] test loss: 1.2539
[2023-06-25 07:04:07,946] cal loss: 54.6061
[2023-06-25 07:04:07,946] cal percent loss: 0.2141
[2023-06-25 07:04:07,946] mass loss: 30.5738
[2023-06-25 07:04:07,946] mass percent loss: 0.1402
[2023-06-25 07:04:07,946] fat loss: 4.0074
[2023-06-25 07:04:07,946] fat percent loss: 0.3155
[2023-06-25 07:04:07,946] carb loss: 5.8469
[2023-06-25 07:04:07,946] carb percent loss: 0.3029
[2023-06-25 07:04:07,946] protein loss: 5.2107
[2023-06-25 07:04:07,946] protein percent loss: 0.2879
[2023-06-25 07:04:07,946] Epoch 65/150
[2023-06-25 07:06:37,727] train loss: 0.8267
[2023-06-25 07:06:37,727] cal loss: 35.7685
[2023-06-25 07:06:37,727] cal percent loss: 0.1403
[2023-06-25 07:06:37,727] mass loss: 23.6347
[2023-06-25 07:06:37,728] mass percent loss: 0.1084
[2023-06-25 07:06:37,728] fat loss: 2.5731
[2023-06-25 07:06:37,728] fat percent loss: 0.2026
[2023-06-25 07:06:37,728] carb loss: 3.6322
[2023-06-25 07:06:37,728] carb percent loss: 0.1882
[2023-06-25 07:06:37,728] protein loss: 3.3313
[2023-06-25 07:06:37,728] protein percent loss: 0.1840
[2023-06-25 07:06:37,728] Epoch 65/150
[2023-06-25 07:07:04,222] test loss: 1.2810
[2023-06-25 07:07:04,223] cal loss: 55.9483
[2023-06-25 07:07:04,223] cal percent loss: 0.2194
[2023-06-25 07:07:04,224] mass loss: 31.3083
[2023-06-25 07:07:04,224] mass percent loss: 0.1436
[2023-06-25 07:07:04,224] fat loss: 4.2374
[2023-06-25 07:07:04,224] fat percent loss: 0.3336
[2023-06-25 07:07:04,224] carb loss: 5.4933
[2023-06-25 07:07:04,225] carb percent loss: 0.2846
[2023-06-25 07:07:04,225] protein loss: 5.5182
[2023-06-25 07:07:04,225] protein percent loss: 0.3049
[2023-06-25 07:07:04,225] Epoch 66/150
[2023-06-25 07:09:41,485] train loss: 0.8047
[2023-06-25 07:09:41,485] cal loss: 34.3710
[2023-06-25 07:09:41,485] cal percent loss: 0.1348
[2023-06-25 07:09:41,486] mass loss: 22.3800
[2023-06-25 07:09:41,486] mass percent loss: 0.1027
[2023-06-25 07:09:41,486] fat loss: 2.5435
[2023-06-25 07:09:41,486] fat percent loss: 0.2003
[2023-06-25 07:09:41,486] carb loss: 3.6149
[2023-06-25 07:09:41,486] carb percent loss: 0.1873
[2023-06-25 07:09:41,486] protein loss: 3.2304
[2023-06-25 07:09:41,487] protein percent loss: 0.1785
[2023-06-25 07:09:41,487] Epoch 66/150
[2023-06-25 07:10:06,183] test loss: 1.2081
[2023-06-25 07:10:06,184] cal loss: 51.2613
[2023-06-25 07:10:06,184] cal percent loss: 0.2010
[2023-06-25 07:10:06,184] mass loss: 28.5941
[2023-06-25 07:10:06,184] mass percent loss: 0.1312
[2023-06-25 07:10:06,184] fat loss: 4.0200
[2023-06-25 07:10:06,184] fat percent loss: 0.3165
[2023-06-25 07:10:06,185] carb loss: 5.5795
[2023-06-25 07:10:06,185] carb percent loss: 0.2891
[2023-06-25 07:10:06,185] protein loss: 5.0597
[2023-06-25 07:10:06,185] protein percent loss: 0.2795
[2023-06-25 07:10:06,185] Epoch 67/150
[2023-06-25 07:12:37,258] train loss: 0.8488
[2023-06-25 07:12:37,259] cal loss: 37.2019
[2023-06-25 07:12:37,259] cal percent loss: 0.1459
[2023-06-25 07:12:37,259] mass loss: 24.1105
[2023-06-25 07:12:37,259] mass percent loss: 0.1106
[2023-06-25 07:12:37,259] fat loss: 2.7876
[2023-06-25 07:12:37,259] fat percent loss: 0.2195
[2023-06-25 07:12:37,259] carb loss: 3.5971
[2023-06-25 07:12:37,260] carb percent loss: 0.1864
[2023-06-25 07:12:37,260] protein loss: 3.2961
[2023-06-25 07:12:37,260] protein percent loss: 0.1821
[2023-06-25 07:12:37,260] Epoch 67/150
[2023-06-25 07:13:02,010] test loss: 1.3722
[2023-06-25 07:13:02,011] cal loss: 60.9092
[2023-06-25 07:13:02,011] cal percent loss: 0.2389
[2023-06-25 07:13:02,011] mass loss: 34.5244
[2023-06-25 07:13:02,012] mass percent loss: 0.1584
[2023-06-25 07:13:02,012] fat loss: 4.5725
[2023-06-25 07:13:02,012] fat percent loss: 0.3600
[2023-06-25 07:13:02,012] carb loss: 5.9920
[2023-06-25 07:13:02,012] carb percent loss: 0.3105
[2023-06-25 07:13:02,012] protein loss: 5.5519
[2023-06-25 07:13:02,012] protein percent loss: 0.3067
[2023-06-25 07:13:02,013] Epoch 68/150
[2023-06-25 07:15:32,841] train loss: 0.8238
[2023-06-25 07:15:32,842] cal loss: 34.7981
[2023-06-25 07:15:32,842] cal percent loss: 0.1365
[2023-06-25 07:15:32,842] mass loss: 23.4005
[2023-06-25 07:15:32,842] mass percent loss: 0.1073
[2023-06-25 07:15:32,842] fat loss: 2.6004
[2023-06-25 07:15:32,842] fat percent loss: 0.2048
[2023-06-25 07:15:32,842] carb loss: 3.6677
[2023-06-25 07:15:32,842] carb percent loss: 0.1900
[2023-06-25 07:15:32,843] protein loss: 3.3175
[2023-06-25 07:15:32,843] protein percent loss: 0.1833
[2023-06-25 07:15:32,843] Epoch 68/150
[2023-06-25 07:15:59,356] test loss: 1.2960
[2023-06-25 07:15:59,357] cal loss: 56.8611
[2023-06-25 07:15:59,357] cal percent loss: 0.2230
[2023-06-25 07:15:59,357] mass loss: 33.4536
[2023-06-25 07:15:59,358] mass percent loss: 0.1535
[2023-06-25 07:15:59,358] fat loss: 4.2478
[2023-06-25 07:15:59,358] fat percent loss: 0.3345
[2023-06-25 07:15:59,358] carb loss: 5.4007
[2023-06-25 07:15:59,358] carb percent loss: 0.2798
[2023-06-25 07:15:59,358] protein loss: 5.5404
[2023-06-25 07:15:59,358] protein percent loss: 0.3061
[2023-06-25 07:15:59,358] Epoch 69/150
[2023-06-25 07:18:31,405] train loss: 0.8867
[2023-06-25 07:18:31,406] cal loss: 39.2870
[2023-06-25 07:18:31,406] cal percent loss: 0.1541
[2023-06-25 07:18:31,406] mass loss: 25.0383
[2023-06-25 07:18:31,406] mass percent loss: 0.1149
[2023-06-25 07:18:31,406] fat loss: 2.9487
[2023-06-25 07:18:31,406] fat percent loss: 0.2322
[2023-06-25 07:18:31,406] carb loss: 3.6152
[2023-06-25 07:18:31,406] carb percent loss: 0.1873
[2023-06-25 07:18:31,407] protein loss: 3.4981
[2023-06-25 07:18:31,407] protein percent loss: 0.1933
[2023-06-25 07:18:31,407] Epoch 69/150
[2023-06-25 07:18:56,711] test loss: 1.2844
[2023-06-25 07:18:56,712] cal loss: 55.3149
[2023-06-25 07:18:56,712] cal percent loss: 0.2169
[2023-06-25 07:18:56,712] mass loss: 36.2087
[2023-06-25 07:18:56,712] mass percent loss: 0.1661
[2023-06-25 07:18:56,712] fat loss: 3.8731
[2023-06-25 07:18:56,713] fat percent loss: 0.3050
[2023-06-25 07:18:56,713] carb loss: 5.9065
[2023-06-25 07:18:56,713] carb percent loss: 0.3060
[2023-06-25 07:18:56,713] protein loss: 5.2130
[2023-06-25 07:18:56,713] protein percent loss: 0.2880
[2023-06-25 07:18:56,713] Epoch 70/150
[2023-06-25 07:21:31,860] train loss: 0.8740
[2023-06-25 07:21:31,861] cal loss: 39.2027
[2023-06-25 07:21:31,861] cal percent loss: 0.1537
[2023-06-25 07:21:31,861] mass loss: 24.1485
[2023-06-25 07:21:31,861] mass percent loss: 0.1108
[2023-06-25 07:21:31,861] fat loss: 2.9214
[2023-06-25 07:21:31,862] fat percent loss: 0.2300
[2023-06-25 07:21:31,862] carb loss: 3.6661
[2023-06-25 07:21:31,862] carb percent loss: 0.1900
[2023-06-25 07:21:31,862] protein loss: 3.3550
[2023-06-25 07:21:31,862] protein percent loss: 0.1854
[2023-06-25 07:21:31,862] Epoch 70/150
[2023-06-25 07:21:58,445] test loss: 1.2703
[2023-06-25 07:21:58,446] cal loss: 58.0598
[2023-06-25 07:21:58,446] cal percent loss: 0.2277
[2023-06-25 07:21:58,446] mass loss: 28.7279
[2023-06-25 07:21:58,447] mass percent loss: 0.1318
[2023-06-25 07:21:58,447] fat loss: 4.2747
[2023-06-25 07:21:58,447] fat percent loss: 0.3366
[2023-06-25 07:21:58,447] carb loss: 5.6643
[2023-06-25 07:21:58,447] carb percent loss: 0.2935
[2023-06-25 07:21:58,447] protein loss: 5.2175
[2023-06-25 07:21:58,447] protein percent loss: 0.2883
[2023-06-25 07:21:58,447] Epoch 71/150
[2023-06-25 07:24:34,514] train loss: 0.8349
[2023-06-25 07:24:34,515] cal loss: 36.1053
[2023-06-25 07:24:34,515] cal percent loss: 0.1416
[2023-06-25 07:24:34,515] mass loss: 23.2873
[2023-06-25 07:24:34,515] mass percent loss: 0.1068
[2023-06-25 07:24:34,516] fat loss: 2.7964
[2023-06-25 07:24:34,516] fat percent loss: 0.2202
[2023-06-25 07:24:34,516] carb loss: 3.5559
[2023-06-25 07:24:34,516] carb percent loss: 0.1842
[2023-06-25 07:24:34,516] protein loss: 3.2433
[2023-06-25 07:24:34,516] protein percent loss: 0.1792
[2023-06-25 07:24:34,516] Epoch 71/150
[2023-06-25 07:24:58,277] test loss: 1.2238
[2023-06-25 07:24:58,277] cal loss: 51.2816
[2023-06-25 07:24:58,278] cal percent loss: 0.2011
[2023-06-25 07:24:58,278] mass loss: 32.3535
[2023-06-25 07:24:58,278] mass percent loss: 0.1484
[2023-06-25 07:24:58,278] fat loss: 3.7685
[2023-06-25 07:24:58,278] fat percent loss: 0.2967
[2023-06-25 07:24:58,278] carb loss: 5.7625
[2023-06-25 07:24:58,278] carb percent loss: 0.2986
[2023-06-25 07:24:58,278] protein loss: 5.1238
[2023-06-25 07:24:58,278] protein percent loss: 0.2831
[2023-06-25 07:24:58,278] Epoch 72/150
[2023-06-25 07:27:24,884] train loss: 0.7961
[2023-06-25 07:27:24,885] cal loss: 33.6712
[2023-06-25 07:27:24,885] cal percent loss: 0.1320
[2023-06-25 07:27:24,885] mass loss: 22.4050
[2023-06-25 07:27:24,885] mass percent loss: 0.1028
[2023-06-25 07:27:24,885] fat loss: 2.5855
[2023-06-25 07:27:24,885] fat percent loss: 0.2036
[2023-06-25 07:27:24,886] carb loss: 3.4783
[2023-06-25 07:27:24,886] carb percent loss: 0.1802
[2023-06-25 07:27:24,886] protein loss: 3.1782
[2023-06-25 07:27:24,886] protein percent loss: 0.1756
[2023-06-25 07:27:24,886] Epoch 72/150
[2023-06-25 07:27:51,458] test loss: 1.2653
[2023-06-25 07:27:51,459] cal loss: 55.5843
[2023-06-25 07:27:51,459] cal percent loss: 0.2180
[2023-06-25 07:27:51,459] mass loss: 33.3814
[2023-06-25 07:27:51,460] mass percent loss: 0.1531
[2023-06-25 07:27:51,460] fat loss: 3.8154
[2023-06-25 07:27:51,460] fat percent loss: 0.3004
[2023-06-25 07:27:51,460] carb loss: 5.3896
[2023-06-25 07:27:51,460] carb percent loss: 0.2793
[2023-06-25 07:27:51,460] protein loss: 5.7090
[2023-06-25 07:27:51,460] protein percent loss: 0.3154
[2023-06-25 07:27:51,461] Epoch 73/150
[2023-06-25 07:30:21,665] train loss: 0.7874
[2023-06-25 07:30:21,666] cal loss: 33.8891
[2023-06-25 07:30:21,666] cal percent loss: 0.1329
[2023-06-25 07:30:21,666] mass loss: 22.5445
[2023-06-25 07:30:21,666] mass percent loss: 0.1034
[2023-06-25 07:30:21,666] fat loss: 2.5153
[2023-06-25 07:30:21,666] fat percent loss: 0.1981
[2023-06-25 07:30:21,666] carb loss: 3.4504
[2023-06-25 07:30:21,666] carb percent loss: 0.1788
[2023-06-25 07:30:21,666] protein loss: 3.0962
[2023-06-25 07:30:21,667] protein percent loss: 0.1711
[2023-06-25 07:30:21,667] Epoch 73/150
[2023-06-25 07:30:48,580] test loss: 1.1927
[2023-06-25 07:30:48,581] cal loss: 49.4026
[2023-06-25 07:30:48,581] cal percent loss: 0.1937
[2023-06-25 07:30:48,581] mass loss: 27.6383
[2023-06-25 07:30:48,581] mass percent loss: 0.1268
[2023-06-25 07:30:48,581] fat loss: 4.2083
[2023-06-25 07:30:48,581] fat percent loss: 0.3314
[2023-06-25 07:30:48,581] carb loss: 5.3919
[2023-06-25 07:30:48,581] carb percent loss: 0.2794
[2023-06-25 07:30:48,581] protein loss: 4.9248
[2023-06-25 07:30:48,581] protein percent loss: 0.2721
[2023-06-25 07:30:48,581] Epoch 74/150
[2023-06-25 07:33:18,839] train loss: 0.8021
[2023-06-25 07:33:18,840] cal loss: 34.7455
[2023-06-25 07:33:18,840] cal percent loss: 0.1363
[2023-06-25 07:33:18,840] mass loss: 23.4380
[2023-06-25 07:33:18,841] mass percent loss: 0.1075
[2023-06-25 07:33:18,843] fat loss: 2.6134
[2023-06-25 07:33:18,843] fat percent loss: 0.2058
[2023-06-25 07:33:18,843] carb loss: 3.3208
[2023-06-25 07:33:18,843] carb percent loss: 0.1721
[2023-06-25 07:33:18,843] protein loss: 3.1737
[2023-06-25 07:33:18,843] protein percent loss: 0.1753
[2023-06-25 07:33:18,843] Epoch 74/150
[2023-06-25 07:33:43,406] test loss: 1.1957
[2023-06-25 07:33:43,407] cal loss: 49.2196
[2023-06-25 07:33:43,407] cal percent loss: 0.1930
[2023-06-25 07:33:43,407] mass loss: 30.0582
[2023-06-25 07:33:43,407] mass percent loss: 0.1379
[2023-06-25 07:33:43,407] fat loss: 3.7870
[2023-06-25 07:33:43,407] fat percent loss: 0.2982
[2023-06-25 07:33:43,407] carb loss: 5.7766
[2023-06-25 07:33:43,408] carb percent loss: 0.2993
[2023-06-25 07:33:43,408] protein loss: 4.9890
[2023-06-25 07:33:43,408] protein percent loss: 0.2756
[2023-06-25 07:33:43,408] Epoch 75/150
[2023-06-25 07:36:15,754] train loss: 0.7863
[2023-06-25 07:36:15,754] cal loss: 34.4213
[2023-06-25 07:36:15,754] cal percent loss: 0.1350
[2023-06-25 07:36:15,754] mass loss: 23.0019
[2023-06-25 07:36:15,754] mass percent loss: 0.1055
[2023-06-25 07:36:15,754] fat loss: 2.4629
[2023-06-25 07:36:15,755] fat percent loss: 0.1939
[2023-06-25 07:36:15,755] carb loss: 3.3797
[2023-06-25 07:36:15,755] carb percent loss: 0.1751
[2023-06-25 07:36:15,755] protein loss: 3.1116
[2023-06-25 07:36:15,755] protein percent loss: 0.1719
[2023-06-25 07:36:15,755] Epoch 75/150
[2023-06-25 07:36:40,703] test loss: 1.2317
[2023-06-25 07:36:40,703] cal loss: 54.1573
[2023-06-25 07:36:40,703] cal percent loss: 0.2124
[2023-06-25 07:36:40,703] mass loss: 29.2127
[2023-06-25 07:36:40,703] mass percent loss: 0.1340
[2023-06-25 07:36:40,703] fat loss: 3.7882
[2023-06-25 07:36:40,703] fat percent loss: 0.2983
[2023-06-25 07:36:40,703] carb loss: 5.7944
[2023-06-25 07:36:40,703] carb percent loss: 0.3002
[2023-06-25 07:36:40,703] protein loss: 5.3499
[2023-06-25 07:36:40,703] protein percent loss: 0.2956
[2023-06-25 07:36:40,704] Epoch 76/150
[2023-06-25 07:39:12,013] train loss: 0.7426
[2023-06-25 07:39:12,014] cal loss: 31.4601
[2023-06-25 07:39:12,014] cal percent loss: 0.1234
[2023-06-25 07:39:12,014] mass loss: 21.2938
[2023-06-25 07:39:12,014] mass percent loss: 0.0977
[2023-06-25 07:39:12,014] fat loss: 2.3512
[2023-06-25 07:39:12,014] fat percent loss: 0.1851
[2023-06-25 07:39:12,014] carb loss: 3.2370
[2023-06-25 07:39:12,015] carb percent loss: 0.1677
[2023-06-25 07:39:12,015] protein loss: 3.0106
[2023-06-25 07:39:12,015] protein percent loss: 0.1663
[2023-06-25 07:39:12,015] Epoch 76/150
[2023-06-25 07:39:38,265] test loss: 1.2066
[2023-06-25 07:39:38,266] cal loss: 50.6750
[2023-06-25 07:39:38,266] cal percent loss: 0.1987
[2023-06-25 07:39:38,266] mass loss: 31.0593
[2023-06-25 07:39:38,266] mass percent loss: 0.1425
[2023-06-25 07:39:38,266] fat loss: 3.9430
[2023-06-25 07:39:38,267] fat percent loss: 0.3105
[2023-06-25 07:39:38,267] carb loss: 5.4287
[2023-06-25 07:39:38,267] carb percent loss: 0.2813
[2023-06-25 07:39:38,267] protein loss: 5.0303
[2023-06-25 07:39:38,267] protein percent loss: 0.2779
[2023-06-25 07:39:38,267] Epoch 77/150
[2023-06-25 07:42:01,792] train loss: 0.7520
[2023-06-25 07:42:01,793] cal loss: 32.7723
[2023-06-25 07:42:01,793] cal percent loss: 0.1285
[2023-06-25 07:42:01,793] mass loss: 21.7045
[2023-06-25 07:42:01,793] mass percent loss: 0.0996
[2023-06-25 07:42:01,793] fat loss: 2.3828
[2023-06-25 07:42:01,793] fat percent loss: 0.1876
[2023-06-25 07:42:01,793] carb loss: 3.2981
[2023-06-25 07:42:01,793] carb percent loss: 0.1709
[2023-06-25 07:42:01,794] protein loss: 2.9260
[2023-06-25 07:42:01,794] protein percent loss: 0.1617
[2023-06-25 07:42:01,794] Epoch 77/150
[2023-06-25 07:42:28,024] test loss: 1.3813
[2023-06-25 07:42:28,024] cal loss: 61.8286
[2023-06-25 07:42:28,025] cal percent loss: 0.2425
[2023-06-25 07:42:28,027] mass loss: 38.3230
[2023-06-25 07:42:28,027] mass percent loss: 0.1758
[2023-06-25 07:42:28,027] fat loss: 4.1879
[2023-06-25 07:42:28,027] fat percent loss: 0.3298
[2023-06-25 07:42:28,027] carb loss: 5.9942
[2023-06-25 07:42:28,027] carb percent loss: 0.3106
[2023-06-25 07:42:28,027] protein loss: 5.7589
[2023-06-25 07:42:28,027] protein percent loss: 0.3182
[2023-06-25 07:42:28,027] Epoch 78/150
[2023-06-25 07:45:03,340] train loss: 0.7388
[2023-06-25 07:45:03,341] cal loss: 31.9060
[2023-06-25 07:45:03,341] cal percent loss: 0.1251
[2023-06-25 07:45:03,341] mass loss: 21.5158
[2023-06-25 07:45:03,341] mass percent loss: 0.0987
[2023-06-25 07:45:03,341] fat loss: 2.3656
[2023-06-25 07:45:03,341] fat percent loss: 0.1863
[2023-06-25 07:45:03,341] carb loss: 3.1650
[2023-06-25 07:45:03,341] carb percent loss: 0.1640
[2023-06-25 07:45:03,341] protein loss: 2.9084
[2023-06-25 07:45:03,341] protein percent loss: 0.1607
[2023-06-25 07:45:03,341] Epoch 78/150
[2023-06-25 07:45:31,351] test loss: 1.2538
[2023-06-25 07:45:31,352] cal loss: 57.8333
[2023-06-25 07:45:31,352] cal percent loss: 0.2268
[2023-06-25 07:45:31,352] mass loss: 30.0232
[2023-06-25 07:45:31,352] mass percent loss: 0.1377
[2023-06-25 07:45:31,353] fat loss: 3.9117
[2023-06-25 07:45:31,353] fat percent loss: 0.3080
[2023-06-25 07:45:31,353] carb loss: 5.2570
[2023-06-25 07:45:31,353] carb percent loss: 0.2724
[2023-06-25 07:45:31,353] protein loss: 5.6608
[2023-06-25 07:45:31,353] protein percent loss: 0.3128
[2023-06-25 07:45:31,353] Epoch 79/150
[2023-06-25 07:48:04,516] train loss: 0.7430
[2023-06-25 07:48:04,517] cal loss: 31.1324
[2023-06-25 07:48:04,517] cal percent loss: 0.1221
[2023-06-25 07:48:04,517] mass loss: 21.6567
[2023-06-25 07:48:04,517] mass percent loss: 0.0993
[2023-06-25 07:48:04,517] fat loss: 2.3485
[2023-06-25 07:48:04,517] fat percent loss: 0.1849
[2023-06-25 07:48:04,517] carb loss: 3.3028
[2023-06-25 07:48:04,517] carb percent loss: 0.1711
[2023-06-25 07:48:04,518] protein loss: 2.9463
[2023-06-25 07:48:04,518] protein percent loss: 0.1628
[2023-06-25 07:48:04,518] Epoch 79/150
[2023-06-25 07:48:29,398] test loss: 1.2128
[2023-06-25 07:48:29,399] cal loss: 49.6424
[2023-06-25 07:48:29,399] cal percent loss: 0.1947
[2023-06-25 07:48:29,399] mass loss: 32.6920
[2023-06-25 07:48:29,399] mass percent loss: 0.1500
[2023-06-25 07:48:29,399] fat loss: 3.6081
[2023-06-25 07:48:29,400] fat percent loss: 0.2841
[2023-06-25 07:48:29,400] carb loss: 5.8696
[2023-06-25 07:48:29,400] carb percent loss: 0.3041
[2023-06-25 07:48:29,400] protein loss: 5.1539
[2023-06-25 07:48:29,400] protein percent loss: 0.2847
[2023-06-25 07:48:29,400] Epoch 80/150
[2023-06-25 07:50:50,187] train loss: 0.7416
[2023-06-25 07:50:50,188] cal loss: 32.4050
[2023-06-25 07:50:50,188] cal percent loss: 0.1271
[2023-06-25 07:50:50,188] mass loss: 20.9473
[2023-06-25 07:50:50,188] mass percent loss: 0.0961
[2023-06-25 07:50:50,188] fat loss: 2.4340
[2023-06-25 07:50:50,188] fat percent loss: 0.1917
[2023-06-25 07:50:50,188] carb loss: 3.1886
[2023-06-25 07:50:50,188] carb percent loss: 0.1652
[2023-06-25 07:50:50,188] protein loss: 2.8646
[2023-06-25 07:50:50,188] protein percent loss: 0.1583
[2023-06-25 07:50:50,188] Epoch 80/150
[2023-06-25 07:51:13,206] test loss: 1.3206
[2023-06-25 07:51:13,207] cal loss: 56.8807
[2023-06-25 07:51:13,207] cal percent loss: 0.2231
[2023-06-25 07:51:13,207] mass loss: 34.2859
[2023-06-25 07:51:13,207] mass percent loss: 0.1573
[2023-06-25 07:51:13,207] fat loss: 4.2180
[2023-06-25 07:51:13,207] fat percent loss: 0.3321
[2023-06-25 07:51:13,207] carb loss: 5.5594
[2023-06-25 07:51:13,207] carb percent loss: 0.2881
[2023-06-25 07:51:13,207] protein loss: 5.8344
[2023-06-25 07:51:13,207] protein percent loss: 0.3223
[2023-06-25 07:51:13,208] Epoch 81/150
[2023-06-25 07:53:48,222] train loss: 0.7168
[2023-06-25 07:53:48,222] cal loss: 30.3229
[2023-06-25 07:53:48,222] cal percent loss: 0.1189
[2023-06-25 07:53:48,222] mass loss: 20.6601
[2023-06-25 07:53:48,223] mass percent loss: 0.0948
[2023-06-25 07:53:48,223] fat loss: 2.2988
[2023-06-25 07:53:48,223] fat percent loss: 0.1810
[2023-06-25 07:53:48,223] carb loss: 3.1328
[2023-06-25 07:53:48,223] carb percent loss: 0.1623
[2023-06-25 07:53:48,223] protein loss: 2.8448
[2023-06-25 07:53:48,223] protein percent loss: 0.1572
[2023-06-25 07:53:48,223] Epoch 81/150
[2023-06-25 07:54:14,194] test loss: 1.3436
[2023-06-25 07:54:14,194] cal loss: 62.9137
[2023-06-25 07:54:14,194] cal percent loss: 0.2467
[2023-06-25 07:54:14,194] mass loss: 30.4166
[2023-06-25 07:54:14,194] mass percent loss: 0.1395
[2023-06-25 07:54:14,195] fat loss: 4.4534
[2023-06-25 07:54:14,195] fat percent loss: 0.3507
[2023-06-25 07:54:14,195] carb loss: 6.1650
[2023-06-25 07:54:14,195] carb percent loss: 0.3194
[2023-06-25 07:54:14,195] protein loss: 5.3233
[2023-06-25 07:54:14,195] protein percent loss: 0.2941
[2023-06-25 07:54:14,195] Epoch 82/150
[2023-06-25 07:56:40,809] train loss: 0.7709
[2023-06-25 07:56:40,810] cal loss: 34.7392
[2023-06-25 07:56:40,810] cal percent loss: 0.1362
[2023-06-25 07:56:40,810] mass loss: 22.2544
[2023-06-25 07:56:40,810] mass percent loss: 0.1021
[2023-06-25 07:56:40,810] fat loss: 2.4650
[2023-06-25 07:56:40,811] fat percent loss: 0.1941
[2023-06-25 07:56:40,811] carb loss: 3.2458
[2023-06-25 07:56:40,811] carb percent loss: 0.1682
[2023-06-25 07:56:40,811] protein loss: 2.9822
[2023-06-25 07:56:40,811] protein percent loss: 0.1648
[2023-06-25 07:56:40,811] Epoch 82/150
[2023-06-25 07:57:08,049] test loss: 1.2562
[2023-06-25 07:57:08,050] cal loss: 59.3220
[2023-06-25 07:57:08,050] cal percent loss: 0.2326
[2023-06-25 07:57:08,051] mass loss: 28.0059
[2023-06-25 07:57:08,051] mass percent loss: 0.1285
[2023-06-25 07:57:08,051] fat loss: 4.2477
[2023-06-25 07:57:08,051] fat percent loss: 0.3345
[2023-06-25 07:57:08,051] carb loss: 5.5372
[2023-06-25 07:57:08,051] carb percent loss: 0.2869
[2023-06-25 07:57:08,051] protein loss: 5.0626
[2023-06-25 07:57:08,052] protein percent loss: 0.2797
[2023-06-25 07:57:08,052] Epoch 83/150
[2023-06-25 07:59:40,031] train loss: 0.7371
[2023-06-25 07:59:40,031] cal loss: 31.4859
[2023-06-25 07:59:40,031] cal percent loss: 0.1235
[2023-06-25 07:59:40,031] mass loss: 20.9606
[2023-06-25 07:59:40,032] mass percent loss: 0.0961
[2023-06-25 07:59:40,032] fat loss: 2.4055
[2023-06-25 07:59:40,032] fat percent loss: 0.1894
[2023-06-25 07:59:40,032] carb loss: 3.2819
[2023-06-25 07:59:40,032] carb percent loss: 0.1700
[2023-06-25 07:59:40,032] protein loss: 2.8144
[2023-06-25 07:59:40,032] protein percent loss: 0.1555
[2023-06-25 07:59:40,032] Epoch 83/150
[2023-06-25 08:00:05,894] test loss: 1.2102
[2023-06-25 08:00:05,895] cal loss: 52.2537
[2023-06-25 08:00:05,895] cal percent loss: 0.2049
[2023-06-25 08:00:05,895] mass loss: 29.1679
[2023-06-25 08:00:05,896] mass percent loss: 0.1338
[2023-06-25 08:00:05,896] fat loss: 3.8799
[2023-06-25 08:00:05,896] fat percent loss: 0.3055
[2023-06-25 08:00:05,896] carb loss: 5.4018
[2023-06-25 08:00:05,896] carb percent loss: 0.2799
[2023-06-25 08:00:05,896] protein loss: 5.3136
[2023-06-25 08:00:05,896] protein percent loss: 0.2936
[2023-06-25 08:00:05,896] Epoch 84/150
[2023-06-25 08:02:36,215] train loss: 0.7128
[2023-06-25 08:02:36,216] cal loss: 29.9578
[2023-06-25 08:02:36,216] cal percent loss: 0.1175
[2023-06-25 08:02:36,216] mass loss: 21.0343
[2023-06-25 08:02:36,216] mass percent loss: 0.0965
[2023-06-25 08:02:36,216] fat loss: 2.2878
[2023-06-25 08:02:36,216] fat percent loss: 0.1801
[2023-06-25 08:02:36,217] carb loss: 3.1046
[2023-06-25 08:02:36,217] carb percent loss: 0.1609
[2023-06-25 08:02:36,217] protein loss: 2.7916
[2023-06-25 08:02:36,217] protein percent loss: 0.1542
[2023-06-25 08:02:36,217] Epoch 84/150
[2023-06-25 08:03:01,738] test loss: 1.3746
[2023-06-25 08:03:01,738] cal loss: 63.0717
[2023-06-25 08:03:01,739] cal percent loss: 0.2473
[2023-06-25 08:03:01,739] mass loss: 36.8590
[2023-06-25 08:03:01,739] mass percent loss: 0.1691
[2023-06-25 08:03:01,739] fat loss: 4.2392
[2023-06-25 08:03:01,739] fat percent loss: 0.3338
[2023-06-25 08:03:01,739] carb loss: 6.0999
[2023-06-25 08:03:01,739] carb percent loss: 0.3161
[2023-06-25 08:03:01,739] protein loss: 5.5173
[2023-06-25 08:03:01,739] protein percent loss: 0.3048
[2023-06-25 08:03:01,740] Epoch 85/150
[2023-06-25 08:05:35,769] train loss: 0.7132
[2023-06-25 08:05:35,769] cal loss: 30.7705
[2023-06-25 08:05:35,769] cal percent loss: 0.1207
[2023-06-25 08:05:35,770] mass loss: 21.4126
[2023-06-25 08:05:35,770] mass percent loss: 0.0982
[2023-06-25 08:05:35,770] fat loss: 2.1762
[2023-06-25 08:05:35,770] fat percent loss: 0.1714
[2023-06-25 08:05:35,770] carb loss: 3.1837
[2023-06-25 08:05:35,770] carb percent loss: 0.1650
[2023-06-25 08:05:35,770] protein loss: 2.7771
[2023-06-25 08:05:35,770] protein percent loss: 0.1534
[2023-06-25 08:05:35,770] Epoch 85/150
[2023-06-25 08:06:02,248] test loss: 1.1970
[2023-06-25 08:06:02,249] cal loss: 53.2300
[2023-06-25 08:06:02,249] cal percent loss: 0.2087
[2023-06-25 08:06:02,249] mass loss: 29.1761
[2023-06-25 08:06:02,249] mass percent loss: 0.1338
[2023-06-25 08:06:02,249] fat loss: 3.7018
[2023-06-25 08:06:02,250] fat percent loss: 0.2915
[2023-06-25 08:06:02,250] carb loss: 5.6573
[2023-06-25 08:06:02,250] carb percent loss: 0.2931
[2023-06-25 08:06:02,250] protein loss: 4.9932
[2023-06-25 08:06:02,250] protein percent loss: 0.2759
[2023-06-25 08:06:02,250] Epoch 86/150
[2023-06-25 08:08:32,563] train loss: 0.6934
[2023-06-25 08:08:32,564] cal loss: 29.4665
[2023-06-25 08:08:32,564] cal percent loss: 0.1156
[2023-06-25 08:08:32,564] mass loss: 20.6150
[2023-06-25 08:08:32,564] mass percent loss: 0.0946
[2023-06-25 08:08:32,564] fat loss: 2.2022
[2023-06-25 08:08:32,564] fat percent loss: 0.1734
[2023-06-25 08:08:32,564] carb loss: 3.0820
[2023-06-25 08:08:32,564] carb percent loss: 0.1597
[2023-06-25 08:08:32,565] protein loss: 2.6476
[2023-06-25 08:08:32,565] protein percent loss: 0.1463
[2023-06-25 08:08:32,565] Epoch 86/150
[2023-06-25 08:08:57,651] test loss: 1.3351
[2023-06-25 08:08:57,652] cal loss: 60.8986
[2023-06-25 08:08:57,652] cal percent loss: 0.2388
[2023-06-25 08:08:57,652] mass loss: 31.1744
[2023-06-25 08:08:57,652] mass percent loss: 0.1430
[2023-06-25 08:08:57,652] fat loss: 4.3380
[2023-06-25 08:08:57,652] fat percent loss: 0.3416
[2023-06-25 08:08:57,652] carb loss: 5.8130
[2023-06-25 08:08:57,652] carb percent loss: 0.3012
[2023-06-25 08:08:57,653] protein loss: 5.7345
[2023-06-25 08:08:57,653] protein percent loss: 0.3168
[2023-06-25 08:08:57,653] Epoch 87/150
[2023-06-25 08:11:34,232] train loss: 0.6910
[2023-06-25 08:11:34,233] cal loss: 30.1676
[2023-06-25 08:11:34,233] cal percent loss: 0.1183
[2023-06-25 08:11:34,234] mass loss: 20.4019
[2023-06-25 08:11:34,234] mass percent loss: 0.0936
[2023-06-25 08:11:34,234] fat loss: 2.2100
[2023-06-25 08:11:34,234] fat percent loss: 0.1740
[2023-06-25 08:11:34,234] carb loss: 2.8918
[2023-06-25 08:11:34,234] carb percent loss: 0.1498
[2023-06-25 08:11:34,234] protein loss: 2.7223
[2023-06-25 08:11:34,234] protein percent loss: 0.1504
[2023-06-25 08:11:34,234] Epoch 87/150
[2023-06-25 08:12:02,011] test loss: 1.3410
[2023-06-25 08:12:02,012] cal loss: 57.9701
[2023-06-25 08:12:02,013] cal percent loss: 0.2273
[2023-06-25 08:12:02,013] mass loss: 36.9923
[2023-06-25 08:12:02,013] mass percent loss: 0.1697
[2023-06-25 08:12:02,013] fat loss: 4.0631
[2023-06-25 08:12:02,013] fat percent loss: 0.3199
[2023-06-25 08:12:02,013] carb loss: 6.0352
[2023-06-25 08:12:02,013] carb percent loss: 0.3127
[2023-06-25 08:12:02,013] protein loss: 5.6133
[2023-06-25 08:12:02,014] protein percent loss: 0.3101
[2023-06-25 08:12:02,014] Epoch 88/150
[2023-06-25 08:14:36,138] train loss: 0.6857
[2023-06-25 08:14:36,139] cal loss: 28.8414
[2023-06-25 08:14:36,139] cal percent loss: 0.1131
[2023-06-25 08:14:36,139] mass loss: 20.3643
[2023-06-25 08:14:36,139] mass percent loss: 0.0934
[2023-06-25 08:14:36,139] fat loss: 2.1584
[2023-06-25 08:14:36,139] fat percent loss: 0.1699
[2023-06-25 08:14:36,139] carb loss: 3.0056
[2023-06-25 08:14:36,139] carb percent loss: 0.1557
[2023-06-25 08:14:36,139] protein loss: 2.7147
[2023-06-25 08:14:36,139] protein percent loss: 0.1500
[2023-06-25 08:14:36,140] Epoch 88/150
[2023-06-25 08:14:59,119] test loss: 1.2518
[2023-06-25 08:14:59,120] cal loss: 54.0728
[2023-06-25 08:14:59,120] cal percent loss: 0.2121
[2023-06-25 08:14:59,120] mass loss: 29.5948
[2023-06-25 08:14:59,120] mass percent loss: 0.1358
[2023-06-25 08:14:59,120] fat loss: 3.9355
[2023-06-25 08:14:59,121] fat percent loss: 0.3099
[2023-06-25 08:14:59,121] carb loss: 5.6569
[2023-06-25 08:14:59,121] carb percent loss: 0.2931
[2023-06-25 08:14:59,121] protein loss: 5.6199
[2023-06-25 08:14:59,121] protein percent loss: 0.3105
[2023-06-25 08:14:59,121] Epoch 89/150
[2023-06-25 08:17:33,284] train loss: 0.6801
[2023-06-25 08:17:33,285] cal loss: 28.8556
[2023-06-25 08:17:33,285] cal percent loss: 0.1132
[2023-06-25 08:17:33,285] mass loss: 20.3527
[2023-06-25 08:17:33,285] mass percent loss: 0.0934
[2023-06-25 08:17:33,285] fat loss: 2.0888
[2023-06-25 08:17:33,285] fat percent loss: 0.1645
[2023-06-25 08:17:33,286] carb loss: 2.9861
[2023-06-25 08:17:33,286] carb percent loss: 0.1547
[2023-06-25 08:17:33,286] protein loss: 2.7248
[2023-06-25 08:17:33,286] protein percent loss: 0.1505
[2023-06-25 08:17:33,286] Epoch 89/150
[2023-06-25 08:17:57,048] test loss: 1.1945
[2023-06-25 08:17:57,049] cal loss: 52.4498
[2023-06-25 08:17:57,049] cal percent loss: 0.2057
[2023-06-25 08:17:57,049] mass loss: 27.3428
[2023-06-25 08:17:57,049] mass percent loss: 0.1254
[2023-06-25 08:17:57,049] fat loss: 3.8953
[2023-06-25 08:17:57,049] fat percent loss: 0.3067
[2023-06-25 08:17:57,049] carb loss: 5.2908
[2023-06-25 08:17:57,050] carb percent loss: 0.2741
[2023-06-25 08:17:57,050] protein loss: 5.2817
[2023-06-25 08:17:57,050] protein percent loss: 0.2918
[2023-06-25 08:17:57,050] Epoch 90/150
[2023-06-25 08:20:19,744] train loss: 0.6755
[2023-06-25 08:20:19,745] cal loss: 29.4095
[2023-06-25 08:20:19,745] cal percent loss: 0.1153
[2023-06-25 08:20:19,745] mass loss: 19.9362
[2023-06-25 08:20:19,745] mass percent loss: 0.0915
[2023-06-25 08:20:19,745] fat loss: 2.1089
[2023-06-25 08:20:19,745] fat percent loss: 0.1661
[2023-06-25 08:20:19,745] carb loss: 2.9136
[2023-06-25 08:20:19,745] carb percent loss: 0.1510
[2023-06-25 08:20:19,746] protein loss: 2.6679
[2023-06-25 08:20:19,746] protein percent loss: 0.1474
[2023-06-25 08:20:19,746] Epoch 90/150
[2023-06-25 08:20:44,321] test loss: 1.1718
[2023-06-25 08:20:44,322] cal loss: 51.6502
[2023-06-25 08:20:44,322] cal percent loss: 0.2025
[2023-06-25 08:20:44,323] mass loss: 28.7694
[2023-06-25 08:20:44,323] mass percent loss: 0.1320
[2023-06-25 08:20:44,323] fat loss: 3.3773
[2023-06-25 08:20:44,323] fat percent loss: 0.2659
[2023-06-25 08:20:44,323] carb loss: 5.5837
[2023-06-25 08:20:44,323] carb percent loss: 0.2893
[2023-06-25 08:20:44,323] protein loss: 5.2347
[2023-06-25 08:20:44,324] protein percent loss: 0.2892
[2023-06-25 08:20:44,324] Epoch 91/150
[2023-06-25 08:23:16,216] train loss: 0.6636
[2023-06-25 08:23:16,216] cal loss: 28.3145
[2023-06-25 08:23:16,216] cal percent loss: 0.1110
[2023-06-25 08:23:16,217] mass loss: 19.3432
[2023-06-25 08:23:16,217] mass percent loss: 0.0887
[2023-06-25 08:23:16,217] fat loss: 2.1200
[2023-06-25 08:23:16,217] fat percent loss: 0.1669
[2023-06-25 08:23:16,217] carb loss: 2.9219
[2023-06-25 08:23:16,217] carb percent loss: 0.1514
[2023-06-25 08:23:16,217] protein loss: 2.5772
[2023-06-25 08:23:16,217] protein percent loss: 0.1424
[2023-06-25 08:23:16,217] Epoch 91/150
[2023-06-25 08:23:40,037] test loss: 1.2716
[2023-06-25 08:23:40,037] cal loss: 55.7819
[2023-06-25 08:23:40,037] cal percent loss: 0.2188
[2023-06-25 08:23:40,038] mass loss: 33.4950
[2023-06-25 08:23:40,038] mass percent loss: 0.1536
[2023-06-25 08:23:40,038] fat loss: 4.0120
[2023-06-25 08:23:40,038] fat percent loss: 0.3159
[2023-06-25 08:23:40,038] carb loss: 5.7910
[2023-06-25 08:23:40,038] carb percent loss: 0.3001
[2023-06-25 08:23:40,038] protein loss: 5.1442
[2023-06-25 08:23:40,039] protein percent loss: 0.2842
[2023-06-25 08:23:40,039] Epoch 92/150
[2023-06-25 08:26:10,856] train loss: 0.6764
[2023-06-25 08:26:10,857] cal loss: 28.7165
[2023-06-25 08:26:10,857] cal percent loss: 0.1126
[2023-06-25 08:26:10,857] mass loss: 19.9205
[2023-06-25 08:26:10,857] mass percent loss: 0.0914
[2023-06-25 08:26:10,857] fat loss: 2.1109
[2023-06-25 08:26:10,857] fat percent loss: 0.1662
[2023-06-25 08:26:10,857] carb loss: 2.9674
[2023-06-25 08:26:10,858] carb percent loss: 0.1537
[2023-06-25 08:26:10,858] protein loss: 2.6993
[2023-06-25 08:26:10,858] protein percent loss: 0.1491
[2023-06-25 08:26:10,858] Epoch 92/150
[2023-06-25 08:26:38,326] test loss: 1.3700
[2023-06-25 08:26:38,327] cal loss: 62.0459
[2023-06-25 08:26:38,327] cal percent loss: 0.2433
[2023-06-25 08:26:38,327] mass loss: 35.8785
[2023-06-25 08:26:38,328] mass percent loss: 0.1646
[2023-06-25 08:26:38,328] fat loss: 4.2936
[2023-06-25 08:26:38,328] fat percent loss: 0.3381
[2023-06-25 08:26:38,328] carb loss: 5.9709
[2023-06-25 08:26:38,328] carb percent loss: 0.3094
[2023-06-25 08:26:38,328] protein loss: 5.6762
[2023-06-25 08:26:38,328] protein percent loss: 0.3136
[2023-06-25 08:26:38,329] Epoch 93/150
[2023-06-25 08:29:09,457] train loss: 0.6436
[2023-06-25 08:29:09,458] cal loss: 26.6710
[2023-06-25 08:29:09,459] cal percent loss: 0.1046
[2023-06-25 08:29:09,459] mass loss: 19.1071
[2023-06-25 08:29:09,459] mass percent loss: 0.0876
[2023-06-25 08:29:09,459] fat loss: 2.0460
[2023-06-25 08:29:09,459] fat percent loss: 0.1611
[2023-06-25 08:29:09,459] carb loss: 2.8423
[2023-06-25 08:29:09,459] carb percent loss: 0.1473
[2023-06-25 08:29:09,460] protein loss: 2.5352
[2023-06-25 08:29:09,460] protein percent loss: 0.1401
[2023-06-25 08:29:09,460] Epoch 93/150
[2023-06-25 08:29:33,908] test loss: 1.2783
[2023-06-25 08:29:33,909] cal loss: 56.9098
[2023-06-25 08:29:33,909] cal percent loss: 0.2232
[2023-06-25 08:29:33,909] mass loss: 31.5047
[2023-06-25 08:29:33,909] mass percent loss: 0.1445
[2023-06-25 08:29:33,909] fat loss: 3.9728
[2023-06-25 08:29:33,910] fat percent loss: 0.3128
[2023-06-25 08:29:33,910] carb loss: 5.6592
[2023-06-25 08:29:33,910] carb percent loss: 0.2932
[2023-06-25 08:29:33,910] protein loss: 5.6014
[2023-06-25 08:29:33,910] protein percent loss: 0.3095
[2023-06-25 08:29:33,910] Epoch 94/150
[2023-06-25 08:32:14,499] train loss: 0.6229
[2023-06-25 08:32:14,500] cal loss: 26.4297
[2023-06-25 08:32:14,500] cal percent loss: 0.1036
[2023-06-25 08:32:14,500] mass loss: 18.4658
[2023-06-25 08:32:14,500] mass percent loss: 0.0847
[2023-06-25 08:32:14,500] fat loss: 1.9026
[2023-06-25 08:32:14,500] fat percent loss: 0.1498
[2023-06-25 08:32:14,500] carb loss: 2.8690
[2023-06-25 08:32:14,500] carb percent loss: 0.1487
[2023-06-25 08:32:14,501] protein loss: 2.4105
[2023-06-25 08:32:14,501] protein percent loss: 0.1332
[2023-06-25 08:32:14,501] Epoch 94/150
[2023-06-25 08:32:41,522] test loss: 1.3279
[2023-06-25 08:32:41,523] cal loss: 59.5958
[2023-06-25 08:32:41,523] cal percent loss: 0.2337
[2023-06-25 08:32:41,523] mass loss: 35.7850
[2023-06-25 08:32:41,523] mass percent loss: 0.1642
[2023-06-25 08:32:41,524] fat loss: 4.1356
[2023-06-25 08:32:41,524] fat percent loss: 0.3256
[2023-06-25 08:32:41,524] carb loss: 5.6377
[2023-06-25 08:32:41,524] carb percent loss: 0.2921
[2023-06-25 08:32:41,524] protein loss: 5.6006
[2023-06-25 08:32:41,524] protein percent loss: 0.3094
[2023-06-25 08:32:41,525] Epoch 95/150
[2023-06-25 08:35:15,414] train loss: 0.6857
[2023-06-25 08:35:15,415] cal loss: 29.8510
[2023-06-25 08:35:15,415] cal percent loss: 0.1171
[2023-06-25 08:35:15,415] mass loss: 20.0876
[2023-06-25 08:35:15,415] mass percent loss: 0.0921
[2023-06-25 08:35:15,415] fat loss: 2.1649
[2023-06-25 08:35:15,415] fat percent loss: 0.1705
[2023-06-25 08:35:15,415] carb loss: 3.0471
[2023-06-25 08:35:15,416] carb percent loss: 0.1579
[2023-06-25 08:35:15,416] protein loss: 2.6104
[2023-06-25 08:35:15,416] protein percent loss: 0.1442
[2023-06-25 08:35:15,416] Epoch 95/150
[2023-06-25 08:35:38,808] test loss: 1.2807
[2023-06-25 08:35:38,808] cal loss: 54.4176
[2023-06-25 08:35:38,809] cal percent loss: 0.2134
[2023-06-25 08:35:38,809] mass loss: 33.4656
[2023-06-25 08:35:38,809] mass percent loss: 0.1535
[2023-06-25 08:35:38,809] fat loss: 3.9669
[2023-06-25 08:35:38,809] fat percent loss: 0.3124
[2023-06-25 08:35:38,809] carb loss: 5.4973
[2023-06-25 08:35:38,809] carb percent loss: 0.2848
[2023-06-25 08:35:38,809] protein loss: 5.7898
[2023-06-25 08:35:38,809] protein percent loss: 0.3199
[2023-06-25 08:35:38,809] Epoch 96/150
[2023-06-25 08:38:09,712] train loss: 0.6315
[2023-06-25 08:38:09,713] cal loss: 26.9766
[2023-06-25 08:38:09,713] cal percent loss: 0.1058
[2023-06-25 08:38:09,713] mass loss: 18.7644
[2023-06-25 08:38:09,713] mass percent loss: 0.0861
[2023-06-25 08:38:09,713] fat loss: 2.0251
[2023-06-25 08:38:09,713] fat percent loss: 0.1595
[2023-06-25 08:38:09,713] carb loss: 2.7007
[2023-06-25 08:38:09,713] carb percent loss: 0.1399
[2023-06-25 08:38:09,714] protein loss: 2.4665
[2023-06-25 08:38:09,714] protein percent loss: 0.1363
[2023-06-25 08:38:09,714] Epoch 96/150
[2023-06-25 08:38:33,223] test loss: 1.1812
[2023-06-25 08:38:33,224] cal loss: 49.9752
[2023-06-25 08:38:33,225] cal percent loss: 0.1960
[2023-06-25 08:38:33,225] mass loss: 30.1429
[2023-06-25 08:38:33,225] mass percent loss: 0.1383
[2023-06-25 08:38:33,225] fat loss: 3.7336
[2023-06-25 08:38:33,225] fat percent loss: 0.2940
[2023-06-25 08:38:33,225] carb loss: 5.4939
[2023-06-25 08:38:33,225] carb percent loss: 0.2847
[2023-06-25 08:38:33,225] protein loss: 4.9527
[2023-06-25 08:38:33,226] protein percent loss: 0.2736
[2023-06-25 08:38:33,226] Epoch 97/150
[2023-06-25 08:41:05,485] train loss: 0.6159
[2023-06-25 08:41:05,486] cal loss: 25.7218
[2023-06-25 08:41:05,486] cal percent loss: 0.1009
[2023-06-25 08:41:05,486] mass loss: 18.3214
[2023-06-25 08:41:05,486] mass percent loss: 0.0840
[2023-06-25 08:41:05,487] fat loss: 1.9447
[2023-06-25 08:41:05,487] fat percent loss: 0.1531
[2023-06-25 08:41:05,487] carb loss: 2.7758
[2023-06-25 08:41:05,487] carb percent loss: 0.1438
[2023-06-25 08:41:05,487] protein loss: 2.3730
[2023-06-25 08:41:05,487] protein percent loss: 0.1311
[2023-06-25 08:41:05,487] Epoch 97/150
[2023-06-25 08:41:30,857] test loss: 1.2300
[2023-06-25 08:41:30,858] cal loss: 54.8190
[2023-06-25 08:41:30,858] cal percent loss: 0.2150
[2023-06-25 08:41:30,858] mass loss: 30.9038
[2023-06-25 08:41:30,858] mass percent loss: 0.1418
[2023-06-25 08:41:30,858] fat loss: 3.7708
[2023-06-25 08:41:30,858] fat percent loss: 0.2969
[2023-06-25 08:41:30,858] carb loss: 5.4281
[2023-06-25 08:41:30,858] carb percent loss: 0.2812
[2023-06-25 08:41:30,858] protein loss: 5.4033
[2023-06-25 08:41:30,859] protein percent loss: 0.2985
[2023-06-25 08:41:30,859] Epoch 98/150
[2023-06-25 08:44:02,881] train loss: 0.6139
[2023-06-25 08:44:02,882] cal loss: 26.0283
[2023-06-25 08:44:02,882] cal percent loss: 0.1021
[2023-06-25 08:44:02,882] mass loss: 18.1959
[2023-06-25 08:44:02,882] mass percent loss: 0.0835
[2023-06-25 08:44:02,882] fat loss: 1.9461
[2023-06-25 08:44:02,882] fat percent loss: 0.1532
[2023-06-25 08:44:02,882] carb loss: 2.7092
[2023-06-25 08:44:02,882] carb percent loss: 0.1404
[2023-06-25 08:44:02,882] protein loss: 2.3801
[2023-06-25 08:44:02,882] protein percent loss: 0.1315
[2023-06-25 08:44:02,882] Epoch 98/150
[2023-06-25 08:44:29,185] test loss: 1.2588
[2023-06-25 08:44:29,185] cal loss: 56.2054
[2023-06-25 08:44:29,186] cal percent loss: 0.2204
[2023-06-25 08:44:29,186] mass loss: 32.2315
[2023-06-25 08:44:29,186] mass percent loss: 0.1479
[2023-06-25 08:44:29,186] fat loss: 3.8970
[2023-06-25 08:44:29,186] fat percent loss: 0.3069
[2023-06-25 08:44:29,186] carb loss: 5.5384
[2023-06-25 08:44:29,186] carb percent loss: 0.2870
[2023-06-25 08:44:29,186] protein loss: 5.4056
[2023-06-25 08:44:29,186] protein percent loss: 0.2986
[2023-06-25 08:44:29,187] Epoch 99/150
[2023-06-25 08:47:00,715] train loss: 0.6186
[2023-06-25 08:47:00,715] cal loss: 26.1544
[2023-06-25 08:47:00,715] cal percent loss: 0.1026
[2023-06-25 08:47:00,715] mass loss: 18.5249
[2023-06-25 08:47:00,716] mass percent loss: 0.0850
[2023-06-25 08:47:00,716] fat loss: 1.9553
[2023-06-25 08:47:00,716] fat percent loss: 0.1540
[2023-06-25 08:47:00,717] carb loss: 2.7277
[2023-06-25 08:47:00,717] carb percent loss: 0.1413
[2023-06-25 08:47:00,717] protein loss: 2.3900
[2023-06-25 08:47:00,717] protein percent loss: 0.1320
[2023-06-25 08:47:00,717] Epoch 99/150
[2023-06-25 08:47:23,576] test loss: 1.2654
[2023-06-25 08:47:23,577] cal loss: 55.8366
[2023-06-25 08:47:23,577] cal percent loss: 0.2190
[2023-06-25 08:47:23,577] mass loss: 32.4823
[2023-06-25 08:47:23,578] mass percent loss: 0.1490
[2023-06-25 08:47:23,578] fat loss: 3.8370
[2023-06-25 08:47:23,578] fat percent loss: 0.3021
[2023-06-25 08:47:23,578] carb loss: 5.9962
[2023-06-25 08:47:23,578] carb percent loss: 0.3107
[2023-06-25 08:47:23,578] protein loss: 5.2164
[2023-06-25 08:47:23,578] protein percent loss: 0.2882
[2023-06-25 08:47:23,578] Epoch 100/150
[2023-06-25 08:49:58,169] train loss: 0.5972
[2023-06-25 08:49:58,170] cal loss: 24.9932
[2023-06-25 08:49:58,170] cal percent loss: 0.0980
[2023-06-25 08:49:58,170] mass loss: 17.9440
[2023-06-25 08:49:58,170] mass percent loss: 0.0823
[2023-06-25 08:49:58,170] fat loss: 1.9125
[2023-06-25 08:49:58,170] fat percent loss: 0.1506
[2023-06-25 08:49:58,170] carb loss: 2.6401
[2023-06-25 08:49:58,170] carb percent loss: 0.1368
[2023-06-25 08:49:58,170] protein loss: 2.2813
[2023-06-25 08:49:58,170] protein percent loss: 0.1260
[2023-06-25 08:49:58,170] Epoch 100/150
[2023-06-25 08:50:23,033] test loss: 1.2560
[2023-06-25 08:50:23,034] cal loss: 56.0330
[2023-06-25 08:50:23,034] cal percent loss: 0.2197
[2023-06-25 08:50:23,034] mass loss: 31.1756
[2023-06-25 08:50:23,034] mass percent loss: 0.1430
[2023-06-25 08:50:23,034] fat loss: 3.9433
[2023-06-25 08:50:23,034] fat percent loss: 0.3105
[2023-06-25 08:50:23,034] carb loss: 5.5654
[2023-06-25 08:50:23,034] carb percent loss: 0.2884
[2023-06-25 08:50:23,035] protein loss: 5.3997
[2023-06-25 08:50:23,035] protein percent loss: 0.2983
[2023-06-25 08:50:23,035] Epoch 101/150
[2023-06-25 08:52:51,700] train loss: 0.6024
[2023-06-25 08:52:51,700] cal loss: 25.8342
[2023-06-25 08:52:51,700] cal percent loss: 0.1013
[2023-06-25 08:52:51,700] mass loss: 17.7407
[2023-06-25 08:52:51,701] mass percent loss: 0.0814
[2023-06-25 08:52:51,701] fat loss: 1.8892
[2023-06-25 08:52:51,701] fat percent loss: 0.1488
[2023-06-25 08:52:51,701] carb loss: 2.7097
[2023-06-25 08:52:51,701] carb percent loss: 0.1404
[2023-06-25 08:52:51,701] protein loss: 2.3069
[2023-06-25 08:52:51,701] protein percent loss: 0.1275
[2023-06-25 08:52:51,702] Epoch 101/150
[2023-06-25 08:53:15,501] test loss: 1.3934
[2023-06-25 08:53:15,502] cal loss: 64.4385
[2023-06-25 08:53:15,502] cal percent loss: 0.2527
[2023-06-25 08:53:15,502] mass loss: 36.0097
[2023-06-25 08:53:15,502] mass percent loss: 0.1652
[2023-06-25 08:53:15,502] fat loss: 4.3191
[2023-06-25 08:53:15,503] fat percent loss: 0.3401
[2023-06-25 08:53:15,503] carb loss: 6.0199
[2023-06-25 08:53:15,503] carb percent loss: 0.3119
[2023-06-25 08:53:15,503] protein loss: 5.8296
[2023-06-25 08:53:15,503] protein percent loss: 0.3221
[2023-06-25 08:53:15,503] Epoch 102/150
[2023-06-25 08:55:41,571] train loss: 0.6766
[2023-06-25 08:55:41,572] cal loss: 29.4681
[2023-06-25 08:55:41,572] cal percent loss: 0.1156
[2023-06-25 08:55:41,572] mass loss: 20.1806
[2023-06-25 08:55:41,572] mass percent loss: 0.0926
[2023-06-25 08:55:41,572] fat loss: 2.0003
[2023-06-25 08:55:41,572] fat percent loss: 0.1575
[2023-06-25 08:55:41,572] carb loss: 2.6610
[2023-06-25 08:55:41,573] carb percent loss: 0.1379
[2023-06-25 08:55:41,573] protein loss: 3.0467
[2023-06-25 08:55:41,573] protein percent loss: 0.1683
[2023-06-25 08:55:41,573] Epoch 102/150
[2023-06-25 08:56:07,079] test loss: 1.2797
[2023-06-25 08:56:07,080] cal loss: 55.9081
[2023-06-25 08:56:07,080] cal percent loss: 0.2192
[2023-06-25 08:56:07,080] mass loss: 33.5327
[2023-06-25 08:56:07,080] mass percent loss: 0.1538
[2023-06-25 08:56:07,080] fat loss: 3.8634
[2023-06-25 08:56:07,080] fat percent loss: 0.3042
[2023-06-25 08:56:07,080] carb loss: 5.9034
[2023-06-25 08:56:07,080] carb percent loss: 0.3059
[2023-06-25 08:56:07,081] protein loss: 5.4134
[2023-06-25 08:56:07,081] protein percent loss: 0.2991
[2023-06-25 08:56:07,081] Epoch 103/150
[2023-06-25 08:58:33,395] train loss: 0.6173
[2023-06-25 08:58:33,396] cal loss: 26.1122
[2023-06-25 08:58:33,396] cal percent loss: 0.1024
[2023-06-25 08:58:33,396] mass loss: 18.0754
[2023-06-25 08:58:33,396] mass percent loss: 0.0829
[2023-06-25 08:58:33,396] fat loss: 1.8743
[2023-06-25 08:58:33,396] fat percent loss: 0.1476
[2023-06-25 08:58:33,396] carb loss: 2.7141
[2023-06-25 08:58:33,396] carb percent loss: 0.1406
[2023-06-25 08:58:33,396] protein loss: 2.5595
[2023-06-25 08:58:33,396] protein percent loss: 0.1414
[2023-06-25 08:58:33,396] Epoch 103/150
[2023-06-25 08:58:58,547] test loss: 1.2219
[2023-06-25 08:58:58,548] cal loss: 54.3770
[2023-06-25 08:58:58,548] cal percent loss: 0.2132
[2023-06-25 08:58:58,548] mass loss: 30.0708
[2023-06-25 08:58:58,548] mass percent loss: 0.1379
[2023-06-25 08:58:58,548] fat loss: 3.8100
[2023-06-25 08:58:58,548] fat percent loss: 0.3000
[2023-06-25 08:58:58,548] carb loss: 5.7472
[2023-06-25 08:58:58,548] carb percent loss: 0.2978
[2023-06-25 08:58:58,548] protein loss: 5.0360
[2023-06-25 08:58:58,548] protein percent loss: 0.2782
[2023-06-25 08:58:58,549] Epoch 104/150
[2023-06-25 09:01:32,792] train loss: 0.6129
[2023-06-25 09:01:32,792] cal loss: 26.0671
[2023-06-25 09:01:32,793] cal percent loss: 0.1022
[2023-06-25 09:01:32,793] mass loss: 18.2240
[2023-06-25 09:01:32,793] mass percent loss: 0.0836
[2023-06-25 09:01:32,793] fat loss: 1.9087
[2023-06-25 09:01:32,793] fat percent loss: 0.1503
[2023-06-25 09:01:32,793] carb loss: 2.7103
[2023-06-25 09:01:32,793] carb percent loss: 0.1404
[2023-06-25 09:01:32,793] protein loss: 2.4073
[2023-06-25 09:01:32,793] protein percent loss: 0.1330
[2023-06-25 09:01:32,793] Epoch 104/150
[2023-06-25 09:01:57,933] test loss: 1.2585
[2023-06-25 09:01:57,933] cal loss: 55.7556
[2023-06-25 09:01:57,933] cal percent loss: 0.2186
[2023-06-25 09:01:57,933] mass loss: 32.5403
[2023-06-25 09:01:57,934] mass percent loss: 0.1493
[2023-06-25 09:01:57,934] fat loss: 3.8784
[2023-06-25 09:01:57,934] fat percent loss: 0.3054
[2023-06-25 09:01:57,934] carb loss: 5.8653
[2023-06-25 09:01:57,934] carb percent loss: 0.3039
[2023-06-25 09:01:57,934] protein loss: 5.1327
[2023-06-25 09:01:57,934] protein percent loss: 0.2836
[2023-06-25 09:01:57,934] Epoch 105/150
[2023-06-25 09:04:32,277] train loss: 0.6075
[2023-06-25 09:04:32,278] cal loss: 26.6097
[2023-06-25 09:04:32,278] cal percent loss: 0.1044
[2023-06-25 09:04:32,278] mass loss: 18.1115
[2023-06-25 09:04:32,279] mass percent loss: 0.0831
[2023-06-25 09:04:32,279] fat loss: 1.8795
[2023-06-25 09:04:32,279] fat percent loss: 0.1480
[2023-06-25 09:04:32,279] carb loss: 2.6540
[2023-06-25 09:04:32,279] carb percent loss: 0.1375
[2023-06-25 09:04:32,279] protein loss: 2.3571
[2023-06-25 09:04:32,279] protein percent loss: 0.1302
[2023-06-25 09:04:32,279] Epoch 105/150
[2023-06-25 09:04:58,022] test loss: 1.3398
[2023-06-25 09:04:58,023] cal loss: 59.7115
[2023-06-25 09:04:58,023] cal percent loss: 0.2342
[2023-06-25 09:04:58,023] mass loss: 36.0599
[2023-06-25 09:04:58,024] mass percent loss: 0.1654
[2023-06-25 09:04:58,024] fat loss: 4.1107
[2023-06-25 09:04:58,024] fat percent loss: 0.3237
[2023-06-25 09:04:58,024] carb loss: 6.0070
[2023-06-25 09:04:58,024] carb percent loss: 0.3112
[2023-06-25 09:04:58,024] protein loss: 5.4992
[2023-06-25 09:04:58,024] protein percent loss: 0.3038
[2023-06-25 09:04:58,025] Epoch 106/150
[2023-06-25 09:07:34,858] train loss: 0.6034
[2023-06-25 09:07:34,859] cal loss: 26.5764
[2023-06-25 09:07:34,859] cal percent loss: 0.1042
[2023-06-25 09:07:34,859] mass loss: 17.9405
[2023-06-25 09:07:34,859] mass percent loss: 0.0823
[2023-06-25 09:07:34,859] fat loss: 1.9105
[2023-06-25 09:07:34,859] fat percent loss: 0.1504
[2023-06-25 09:07:34,859] carb loss: 2.5997
[2023-06-25 09:07:34,859] carb percent loss: 0.1347
[2023-06-25 09:07:34,859] protein loss: 2.3015
[2023-06-25 09:07:34,859] protein percent loss: 0.1272
[2023-06-25 09:07:34,859] Epoch 106/150
[2023-06-25 09:08:01,413] test loss: 1.2783
[2023-06-25 09:08:01,414] cal loss: 57.1488
[2023-06-25 09:08:01,414] cal percent loss: 0.2241
[2023-06-25 09:08:01,414] mass loss: 31.5583
[2023-06-25 09:08:01,414] mass percent loss: 0.1448
[2023-06-25 09:08:01,414] fat loss: 4.2156
[2023-06-25 09:08:01,414] fat percent loss: 0.3319
[2023-06-25 09:08:01,414] carb loss: 5.5515
[2023-06-25 09:08:01,414] carb percent loss: 0.2876
[2023-06-25 09:08:01,414] protein loss: 5.3031
[2023-06-25 09:08:01,414] protein percent loss: 0.2930
[2023-06-25 09:08:01,415] Epoch 107/150
[2023-06-25 09:10:29,485] train loss: 0.5860
[2023-06-25 09:10:29,485] cal loss: 24.6062
[2023-06-25 09:10:29,485] cal percent loss: 0.0965
[2023-06-25 09:10:29,486] mass loss: 17.5316
[2023-06-25 09:10:29,486] mass percent loss: 0.0804
[2023-06-25 09:10:29,486] fat loss: 1.8018
[2023-06-25 09:10:29,486] fat percent loss: 0.1419
[2023-06-25 09:10:29,486] carb loss: 2.6622
[2023-06-25 09:10:29,486] carb percent loss: 0.1379
[2023-06-25 09:10:29,486] protein loss: 2.2879
[2023-06-25 09:10:29,486] protein percent loss: 0.1264
[2023-06-25 09:10:29,486] Epoch 107/150
[2023-06-25 09:10:55,656] test loss: 1.2511
[2023-06-25 09:10:55,657] cal loss: 55.0253
[2023-06-25 09:10:55,657] cal percent loss: 0.2158
[2023-06-25 09:10:55,658] mass loss: 33.3017
[2023-06-25 09:10:55,658] mass percent loss: 0.1528
[2023-06-25 09:10:55,658] fat loss: 3.7225
[2023-06-25 09:10:55,658] fat percent loss: 0.2931
[2023-06-25 09:10:55,658] carb loss: 5.6706
[2023-06-25 09:10:55,658] carb percent loss: 0.2938
[2023-06-25 09:10:55,659] protein loss: 5.3671
[2023-06-25 09:10:55,659] protein percent loss: 0.2965
[2023-06-25 09:10:55,659] Epoch 108/150
[2023-06-25 09:13:29,030] train loss: 0.6219
[2023-06-25 09:13:29,031] cal loss: 26.7704
[2023-06-25 09:13:29,031] cal percent loss: 0.1050
[2023-06-25 09:13:29,031] mass loss: 18.2757
[2023-06-25 09:13:29,031] mass percent loss: 0.0838
[2023-06-25 09:13:29,031] fat loss: 2.0949
[2023-06-25 09:13:29,031] fat percent loss: 0.1650
[2023-06-25 09:13:29,031] carb loss: 2.6033
[2023-06-25 09:13:29,032] carb percent loss: 0.1349
[2023-06-25 09:13:29,032] protein loss: 2.3339
[2023-06-25 09:13:29,032] protein percent loss: 0.1289
[2023-06-25 09:13:29,032] Epoch 108/150
[2023-06-25 09:13:55,857] test loss: 1.3309
[2023-06-25 09:13:55,858] cal loss: 60.5567
[2023-06-25 09:13:55,858] cal percent loss: 0.2375
[2023-06-25 09:13:55,858] mass loss: 34.2759
[2023-06-25 09:13:55,858] mass percent loss: 0.1572
[2023-06-25 09:13:55,858] fat loss: 4.1405
[2023-06-25 09:13:55,858] fat percent loss: 0.3260
[2023-06-25 09:13:55,858] carb loss: 5.7333
[2023-06-25 09:13:55,859] carb percent loss: 0.2971
[2023-06-25 09:13:55,859] protein loss: 5.6673
[2023-06-25 09:13:55,859] protein percent loss: 0.3131
[2023-06-25 09:13:55,859] Epoch 109/150
[2023-06-25 09:16:26,382] train loss: 0.5787
[2023-06-25 09:16:26,383] cal loss: 25.1197
[2023-06-25 09:16:26,383] cal percent loss: 0.0985
[2023-06-25 09:16:26,383] mass loss: 17.3612
[2023-06-25 09:16:26,383] mass percent loss: 0.0796
[2023-06-25 09:16:26,383] fat loss: 1.8302
[2023-06-25 09:16:26,383] fat percent loss: 0.1441
[2023-06-25 09:16:26,383] carb loss: 2.5419
[2023-06-25 09:16:26,384] carb percent loss: 0.1317
[2023-06-25 09:16:26,384] protein loss: 2.1813
[2023-06-25 09:16:26,384] protein percent loss: 0.1205
[2023-06-25 09:16:26,384] Epoch 109/150
[2023-06-25 09:16:51,315] test loss: 1.2959
[2023-06-25 09:16:51,316] cal loss: 57.7713
[2023-06-25 09:16:51,316] cal percent loss: 0.2266
[2023-06-25 09:16:51,316] mass loss: 33.6861
[2023-06-25 09:16:51,316] mass percent loss: 0.1545
[2023-06-25 09:16:51,317] fat loss: 3.8897
[2023-06-25 09:16:51,317] fat percent loss: 0.3063
[2023-06-25 09:16:51,317] carb loss: 5.8358
[2023-06-25 09:16:51,317] carb percent loss: 0.3024
[2023-06-25 09:16:51,317] protein loss: 5.5728
[2023-06-25 09:16:51,317] protein percent loss: 0.3079
[2023-06-25 09:16:51,317] Epoch 110/150
[2023-06-25 09:19:26,195] train loss: 0.5569
[2023-06-25 09:19:26,195] cal loss: 23.7339
[2023-06-25 09:19:26,195] cal percent loss: 0.0931
[2023-06-25 09:19:26,196] mass loss: 16.9189
[2023-06-25 09:19:26,196] mass percent loss: 0.0776
[2023-06-25 09:19:26,196] fat loss: 1.7532
[2023-06-25 09:19:26,196] fat percent loss: 0.1381
[2023-06-25 09:19:26,196] carb loss: 2.4165
[2023-06-25 09:19:26,196] carb percent loss: 0.1252
[2023-06-25 09:19:26,196] protein loss: 2.1524
[2023-06-25 09:19:26,196] protein percent loss: 0.1189
[2023-06-25 09:19:26,196] Epoch 110/150
[2023-06-25 09:19:51,340] test loss: 1.2900
[2023-06-25 09:19:51,341] cal loss: 56.9727
[2023-06-25 09:19:51,341] cal percent loss: 0.2234
[2023-06-25 09:19:51,342] mass loss: 33.6832
[2023-06-25 09:19:51,342] mass percent loss: 0.1545
[2023-06-25 09:19:51,342] fat loss: 3.8713
[2023-06-25 09:19:51,342] fat percent loss: 0.3048
[2023-06-25 09:19:51,342] carb loss: 5.7590
[2023-06-25 09:19:51,342] carb percent loss: 0.2984
[2023-06-25 09:19:51,342] protein loss: 5.6232
[2023-06-25 09:19:51,342] protein percent loss: 0.3107
[2023-06-25 09:19:51,343] Epoch 111/150
[2023-06-25 09:22:25,798] train loss: 0.5583
[2023-06-25 09:22:25,798] cal loss: 23.7306
[2023-06-25 09:22:25,799] cal percent loss: 0.0931
[2023-06-25 09:22:25,799] mass loss: 16.9365
[2023-06-25 09:22:25,799] mass percent loss: 0.0777
[2023-06-25 09:22:25,799] fat loss: 1.7483
[2023-06-25 09:22:25,799] fat percent loss: 0.1377
[2023-06-25 09:22:25,799] carb loss: 2.3810
[2023-06-25 09:22:25,799] carb percent loss: 0.1234
[2023-06-25 09:22:25,799] protein loss: 2.2167
[2023-06-25 09:22:25,799] protein percent loss: 0.1225
[2023-06-25 09:22:25,799] Epoch 111/150
[2023-06-25 09:22:51,680] test loss: 1.3258
[2023-06-25 09:22:51,680] cal loss: 57.8439
[2023-06-25 09:22:51,681] cal percent loss: 0.2268
[2023-06-25 09:22:51,681] mass loss: 36.4598
[2023-06-25 09:22:51,681] mass percent loss: 0.1672
[2023-06-25 09:22:51,681] fat loss: 3.8725
[2023-06-25 09:22:51,681] fat percent loss: 0.3049
[2023-06-25 09:22:51,681] carb loss: 6.0076
[2023-06-25 09:22:51,681] carb percent loss: 0.3113
[2023-06-25 09:22:51,681] protein loss: 5.6954
[2023-06-25 09:22:51,681] protein percent loss: 0.3147
[2023-06-25 09:22:51,682] Epoch 112/150
[2023-06-25 09:25:23,630] train loss: 0.5502
[2023-06-25 09:25:23,631] cal loss: 23.6192
[2023-06-25 09:25:23,631] cal percent loss: 0.0926
[2023-06-25 09:25:23,631] mass loss: 16.5523
[2023-06-25 09:25:23,632] mass percent loss: 0.0759
[2023-06-25 09:25:23,632] fat loss: 1.7227
[2023-06-25 09:25:23,632] fat percent loss: 0.1356
[2023-06-25 09:25:23,632] carb loss: 2.3968
[2023-06-25 09:25:23,632] carb percent loss: 0.1242
[2023-06-25 09:25:23,632] protein loss: 2.1354
[2023-06-25 09:25:23,632] protein percent loss: 0.1180
[2023-06-25 09:25:23,632] Epoch 112/150
[2023-06-25 09:25:47,985] test loss: 1.2555
[2023-06-25 09:25:47,986] cal loss: 55.7877
[2023-06-25 09:25:47,986] cal percent loss: 0.2188
[2023-06-25 09:25:47,987] mass loss: 32.3710
[2023-06-25 09:25:47,987] mass percent loss: 0.1485
[2023-06-25 09:25:47,987] fat loss: 3.9501
[2023-06-25 09:25:47,987] fat percent loss: 0.3110
[2023-06-25 09:25:47,987] carb loss: 5.5383
[2023-06-25 09:25:47,988] carb percent loss: 0.2870
[2023-06-25 09:25:47,988] protein loss: 5.2791
[2023-06-25 09:25:47,988] protein percent loss: 0.2917
[2023-06-25 09:25:47,988] Epoch 113/150
[2023-06-25 09:28:21,041] train loss: 0.5404
[2023-06-25 09:28:21,042] cal loss: 22.5533
[2023-06-25 09:28:21,042] cal percent loss: 0.0884
[2023-06-25 09:28:21,042] mass loss: 16.7499
[2023-06-25 09:28:21,042] mass percent loss: 0.0768
[2023-06-25 09:28:21,043] fat loss: 1.6453
[2023-06-25 09:28:21,043] fat percent loss: 0.1295
[2023-06-25 09:28:21,043] carb loss: 2.4026
[2023-06-25 09:28:21,043] carb percent loss: 0.1245
[2023-06-25 09:28:21,043] protein loss: 2.1232
[2023-06-25 09:28:21,043] protein percent loss: 0.1173
[2023-06-25 09:28:21,043] Epoch 113/150
[2023-06-25 09:28:45,947] test loss: 1.3108
[2023-06-25 09:28:45,948] cal loss: 58.6216
[2023-06-25 09:28:45,948] cal percent loss: 0.2299
[2023-06-25 09:28:45,948] mass loss: 33.5292
[2023-06-25 09:28:45,949] mass percent loss: 0.1538
[2023-06-25 09:28:45,949] fat loss: 4.0826
[2023-06-25 09:28:45,949] fat percent loss: 0.3215
[2023-06-25 09:28:45,949] carb loss: 5.8872
[2023-06-25 09:28:45,949] carb percent loss: 0.3050
[2023-06-25 09:28:45,949] protein loss: 5.4777
[2023-06-25 09:28:45,949] protein percent loss: 0.3026
[2023-06-25 09:28:45,949] Epoch 114/150
[2023-06-25 09:31:20,500] train loss: 0.5258
[2023-06-25 09:31:20,500] cal loss: 22.3450
[2023-06-25 09:31:20,500] cal percent loss: 0.0876
[2023-06-25 09:31:20,500] mass loss: 16.0458
[2023-06-25 09:31:20,500] mass percent loss: 0.0736
[2023-06-25 09:31:20,500] fat loss: 1.6453
[2023-06-25 09:31:20,501] fat percent loss: 0.1295
[2023-06-25 09:31:20,501] carb loss: 2.3020
[2023-06-25 09:31:20,501] carb percent loss: 0.1193
[2023-06-25 09:31:20,501] protein loss: 2.0255
[2023-06-25 09:31:20,501] protein percent loss: 0.1119
[2023-06-25 09:31:20,501] Epoch 114/150
[2023-06-25 09:31:44,734] test loss: 1.2911
[2023-06-25 09:31:44,735] cal loss: 57.2428
[2023-06-25 09:31:44,735] cal percent loss: 0.2245
[2023-06-25 09:31:44,736] mass loss: 32.4027
[2023-06-25 09:31:44,736] mass percent loss: 0.1486
[2023-06-25 09:31:44,736] fat loss: 4.0139
[2023-06-25 09:31:44,736] fat percent loss: 0.3161
[2023-06-25 09:31:44,736] carb loss: 5.7414
[2023-06-25 09:31:44,736] carb percent loss: 0.2975
[2023-06-25 09:31:44,736] protein loss: 5.5803
[2023-06-25 09:31:44,736] protein percent loss: 0.3083
[2023-06-25 09:31:44,737] Epoch 115/150
[2023-06-25 09:34:14,482] train loss: 0.5304
[2023-06-25 09:34:14,483] cal loss: 22.5089
[2023-06-25 09:34:14,483] cal percent loss: 0.0883
[2023-06-25 09:34:14,483] mass loss: 15.9335
[2023-06-25 09:34:14,483] mass percent loss: 0.0731
[2023-06-25 09:34:14,483] fat loss: 1.6580
[2023-06-25 09:34:14,483] fat percent loss: 0.1306
[2023-06-25 09:34:14,484] carb loss: 2.3164
[2023-06-25 09:34:14,484] carb percent loss: 0.1200
[2023-06-25 09:34:14,484] protein loss: 2.0850
[2023-06-25 09:34:14,484] protein percent loss: 0.1152
[2023-06-25 09:34:14,484] Epoch 115/150
[2023-06-25 09:34:42,269] test loss: 1.3164
[2023-06-25 09:34:42,269] cal loss: 58.7726
[2023-06-25 09:34:42,269] cal percent loss: 0.2305
[2023-06-25 09:34:42,269] mass loss: 32.9191
[2023-06-25 09:34:42,269] mass percent loss: 0.1510
[2023-06-25 09:34:42,269] fat loss: 4.1512
[2023-06-25 09:34:42,269] fat percent loss: 0.3269
[2023-06-25 09:34:42,269] carb loss: 5.9651
[2023-06-25 09:34:42,270] carb percent loss: 0.3091
[2023-06-25 09:34:42,270] protein loss: 5.4786
[2023-06-25 09:34:42,270] protein percent loss: 0.3027
[2023-06-25 09:34:42,270] Epoch 116/150
[2023-06-25 09:37:21,051] train loss: 0.5217
[2023-06-25 09:37:21,051] cal loss: 22.3020
[2023-06-25 09:37:21,052] cal percent loss: 0.0875
[2023-06-25 09:37:21,052] mass loss: 15.5319
[2023-06-25 09:37:21,052] mass percent loss: 0.0712
[2023-06-25 09:37:21,052] fat loss: 1.6481
[2023-06-25 09:37:21,052] fat percent loss: 0.1298
[2023-06-25 09:37:21,052] carb loss: 2.2668
[2023-06-25 09:37:21,052] carb percent loss: 0.1175
[2023-06-25 09:37:21,052] protein loss: 2.0368
[2023-06-25 09:37:21,052] protein percent loss: 0.1125
[2023-06-25 09:37:21,052] Epoch 116/150
[2023-06-25 09:37:47,296] test loss: 1.3089
[2023-06-25 09:37:47,296] cal loss: 59.7315
[2023-06-25 09:37:47,296] cal percent loss: 0.2342
[2023-06-25 09:37:47,297] mass loss: 33.1576
[2023-06-25 09:37:47,297] mass percent loss: 0.1521
[2023-06-25 09:37:47,297] fat loss: 4.0853
[2023-06-25 09:37:47,297] fat percent loss: 0.3217
[2023-06-25 09:37:47,297] carb loss: 5.6939
[2023-06-25 09:37:47,297] carb percent loss: 0.2950
[2023-06-25 09:37:47,297] protein loss: 5.5546
[2023-06-25 09:37:47,297] protein percent loss: 0.3069
[2023-06-25 09:37:47,298] Epoch 117/150
[2023-06-25 09:40:15,049] train loss: 0.5303
[2023-06-25 09:40:15,050] cal loss: 22.9922
[2023-06-25 09:40:15,050] cal percent loss: 0.0902
[2023-06-25 09:40:15,050] mass loss: 16.1249
[2023-06-25 09:40:15,050] mass percent loss: 0.0740
[2023-06-25 09:40:15,050] fat loss: 1.6551
[2023-06-25 09:40:15,050] fat percent loss: 0.1303
[2023-06-25 09:40:15,050] carb loss: 2.3165
[2023-06-25 09:40:15,051] carb percent loss: 0.1200
[2023-06-25 09:40:15,051] protein loss: 2.0187
[2023-06-25 09:40:15,051] protein percent loss: 0.1115
[2023-06-25 09:40:15,051] Epoch 117/150
[2023-06-25 09:40:40,082] test loss: 1.2999
[2023-06-25 09:40:40,083] cal loss: 58.8064
[2023-06-25 09:40:40,083] cal percent loss: 0.2306
[2023-06-25 09:40:40,083] mass loss: 33.2332
[2023-06-25 09:40:40,083] mass percent loss: 0.1524
[2023-06-25 09:40:40,084] fat loss: 4.0232
[2023-06-25 09:40:40,084] fat percent loss: 0.3168
[2023-06-25 09:40:40,084] carb loss: 5.7730
[2023-06-25 09:40:40,084] carb percent loss: 0.2991
[2023-06-25 09:40:40,084] protein loss: 5.4701
[2023-06-25 09:40:40,084] protein percent loss: 0.3022
[2023-06-25 09:40:40,084] Epoch 118/150
[2023-06-25 09:43:10,741] train loss: 0.5212
[2023-06-25 09:43:10,742] cal loss: 22.1176
[2023-06-25 09:43:10,742] cal percent loss: 0.0867
[2023-06-25 09:43:10,742] mass loss: 15.7740
[2023-06-25 09:43:10,742] mass percent loss: 0.0724
[2023-06-25 09:43:10,742] fat loss: 1.6221
[2023-06-25 09:43:10,742] fat percent loss: 0.1277
[2023-06-25 09:43:10,743] carb loss: 2.3096
[2023-06-25 09:43:10,743] carb percent loss: 0.1197
[2023-06-25 09:43:10,743] protein loss: 2.0136
[2023-06-25 09:43:10,743] protein percent loss: 0.1113
[2023-06-25 09:43:10,743] Epoch 118/150
[2023-06-25 09:43:35,920] test loss: 1.3239
[2023-06-25 09:43:35,921] cal loss: 58.8283
[2023-06-25 09:43:35,921] cal percent loss: 0.2307
[2023-06-25 09:43:35,922] mass loss: 35.6463
[2023-06-25 09:43:35,922] mass percent loss: 0.1635
[2023-06-25 09:43:35,922] fat loss: 3.9742
[2023-06-25 09:43:35,922] fat percent loss: 0.3129
[2023-06-25 09:43:35,922] carb loss: 5.8398
[2023-06-25 09:43:35,922] carb percent loss: 0.3026
[2023-06-25 09:43:35,922] protein loss: 5.6681
[2023-06-25 09:43:35,922] protein percent loss: 0.3132
[2023-06-25 09:43:35,923] Epoch 119/150
[2023-06-25 09:46:05,739] train loss: 0.5204
[2023-06-25 09:46:05,740] cal loss: 22.2790
[2023-06-25 09:46:05,740] cal percent loss: 0.0874
[2023-06-25 09:46:05,740] mass loss: 15.3521
[2023-06-25 09:46:05,740] mass percent loss: 0.0704
[2023-06-25 09:46:05,740] fat loss: 1.6392
[2023-06-25 09:46:05,741] fat percent loss: 0.1291
[2023-06-25 09:46:05,741] carb loss: 2.2903
[2023-06-25 09:46:05,741] carb percent loss: 0.1187
[2023-06-25 09:46:05,741] protein loss: 2.0281
[2023-06-25 09:46:05,741] protein percent loss: 0.1120
[2023-06-25 09:46:05,741] Epoch 119/150
[2023-06-25 09:46:29,593] test loss: 1.3013
[2023-06-25 09:46:29,594] cal loss: 59.1520
[2023-06-25 09:46:29,594] cal percent loss: 0.2320
[2023-06-25 09:46:29,594] mass loss: 33.4914
[2023-06-25 09:46:29,594] mass percent loss: 0.1536
[2023-06-25 09:46:29,594] fat loss: 3.9634
[2023-06-25 09:46:29,594] fat percent loss: 0.3121
[2023-06-25 09:46:29,594] carb loss: 5.7762
[2023-06-25 09:46:29,594] carb percent loss: 0.2993
[2023-06-25 09:46:29,595] protein loss: 5.5228
[2023-06-25 09:46:29,595] protein percent loss: 0.3051
[2023-06-25 09:46:29,595] Epoch 120/150
[2023-06-25 09:49:11,708] train loss: 0.5152
[2023-06-25 09:49:11,709] cal loss: 21.8760
[2023-06-25 09:49:11,709] cal percent loss: 0.0858
[2023-06-25 09:49:11,709] mass loss: 15.0995
[2023-06-25 09:49:11,710] mass percent loss: 0.0693
[2023-06-25 09:49:11,710] fat loss: 1.5939
[2023-06-25 09:49:11,710] fat percent loss: 0.1255
[2023-06-25 09:49:11,710] carb loss: 2.3248
[2023-06-25 09:49:11,710] carb percent loss: 0.1205
[2023-06-25 09:49:11,710] protein loss: 2.0272
[2023-06-25 09:49:11,710] protein percent loss: 0.1120
[2023-06-25 09:49:11,710] Epoch 120/150
[2023-06-25 09:49:34,787] test loss: 1.2849
[2023-06-25 09:49:34,787] cal loss: 57.3703
[2023-06-25 09:49:34,787] cal percent loss: 0.2250
[2023-06-25 09:49:34,787] mass loss: 34.0449
[2023-06-25 09:49:34,787] mass percent loss: 0.1562
[2023-06-25 09:49:34,787] fat loss: 3.9306
[2023-06-25 09:49:34,787] fat percent loss: 0.3095
[2023-06-25 09:49:34,788] carb loss: 5.6458
[2023-06-25 09:49:34,788] carb percent loss: 0.2925
[2023-06-25 09:49:34,788] protein loss: 5.4523
[2023-06-25 09:49:34,788] protein percent loss: 0.3012
[2023-06-25 09:49:34,788] Epoch 121/150
[2023-06-25 09:51:59,173] train loss: 0.5239
[2023-06-25 09:51:59,174] cal loss: 22.4556
[2023-06-25 09:51:59,174] cal percent loss: 0.0881
[2023-06-25 09:51:59,174] mass loss: 15.4308
[2023-06-25 09:51:59,175] mass percent loss: 0.0708
[2023-06-25 09:51:59,175] fat loss: 1.6609
[2023-06-25 09:51:59,175] fat percent loss: 0.1308
[2023-06-25 09:51:59,175] carb loss: 2.2610
[2023-06-25 09:51:59,175] carb percent loss: 0.1172
[2023-06-25 09:51:59,175] protein loss: 2.0664
[2023-06-25 09:51:59,175] protein percent loss: 0.1142
[2023-06-25 09:51:59,175] Epoch 121/150
[2023-06-25 09:52:24,254] test loss: 1.3041
[2023-06-25 09:52:24,255] cal loss: 57.2838
[2023-06-25 09:52:24,255] cal percent loss: 0.2246
[2023-06-25 09:52:24,255] mass loss: 35.9213
[2023-06-25 09:52:24,256] mass percent loss: 0.1648
[2023-06-25 09:52:24,256] fat loss: 3.8681
[2023-06-25 09:52:24,256] fat percent loss: 0.3046
[2023-06-25 09:52:24,256] carb loss: 5.8944
[2023-06-25 09:52:24,256] carb percent loss: 0.3054
[2023-06-25 09:52:24,256] protein loss: 5.4844
[2023-06-25 09:52:24,256] protein percent loss: 0.3030
[2023-06-25 09:52:24,256] Epoch 122/150
[2023-06-25 09:54:53,815] train loss: 0.5023
[2023-06-25 09:54:53,816] cal loss: 21.0491
[2023-06-25 09:54:53,816] cal percent loss: 0.0825
[2023-06-25 09:54:53,816] mass loss: 15.2587
[2023-06-25 09:54:53,816] mass percent loss: 0.0700
[2023-06-25 09:54:53,816] fat loss: 1.5704
[2023-06-25 09:54:53,816] fat percent loss: 0.1237
[2023-06-25 09:54:53,816] carb loss: 2.1901
[2023-06-25 09:54:53,816] carb percent loss: 0.1135
[2023-06-25 09:54:53,816] protein loss: 1.9795
[2023-06-25 09:54:53,816] protein percent loss: 0.1094
[2023-06-25 09:54:53,816] Epoch 122/150
[2023-06-25 09:55:17,840] test loss: 1.3223
[2023-06-25 09:55:17,841] cal loss: 58.1411
[2023-06-25 09:55:17,841] cal percent loss: 0.2280
[2023-06-25 09:55:17,842] mass loss: 35.3071
[2023-06-25 09:55:17,842] mass percent loss: 0.1620
[2023-06-25 09:55:17,842] fat loss: 3.9640
[2023-06-25 09:55:17,842] fat percent loss: 0.3121
[2023-06-25 09:55:17,842] carb loss: 5.8946
[2023-06-25 09:55:17,842] carb percent loss: 0.3054
[2023-06-25 09:55:17,842] protein loss: 5.7065
[2023-06-25 09:55:17,843] protein percent loss: 0.3153
[2023-06-25 09:55:17,843] Epoch 123/150
[2023-06-25 09:57:53,041] train loss: 0.5052
[2023-06-25 09:57:53,041] cal loss: 21.5716
[2023-06-25 09:57:53,041] cal percent loss: 0.0846
[2023-06-25 09:57:53,041] mass loss: 15.1418
[2023-06-25 09:57:53,041] mass percent loss: 0.0695
[2023-06-25 09:57:53,041] fat loss: 1.5653
[2023-06-25 09:57:53,041] fat percent loss: 0.1232
[2023-06-25 09:57:53,041] carb loss: 2.2186
[2023-06-25 09:57:53,041] carb percent loss: 0.1150
[2023-06-25 09:57:53,041] protein loss: 1.9875
[2023-06-25 09:57:53,041] protein percent loss: 0.1098
[2023-06-25 09:57:53,041] Epoch 123/150
[2023-06-25 09:58:18,281] test loss: 1.2744
[2023-06-25 09:58:18,282] cal loss: 56.3144
[2023-06-25 09:58:18,282] cal percent loss: 0.2208
[2023-06-25 09:58:18,282] mass loss: 33.9090
[2023-06-25 09:58:18,282] mass percent loss: 0.1555
[2023-06-25 09:58:18,283] fat loss: 3.8117
[2023-06-25 09:58:18,283] fat percent loss: 0.3001
[2023-06-25 09:58:18,283] carb loss: 5.8154
[2023-06-25 09:58:18,283] carb percent loss: 0.3013
[2023-06-25 09:58:18,283] protein loss: 5.3799
[2023-06-25 09:58:18,283] protein percent loss: 0.2972
[2023-06-25 09:58:18,283] Epoch 124/150
[2023-06-25 10:00:57,843] train loss: 0.4968
[2023-06-25 10:00:57,844] cal loss: 20.5895
[2023-06-25 10:00:57,844] cal percent loss: 0.0807
[2023-06-25 10:00:57,844] mass loss: 14.8543
[2023-06-25 10:00:57,844] mass percent loss: 0.0681
[2023-06-25 10:00:57,844] fat loss: 1.5547
[2023-06-25 10:00:57,844] fat percent loss: 0.1224
[2023-06-25 10:00:57,844] carb loss: 2.2643
[2023-06-25 10:00:57,844] carb percent loss: 0.1173
[2023-06-25 10:00:57,844] protein loss: 1.9173
[2023-06-25 10:00:57,844] protein percent loss: 0.1059
[2023-06-25 10:00:57,844] Epoch 124/150
[2023-06-25 10:01:26,509] test loss: 1.2974
[2023-06-25 10:01:26,509] cal loss: 57.6163
[2023-06-25 10:01:26,509] cal percent loss: 0.2259
[2023-06-25 10:01:26,509] mass loss: 34.8178
[2023-06-25 10:01:26,510] mass percent loss: 0.1597
[2023-06-25 10:01:26,510] fat loss: 3.9818
[2023-06-25 10:01:26,510] fat percent loss: 0.3135
[2023-06-25 10:01:26,510] carb loss: 5.8542
[2023-06-25 10:01:26,510] carb percent loss: 0.3033
[2023-06-25 10:01:26,510] protein loss: 5.3208
[2023-06-25 10:01:26,510] protein percent loss: 0.2940
[2023-06-25 10:01:26,510] Epoch 125/150
[2023-06-25 10:03:53,486] train loss: 0.5007
[2023-06-25 10:03:53,486] cal loss: 20.9998
[2023-06-25 10:03:53,486] cal percent loss: 0.0824
[2023-06-25 10:03:53,486] mass loss: 15.1766
[2023-06-25 10:03:53,486] mass percent loss: 0.0696
[2023-06-25 10:03:53,487] fat loss: 1.5475
[2023-06-25 10:03:53,487] fat percent loss: 0.1219
[2023-06-25 10:03:53,487] carb loss: 2.2268
[2023-06-25 10:03:53,487] carb percent loss: 0.1154
[2023-06-25 10:03:53,487] protein loss: 1.9644
[2023-06-25 10:03:53,487] protein percent loss: 0.1085
[2023-06-25 10:03:53,487] Epoch 125/150
[2023-06-25 10:04:20,057] test loss: 1.2802
[2023-06-25 10:04:20,058] cal loss: 58.2998
[2023-06-25 10:04:20,059] cal percent loss: 0.2286
[2023-06-25 10:04:20,059] mass loss: 33.3651
[2023-06-25 10:04:20,059] mass percent loss: 0.1531
[2023-06-25 10:04:20,059] fat loss: 3.9090
[2023-06-25 10:04:20,059] fat percent loss: 0.3078
[2023-06-25 10:04:20,059] carb loss: 5.6622
[2023-06-25 10:04:20,059] carb percent loss: 0.2934
[2023-06-25 10:04:20,060] protein loss: 5.3756
[2023-06-25 10:04:20,060] protein percent loss: 0.2970
[2023-06-25 10:04:20,060] Epoch 126/150
[2023-06-25 10:06:48,168] train loss: 0.5008
[2023-06-25 10:06:48,168] cal loss: 20.9345
[2023-06-25 10:06:48,168] cal percent loss: 0.0821
[2023-06-25 10:06:48,168] mass loss: 15.3177
[2023-06-25 10:06:48,168] mass percent loss: 0.0703
[2023-06-25 10:06:48,169] fat loss: 1.5534
[2023-06-25 10:06:48,169] fat percent loss: 0.1223
[2023-06-25 10:06:48,169] carb loss: 2.1852
[2023-06-25 10:06:48,169] carb percent loss: 0.1132
[2023-06-25 10:06:48,169] protein loss: 1.9831
[2023-06-25 10:06:48,169] protein percent loss: 0.1096
[2023-06-25 10:06:48,169] Epoch 126/150
[2023-06-25 10:07:14,434] test loss: 1.2556
[2023-06-25 10:07:14,435] cal loss: 54.8269
[2023-06-25 10:07:14,435] cal percent loss: 0.2150
[2023-06-25 10:07:14,436] mass loss: 31.8895
[2023-06-25 10:07:14,436] mass percent loss: 0.1463
[2023-06-25 10:07:14,436] fat loss: 3.9234
[2023-06-25 10:07:14,436] fat percent loss: 0.3089
[2023-06-25 10:07:14,436] carb loss: 5.7809
[2023-06-25 10:07:14,436] carb percent loss: 0.2995
[2023-06-25 10:07:14,436] protein loss: 5.2495
[2023-06-25 10:07:14,436] protein percent loss: 0.2900
[2023-06-25 10:07:14,437] Epoch 127/150
[2023-06-25 10:09:42,927] train loss: 0.4987
[2023-06-25 10:09:42,927] cal loss: 21.1070
[2023-06-25 10:09:42,928] cal percent loss: 0.0828
[2023-06-25 10:09:42,928] mass loss: 15.5853
[2023-06-25 10:09:42,928] mass percent loss: 0.0715
[2023-06-25 10:09:42,928] fat loss: 1.5353
[2023-06-25 10:09:42,928] fat percent loss: 0.1209
[2023-06-25 10:09:42,928] carb loss: 2.2481
[2023-06-25 10:09:42,928] carb percent loss: 0.1165
[2023-06-25 10:09:42,929] protein loss: 1.8620
[2023-06-25 10:09:42,929] protein percent loss: 0.1029
[2023-06-25 10:09:42,929] Epoch 127/150
[2023-06-25 10:10:08,278] test loss: 1.2698
[2023-06-25 10:10:08,279] cal loss: 55.5228
[2023-06-25 10:10:08,279] cal percent loss: 0.2177
[2023-06-25 10:10:08,279] mass loss: 33.0817
[2023-06-25 10:10:08,279] mass percent loss: 0.1518
[2023-06-25 10:10:08,280] fat loss: 3.9268
[2023-06-25 10:10:08,280] fat percent loss: 0.3092
[2023-06-25 10:10:08,280] carb loss: 5.7868
[2023-06-25 10:10:08,280] carb percent loss: 0.2998
[2023-06-25 10:10:08,280] protein loss: 5.3146
[2023-06-25 10:10:08,280] protein percent loss: 0.2936
[2023-06-25 10:10:08,280] Epoch 128/150
[2023-06-25 10:12:39,927] train loss: 0.4835
[2023-06-25 10:12:39,928] cal loss: 20.0579
[2023-06-25 10:12:39,928] cal percent loss: 0.0787
[2023-06-25 10:12:39,928] mass loss: 14.5204
[2023-06-25 10:12:39,928] mass percent loss: 0.0666
[2023-06-25 10:12:39,928] fat loss: 1.5139
[2023-06-25 10:12:39,928] fat percent loss: 0.1192
[2023-06-25 10:12:39,929] carb loss: 2.1557
[2023-06-25 10:12:39,929] carb percent loss: 0.1117
[2023-06-25 10:12:39,929] protein loss: 1.8989
[2023-06-25 10:12:39,929] protein percent loss: 0.1049
[2023-06-25 10:12:39,929] Epoch 128/150
[2023-06-25 10:13:05,815] test loss: 1.2882
[2023-06-25 10:13:05,816] cal loss: 56.9468
[2023-06-25 10:13:05,816] cal percent loss: 0.2233
[2023-06-25 10:13:05,816] mass loss: 33.2205
[2023-06-25 10:13:05,816] mass percent loss: 0.1524
[2023-06-25 10:13:05,816] fat loss: 3.9159
[2023-06-25 10:13:05,816] fat percent loss: 0.3083
[2023-06-25 10:13:05,816] carb loss: 5.8626
[2023-06-25 10:13:05,816] carb percent loss: 0.3038
[2023-06-25 10:13:05,817] protein loss: 5.4856
[2023-06-25 10:13:05,817] protein percent loss: 0.3031
[2023-06-25 10:13:05,817] Epoch 129/150
[2023-06-25 10:15:39,053] train loss: 0.4949
[2023-06-25 10:15:39,054] cal loss: 21.3969
[2023-06-25 10:15:39,054] cal percent loss: 0.0839
[2023-06-25 10:15:39,054] mass loss: 14.5814
[2023-06-25 10:15:39,054] mass percent loss: 0.0669
[2023-06-25 10:15:39,054] fat loss: 1.5410
[2023-06-25 10:15:39,055] fat percent loss: 0.1213
[2023-06-25 10:15:39,055] carb loss: 2.2041
[2023-06-25 10:15:39,055] carb percent loss: 0.1142
[2023-06-25 10:15:39,055] protein loss: 1.9148
[2023-06-25 10:15:39,055] protein percent loss: 0.1058
[2023-06-25 10:15:39,055] Epoch 129/150
[2023-06-25 10:16:02,903] test loss: 1.2783
[2023-06-25 10:16:02,904] cal loss: 57.2441
[2023-06-25 10:16:02,904] cal percent loss: 0.2245
[2023-06-25 10:16:02,904] mass loss: 33.4334
[2023-06-25 10:16:02,904] mass percent loss: 0.1534
[2023-06-25 10:16:02,904] fat loss: 3.9206
[2023-06-25 10:16:02,904] fat percent loss: 0.3087
[2023-06-25 10:16:02,904] carb loss: 5.7640
[2023-06-25 10:16:02,904] carb percent loss: 0.2987
[2023-06-25 10:16:02,904] protein loss: 5.3158
[2023-06-25 10:16:02,904] protein percent loss: 0.2937
[2023-06-25 10:16:02,905] Epoch 130/150
[2023-06-25 10:18:35,198] train loss: 0.4900
[2023-06-25 10:18:35,199] cal loss: 20.5784
[2023-06-25 10:18:35,199] cal percent loss: 0.0807
[2023-06-25 10:18:35,199] mass loss: 14.8151
[2023-06-25 10:18:35,199] mass percent loss: 0.0680
[2023-06-25 10:18:35,199] fat loss: 1.5221
[2023-06-25 10:18:35,199] fat percent loss: 0.1199
[2023-06-25 10:18:35,199] carb loss: 2.1841
[2023-06-25 10:18:35,199] carb percent loss: 0.1132
[2023-06-25 10:18:35,200] protein loss: 1.9074
[2023-06-25 10:18:35,200] protein percent loss: 0.1054
[2023-06-25 10:18:35,200] Epoch 130/150
[2023-06-25 10:18:59,546] test loss: 1.2752
[2023-06-25 10:18:59,547] cal loss: 55.9231
[2023-06-25 10:18:59,548] cal percent loss: 0.2193
[2023-06-25 10:18:59,548] mass loss: 33.5120
[2023-06-25 10:18:59,548] mass percent loss: 0.1537
[2023-06-25 10:18:59,548] fat loss: 3.8582
[2023-06-25 10:18:59,548] fat percent loss: 0.3038
[2023-06-25 10:18:59,548] carb loss: 5.8791
[2023-06-25 10:18:59,548] carb percent loss: 0.3046
[2023-06-25 10:18:59,548] protein loss: 5.3537
[2023-06-25 10:18:59,548] protein percent loss: 0.2958
[2023-06-25 10:18:59,549] Epoch 131/150
[2023-06-25 10:21:28,875] train loss: 0.4884
[2023-06-25 10:21:28,875] cal loss: 20.6465
[2023-06-25 10:21:28,875] cal percent loss: 0.0810
[2023-06-25 10:21:28,876] mass loss: 14.6570
[2023-06-25 10:21:28,876] mass percent loss: 0.0672
[2023-06-25 10:21:28,876] fat loss: 1.5393
[2023-06-25 10:21:28,876] fat percent loss: 0.1212
[2023-06-25 10:21:28,876] carb loss: 2.1722
[2023-06-25 10:21:28,876] carb percent loss: 0.1125
[2023-06-25 10:21:28,876] protein loss: 1.8743
[2023-06-25 10:21:28,876] protein percent loss: 0.1036
[2023-06-25 10:21:28,876] Epoch 131/150
[2023-06-25 10:21:55,523] test loss: 1.2960
[2023-06-25 10:21:55,523] cal loss: 58.5856
[2023-06-25 10:21:55,523] cal percent loss: 0.2297
[2023-06-25 10:21:55,524] mass loss: 33.6386
[2023-06-25 10:21:55,524] mass percent loss: 0.1543
[2023-06-25 10:21:55,524] fat loss: 3.9902
[2023-06-25 10:21:55,524] fat percent loss: 0.3142
[2023-06-25 10:21:55,524] carb loss: 5.7937
[2023-06-25 10:21:55,524] carb percent loss: 0.3002
[2023-06-25 10:21:55,524] protein loss: 5.3925
[2023-06-25 10:21:55,524] protein percent loss: 0.2979
[2023-06-25 10:21:55,524] Epoch 132/150
[2023-06-25 10:24:19,099] train loss: 0.4942
[2023-06-25 10:24:19,099] cal loss: 21.2709
[2023-06-25 10:24:19,100] cal percent loss: 0.0834
[2023-06-25 10:24:19,100] mass loss: 14.4945
[2023-06-25 10:24:19,100] mass percent loss: 0.0665
[2023-06-25 10:24:19,100] fat loss: 1.5469
[2023-06-25 10:24:19,100] fat percent loss: 0.1218
[2023-06-25 10:24:19,100] carb loss: 2.2165
[2023-06-25 10:24:19,100] carb percent loss: 0.1148
[2023-06-25 10:24:19,100] protein loss: 1.9034
[2023-06-25 10:24:19,100] protein percent loss: 0.1052
[2023-06-25 10:24:19,101] Epoch 132/150
[2023-06-25 10:24:44,528] test loss: 1.2961
[2023-06-25 10:24:44,528] cal loss: 57.1775
[2023-06-25 10:24:44,528] cal percent loss: 0.2242
[2023-06-25 10:24:44,528] mass loss: 34.0367
[2023-06-25 10:24:44,528] mass percent loss: 0.1561
[2023-06-25 10:24:44,528] fat loss: 3.9652
[2023-06-25 10:24:44,528] fat percent loss: 0.3122
[2023-06-25 10:24:44,528] carb loss: 5.9015
[2023-06-25 10:24:44,528] carb percent loss: 0.3058
[2023-06-25 10:24:44,528] protein loss: 5.4135
[2023-06-25 10:24:44,529] protein percent loss: 0.2991
[2023-06-25 10:24:44,529] Epoch 133/150
[2023-06-25 10:27:12,668] train loss: 0.4785
[2023-06-25 10:27:12,669] cal loss: 20.1522
[2023-06-25 10:27:12,669] cal percent loss: 0.0790
[2023-06-25 10:27:12,669] mass loss: 14.4897
[2023-06-25 10:27:12,669] mass percent loss: 0.0665
[2023-06-25 10:27:12,669] fat loss: 1.4654
[2023-06-25 10:27:12,670] fat percent loss: 0.1154
[2023-06-25 10:27:12,670] carb loss: 2.1944
[2023-06-25 10:27:12,670] carb percent loss: 0.1137
[2023-06-25 10:27:12,670] protein loss: 1.8317
[2023-06-25 10:27:12,670] protein percent loss: 0.1012
[2023-06-25 10:27:12,670] Epoch 133/150
[2023-06-25 10:27:40,277] test loss: 1.3226
[2023-06-25 10:27:40,278] cal loss: 58.9473
[2023-06-25 10:27:40,278] cal percent loss: 0.2312
[2023-06-25 10:27:40,278] mass loss: 35.5397
[2023-06-25 10:27:40,278] mass percent loss: 0.1630
[2023-06-25 10:27:40,279] fat loss: 4.0568
[2023-06-25 10:27:40,279] fat percent loss: 0.3194
[2023-06-25 10:27:40,279] carb loss: 5.8385
[2023-06-25 10:27:40,279] carb percent loss: 0.3025
[2023-06-25 10:27:40,279] protein loss: 5.5208
[2023-06-25 10:27:40,279] protein percent loss: 0.3050
[2023-06-25 10:27:40,279] Epoch 134/150
[2023-06-25 10:30:08,731] train loss: 0.4754
[2023-06-25 10:30:08,732] cal loss: 20.0343
[2023-06-25 10:30:08,732] cal percent loss: 0.0786
[2023-06-25 10:30:08,732] mass loss: 14.2321
[2023-06-25 10:30:08,732] mass percent loss: 0.0653
[2023-06-25 10:30:08,732] fat loss: 1.4768
[2023-06-25 10:30:08,732] fat percent loss: 0.1163
[2023-06-25 10:30:08,732] carb loss: 2.1408
[2023-06-25 10:30:08,733] carb percent loss: 0.1109
[2023-06-25 10:30:08,733] protein loss: 1.8432
[2023-06-25 10:30:08,733] protein percent loss: 0.1018
[2023-06-25 10:30:08,733] Epoch 134/150
[2023-06-25 10:30:33,642] test loss: 1.2985
[2023-06-25 10:30:33,643] cal loss: 58.4720
[2023-06-25 10:30:33,643] cal percent loss: 0.2293
[2023-06-25 10:30:33,643] mass loss: 34.7230
[2023-06-25 10:30:33,643] mass percent loss: 0.1593
[2023-06-25 10:30:33,644] fat loss: 3.9684
[2023-06-25 10:30:33,644] fat percent loss: 0.3125
[2023-06-25 10:30:33,644] carb loss: 5.6959
[2023-06-25 10:30:33,644] carb percent loss: 0.2951
[2023-06-25 10:30:33,644] protein loss: 5.4406
[2023-06-25 10:30:33,644] protein percent loss: 0.3006
[2023-06-25 10:30:33,645] Epoch 135/150
[2023-06-25 10:33:00,993] train loss: 0.4769
[2023-06-25 10:33:00,993] cal loss: 19.9803
[2023-06-25 10:33:00,993] cal percent loss: 0.0784
[2023-06-25 10:33:00,993] mass loss: 14.7170
[2023-06-25 10:33:00,993] mass percent loss: 0.0675
[2023-06-25 10:33:00,994] fat loss: 1.4557
[2023-06-25 10:33:00,994] fat percent loss: 0.1146
[2023-06-25 10:33:00,994] carb loss: 2.1240
[2023-06-25 10:33:00,994] carb percent loss: 0.1101
[2023-06-25 10:33:00,994] protein loss: 1.8648
[2023-06-25 10:33:00,994] protein percent loss: 0.1030
[2023-06-25 10:33:00,994] Epoch 135/150
[2023-06-25 10:33:26,233] test loss: 1.2907
[2023-06-25 10:33:26,234] cal loss: 57.2794
[2023-06-25 10:33:26,234] cal percent loss: 0.2246
[2023-06-25 10:33:26,234] mass loss: 33.9074
[2023-06-25 10:33:26,234] mass percent loss: 0.1555
[2023-06-25 10:33:26,234] fat loss: 4.0082
[2023-06-25 10:33:26,234] fat percent loss: 0.3156
[2023-06-25 10:33:26,234] carb loss: 5.6891
[2023-06-25 10:33:26,234] carb percent loss: 0.2948
[2023-06-25 10:33:26,235] protein loss: 5.4389
[2023-06-25 10:33:26,235] protein percent loss: 0.3005
[2023-06-25 10:33:26,235] Epoch 136/150
[2023-06-25 10:36:00,524] train loss: 0.4706
[2023-06-25 10:36:00,524] cal loss: 19.9167
[2023-06-25 10:36:00,524] cal percent loss: 0.0781
[2023-06-25 10:36:00,524] mass loss: 14.1444
[2023-06-25 10:36:00,525] mass percent loss: 0.0649
[2023-06-25 10:36:00,525] fat loss: 1.4902
[2023-06-25 10:36:00,525] fat percent loss: 0.1173
[2023-06-25 10:36:00,525] carb loss: 2.0490
[2023-06-25 10:36:00,525] carb percent loss: 0.1062
[2023-06-25 10:36:00,525] protein loss: 1.8299
[2023-06-25 10:36:00,525] protein percent loss: 0.1011
[2023-06-25 10:36:00,525] Epoch 136/150
[2023-06-25 10:36:26,654] test loss: 1.3195
[2023-06-25 10:36:26,655] cal loss: 60.0024
[2023-06-25 10:36:26,655] cal percent loss: 0.2353
[2023-06-25 10:36:26,655] mass loss: 33.1172
[2023-06-25 10:36:26,655] mass percent loss: 0.1519
[2023-06-25 10:36:26,655] fat loss: 4.1098
[2023-06-25 10:36:26,655] fat percent loss: 0.3236
[2023-06-25 10:36:26,655] carb loss: 5.7965
[2023-06-25 10:36:26,655] carb percent loss: 0.3003
[2023-06-25 10:36:26,655] protein loss: 5.6197
[2023-06-25 10:36:26,655] protein percent loss: 0.3105
[2023-06-25 10:36:26,656] Epoch 137/150
[2023-06-25 10:38:57,357] train loss: 0.4816
[2023-06-25 10:38:57,357] cal loss: 20.6139
[2023-06-25 10:38:57,357] cal percent loss: 0.0808
[2023-06-25 10:38:57,357] mass loss: 14.6459
[2023-06-25 10:38:57,357] mass percent loss: 0.0672
[2023-06-25 10:38:57,357] fat loss: 1.5029
[2023-06-25 10:38:57,358] fat percent loss: 0.1183
[2023-06-25 10:38:57,358] carb loss: 2.1139
[2023-06-25 10:38:57,358] carb percent loss: 0.1095
[2023-06-25 10:38:57,358] protein loss: 1.8494
[2023-06-25 10:38:57,358] protein percent loss: 0.1022
[2023-06-25 10:38:57,358] Epoch 137/150
[2023-06-25 10:39:23,130] test loss: 1.3078
[2023-06-25 10:39:23,131] cal loss: 59.1689
[2023-06-25 10:39:23,131] cal percent loss: 0.2320
[2023-06-25 10:39:23,131] mass loss: 34.0591
[2023-06-25 10:39:23,131] mass percent loss: 0.1562
[2023-06-25 10:39:23,132] fat loss: 4.0599
[2023-06-25 10:39:23,132] fat percent loss: 0.3197
[2023-06-25 10:39:23,132] carb loss: 5.6904
[2023-06-25 10:39:23,132] carb percent loss: 0.2948
[2023-06-25 10:39:23,132] protein loss: 5.5146
[2023-06-25 10:39:23,132] protein percent loss: 0.3047
[2023-06-25 10:39:23,132] Epoch 138/150
[2023-06-25 10:41:52,905] train loss: 0.4724
[2023-06-25 10:41:52,905] cal loss: 19.7360
[2023-06-25 10:41:52,905] cal percent loss: 0.0774
[2023-06-25 10:41:52,905] mass loss: 14.1416
[2023-06-25 10:41:52,905] mass percent loss: 0.0649
[2023-06-25 10:41:52,905] fat loss: 1.5093
[2023-06-25 10:41:52,905] fat percent loss: 0.1188
[2023-06-25 10:41:52,905] carb loss: 2.0649
[2023-06-25 10:41:52,905] carb percent loss: 0.1070
[2023-06-25 10:41:52,905] protein loss: 1.8402
[2023-06-25 10:41:52,905] protein percent loss: 0.1017
[2023-06-25 10:41:52,905] Epoch 138/150
[2023-06-25 10:42:19,330] test loss: 1.2949
[2023-06-25 10:42:19,331] cal loss: 57.2337
[2023-06-25 10:42:19,331] cal percent loss: 0.2244
[2023-06-25 10:42:19,331] mass loss: 34.5802
[2023-06-25 10:42:19,331] mass percent loss: 0.1586
[2023-06-25 10:42:19,331] fat loss: 3.9784
[2023-06-25 10:42:19,331] fat percent loss: 0.3133
[2023-06-25 10:42:19,331] carb loss: 5.6988
[2023-06-25 10:42:19,331] carb percent loss: 0.2953
[2023-06-25 10:42:19,332] protein loss: 5.4816
[2023-06-25 10:42:19,332] protein percent loss: 0.3028
[2023-06-25 10:42:19,332] Epoch 139/150
[2023-06-25 10:44:50,909] train loss: 0.4756
[2023-06-25 10:44:50,910] cal loss: 20.0140
[2023-06-25 10:44:50,910] cal percent loss: 0.0785
[2023-06-25 10:44:50,910] mass loss: 14.5376
[2023-06-25 10:44:50,910] mass percent loss: 0.0667
[2023-06-25 10:44:50,910] fat loss: 1.4560
[2023-06-25 10:44:50,910] fat percent loss: 0.1146
[2023-06-25 10:44:50,910] carb loss: 2.1344
[2023-06-25 10:44:50,910] carb percent loss: 0.1106
[2023-06-25 10:44:50,911] protein loss: 1.8483
[2023-06-25 10:44:50,911] protein percent loss: 0.1021
[2023-06-25 10:44:50,911] Epoch 139/150
[2023-06-25 10:45:16,730] test loss: 1.2800
[2023-06-25 10:45:16,731] cal loss: 55.9827
[2023-06-25 10:45:16,731] cal percent loss: 0.2195
[2023-06-25 10:45:16,731] mass loss: 34.2938
[2023-06-25 10:45:16,731] mass percent loss: 0.1573
[2023-06-25 10:45:16,731] fat loss: 3.9784
[2023-06-25 10:45:16,731] fat percent loss: 0.3133
[2023-06-25 10:45:16,732] carb loss: 5.7653
[2023-06-25 10:45:16,732] carb percent loss: 0.2987
[2023-06-25 10:45:16,732] protein loss: 5.2697
[2023-06-25 10:45:16,732] protein percent loss: 0.2911
[2023-06-25 10:45:16,732] Epoch 140/150
[2023-06-25 10:47:46,873] train loss: 0.4777
[2023-06-25 10:47:46,873] cal loss: 19.6973
[2023-06-25 10:47:46,873] cal percent loss: 0.0772
[2023-06-25 10:47:46,873] mass loss: 14.5690
[2023-06-25 10:47:46,874] mass percent loss: 0.0668
[2023-06-25 10:47:46,874] fat loss: 1.5156
[2023-06-25 10:47:46,874] fat percent loss: 0.1193
[2023-06-25 10:47:46,874] carb loss: 2.1205
[2023-06-25 10:47:46,874] carb percent loss: 0.1099
[2023-06-25 10:47:46,874] protein loss: 1.8387
[2023-06-25 10:47:46,874] protein percent loss: 0.1016
[2023-06-25 10:47:46,874] Epoch 140/150
[2023-06-25 10:48:09,426] test loss: 1.2826
[2023-06-25 10:48:09,427] cal loss: 56.7972
[2023-06-25 10:48:09,427] cal percent loss: 0.2227
[2023-06-25 10:48:09,427] mass loss: 33.8629
[2023-06-25 10:48:09,427] mass percent loss: 0.1553
[2023-06-25 10:48:09,427] fat loss: 3.9211
[2023-06-25 10:48:09,428] fat percent loss: 0.3088
[2023-06-25 10:48:09,428] carb loss: 5.7406
[2023-06-25 10:48:09,428] carb percent loss: 0.2974
[2023-06-25 10:48:09,428] protein loss: 5.4105
[2023-06-25 10:48:09,428] protein percent loss: 0.2989
[2023-06-25 10:48:09,428] Epoch 141/150
[2023-06-25 10:50:39,425] train loss: 0.4666
[2023-06-25 10:50:39,426] cal loss: 19.8832
[2023-06-25 10:50:39,426] cal percent loss: 0.0780
[2023-06-25 10:50:39,426] mass loss: 14.1654
[2023-06-25 10:50:39,426] mass percent loss: 0.0650
[2023-06-25 10:50:39,426] fat loss: 1.4378
[2023-06-25 10:50:39,427] fat percent loss: 0.1132
[2023-06-25 10:50:39,427] carb loss: 2.0863
[2023-06-25 10:50:39,427] carb percent loss: 0.1081
[2023-06-25 10:50:39,427] protein loss: 1.7942
[2023-06-25 10:50:39,427] protein percent loss: 0.0991
[2023-06-25 10:50:39,427] Epoch 141/150
[2023-06-25 10:51:04,838] test loss: 1.2862
[2023-06-25 10:51:04,839] cal loss: 56.5192
[2023-06-25 10:51:04,839] cal percent loss: 0.2216
[2023-06-25 10:51:04,839] mass loss: 34.1226
[2023-06-25 10:51:04,839] mass percent loss: 0.1565
[2023-06-25 10:51:04,839] fat loss: 3.8872
[2023-06-25 10:51:04,839] fat percent loss: 0.3061
[2023-06-25 10:51:04,839] carb loss: 5.7485
[2023-06-25 10:51:04,839] carb percent loss: 0.2978
[2023-06-25 10:51:04,839] protein loss: 5.5195
[2023-06-25 10:51:04,839] protein percent loss: 0.3049
[2023-06-25 10:51:04,839] Epoch 142/150
[2023-06-25 10:53:37,987] train loss: 0.4704
[2023-06-25 10:53:37,987] cal loss: 19.9045
[2023-06-25 10:53:37,987] cal percent loss: 0.0781
[2023-06-25 10:53:37,987] mass loss: 14.1678
[2023-06-25 10:53:37,987] mass percent loss: 0.0650
[2023-06-25 10:53:37,987] fat loss: 1.4422
[2023-06-25 10:53:37,987] fat percent loss: 0.1136
[2023-06-25 10:53:37,987] carb loss: 2.1136
[2023-06-25 10:53:37,987] carb percent loss: 0.1095
[2023-06-25 10:53:37,987] protein loss: 1.8381
[2023-06-25 10:53:37,987] protein percent loss: 0.1016
[2023-06-25 10:53:37,987] Epoch 142/150
[2023-06-25 10:54:06,074] test loss: 1.3023
[2023-06-25 10:54:06,075] cal loss: 58.0401
[2023-06-25 10:54:06,075] cal percent loss: 0.2276
[2023-06-25 10:54:06,075] mass loss: 35.1206
[2023-06-25 10:54:06,075] mass percent loss: 0.1611
[2023-06-25 10:54:06,076] fat loss: 3.9023
[2023-06-25 10:54:06,076] fat percent loss: 0.3073
[2023-06-25 10:54:06,076] carb loss: 5.8451
[2023-06-25 10:54:06,076] carb percent loss: 0.3029
[2023-06-25 10:54:06,076] protein loss: 5.4724
[2023-06-25 10:54:06,076] protein percent loss: 0.3023
[2023-06-25 10:54:06,076] Epoch 143/150
[2023-06-25 10:56:41,449] train loss: 0.4681
[2023-06-25 10:56:41,450] cal loss: 19.7922
[2023-06-25 10:56:41,450] cal percent loss: 0.0776
[2023-06-25 10:56:41,450] mass loss: 14.2140
[2023-06-25 10:56:41,450] mass percent loss: 0.0652
[2023-06-25 10:56:41,450] fat loss: 1.4331
[2023-06-25 10:56:41,450] fat percent loss: 0.1128
[2023-06-25 10:56:41,450] carb loss: 2.1231
[2023-06-25 10:56:41,450] carb percent loss: 0.1100
[2023-06-25 10:56:41,450] protein loss: 1.8009
[2023-06-25 10:56:41,450] protein percent loss: 0.0995
[2023-06-25 10:56:41,451] Epoch 143/150
[2023-06-25 10:57:06,581] test loss: 1.2929
[2023-06-25 10:57:06,582] cal loss: 57.2291
[2023-06-25 10:57:06,582] cal percent loss: 0.2244
[2023-06-25 10:57:06,582] mass loss: 33.9329
[2023-06-25 10:57:06,583] mass percent loss: 0.1557
[2023-06-25 10:57:06,583] fat loss: 4.0164
[2023-06-25 10:57:06,583] fat percent loss: 0.3162
[2023-06-25 10:57:06,583] carb loss: 5.7456
[2023-06-25 10:57:06,583] carb percent loss: 0.2977
[2023-06-25 10:57:06,583] protein loss: 5.4217
[2023-06-25 10:57:06,583] protein percent loss: 0.2995
[2023-06-25 10:57:06,584] Epoch 144/150
[2023-06-25 10:59:40,777] train loss: 0.4693
[2023-06-25 10:59:40,778] cal loss: 19.2037
[2023-06-25 10:59:40,778] cal percent loss: 0.0753
[2023-06-25 10:59:40,778] mass loss: 14.6019
[2023-06-25 10:59:40,778] mass percent loss: 0.0670
[2023-06-25 10:59:40,778] fat loss: 1.4463
[2023-06-25 10:59:40,779] fat percent loss: 0.1139
[2023-06-25 10:59:40,779] carb loss: 2.1126
[2023-06-25 10:59:40,779] carb percent loss: 0.1095
[2023-06-25 10:59:40,779] protein loss: 1.8209
[2023-06-25 10:59:40,779] protein percent loss: 0.1006
[2023-06-25 10:59:40,779] Epoch 144/150
[2023-06-25 11:00:01,904] test loss: 1.2818
[2023-06-25 11:00:01,904] cal loss: 56.3564
[2023-06-25 11:00:01,904] cal percent loss: 0.2210
[2023-06-25 11:00:01,905] mass loss: 33.9894
[2023-06-25 11:00:01,905] mass percent loss: 0.1559
[2023-06-25 11:00:01,905] fat loss: 3.9255
[2023-06-25 11:00:01,905] fat percent loss: 0.3091
[2023-06-25 11:00:01,905] carb loss: 5.8172
[2023-06-25 11:00:01,905] carb percent loss: 0.3014
[2023-06-25 11:00:01,905] protein loss: 5.3420
[2023-06-25 11:00:01,905] protein percent loss: 0.2951
[2023-06-25 11:00:01,906] Epoch 145/150
[2023-06-25 11:02:30,859] train loss: 0.4656
[2023-06-25 11:02:30,860] cal loss: 19.3001
[2023-06-25 11:02:30,860] cal percent loss: 0.0757
[2023-06-25 11:02:30,860] mass loss: 14.1341
[2023-06-25 11:02:30,861] mass percent loss: 0.0648
[2023-06-25 11:02:30,861] fat loss: 1.4914
[2023-06-25 11:02:30,861] fat percent loss: 0.1174
[2023-06-25 11:02:30,861] carb loss: 2.0819
[2023-06-25 11:02:30,861] carb percent loss: 0.1079
[2023-06-25 11:02:30,861] protein loss: 1.7550
[2023-06-25 11:02:30,861] protein percent loss: 0.0970
[2023-06-25 11:02:30,861] Epoch 145/150
[2023-06-25 11:02:55,152] test loss: 1.3129
[2023-06-25 11:02:55,152] cal loss: 58.8013
[2023-06-25 11:02:55,153] cal percent loss: 0.2306
[2023-06-25 11:02:55,153] mass loss: 33.8276
[2023-06-25 11:02:55,153] mass percent loss: 0.1552
[2023-06-25 11:02:55,153] fat loss: 4.0471
[2023-06-25 11:02:55,153] fat percent loss: 0.3187
[2023-06-25 11:02:55,153] carb loss: 5.8937
[2023-06-25 11:02:55,153] carb percent loss: 0.3054
[2023-06-25 11:02:55,153] protein loss: 5.5135
[2023-06-25 11:02:55,153] protein percent loss: 0.3046
[2023-06-25 11:02:55,154] Epoch 146/150
[2023-06-25 11:05:34,512] train loss: 0.4620
[2023-06-25 11:05:34,513] cal loss: 19.3619
[2023-06-25 11:05:34,513] cal percent loss: 0.0759
[2023-06-25 11:05:34,513] mass loss: 14.0313
[2023-06-25 11:05:34,513] mass percent loss: 0.0644
[2023-06-25 11:05:34,514] fat loss: 1.4367
[2023-06-25 11:05:34,514] fat percent loss: 0.1131
[2023-06-25 11:05:34,514] carb loss: 2.1004
[2023-06-25 11:05:34,514] carb percent loss: 0.1088
[2023-06-25 11:05:34,514] protein loss: 1.7564
[2023-06-25 11:05:34,514] protein percent loss: 0.0970
[2023-06-25 11:05:34,514] Epoch 146/150
[2023-06-25 11:05:58,754] test loss: 1.3170
[2023-06-25 11:05:58,754] cal loss: 59.3569
[2023-06-25 11:05:58,754] cal percent loss: 0.2328
[2023-06-25 11:05:58,754] mass loss: 34.3567
[2023-06-25 11:05:58,754] mass percent loss: 0.1576
[2023-06-25 11:05:58,755] fat loss: 4.0848
[2023-06-25 11:05:58,755] fat percent loss: 0.3216
[2023-06-25 11:05:58,755] carb loss: 5.7648
[2023-06-25 11:05:58,755] carb percent loss: 0.2987
[2023-06-25 11:05:58,755] protein loss: 5.5399
[2023-06-25 11:05:58,755] protein percent loss: 0.3061
[2023-06-25 11:05:58,755] Epoch 147/150
[2023-06-25 11:08:29,200] train loss: 0.4684
[2023-06-25 11:08:29,201] cal loss: 19.4760
[2023-06-25 11:08:29,201] cal percent loss: 0.0764
[2023-06-25 11:08:29,201] mass loss: 14.1089
[2023-06-25 11:08:29,201] mass percent loss: 0.0647
[2023-06-25 11:08:29,201] fat loss: 1.4578
[2023-06-25 11:08:29,201] fat percent loss: 0.1148
[2023-06-25 11:08:29,201] carb loss: 2.1172
[2023-06-25 11:08:29,201] carb percent loss: 0.1097
[2023-06-25 11:08:29,201] protein loss: 1.8172
[2023-06-25 11:08:29,202] protein percent loss: 0.1004
[2023-06-25 11:08:29,202] Epoch 147/150
[2023-06-25 11:08:55,208] test loss: 1.3000
[2023-06-25 11:08:55,209] cal loss: 57.4648
[2023-06-25 11:08:55,209] cal percent loss: 0.2254
[2023-06-25 11:08:55,209] mass loss: 34.2473
[2023-06-25 11:08:55,209] mass percent loss: 0.1571
[2023-06-25 11:08:55,209] fat loss: 3.9952
[2023-06-25 11:08:55,210] fat percent loss: 0.3146
[2023-06-25 11:08:55,210] carb loss: 5.7648
[2023-06-25 11:08:55,210] carb percent loss: 0.2987
[2023-06-25 11:08:55,210] protein loss: 5.5194
[2023-06-25 11:08:55,210] protein percent loss: 0.3049
[2023-06-25 11:08:55,210] Epoch 148/150
[2023-06-25 11:11:32,087] train loss: 0.4641
[2023-06-25 11:11:32,088] cal loss: 19.2346
[2023-06-25 11:11:32,088] cal percent loss: 0.0754
[2023-06-25 11:11:32,088] mass loss: 14.4355
[2023-06-25 11:11:32,088] mass percent loss: 0.0662
[2023-06-25 11:11:32,088] fat loss: 1.4101
[2023-06-25 11:11:32,089] fat percent loss: 0.1110
[2023-06-25 11:11:32,089] carb loss: 2.1223
[2023-06-25 11:11:32,089] carb percent loss: 0.1100
[2023-06-25 11:11:32,089] protein loss: 1.7796
[2023-06-25 11:11:32,089] protein percent loss: 0.0983
[2023-06-25 11:11:32,089] Epoch 148/150
[2023-06-25 11:12:00,336] test loss: 1.3099
[2023-06-25 11:12:00,336] cal loss: 58.8105
[2023-06-25 11:12:00,336] cal percent loss: 0.2306
[2023-06-25 11:12:00,336] mass loss: 33.5830
[2023-06-25 11:12:00,336] mass percent loss: 0.1541
[2023-06-25 11:12:00,336] fat loss: 4.1046
[2023-06-25 11:12:00,337] fat percent loss: 0.3232
[2023-06-25 11:12:00,337] carb loss: 5.7552
[2023-06-25 11:12:00,337] carb percent loss: 0.2982
[2023-06-25 11:12:00,337] protein loss: 5.5220
[2023-06-25 11:12:00,337] protein percent loss: 0.3051
[2023-06-25 11:12:00,337] Epoch 149/150
[2023-06-25 11:14:32,988] train loss: 0.4612
[2023-06-25 11:14:32,988] cal loss: 18.5849
[2023-06-25 11:14:32,988] cal percent loss: 0.0729
[2023-06-25 11:14:32,989] mass loss: 14.0876
[2023-06-25 11:14:32,989] mass percent loss: 0.0646
[2023-06-25 11:14:32,989] fat loss: 1.4349
[2023-06-25 11:14:32,989] fat percent loss: 0.1130
[2023-06-25 11:14:32,989] carb loss: 2.0656
[2023-06-25 11:14:32,989] carb percent loss: 0.1070
[2023-06-25 11:14:32,989] protein loss: 1.8381
[2023-06-25 11:14:32,989] protein percent loss: 0.1016
[2023-06-25 11:14:32,989] Epoch 149/150
[2023-06-25 11:14:59,534] test loss: 1.3034
[2023-06-25 11:14:59,534] cal loss: 58.6090
[2023-06-25 11:14:59,534] cal percent loss: 0.2298
[2023-06-25 11:14:59,534] mass loss: 33.5306
[2023-06-25 11:14:59,534] mass percent loss: 0.1538
[2023-06-25 11:14:59,534] fat loss: 4.1142
[2023-06-25 11:14:59,535] fat percent loss: 0.3240
[2023-06-25 11:14:59,535] carb loss: 5.7098
[2023-06-25 11:14:59,535] carb percent loss: 0.2958
[2023-06-25 11:14:59,535] protein loss: 5.4429
[2023-06-25 11:14:59,535] protein percent loss: 0.3007
[2023-06-25 11:14:59,535] Epoch 150/150
[2023-06-25 11:17:34,693] train loss: 0.4676
[2023-06-25 11:17:34,694] cal loss: 19.2766
[2023-06-25 11:17:34,694] cal percent loss: 0.0756
[2023-06-25 11:17:34,694] mass loss: 14.4695
[2023-06-25 11:17:34,694] mass percent loss: 0.0664
[2023-06-25 11:17:34,694] fat loss: 1.4164
[2023-06-25 11:17:34,694] fat percent loss: 0.1115
[2023-06-25 11:17:34,694] carb loss: 2.0970
[2023-06-25 11:17:34,695] carb percent loss: 0.1087
[2023-06-25 11:17:34,695] protein loss: 1.8566
[2023-06-25 11:17:34,695] protein percent loss: 0.1026
[2023-06-25 11:17:34,695] Epoch 150/150
[2023-06-25 11:18:00,946] test loss: 1.2959
[2023-06-25 11:18:00,947] cal loss: 58.1518
[2023-06-25 11:18:00,947] cal percent loss: 0.2280
[2023-06-25 11:18:00,947] mass loss: 34.1982
[2023-06-25 11:18:00,948] mass percent loss: 0.1569
[2023-06-25 11:18:00,948] fat loss: 3.9800
[2023-06-25 11:18:00,948] fat percent loss: 0.3134
[2023-06-25 11:18:00,948] carb loss: 5.6787
[2023-06-25 11:18:00,948] carb percent loss: 0.2942
[2023-06-25 11:18:00,948] protein loss: 5.4804
[2023-06-25 11:18:00,948] protein percent loss: 0.3028
[2023-06-25 11:18:23,454] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 11:18:24,240] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 11:18:27,131] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,133] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,133] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,140] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,141] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,147] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,147] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,148] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,148] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,154] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,155] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,161] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,161] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,162] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,163] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,169] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,169] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,175] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,175] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,177] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,177] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,183] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,183] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,189] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,189] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,191] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,191] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,197] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,197] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,203] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,203] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,205] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,205] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,211] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,211] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,217] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,217] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,219] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,219] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,225] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,225] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,232] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,232] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,234] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,234] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,240] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,240] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,246] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,246] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,247] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,248] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,254] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,254] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,259] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,260] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,261] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,261] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,271] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,271] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,277] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,277] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,278] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,279] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,285] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,285] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,291] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,291] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,292] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,292] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,298] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:27,298] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:18:27,304] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,023] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,024] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,024] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,025] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,026] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,026] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,027] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:18:28,028] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,029] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,029] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,030] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,030] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,030] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:18:28,030] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,030] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:18:28,030] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,030] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,031] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,031] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,031] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:18:28,031] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,031] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,032] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,033] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,034] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,035] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,036] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,037] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,038] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,039] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,040] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,041] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,044] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,045] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,046] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,047] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,048] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,049] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,050] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,051] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,052] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,053] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,054] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,055] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,056] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,057] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,058] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,059] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,060] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,061] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,062] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,063] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,064] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,065] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,066] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,067] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,068] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,069] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:18:28,070] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:18:28,071] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:18:28,071] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 11:18:28,071] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 11:18:28,071] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 11:18:30,151] Epoch 1/150
[2023-06-25 11:20:58,507] train loss: 3.6236
[2023-06-25 11:20:58,508] cal loss: 167.6174
[2023-06-25 11:20:58,508] cal percent loss: 0.6573
[2023-06-25 11:20:58,508] mass loss: 122.3821
[2023-06-25 11:20:58,508] mass percent loss: 0.5614
[2023-06-25 11:20:58,508] fat loss: 10.2883
[2023-06-25 11:20:58,508] fat percent loss: 0.8101
[2023-06-25 11:20:58,508] carb loss: 12.2174
[2023-06-25 11:20:58,508] carb percent loss: 0.6330
[2023-06-25 11:20:58,508] protein loss: 16.1334
[2023-06-25 11:20:58,508] protein percent loss: 0.8913
[2023-06-25 11:20:58,508] Epoch 1/150
[2023-06-25 11:21:24,328] test loss: 3.6922
[2023-06-25 11:21:24,329] cal loss: 168.9193
[2023-06-25 11:21:24,329] cal percent loss: 0.6624
[2023-06-25 11:21:24,329] mass loss: 120.8865
[2023-06-25 11:21:24,330] mass percent loss: 0.5545
[2023-06-25 11:21:24,330] fat loss: 10.7350
[2023-06-25 11:21:24,330] fat percent loss: 0.8453
[2023-06-25 11:21:24,330] carb loss: 13.4293
[2023-06-25 11:21:24,330] carb percent loss: 0.6958
[2023-06-25 11:21:24,330] protein loss: 15.8142
[2023-06-25 11:21:24,330] protein percent loss: 0.8737
[2023-06-25 11:21:24,330] Epoch 2/150
[2023-06-25 11:23:56,253] train loss: 2.9809
[2023-06-25 11:23:56,254] cal loss: 136.0090
[2023-06-25 11:23:56,254] cal percent loss: 0.5334
[2023-06-25 11:23:56,254] mass loss: 93.4287
[2023-06-25 11:23:56,254] mass percent loss: 0.4286
[2023-06-25 11:23:56,254] fat loss: 8.7157
[2023-06-25 11:23:56,254] fat percent loss: 0.6863
[2023-06-25 11:23:56,254] carb loss: 11.4107
[2023-06-25 11:23:56,255] carb percent loss: 0.5912
[2023-06-25 11:23:56,255] protein loss: 12.7301
[2023-06-25 11:23:56,255] protein percent loss: 0.7033
[2023-06-25 11:23:56,255] Epoch 2/150
[2023-06-25 11:24:19,271] test loss: 2.7283
[2023-06-25 11:24:19,272] cal loss: 121.1471
[2023-06-25 11:24:19,272] cal percent loss: 0.4751
[2023-06-25 11:24:19,272] mass loss: 71.9584
[2023-06-25 11:24:19,272] mass percent loss: 0.3301
[2023-06-25 11:24:19,272] fat loss: 8.4815
[2023-06-25 11:24:19,272] fat percent loss: 0.6678
[2023-06-25 11:24:19,272] carb loss: 11.8507
[2023-06-25 11:24:19,273] carb percent loss: 0.6140
[2023-06-25 11:24:19,273] protein loss: 11.5998
[2023-06-25 11:24:19,273] protein percent loss: 0.6409
[2023-06-25 11:24:19,273] Epoch 3/150
[2023-06-25 11:25:25,385] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpnopenseed_wrot_fc3_drop_attninit_warmup_150ep_mltscl.pt
TITLE:
- fpn openseed with aug+rotate fc 3 dropout freeze new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 5.0e-05
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 11:25:26,279] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 11:25:28,524] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,527] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,527] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,536] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,536] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,542] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,542] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,544] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,544] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,550] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,550] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,556] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,556] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,557] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,557] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,563] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,563] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,569] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,569] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,571] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,571] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,581] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,582] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,592] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,592] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,594] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,594] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,600] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,600] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,606] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,606] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,608] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,608] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,614] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,614] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,620] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,620] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,621] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,621] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,627] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,627] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,633] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,633] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,635] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,635] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,641] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,641] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,647] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,647] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,649] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,649] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,655] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,656] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,662] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,662] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,663] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,663] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,669] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,669] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,675] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,675] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,677] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,677] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,683] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,683] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,689] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,689] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,691] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,691] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,697] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:28,697] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 11:25:28,703] => init bias of Linear/Conv2d to zeros
[2023-06-25 11:25:29,356] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,357] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,358] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,358] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,358] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,358] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,358] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,358] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,359] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,359] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,360] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,361] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,362] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,363] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,363] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,364] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,364] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,364] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,364] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 11:25:29,365] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,365] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 11:25:29,365] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,365] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,365] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,365] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,365] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 11:25:29,365] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,365] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,366] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,367] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,368] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,369] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,370] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,371] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,372] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,373] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,374] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,375] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,376] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,377] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,378] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,379] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,380] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,381] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,382] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,383] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,384] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,385] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,386] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,387] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,388] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,389] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,390] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,391] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,392] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,393] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,394] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,395] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,396] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,397] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 11:25:29,398] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 11:25:29,399] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 11:25:29,399] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 11:25:29,399] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 11:25:30,637] Epoch 1/150
[2023-06-25 11:27:58,693] train loss: 3.6236
[2023-06-25 11:27:58,694] cal loss: 167.6174
[2023-06-25 11:27:58,694] cal percent loss: 0.6573
[2023-06-25 11:27:58,694] mass loss: 122.3821
[2023-06-25 11:27:58,694] mass percent loss: 0.5614
[2023-06-25 11:27:58,694] fat loss: 10.2883
[2023-06-25 11:27:58,694] fat percent loss: 0.8101
[2023-06-25 11:27:58,694] carb loss: 12.2174
[2023-06-25 11:27:58,694] carb percent loss: 0.6330
[2023-06-25 11:27:58,695] protein loss: 16.1334
[2023-06-25 11:27:58,695] protein percent loss: 0.8913
[2023-06-25 11:27:58,695] Epoch 1/150
[2023-06-25 11:28:24,588] test loss: 3.6922
[2023-06-25 11:28:24,589] cal loss: 168.9193
[2023-06-25 11:28:24,589] cal percent loss: 0.6624
[2023-06-25 11:28:24,589] mass loss: 120.8865
[2023-06-25 11:28:24,589] mass percent loss: 0.5545
[2023-06-25 11:28:24,589] fat loss: 10.7350
[2023-06-25 11:28:24,589] fat percent loss: 0.8453
[2023-06-25 11:28:24,589] carb loss: 13.4293
[2023-06-25 11:28:24,589] carb percent loss: 0.6958
[2023-06-25 11:28:24,589] protein loss: 15.8142
[2023-06-25 11:28:24,589] protein percent loss: 0.8737
[2023-06-25 11:28:24,590] Epoch 2/150
[2023-06-25 11:30:56,693] train loss: 3.2084
[2023-06-25 11:30:56,694] cal loss: 147.8902
[2023-06-25 11:30:56,694] cal percent loss: 0.5800
[2023-06-25 11:30:56,694] mass loss: 105.1525
[2023-06-25 11:30:56,694] mass percent loss: 0.4824
[2023-06-25 11:30:56,694] fat loss: 9.2298
[2023-06-25 11:30:56,694] fat percent loss: 0.7268
[2023-06-25 11:30:56,694] carb loss: 11.7400
[2023-06-25 11:30:56,695] carb percent loss: 0.6083
[2023-06-25 11:30:56,695] protein loss: 13.7133
[2023-06-25 11:30:56,695] protein percent loss: 0.7576
[2023-06-25 11:30:56,695] Epoch 2/150
[2023-06-25 11:31:19,754] test loss: 2.9375
[2023-06-25 11:31:19,755] cal loss: 131.7091
[2023-06-25 11:31:19,755] cal percent loss: 0.5165
[2023-06-25 11:31:19,755] mass loss: 83.8749
[2023-06-25 11:31:19,755] mass percent loss: 0.3847
[2023-06-25 11:31:19,755] fat loss: 8.9001
[2023-06-25 11:31:19,755] fat percent loss: 0.7008
[2023-06-25 11:31:19,755] carb loss: 12.4123
[2023-06-25 11:31:19,756] carb percent loss: 0.6431
[2023-06-25 11:31:19,756] protein loss: 12.2454
[2023-06-25 11:31:19,756] protein percent loss: 0.6765
[2023-06-25 11:31:19,756] Epoch 3/150
[2023-06-25 11:33:51,573] train loss: 2.5992
[2023-06-25 11:33:51,574] cal loss: 116.5923
[2023-06-25 11:33:51,574] cal percent loss: 0.4572
[2023-06-25 11:33:51,574] mass loss: 76.5874
[2023-06-25 11:33:51,574] mass percent loss: 0.3513
[2023-06-25 11:33:51,574] fat loss: 7.8855
[2023-06-25 11:33:51,574] fat percent loss: 0.6209
[2023-06-25 11:33:51,574] carb loss: 10.6165
[2023-06-25 11:33:51,574] carb percent loss: 0.5501
[2023-06-25 11:33:51,574] protein loss: 10.8511
[2023-06-25 11:33:51,574] protein percent loss: 0.5995
[2023-06-25 11:33:51,575] Epoch 3/150
[2023-06-25 11:34:16,703] test loss: 2.5310
[2023-06-25 11:34:16,703] cal loss: 116.3906
[2023-06-25 11:34:16,703] cal percent loss: 0.4564
[2023-06-25 11:34:16,704] mass loss: 63.4543
[2023-06-25 11:34:16,704] mass percent loss: 0.2911
[2023-06-25 11:34:16,704] fat loss: 8.1608
[2023-06-25 11:34:16,704] fat percent loss: 0.6426
[2023-06-25 11:34:16,704] carb loss: 10.5951
[2023-06-25 11:34:16,704] carb percent loss: 0.5490
[2023-06-25 11:34:16,704] protein loss: 10.7257
[2023-06-25 11:34:16,704] protein percent loss: 0.5926
[2023-06-25 11:34:16,705] Epoch 4/150
[2023-06-25 11:36:48,817] train loss: 2.2453
[2023-06-25 11:36:48,818] cal loss: 98.3548
[2023-06-25 11:36:48,818] cal percent loss: 0.3857
[2023-06-25 11:36:48,818] mass loss: 62.3302
[2023-06-25 11:36:48,818] mass percent loss: 0.2859
[2023-06-25 11:36:48,818] fat loss: 7.1873
[2023-06-25 11:36:48,818] fat percent loss: 0.5659
[2023-06-25 11:36:48,818] carb loss: 9.5088
[2023-06-25 11:36:48,818] carb percent loss: 0.4927
[2023-06-25 11:36:48,819] protein loss: 9.1926
[2023-06-25 11:36:48,819] protein percent loss: 0.5079
[2023-06-25 11:36:48,819] Epoch 4/150
[2023-06-25 11:37:17,548] test loss: 2.2183
[2023-06-25 11:37:17,549] cal loss: 89.5316
[2023-06-25 11:37:17,549] cal percent loss: 0.3511
[2023-06-25 11:37:17,549] mass loss: 61.3295
[2023-06-25 11:37:17,549] mass percent loss: 0.2813
[2023-06-25 11:37:17,549] fat loss: 7.6482
[2023-06-25 11:37:17,549] fat percent loss: 0.6022
[2023-06-25 11:37:17,549] carb loss: 9.6397
[2023-06-25 11:37:17,549] carb percent loss: 0.4995
[2023-06-25 11:37:17,549] protein loss: 8.7649
[2023-06-25 11:37:17,549] protein percent loss: 0.4842
[2023-06-25 11:37:17,549] Epoch 5/150
[2023-06-25 11:39:48,491] train loss: 2.0370
[2023-06-25 11:39:48,492] cal loss: 87.7527
[2023-06-25 11:39:48,492] cal percent loss: 0.3441
[2023-06-25 11:39:48,492] mass loss: 55.1881
[2023-06-25 11:39:48,492] mass percent loss: 0.2532
[2023-06-25 11:39:48,492] fat loss: 6.7224
[2023-06-25 11:39:48,493] fat percent loss: 0.5293
[2023-06-25 11:39:48,493] carb loss: 8.8812
[2023-06-25 11:39:48,493] carb percent loss: 0.4602
[2023-06-25 11:39:48,493] protein loss: 8.1095
[2023-06-25 11:39:48,493] protein percent loss: 0.4480
[2023-06-25 11:39:48,493] Epoch 5/150
[2023-06-25 11:40:16,022] test loss: 2.2242
[2023-06-25 11:40:16,023] cal loss: 95.0894
[2023-06-25 11:40:16,023] cal percent loss: 0.3729
[2023-06-25 11:40:16,023] mass loss: 53.4740
[2023-06-25 11:40:16,023] mass percent loss: 0.2453
[2023-06-25 11:40:16,023] fat loss: 7.4476
[2023-06-25 11:40:16,023] fat percent loss: 0.5864
[2023-06-25 11:40:16,024] carb loss: 8.8706
[2023-06-25 11:40:16,024] carb percent loss: 0.4596
[2023-06-25 11:40:16,024] protein loss: 10.3482
[2023-06-25 11:40:16,024] protein percent loss: 0.5717
[2023-06-25 11:40:16,024] Epoch 6/150
[2023-06-25 11:42:42,108] train loss: 1.9076
[2023-06-25 11:42:42,109] cal loss: 84.0398
[2023-06-25 11:42:42,109] cal percent loss: 0.3296
[2023-06-25 11:42:42,109] mass loss: 49.3338
[2023-06-25 11:42:42,109] mass percent loss: 0.2263
[2023-06-25 11:42:42,109] fat loss: 6.3911
[2023-06-25 11:42:42,109] fat percent loss: 0.5032
[2023-06-25 11:42:42,109] carb loss: 8.0397
[2023-06-25 11:42:42,109] carb percent loss: 0.4166
[2023-06-25 11:42:42,109] protein loss: 7.8208
[2023-06-25 11:42:42,110] protein percent loss: 0.4321
[2023-06-25 11:42:42,110] Epoch 6/150
[2023-06-25 11:43:06,339] test loss: 1.8155
[2023-06-25 11:43:06,340] cal loss: 72.5929
[2023-06-25 11:43:06,340] cal percent loss: 0.2847
[2023-06-25 11:43:06,340] mass loss: 48.4854
[2023-06-25 11:43:06,340] mass percent loss: 0.2224
[2023-06-25 11:43:06,340] fat loss: 6.2893
[2023-06-25 11:43:06,341] fat percent loss: 0.4952
[2023-06-25 11:43:06,341] carb loss: 8.1158
[2023-06-25 11:43:06,341] carb percent loss: 0.4205
[2023-06-25 11:43:06,341] protein loss: 7.1968
[2023-06-25 11:43:06,341] protein percent loss: 0.3976
[2023-06-25 11:43:06,341] Epoch 7/150
[2023-06-25 11:45:34,600] train loss: 1.7884
[2023-06-25 11:45:34,601] cal loss: 78.2153
[2023-06-25 11:45:34,601] cal percent loss: 0.3067
[2023-06-25 11:45:34,601] mass loss: 47.1015
[2023-06-25 11:45:34,601] mass percent loss: 0.2161
[2023-06-25 11:45:34,601] fat loss: 5.9200
[2023-06-25 11:45:34,601] fat percent loss: 0.4661
[2023-06-25 11:45:34,601] carb loss: 7.7811
[2023-06-25 11:45:34,601] carb percent loss: 0.4032
[2023-06-25 11:45:34,601] protein loss: 7.1671
[2023-06-25 11:45:34,601] protein percent loss: 0.3960
[2023-06-25 11:45:34,601] Epoch 7/150
[2023-06-25 11:45:59,543] test loss: 1.7823
[2023-06-25 11:45:59,544] cal loss: 73.8232
[2023-06-25 11:45:59,544] cal percent loss: 0.2895
[2023-06-25 11:45:59,544] mass loss: 42.8916
[2023-06-25 11:45:59,544] mass percent loss: 0.1968
[2023-06-25 11:45:59,544] fat loss: 5.7447
[2023-06-25 11:45:59,545] fat percent loss: 0.4523
[2023-06-25 11:45:59,545] carb loss: 7.9850
[2023-06-25 11:45:59,545] carb percent loss: 0.4137
[2023-06-25 11:45:59,545] protein loss: 8.0461
[2023-06-25 11:45:59,545] protein percent loss: 0.4445
[2023-06-25 11:45:59,545] Epoch 8/150
[2023-06-25 11:48:34,477] train loss: 1.7245
[2023-06-25 11:48:34,478] cal loss: 74.8148
[2023-06-25 11:48:34,478] cal percent loss: 0.2934
[2023-06-25 11:48:34,478] mass loss: 44.2716
[2023-06-25 11:48:34,478] mass percent loss: 0.2031
[2023-06-25 11:48:34,478] fat loss: 5.6875
[2023-06-25 11:48:34,479] fat percent loss: 0.4478
[2023-06-25 11:48:34,479] carb loss: 7.3286
[2023-06-25 11:48:34,479] carb percent loss: 0.3797
[2023-06-25 11:48:34,479] protein loss: 7.2975
[2023-06-25 11:48:34,479] protein percent loss: 0.4032
[2023-06-25 11:48:34,479] Epoch 8/150
[2023-06-25 11:48:59,193] test loss: 1.8618
[2023-06-25 11:48:59,194] cal loss: 78.9920
[2023-06-25 11:48:59,194] cal percent loss: 0.3098
[2023-06-25 11:48:59,194] mass loss: 43.2940
[2023-06-25 11:48:59,194] mass percent loss: 0.1986
[2023-06-25 11:48:59,194] fat loss: 6.4482
[2023-06-25 11:48:59,194] fat percent loss: 0.5077
[2023-06-25 11:48:59,194] carb loss: 9.1812
[2023-06-25 11:48:59,194] carb percent loss: 0.4757
[2023-06-25 11:48:59,194] protein loss: 6.9870
[2023-06-25 11:48:59,194] protein percent loss: 0.3860
[2023-06-25 11:48:59,195] Epoch 9/150
[2023-06-25 11:51:26,398] train loss: 1.6559
[2023-06-25 11:51:26,399] cal loss: 71.5299
[2023-06-25 11:51:26,399] cal percent loss: 0.2805
[2023-06-25 11:51:26,399] mass loss: 43.7324
[2023-06-25 11:51:26,399] mass percent loss: 0.2006
[2023-06-25 11:51:26,399] fat loss: 5.4877
[2023-06-25 11:51:26,399] fat percent loss: 0.4321
[2023-06-25 11:51:26,399] carb loss: 7.1602
[2023-06-25 11:51:26,399] carb percent loss: 0.3710
[2023-06-25 11:51:26,399] protein loss: 6.7335
[2023-06-25 11:51:26,399] protein percent loss: 0.3720
[2023-06-25 11:51:26,400] Epoch 9/150
[2023-06-25 11:51:51,753] test loss: 2.0778
[2023-06-25 11:51:51,754] cal loss: 102.9621
[2023-06-25 11:51:51,754] cal percent loss: 0.4038
[2023-06-25 11:51:51,754] mass loss: 57.5576
[2023-06-25 11:51:51,754] mass percent loss: 0.2640
[2023-06-25 11:51:51,754] fat loss: 5.4733
[2023-06-25 11:51:51,755] fat percent loss: 0.4310
[2023-06-25 11:51:51,755] carb loss: 10.9391
[2023-06-25 11:51:51,755] carb percent loss: 0.5668
[2023-06-25 11:51:51,755] protein loss: 7.2674
[2023-06-25 11:51:51,755] protein percent loss: 0.4015
[2023-06-25 11:51:51,755] Epoch 10/150
[2023-06-25 11:54:22,585] train loss: 1.5857
[2023-06-25 11:54:22,586] cal loss: 68.8389
[2023-06-25 11:54:22,586] cal percent loss: 0.2700
[2023-06-25 11:54:22,586] mass loss: 40.7099
[2023-06-25 11:54:22,586] mass percent loss: 0.1867
[2023-06-25 11:54:22,586] fat loss: 5.1114
[2023-06-25 11:54:22,586] fat percent loss: 0.4025
[2023-06-25 11:54:22,586] carb loss: 7.1220
[2023-06-25 11:54:22,587] carb percent loss: 0.3690
[2023-06-25 11:54:22,587] protein loss: 6.5375
[2023-06-25 11:54:22,587] protein percent loss: 0.3612
[2023-06-25 11:54:22,587] Epoch 10/150
[2023-06-25 11:54:47,294] test loss: 1.5699
[2023-06-25 11:54:47,295] cal loss: 65.9613
[2023-06-25 11:54:47,295] cal percent loss: 0.2587
[2023-06-25 11:54:47,295] mass loss: 39.5284
[2023-06-25 11:54:47,295] mass percent loss: 0.1813
[2023-06-25 11:54:47,296] fat loss: 4.9954
[2023-06-25 11:54:47,296] fat percent loss: 0.3933
[2023-06-25 11:54:47,296] carb loss: 7.2881
[2023-06-25 11:54:47,296] carb percent loss: 0.3776
[2023-06-25 11:54:47,296] protein loss: 6.6518
[2023-06-25 11:54:47,296] protein percent loss: 0.3675
[2023-06-25 11:54:47,296] Epoch 11/150
[2023-06-25 11:57:14,326] train loss: 1.5543
[2023-06-25 11:57:14,327] cal loss: 66.6876
[2023-06-25 11:57:14,327] cal percent loss: 0.2615
[2023-06-25 11:57:14,327] mass loss: 39.3775
[2023-06-25 11:57:14,327] mass percent loss: 0.1806
[2023-06-25 11:57:14,328] fat loss: 5.1895
[2023-06-25 11:57:14,328] fat percent loss: 0.4086
[2023-06-25 11:57:14,328] carb loss: 6.8495
[2023-06-25 11:57:14,328] carb percent loss: 0.3549
[2023-06-25 11:57:14,328] protein loss: 6.3947
[2023-06-25 11:57:14,328] protein percent loss: 0.3533
[2023-06-25 11:57:14,328] Epoch 11/150
[2023-06-25 11:57:40,314] test loss: 1.6894
[2023-06-25 11:57:40,314] cal loss: 77.7084
[2023-06-25 11:57:40,315] cal percent loss: 0.3047
[2023-06-25 11:57:40,315] mass loss: 35.3017
[2023-06-25 11:57:40,315] mass percent loss: 0.1619
[2023-06-25 11:57:40,315] fat loss: 6.0581
[2023-06-25 11:57:40,315] fat percent loss: 0.4770
[2023-06-25 11:57:40,315] carb loss: 7.9216
[2023-06-25 11:57:40,315] carb percent loss: 0.4104
[2023-06-25 11:57:40,315] protein loss: 6.3413
[2023-06-25 11:57:40,315] protein percent loss: 0.3503
[2023-06-25 11:57:40,316] Epoch 12/150
[2023-06-25 12:00:11,356] train loss: 1.5031
[2023-06-25 12:00:11,357] cal loss: 66.1545
[2023-06-25 12:00:11,357] cal percent loss: 0.2594
[2023-06-25 12:00:11,357] mass loss: 37.5859
[2023-06-25 12:00:11,357] mass percent loss: 0.1724
[2023-06-25 12:00:11,357] fat loss: 4.9132
[2023-06-25 12:00:11,357] fat percent loss: 0.3869
[2023-06-25 12:00:11,358] carb loss: 6.5153
[2023-06-25 12:00:11,358] carb percent loss: 0.3376
[2023-06-25 12:00:11,358] protein loss: 6.3501
[2023-06-25 12:00:11,358] protein percent loss: 0.3508
[2023-06-25 12:00:11,358] Epoch 12/150
[2023-06-25 12:00:35,300] test loss: 1.6185
[2023-06-25 12:00:35,301] cal loss: 63.1483
[2023-06-25 12:00:35,301] cal percent loss: 0.2476
[2023-06-25 12:00:35,301] mass loss: 55.0879
[2023-06-25 12:00:35,301] mass percent loss: 0.2527
[2023-06-25 12:00:35,301] fat loss: 4.7209
[2023-06-25 12:00:35,301] fat percent loss: 0.3717
[2023-06-25 12:00:35,301] carb loss: 7.0593
[2023-06-25 12:00:35,301] carb percent loss: 0.3658
[2023-06-25 12:00:35,302] protein loss: 6.5835
[2023-06-25 12:00:35,302] protein percent loss: 0.3637
[2023-06-25 12:00:35,302] Epoch 13/150
[2023-06-25 12:03:09,625] train loss: 1.5059
[2023-06-25 12:03:09,625] cal loss: 64.9665
[2023-06-25 12:03:09,625] cal percent loss: 0.2548
[2023-06-25 12:03:09,625] mass loss: 38.3060
[2023-06-25 12:03:09,625] mass percent loss: 0.1757
[2023-06-25 12:03:09,626] fat loss: 4.9642
[2023-06-25 12:03:09,626] fat percent loss: 0.3909
[2023-06-25 12:03:09,626] carb loss: 6.4404
[2023-06-25 12:03:09,626] carb percent loss: 0.3337
[2023-06-25 12:03:09,626] protein loss: 6.4159
[2023-06-25 12:03:09,626] protein percent loss: 0.3545
[2023-06-25 12:03:09,626] Epoch 13/150
[2023-06-25 12:03:33,325] test loss: 1.4566
[2023-06-25 12:03:33,325] cal loss: 52.3288
[2023-06-25 12:03:33,326] cal percent loss: 0.2052
[2023-06-25 12:03:33,326] mass loss: 37.1739
[2023-06-25 12:03:33,326] mass percent loss: 0.1705
[2023-06-25 12:03:33,326] fat loss: 4.9361
[2023-06-25 12:03:33,326] fat percent loss: 0.3887
[2023-06-25 12:03:33,326] carb loss: 7.3202
[2023-06-25 12:03:33,326] carb percent loss: 0.3793
[2023-06-25 12:03:33,326] protein loss: 5.9624
[2023-06-25 12:03:33,326] protein percent loss: 0.3294
[2023-06-25 12:03:33,327] Epoch 14/150
[2023-06-25 12:06:07,373] train loss: 1.4474
[2023-06-25 12:06:07,374] cal loss: 62.1910
[2023-06-25 12:06:07,374] cal percent loss: 0.2439
[2023-06-25 12:06:07,374] mass loss: 36.6321
[2023-06-25 12:06:07,374] mass percent loss: 0.1680
[2023-06-25 12:06:07,374] fat loss: 4.7589
[2023-06-25 12:06:07,374] fat percent loss: 0.3747
[2023-06-25 12:06:07,375] carb loss: 6.5153
[2023-06-25 12:06:07,375] carb percent loss: 0.3376
[2023-06-25 12:06:07,375] protein loss: 5.9384
[2023-06-25 12:06:07,375] protein percent loss: 0.3281
[2023-06-25 12:06:07,375] Epoch 14/150
[2023-06-25 12:06:30,997] test loss: 1.8637
[2023-06-25 12:06:30,998] cal loss: 87.3751
[2023-06-25 12:06:30,998] cal percent loss: 0.3426
[2023-06-25 12:06:30,998] mass loss: 48.4532
[2023-06-25 12:06:30,999] mass percent loss: 0.2223
[2023-06-25 12:06:30,999] fat loss: 5.7534
[2023-06-25 12:06:30,999] fat percent loss: 0.4530
[2023-06-25 12:06:30,999] carb loss: 7.8756
[2023-06-25 12:06:30,999] carb percent loss: 0.4081
[2023-06-25 12:06:30,999] protein loss: 7.8497
[2023-06-25 12:06:30,999] protein percent loss: 0.4337
[2023-06-25 12:06:31,000] Epoch 15/150
[2023-06-25 12:08:57,907] train loss: 1.5107
[2023-06-25 12:08:57,908] cal loss: 66.5521
[2023-06-25 12:08:57,908] cal percent loss: 0.2610
[2023-06-25 12:08:57,908] mass loss: 37.4716
[2023-06-25 12:08:57,908] mass percent loss: 0.1719
[2023-06-25 12:08:57,909] fat loss: 5.1436
[2023-06-25 12:08:57,909] fat percent loss: 0.4050
[2023-06-25 12:08:57,909] carb loss: 6.2834
[2023-06-25 12:08:57,909] carb percent loss: 0.3256
[2023-06-25 12:08:57,909] protein loss: 6.3435
[2023-06-25 12:08:57,909] protein percent loss: 0.3505
[2023-06-25 12:08:57,909] Epoch 15/150
[2023-06-25 12:09:22,625] test loss: 1.5622
[2023-06-25 12:09:22,626] cal loss: 71.1167
[2023-06-25 12:09:22,626] cal percent loss: 0.2789
[2023-06-25 12:09:22,626] mass loss: 37.9205
[2023-06-25 12:09:22,627] mass percent loss: 0.1739
[2023-06-25 12:09:22,627] fat loss: 4.8930
[2023-06-25 12:09:22,627] fat percent loss: 0.3853
[2023-06-25 12:09:22,627] carb loss: 7.2159
[2023-06-25 12:09:22,627] carb percent loss: 0.3739
[2023-06-25 12:09:22,627] protein loss: 6.4437
[2023-06-25 12:09:22,627] protein percent loss: 0.3560
[2023-06-25 12:09:22,627] Epoch 16/150
[2023-06-25 12:11:54,454] train loss: 1.4337
[2023-06-25 12:11:54,455] cal loss: 62.9884
[2023-06-25 12:11:54,455] cal percent loss: 0.2470
[2023-06-25 12:11:54,455] mass loss: 36.3145
[2023-06-25 12:11:54,455] mass percent loss: 0.1666
[2023-06-25 12:11:54,455] fat loss: 4.6242
[2023-06-25 12:11:54,455] fat percent loss: 0.3641
[2023-06-25 12:11:54,455] carb loss: 6.2161
[2023-06-25 12:11:54,455] carb percent loss: 0.3221
[2023-06-25 12:11:54,455] protein loss: 6.1025
[2023-06-25 12:11:54,455] protein percent loss: 0.3372
[2023-06-25 12:11:54,455] Epoch 16/150
[2023-06-25 12:12:20,081] test loss: 1.6320
[2023-06-25 12:12:20,082] cal loss: 78.7437
[2023-06-25 12:12:20,082] cal percent loss: 0.3088
[2023-06-25 12:12:20,082] mass loss: 37.1072
[2023-06-25 12:12:20,082] mass percent loss: 0.1702
[2023-06-25 12:12:20,082] fat loss: 5.3286
[2023-06-25 12:12:20,082] fat percent loss: 0.4196
[2023-06-25 12:12:20,082] carb loss: 6.8185
[2023-06-25 12:12:20,082] carb percent loss: 0.3533
[2023-06-25 12:12:20,082] protein loss: 6.9611
[2023-06-25 12:12:20,082] protein percent loss: 0.3846
[2023-06-25 12:12:20,082] Epoch 17/150
[2023-06-25 12:14:52,616] train loss: 1.4511
[2023-06-25 12:14:52,616] cal loss: 64.0907
[2023-06-25 12:14:52,616] cal percent loss: 0.2513
[2023-06-25 12:14:52,617] mass loss: 36.8907
[2023-06-25 12:14:52,617] mass percent loss: 0.1692
[2023-06-25 12:14:52,617] fat loss: 4.6038
[2023-06-25 12:14:52,617] fat percent loss: 0.3625
[2023-06-25 12:14:52,617] carb loss: 6.4079
[2023-06-25 12:14:52,617] carb percent loss: 0.3320
[2023-06-25 12:14:52,617] protein loss: 6.1386
[2023-06-25 12:14:52,617] protein percent loss: 0.3392
[2023-06-25 12:14:52,618] Epoch 17/150
[2023-06-25 12:15:17,064] test loss: 1.7680
[2023-06-25 12:15:17,064] cal loss: 80.0458
[2023-06-25 12:15:17,065] cal percent loss: 0.3139
[2023-06-25 12:15:17,065] mass loss: 50.6398
[2023-06-25 12:15:17,065] mass percent loss: 0.2323
[2023-06-25 12:15:17,065] fat loss: 5.3608
[2023-06-25 12:15:17,065] fat percent loss: 0.4221
[2023-06-25 12:15:17,065] carb loss: 9.2787
[2023-06-25 12:15:17,065] carb percent loss: 0.4808
[2023-06-25 12:15:17,065] protein loss: 5.6346
[2023-06-25 12:15:17,065] protein percent loss: 0.3113
[2023-06-25 12:15:17,066] Epoch 18/150
[2023-06-25 12:17:51,786] train loss: 1.3969
[2023-06-25 12:17:51,787] cal loss: 61.0743
[2023-06-25 12:17:51,787] cal percent loss: 0.2395
[2023-06-25 12:17:51,787] mass loss: 35.6542
[2023-06-25 12:17:51,787] mass percent loss: 0.1636
[2023-06-25 12:17:51,787] fat loss: 4.5249
[2023-06-25 12:17:51,787] fat percent loss: 0.3563
[2023-06-25 12:17:51,787] carb loss: 6.1399
[2023-06-25 12:17:51,787] carb percent loss: 0.3181
[2023-06-25 12:17:51,787] protein loss: 5.8336
[2023-06-25 12:17:51,788] protein percent loss: 0.3223
[2023-06-25 12:17:51,788] Epoch 18/150
[2023-06-25 12:18:16,241] test loss: 1.5232
[2023-06-25 12:18:16,241] cal loss: 70.2918
[2023-06-25 12:18:16,241] cal percent loss: 0.2757
[2023-06-25 12:18:16,241] mass loss: 34.0117
[2023-06-25 12:18:16,241] mass percent loss: 0.1560
[2023-06-25 12:18:16,241] fat loss: 5.8931
[2023-06-25 12:18:16,241] fat percent loss: 0.4640
[2023-06-25 12:18:16,241] carb loss: 6.3575
[2023-06-25 12:18:16,241] carb percent loss: 0.3294
[2023-06-25 12:18:16,242] protein loss: 5.4865
[2023-06-25 12:18:16,242] protein percent loss: 0.3031
[2023-06-25 12:18:16,242] Epoch 19/150
[2023-06-25 12:20:41,567] train loss: 1.3836
[2023-06-25 12:20:41,568] cal loss: 60.0012
[2023-06-25 12:20:41,568] cal percent loss: 0.2353
[2023-06-25 12:20:41,568] mass loss: 33.7067
[2023-06-25 12:20:41,568] mass percent loss: 0.1546
[2023-06-25 12:20:41,568] fat loss: 4.7051
[2023-06-25 12:20:41,568] fat percent loss: 0.3705
[2023-06-25 12:20:41,568] carb loss: 6.1100
[2023-06-25 12:20:41,568] carb percent loss: 0.3166
[2023-06-25 12:20:41,568] protein loss: 5.6598
[2023-06-25 12:20:41,568] protein percent loss: 0.3127
[2023-06-25 12:20:41,568] Epoch 19/150
[2023-06-25 12:21:08,094] test loss: 1.4943
[2023-06-25 12:21:08,095] cal loss: 67.2817
[2023-06-25 12:21:08,095] cal percent loss: 0.2638
[2023-06-25 12:21:08,095] mass loss: 36.1608
[2023-06-25 12:21:08,095] mass percent loss: 0.1659
[2023-06-25 12:21:08,095] fat loss: 4.8768
[2023-06-25 12:21:08,095] fat percent loss: 0.3840
[2023-06-25 12:21:08,095] carb loss: 6.3368
[2023-06-25 12:21:08,095] carb percent loss: 0.3283
[2023-06-25 12:21:08,096] protein loss: 6.4627
[2023-06-25 12:21:08,096] protein percent loss: 0.3571
[2023-06-25 12:21:08,096] Epoch 20/150
[2023-06-25 12:23:40,104] train loss: 1.3392
[2023-06-25 12:23:40,105] cal loss: 57.9145
[2023-06-25 12:23:40,105] cal percent loss: 0.2271
[2023-06-25 12:23:40,105] mass loss: 33.7915
[2023-06-25 12:23:40,105] mass percent loss: 0.1550
[2023-06-25 12:23:40,105] fat loss: 4.3404
[2023-06-25 12:23:40,105] fat percent loss: 0.3418
[2023-06-25 12:23:40,105] carb loss: 5.9919
[2023-06-25 12:23:40,105] carb percent loss: 0.3105
[2023-06-25 12:23:40,105] protein loss: 5.5997
[2023-06-25 12:23:40,105] protein percent loss: 0.3094
[2023-06-25 12:23:40,105] Epoch 20/150
[2023-06-25 12:24:03,509] test loss: 1.4443
[2023-06-25 12:24:03,510] cal loss: 51.7613
[2023-06-25 12:24:03,510] cal percent loss: 0.2030
[2023-06-25 12:24:03,510] mass loss: 43.7143
[2023-06-25 12:24:03,510] mass percent loss: 0.2005
[2023-06-25 12:24:03,510] fat loss: 4.3523
[2023-06-25 12:24:03,511] fat percent loss: 0.3427
[2023-06-25 12:24:03,511] carb loss: 6.8018
[2023-06-25 12:24:03,511] carb percent loss: 0.3524
[2023-06-25 12:24:03,511] protein loss: 6.3038
[2023-06-25 12:24:03,511] protein percent loss: 0.3483
[2023-06-25 12:24:03,511] Epoch 21/150
[2023-06-25 12:26:36,023] train loss: 1.3156
[2023-06-25 12:26:36,024] cal loss: 56.4995
[2023-06-25 12:26:36,024] cal percent loss: 0.2216
[2023-06-25 12:26:36,024] mass loss: 33.4084
[2023-06-25 12:26:36,024] mass percent loss: 0.1532
[2023-06-25 12:26:36,024] fat loss: 4.2469
[2023-06-25 12:26:36,024] fat percent loss: 0.3344
[2023-06-25 12:26:36,024] carb loss: 5.9097
[2023-06-25 12:26:36,024] carb percent loss: 0.3062
[2023-06-25 12:26:36,024] protein loss: 5.5147
[2023-06-25 12:26:36,025] protein percent loss: 0.3047
[2023-06-25 12:26:36,025] Epoch 21/150
[2023-06-25 12:27:01,785] test loss: 1.4085
[2023-06-25 12:27:01,785] cal loss: 52.7137
[2023-06-25 12:27:01,786] cal percent loss: 0.2067
[2023-06-25 12:27:01,786] mass loss: 47.0272
[2023-06-25 12:27:01,786] mass percent loss: 0.2157
[2023-06-25 12:27:01,786] fat loss: 3.9889
[2023-06-25 12:27:01,786] fat percent loss: 0.3141
[2023-06-25 12:27:01,786] carb loss: 6.6724
[2023-06-25 12:27:01,786] carb percent loss: 0.3457
[2023-06-25 12:27:01,786] protein loss: 5.7485
[2023-06-25 12:27:01,787] protein percent loss: 0.3176
[2023-06-25 12:27:01,787] Epoch 22/150
[2023-06-25 12:29:36,867] train loss: 1.2850
[2023-06-25 12:29:36,867] cal loss: 56.2055
[2023-06-25 12:29:36,867] cal percent loss: 0.2204
[2023-06-25 12:29:36,867] mass loss: 32.4430
[2023-06-25 12:29:36,868] mass percent loss: 0.1488
[2023-06-25 12:29:36,868] fat loss: 4.1586
[2023-06-25 12:29:36,868] fat percent loss: 0.3274
[2023-06-25 12:29:36,868] carb loss: 5.6964
[2023-06-25 12:29:36,868] carb percent loss: 0.2952
[2023-06-25 12:29:36,868] protein loss: 5.3708
[2023-06-25 12:29:36,868] protein percent loss: 0.2967
[2023-06-25 12:29:36,868] Epoch 22/150
[2023-06-25 12:30:01,207] test loss: 1.7235
[2023-06-25 12:30:01,208] cal loss: 85.0192
[2023-06-25 12:30:01,208] cal percent loss: 0.3334
[2023-06-25 12:30:01,208] mass loss: 34.5021
[2023-06-25 12:30:01,208] mass percent loss: 0.1583
[2023-06-25 12:30:01,208] fat loss: 6.1702
[2023-06-25 12:30:01,208] fat percent loss: 0.4858
[2023-06-25 12:30:01,208] carb loss: 6.6506
[2023-06-25 12:30:01,209] carb percent loss: 0.3446
[2023-06-25 12:30:01,209] protein loss: 7.4428
[2023-06-25 12:30:01,209] protein percent loss: 0.4112
[2023-06-25 12:30:01,209] Epoch 23/150
[2023-06-25 12:32:35,341] train loss: 1.2578
[2023-06-25 12:32:35,341] cal loss: 53.7236
[2023-06-25 12:32:35,341] cal percent loss: 0.2107
[2023-06-25 12:32:35,342] mass loss: 32.1542
[2023-06-25 12:32:35,342] mass percent loss: 0.1475
[2023-06-25 12:32:35,342] fat loss: 4.1306
[2023-06-25 12:32:35,342] fat percent loss: 0.3252
[2023-06-25 12:32:35,342] carb loss: 5.5424
[2023-06-25 12:32:35,342] carb percent loss: 0.2872
[2023-06-25 12:32:35,342] protein loss: 5.2649
[2023-06-25 12:32:35,342] protein percent loss: 0.2909
[2023-06-25 12:32:35,342] Epoch 23/150
[2023-06-25 12:32:59,451] test loss: 1.4602
[2023-06-25 12:32:59,452] cal loss: 56.0445
[2023-06-25 12:32:59,452] cal percent loss: 0.2198
[2023-06-25 12:32:59,452] mass loss: 34.7425
[2023-06-25 12:32:59,452] mass percent loss: 0.1594
[2023-06-25 12:32:59,452] fat loss: 5.4563
[2023-06-25 12:32:59,452] fat percent loss: 0.4296
[2023-06-25 12:32:59,452] carb loss: 6.9736
[2023-06-25 12:32:59,452] carb percent loss: 0.3613
[2023-06-25 12:32:59,453] protein loss: 5.5263
[2023-06-25 12:32:59,453] protein percent loss: 0.3053
[2023-06-25 12:32:59,453] Epoch 24/150
[2023-06-25 12:35:28,721] train loss: 1.2558
[2023-06-25 12:35:28,722] cal loss: 55.4247
[2023-06-25 12:35:28,722] cal percent loss: 0.2174
[2023-06-25 12:35:28,722] mass loss: 31.4486
[2023-06-25 12:35:28,722] mass percent loss: 0.1443
[2023-06-25 12:35:28,722] fat loss: 4.0938
[2023-06-25 12:35:28,722] fat percent loss: 0.3223
[2023-06-25 12:35:28,722] carb loss: 5.6734
[2023-06-25 12:35:28,722] carb percent loss: 0.2940
[2023-06-25 12:35:28,723] protein loss: 5.0930
[2023-06-25 12:35:28,723] protein percent loss: 0.2814
[2023-06-25 12:35:28,723] Epoch 24/150
[2023-06-25 12:35:54,174] test loss: 1.3630
[2023-06-25 12:35:54,175] cal loss: 54.4343
[2023-06-25 12:35:54,175] cal percent loss: 0.2135
[2023-06-25 12:35:54,176] mass loss: 34.0729
[2023-06-25 12:35:54,176] mass percent loss: 0.1563
[2023-06-25 12:35:54,176] fat loss: 4.4693
[2023-06-25 12:35:54,176] fat percent loss: 0.3519
[2023-06-25 12:35:54,176] carb loss: 6.2851
[2023-06-25 12:35:54,176] carb percent loss: 0.3257
[2023-06-25 12:35:54,176] protein loss: 5.9040
[2023-06-25 12:35:54,177] protein percent loss: 0.3262
[2023-06-25 12:35:54,177] Epoch 25/150
[2023-06-25 12:38:24,059] train loss: 1.1853
[2023-06-25 12:38:24,060] cal loss: 51.4509
[2023-06-25 12:38:24,060] cal percent loss: 0.2018
[2023-06-25 12:38:24,060] mass loss: 28.9906
[2023-06-25 12:38:24,060] mass percent loss: 0.1330
[2023-06-25 12:38:24,060] fat loss: 3.8441
[2023-06-25 12:38:24,060] fat percent loss: 0.3027
[2023-06-25 12:38:24,060] carb loss: 5.4039
[2023-06-25 12:38:24,060] carb percent loss: 0.2800
[2023-06-25 12:38:24,060] protein loss: 4.9572
[2023-06-25 12:38:24,060] protein percent loss: 0.2739
[2023-06-25 12:38:24,060] Epoch 25/150
[2023-06-25 12:38:50,220] test loss: 1.4528
[2023-06-25 12:38:50,221] cal loss: 66.9939
[2023-06-25 12:38:50,221] cal percent loss: 0.2627
[2023-06-25 12:38:50,221] mass loss: 35.8260
[2023-06-25 12:38:50,221] mass percent loss: 0.1643
[2023-06-25 12:38:50,221] fat loss: 4.4641
[2023-06-25 12:38:50,222] fat percent loss: 0.3515
[2023-06-25 12:38:50,222] carb loss: 7.2176
[2023-06-25 12:38:50,222] carb percent loss: 0.3740
[2023-06-25 12:38:50,222] protein loss: 5.5157
[2023-06-25 12:38:50,222] protein percent loss: 0.3047
[2023-06-25 12:38:50,222] Epoch 26/150
[2023-06-25 12:41:27,701] train loss: 1.2011
[2023-06-25 12:41:27,702] cal loss: 51.5403
[2023-06-25 12:41:27,702] cal percent loss: 0.2021
[2023-06-25 12:41:27,703] mass loss: 31.3799
[2023-06-25 12:41:27,703] mass percent loss: 0.1439
[2023-06-25 12:41:27,703] fat loss: 3.9221
[2023-06-25 12:41:27,703] fat percent loss: 0.3088
[2023-06-25 12:41:27,703] carb loss: 5.3609
[2023-06-25 12:41:27,703] carb percent loss: 0.2778
[2023-06-25 12:41:27,703] protein loss: 4.8947
[2023-06-25 12:41:27,703] protein percent loss: 0.2704
[2023-06-25 12:41:27,703] Epoch 26/150
[2023-06-25 12:41:50,908] test loss: 1.2499
[2023-06-25 12:41:50,908] cal loss: 49.6092
[2023-06-25 12:41:50,909] cal percent loss: 0.1945
[2023-06-25 12:41:50,909] mass loss: 33.5905
[2023-06-25 12:41:50,909] mass percent loss: 0.1541
[2023-06-25 12:41:50,909] fat loss: 3.8947
[2023-06-25 12:41:50,909] fat percent loss: 0.3067
[2023-06-25 12:41:50,909] carb loss: 6.3846
[2023-06-25 12:41:50,909] carb percent loss: 0.3308
[2023-06-25 12:41:50,909] protein loss: 4.8955
[2023-06-25 12:41:50,909] protein percent loss: 0.2705
[2023-06-25 12:41:50,910] Epoch 27/150
[2023-06-25 12:44:25,064] train loss: 1.1486
[2023-06-25 12:44:25,064] cal loss: 48.7484
[2023-06-25 12:44:25,064] cal percent loss: 0.1912
[2023-06-25 12:44:25,065] mass loss: 29.7865
[2023-06-25 12:44:25,065] mass percent loss: 0.1366
[2023-06-25 12:44:25,065] fat loss: 3.7095
[2023-06-25 12:44:25,065] fat percent loss: 0.2921
[2023-06-25 12:44:25,065] carb loss: 5.2950
[2023-06-25 12:44:25,065] carb percent loss: 0.2744
[2023-06-25 12:44:25,065] protein loss: 4.6658
[2023-06-25 12:44:25,065] protein percent loss: 0.2578
[2023-06-25 12:44:25,065] Epoch 27/150
[2023-06-25 12:44:50,011] test loss: 1.3155
[2023-06-25 12:44:50,012] cal loss: 55.8265
[2023-06-25 12:44:50,012] cal percent loss: 0.2189
[2023-06-25 12:44:50,012] mass loss: 30.5854
[2023-06-25 12:44:50,012] mass percent loss: 0.1403
[2023-06-25 12:44:50,012] fat loss: 4.2378
[2023-06-25 12:44:50,012] fat percent loss: 0.3337
[2023-06-25 12:44:50,012] carb loss: 6.6377
[2023-06-25 12:44:50,012] carb percent loss: 0.3439
[2023-06-25 12:44:50,012] protein loss: 5.2783
[2023-06-25 12:44:50,012] protein percent loss: 0.2916
[2023-06-25 12:44:50,013] Epoch 28/150
[2023-06-25 12:47:15,659] train loss: 1.1613
[2023-06-25 12:47:15,660] cal loss: 50.1726
[2023-06-25 12:47:15,660] cal percent loss: 0.1968
[2023-06-25 12:47:15,661] mass loss: 30.0782
[2023-06-25 12:47:15,661] mass percent loss: 0.1380
[2023-06-25 12:47:15,661] fat loss: 3.7804
[2023-06-25 12:47:15,661] fat percent loss: 0.2977
[2023-06-25 12:47:15,661] carb loss: 5.1616
[2023-06-25 12:47:15,661] carb percent loss: 0.2674
[2023-06-25 12:47:15,661] protein loss: 4.7698
[2023-06-25 12:47:15,661] protein percent loss: 0.2635
[2023-06-25 12:47:15,661] Epoch 28/150
[2023-06-25 12:47:42,256] test loss: 1.6710
[2023-06-25 12:47:42,257] cal loss: 84.7441
[2023-06-25 12:47:42,257] cal percent loss: 0.3323
[2023-06-25 12:47:42,257] mass loss: 31.2315
[2023-06-25 12:47:42,257] mass percent loss: 0.1433
[2023-06-25 12:47:42,258] fat loss: 6.3984
[2023-06-25 12:47:42,258] fat percent loss: 0.5038
[2023-06-25 12:47:42,258] carb loss: 6.6304
[2023-06-25 12:47:42,258] carb percent loss: 0.3435
[2023-06-25 12:47:42,258] protein loss: 6.4867
[2023-06-25 12:47:42,258] protein percent loss: 0.3584
[2023-06-25 12:47:42,258] Epoch 29/150
[2023-06-25 12:50:10,402] train loss: 1.1810
[2023-06-25 12:50:10,403] cal loss: 51.2957
[2023-06-25 12:50:10,403] cal percent loss: 0.2012
[2023-06-25 12:50:10,403] mass loss: 30.3567
[2023-06-25 12:50:10,403] mass percent loss: 0.1393
[2023-06-25 12:50:10,403] fat loss: 3.8488
[2023-06-25 12:50:10,403] fat percent loss: 0.3031
[2023-06-25 12:50:10,403] carb loss: 5.2156
[2023-06-25 12:50:10,403] carb percent loss: 0.2702
[2023-06-25 12:50:10,404] protein loss: 4.8801
[2023-06-25 12:50:10,404] protein percent loss: 0.2696
[2023-06-25 12:50:10,404] Epoch 29/150
[2023-06-25 12:50:36,847] test loss: 1.3162
[2023-06-25 12:50:36,847] cal loss: 51.6515
[2023-06-25 12:50:36,847] cal percent loss: 0.2026
[2023-06-25 12:50:36,847] mass loss: 34.6052
[2023-06-25 12:50:36,847] mass percent loss: 0.1587
[2023-06-25 12:50:36,847] fat loss: 3.8979
[2023-06-25 12:50:36,847] fat percent loss: 0.3069
[2023-06-25 12:50:36,847] carb loss: 6.2297
[2023-06-25 12:50:36,847] carb percent loss: 0.3228
[2023-06-25 12:50:36,848] protein loss: 6.0593
[2023-06-25 12:50:36,848] protein percent loss: 0.3348
[2023-06-25 12:50:36,848] Epoch 30/150
[2023-06-25 12:53:15,028] train loss: 1.1684
[2023-06-25 12:53:15,029] cal loss: 48.0327
[2023-06-25 12:53:15,029] cal percent loss: 0.1884
[2023-06-25 12:53:15,029] mass loss: 31.6166
[2023-06-25 12:53:15,029] mass percent loss: 0.1450
[2023-06-25 12:53:15,029] fat loss: 3.7479
[2023-06-25 12:53:15,030] fat percent loss: 0.2951
[2023-06-25 12:53:15,030] carb loss: 5.1158
[2023-06-25 12:53:15,030] carb percent loss: 0.2651
[2023-06-25 12:53:15,030] protein loss: 5.0094
[2023-06-25 12:53:15,030] protein percent loss: 0.2768
[2023-06-25 12:53:15,030] Epoch 30/150
[2023-06-25 12:53:38,911] test loss: 1.4232
[2023-06-25 12:53:38,912] cal loss: 62.2089
[2023-06-25 12:53:38,912] cal percent loss: 0.2440
[2023-06-25 12:53:38,912] mass loss: 34.6925
[2023-06-25 12:53:38,912] mass percent loss: 0.1591
[2023-06-25 12:53:38,912] fat loss: 4.4144
[2023-06-25 12:53:38,913] fat percent loss: 0.3476
[2023-06-25 12:53:38,913] carb loss: 6.6229
[2023-06-25 12:53:38,913] carb percent loss: 0.3432
[2023-06-25 12:53:38,913] protein loss: 6.1099
[2023-06-25 12:53:38,913] protein percent loss: 0.3376
[2023-06-25 12:53:38,913] Epoch 31/150
[2023-06-25 12:56:10,116] train loss: 1.1748
[2023-06-25 12:56:10,117] cal loss: 50.2839
[2023-06-25 12:56:10,117] cal percent loss: 0.1972
[2023-06-25 12:56:10,117] mass loss: 31.4675
[2023-06-25 12:56:10,118] mass percent loss: 0.1443
[2023-06-25 12:56:10,118] fat loss: 3.8172
[2023-06-25 12:56:10,118] fat percent loss: 0.3006
[2023-06-25 12:56:10,118] carb loss: 5.0574
[2023-06-25 12:56:10,118] carb percent loss: 0.2620
[2023-06-25 12:56:10,118] protein loss: 4.8998
[2023-06-25 12:56:10,118] protein percent loss: 0.2707
[2023-06-25 12:56:10,118] Epoch 31/150
[2023-06-25 12:56:36,555] test loss: 1.3314
[2023-06-25 12:56:36,555] cal loss: 51.1523
[2023-06-25 12:56:36,555] cal percent loss: 0.2006
[2023-06-25 12:56:36,555] mass loss: 33.7243
[2023-06-25 12:56:36,555] mass percent loss: 0.1547
[2023-06-25 12:56:36,556] fat loss: 4.0853
[2023-06-25 12:56:36,556] fat percent loss: 0.3217
[2023-06-25 12:56:36,556] carb loss: 7.0370
[2023-06-25 12:56:36,556] carb percent loss: 0.3646
[2023-06-25 12:56:36,556] protein loss: 5.5070
[2023-06-25 12:56:36,556] protein percent loss: 0.3043
[2023-06-25 12:56:36,556] Epoch 32/150
[2023-06-25 12:59:08,555] train loss: 1.0674
[2023-06-25 12:59:08,556] cal loss: 44.9202
[2023-06-25 12:59:08,556] cal percent loss: 0.1762
[2023-06-25 12:59:08,556] mass loss: 26.4579
[2023-06-25 12:59:08,556] mass percent loss: 0.1214
[2023-06-25 12:59:08,557] fat loss: 3.4975
[2023-06-25 12:59:08,557] fat percent loss: 0.2754
[2023-06-25 12:59:08,557] carb loss: 5.0144
[2023-06-25 12:59:08,557] carb percent loss: 0.2598
[2023-06-25 12:59:08,557] protein loss: 4.3620
[2023-06-25 12:59:08,557] protein percent loss: 0.2410
[2023-06-25 12:59:08,557] Epoch 32/150
[2023-06-25 12:59:33,089] test loss: 1.2967
[2023-06-25 12:59:33,089] cal loss: 50.9245
[2023-06-25 12:59:33,090] cal percent loss: 0.1997
[2023-06-25 12:59:33,090] mass loss: 34.7642
[2023-06-25 12:59:33,090] mass percent loss: 0.1595
[2023-06-25 12:59:33,090] fat loss: 4.0921
[2023-06-25 12:59:33,090] fat percent loss: 0.3222
[2023-06-25 12:59:33,090] carb loss: 6.6647
[2023-06-25 12:59:33,090] carb percent loss: 0.3453
[2023-06-25 12:59:33,090] protein loss: 5.0253
[2023-06-25 12:59:33,090] protein percent loss: 0.2776
[2023-06-25 12:59:33,091] Epoch 33/150
[2023-06-25 13:02:07,998] train loss: 1.1029
[2023-06-25 13:02:07,999] cal loss: 46.7061
[2023-06-25 13:02:07,999] cal percent loss: 0.1832
[2023-06-25 13:02:07,999] mass loss: 29.1850
[2023-06-25 13:02:07,999] mass percent loss: 0.1339
[2023-06-25 13:02:07,999] fat loss: 3.5887
[2023-06-25 13:02:07,999] fat percent loss: 0.2826
[2023-06-25 13:02:07,999] carb loss: 4.9234
[2023-06-25 13:02:07,999] carb percent loss: 0.2551
[2023-06-25 13:02:07,999] protein loss: 4.5230
[2023-06-25 13:02:07,999] protein percent loss: 0.2499
[2023-06-25 13:02:07,999] Epoch 33/150
[2023-06-25 13:02:31,934] test loss: 1.2542
[2023-06-25 13:02:31,935] cal loss: 50.5393
[2023-06-25 13:02:31,935] cal percent loss: 0.1982
[2023-06-25 13:02:31,935] mass loss: 31.8968
[2023-06-25 13:02:31,935] mass percent loss: 0.1463
[2023-06-25 13:02:31,935] fat loss: 3.8623
[2023-06-25 13:02:31,935] fat percent loss: 0.3041
[2023-06-25 13:02:31,935] carb loss: 6.2260
[2023-06-25 13:02:31,935] carb percent loss: 0.3226
[2023-06-25 13:02:31,935] protein loss: 5.3009
[2023-06-25 13:02:31,935] protein percent loss: 0.2929
[2023-06-25 13:02:31,936] Epoch 34/150
[2023-06-25 13:05:08,851] train loss: 1.0974
[2023-06-25 13:05:08,852] cal loss: 47.5613
[2023-06-25 13:05:08,852] cal percent loss: 0.1865
[2023-06-25 13:05:08,852] mass loss: 28.8048
[2023-06-25 13:05:08,852] mass percent loss: 0.1321
[2023-06-25 13:05:08,852] fat loss: 3.6029
[2023-06-25 13:05:08,852] fat percent loss: 0.2837
[2023-06-25 13:05:08,853] carb loss: 4.8406
[2023-06-25 13:05:08,853] carb percent loss: 0.2508
[2023-06-25 13:05:08,853] protein loss: 4.4336
[2023-06-25 13:05:08,853] protein percent loss: 0.2449
[2023-06-25 13:05:08,853] Epoch 34/150
[2023-06-25 13:05:35,968] test loss: 1.2227
[2023-06-25 13:05:35,968] cal loss: 49.6664
[2023-06-25 13:05:35,968] cal percent loss: 0.1948
[2023-06-25 13:05:35,968] mass loss: 29.3822
[2023-06-25 13:05:35,968] mass percent loss: 0.1348
[2023-06-25 13:05:35,968] fat loss: 4.0352
[2023-06-25 13:05:35,968] fat percent loss: 0.3177
[2023-06-25 13:05:35,968] carb loss: 5.8088
[2023-06-25 13:05:35,968] carb percent loss: 0.3010
[2023-06-25 13:05:35,968] protein loss: 5.1720
[2023-06-25 13:05:35,969] protein percent loss: 0.2857
[2023-06-25 13:05:35,969] Epoch 35/150
[2023-06-25 13:08:14,173] train loss: 1.0036
[2023-06-25 13:08:14,173] cal loss: 42.1710
[2023-06-25 13:08:14,173] cal percent loss: 0.1654
[2023-06-25 13:08:14,173] mass loss: 26.2020
[2023-06-25 13:08:14,173] mass percent loss: 0.1202
[2023-06-25 13:08:14,174] fat loss: 3.2911
[2023-06-25 13:08:14,174] fat percent loss: 0.2591
[2023-06-25 13:08:14,174] carb loss: 4.5368
[2023-06-25 13:08:14,174] carb percent loss: 0.2351
[2023-06-25 13:08:14,174] protein loss: 4.1007
[2023-06-25 13:08:14,174] protein percent loss: 0.2266
[2023-06-25 13:08:14,174] Epoch 35/150
[2023-06-25 13:08:38,936] test loss: 1.2086
[2023-06-25 13:08:38,937] cal loss: 48.2664
[2023-06-25 13:08:38,937] cal percent loss: 0.1893
[2023-06-25 13:08:38,937] mass loss: 31.2309
[2023-06-25 13:08:38,938] mass percent loss: 0.1433
[2023-06-25 13:08:38,938] fat loss: 3.8092
[2023-06-25 13:08:38,938] fat percent loss: 0.2999
[2023-06-25 13:08:38,938] carb loss: 5.8250
[2023-06-25 13:08:38,938] carb percent loss: 0.3018
[2023-06-25 13:08:38,938] protein loss: 5.1126
[2023-06-25 13:08:38,938] protein percent loss: 0.2825
[2023-06-25 13:08:38,938] Epoch 36/150
[2023-06-25 13:11:14,010] train loss: 1.0489
[2023-06-25 13:11:14,011] cal loss: 44.5867
[2023-06-25 13:11:14,011] cal percent loss: 0.1748
[2023-06-25 13:11:14,011] mass loss: 28.0738
[2023-06-25 13:11:14,011] mass percent loss: 0.1288
[2023-06-25 13:11:14,011] fat loss: 3.4443
[2023-06-25 13:11:14,011] fat percent loss: 0.2712
[2023-06-25 13:11:14,011] carb loss: 4.7173
[2023-06-25 13:11:14,011] carb percent loss: 0.2444
[2023-06-25 13:11:14,011] protein loss: 4.1676
[2023-06-25 13:11:14,011] protein percent loss: 0.2303
[2023-06-25 13:11:14,011] Epoch 36/150
[2023-06-25 13:11:39,750] test loss: 1.2183
[2023-06-25 13:11:39,750] cal loss: 49.7095
[2023-06-25 13:11:39,751] cal percent loss: 0.1949
[2023-06-25 13:11:39,751] mass loss: 29.4931
[2023-06-25 13:11:39,751] mass percent loss: 0.1353
[2023-06-25 13:11:39,751] fat loss: 3.8968
[2023-06-25 13:11:39,751] fat percent loss: 0.3068
[2023-06-25 13:11:39,751] carb loss: 5.5071
[2023-06-25 13:11:39,751] carb percent loss: 0.2853
[2023-06-25 13:11:39,751] protein loss: 5.5476
[2023-06-25 13:11:39,752] protein percent loss: 0.3065
[2023-06-25 13:11:39,752] Epoch 37/150
[2023-06-25 13:14:16,255] train loss: 1.0271
[2023-06-25 13:14:16,256] cal loss: 44.1599
[2023-06-25 13:14:16,256] cal percent loss: 0.1732
[2023-06-25 13:14:16,256] mass loss: 27.2021
[2023-06-25 13:14:16,256] mass percent loss: 0.1248
[2023-06-25 13:14:16,256] fat loss: 3.2970
[2023-06-25 13:14:16,257] fat percent loss: 0.2596
[2023-06-25 13:14:16,257] carb loss: 4.6050
[2023-06-25 13:14:16,257] carb percent loss: 0.2386
[2023-06-25 13:14:16,257] protein loss: 4.1983
[2023-06-25 13:14:16,257] protein percent loss: 0.2319
[2023-06-25 13:14:16,257] Epoch 37/150
[2023-06-25 13:14:42,162] test loss: 1.1539
[2023-06-25 13:14:42,163] cal loss: 46.6041
[2023-06-25 13:14:42,163] cal percent loss: 0.1828
[2023-06-25 13:14:42,163] mass loss: 29.9498
[2023-06-25 13:14:42,163] mass percent loss: 0.1374
[2023-06-25 13:14:42,163] fat loss: 3.6253
[2023-06-25 13:14:42,163] fat percent loss: 0.2855
[2023-06-25 13:14:42,163] carb loss: 5.7561
[2023-06-25 13:14:42,163] carb percent loss: 0.2982
[2023-06-25 13:14:42,163] protein loss: 4.6581
[2023-06-25 13:14:42,163] protein percent loss: 0.2574
[2023-06-25 13:14:42,164] Epoch 38/150
[2023-06-25 13:17:14,817] train loss: 0.9812
[2023-06-25 13:17:14,818] cal loss: 42.4016
[2023-06-25 13:17:14,818] cal percent loss: 0.1663
[2023-06-25 13:17:14,818] mass loss: 25.2029
[2023-06-25 13:17:14,818] mass percent loss: 0.1156
[2023-06-25 13:17:14,818] fat loss: 3.2188
[2023-06-25 13:17:14,818] fat percent loss: 0.2534
[2023-06-25 13:17:14,818] carb loss: 4.3646
[2023-06-25 13:17:14,818] carb percent loss: 0.2261
[2023-06-25 13:17:14,818] protein loss: 4.0153
[2023-06-25 13:17:14,819] protein percent loss: 0.2218
[2023-06-25 13:17:14,819] Epoch 38/150
[2023-06-25 13:17:39,657] test loss: 1.4824
[2023-06-25 13:17:39,658] cal loss: 65.8922
[2023-06-25 13:17:39,658] cal percent loss: 0.2584
[2023-06-25 13:17:39,658] mass loss: 37.7454
[2023-06-25 13:17:39,658] mass percent loss: 0.1731
[2023-06-25 13:17:39,658] fat loss: 4.8783
[2023-06-25 13:17:39,658] fat percent loss: 0.3841
[2023-06-25 13:17:39,658] carb loss: 5.9862
[2023-06-25 13:17:39,658] carb percent loss: 0.3102
[2023-06-25 13:17:39,658] protein loss: 6.4681
[2023-06-25 13:17:39,659] protein percent loss: 0.3574
[2023-06-25 13:17:39,659] Epoch 39/150
[2023-06-25 13:20:11,976] train loss: 1.1039
[2023-06-25 13:20:11,976] cal loss: 47.8482
[2023-06-25 13:20:11,976] cal percent loss: 0.1876
[2023-06-25 13:20:11,976] mass loss: 30.4812
[2023-06-25 13:20:11,976] mass percent loss: 0.1398
[2023-06-25 13:20:11,976] fat loss: 3.4348
[2023-06-25 13:20:11,976] fat percent loss: 0.2705
[2023-06-25 13:20:11,976] carb loss: 4.7264
[2023-06-25 13:20:11,976] carb percent loss: 0.2449
[2023-06-25 13:20:11,976] protein loss: 4.6884
[2023-06-25 13:20:11,976] protein percent loss: 0.2590
[2023-06-25 13:20:11,976] Epoch 39/150
[2023-06-25 13:20:35,351] test loss: 1.2225
[2023-06-25 13:20:35,351] cal loss: 50.3376
[2023-06-25 13:20:35,351] cal percent loss: 0.1974
[2023-06-25 13:20:35,351] mass loss: 30.2212
[2023-06-25 13:20:35,352] mass percent loss: 0.1386
[2023-06-25 13:20:35,352] fat loss: 3.9454
[2023-06-25 13:20:35,352] fat percent loss: 0.3107
[2023-06-25 13:20:35,352] carb loss: 5.9465
[2023-06-25 13:20:35,352] carb percent loss: 0.3081
[2023-06-25 13:20:35,352] protein loss: 5.0137
[2023-06-25 13:20:35,352] protein percent loss: 0.2770
[2023-06-25 13:20:35,353] Epoch 40/150
[2023-06-25 13:23:07,180] train loss: 1.0140
[2023-06-25 13:23:07,181] cal loss: 45.1831
[2023-06-25 13:23:07,181] cal percent loss: 0.1772
[2023-06-25 13:23:07,181] mass loss: 26.2752
[2023-06-25 13:23:07,181] mass percent loss: 0.1205
[2023-06-25 13:23:07,181] fat loss: 3.2643
[2023-06-25 13:23:07,181] fat percent loss: 0.2570
[2023-06-25 13:23:07,181] carb loss: 4.4813
[2023-06-25 13:23:07,181] carb percent loss: 0.2322
[2023-06-25 13:23:07,181] protein loss: 4.1162
[2023-06-25 13:23:07,181] protein percent loss: 0.2274
[2023-06-25 13:23:07,181] Epoch 40/150
[2023-06-25 13:23:32,833] test loss: 1.2028
[2023-06-25 13:23:32,834] cal loss: 47.8119
[2023-06-25 13:23:32,834] cal percent loss: 0.1875
[2023-06-25 13:23:32,835] mass loss: 29.7787
[2023-06-25 13:23:32,835] mass percent loss: 0.1366
[2023-06-25 13:23:32,835] fat loss: 3.9514
[2023-06-25 13:23:32,835] fat percent loss: 0.3111
[2023-06-25 13:23:32,835] carb loss: 5.7627
[2023-06-25 13:23:32,835] carb percent loss: 0.2986
[2023-06-25 13:23:32,835] protein loss: 5.0594
[2023-06-25 13:23:32,835] protein percent loss: 0.2795
[2023-06-25 13:23:32,836] Epoch 41/150
[2023-06-25 13:26:07,043] train loss: 0.9493
[2023-06-25 13:26:07,044] cal loss: 39.7882
[2023-06-25 13:26:07,044] cal percent loss: 0.1560
[2023-06-25 13:26:07,044] mass loss: 24.4313
[2023-06-25 13:26:07,044] mass percent loss: 0.1121
[2023-06-25 13:26:07,044] fat loss: 3.0644
[2023-06-25 13:26:07,044] fat percent loss: 0.2413
[2023-06-25 13:26:07,044] carb loss: 4.2925
[2023-06-25 13:26:07,045] carb percent loss: 0.2224
[2023-06-25 13:26:07,045] protein loss: 4.0046
[2023-06-25 13:26:07,045] protein percent loss: 0.2212
[2023-06-25 13:26:07,045] Epoch 41/150
[2023-06-25 13:26:31,916] test loss: 1.2694
[2023-06-25 13:26:31,917] cal loss: 55.3240
[2023-06-25 13:26:31,917] cal percent loss: 0.2170
[2023-06-25 13:26:31,917] mass loss: 32.5713
[2023-06-25 13:26:31,917] mass percent loss: 0.1494
[2023-06-25 13:26:31,917] fat loss: 3.9901
[2023-06-25 13:26:31,917] fat percent loss: 0.3142
[2023-06-25 13:26:31,918] carb loss: 6.1468
[2023-06-25 13:26:31,918] carb percent loss: 0.3185
[2023-06-25 13:26:31,918] protein loss: 4.9650
[2023-06-25 13:26:31,918] protein percent loss: 0.2743
[2023-06-25 13:26:31,918] Epoch 42/150
[2023-06-25 13:29:00,905] train loss: 1.0420
[2023-06-25 13:29:00,906] cal loss: 43.4225
[2023-06-25 13:29:00,906] cal percent loss: 0.1703
[2023-06-25 13:29:00,906] mass loss: 26.7750
[2023-06-25 13:29:00,906] mass percent loss: 0.1228
[2023-06-25 13:29:00,907] fat loss: 3.3379
[2023-06-25 13:29:00,907] fat percent loss: 0.2628
[2023-06-25 13:29:00,907] carb loss: 4.6714
[2023-06-25 13:29:00,907] carb percent loss: 0.2420
[2023-06-25 13:29:00,907] protein loss: 4.4976
[2023-06-25 13:29:00,907] protein percent loss: 0.2485
[2023-06-25 13:29:00,907] Epoch 42/150
[2023-06-25 13:29:25,977] test loss: 1.3477
[2023-06-25 13:29:25,977] cal loss: 61.3710
[2023-06-25 13:29:25,977] cal percent loss: 0.2407
[2023-06-25 13:29:25,977] mass loss: 30.6482
[2023-06-25 13:29:25,978] mass percent loss: 0.1406
[2023-06-25 13:29:25,978] fat loss: 4.8477
[2023-06-25 13:29:25,978] fat percent loss: 0.3817
[2023-06-25 13:29:25,978] carb loss: 6.0601
[2023-06-25 13:29:25,978] carb percent loss: 0.3140
[2023-06-25 13:29:25,978] protein loss: 5.0189
[2023-06-25 13:29:25,978] protein percent loss: 0.2773
[2023-06-25 13:29:25,978] Epoch 43/150
[2023-06-25 13:32:03,450] train loss: 1.0307
[2023-06-25 13:32:03,451] cal loss: 44.8317
[2023-06-25 13:32:03,451] cal percent loss: 0.1758
[2023-06-25 13:32:03,451] mass loss: 26.4907
[2023-06-25 13:32:03,451] mass percent loss: 0.1215
[2023-06-25 13:32:03,451] fat loss: 3.6945
[2023-06-25 13:32:03,451] fat percent loss: 0.2909
[2023-06-25 13:32:03,451] carb loss: 4.2932
[2023-06-25 13:32:03,451] carb percent loss: 0.2224
[2023-06-25 13:32:03,452] protein loss: 3.9806
[2023-06-25 13:32:03,452] protein percent loss: 0.2199
[2023-06-25 13:32:03,452] Epoch 43/150
[2023-06-25 13:32:30,981] test loss: 1.3206
[2023-06-25 13:32:30,982] cal loss: 60.4870
[2023-06-25 13:32:30,982] cal percent loss: 0.2372
[2023-06-25 13:32:30,982] mass loss: 30.9113
[2023-06-25 13:32:30,983] mass percent loss: 0.1418
[2023-06-25 13:32:30,983] fat loss: 4.5947
[2023-06-25 13:32:30,983] fat percent loss: 0.3618
[2023-06-25 13:32:30,983] carb loss: 6.0028
[2023-06-25 13:32:30,983] carb percent loss: 0.3110
[2023-06-25 13:32:30,983] protein loss: 4.9520
[2023-06-25 13:32:30,984] protein percent loss: 0.2736
[2023-06-25 13:32:30,984] Epoch 44/150
[2023-06-25 13:35:01,741] train loss: 0.9586
[2023-06-25 13:35:01,742] cal loss: 41.1346
[2023-06-25 13:35:01,742] cal percent loss: 0.1613
[2023-06-25 13:35:01,742] mass loss: 25.0473
[2023-06-25 13:35:01,742] mass percent loss: 0.1149
[2023-06-25 13:35:01,742] fat loss: 3.2000
[2023-06-25 13:35:01,742] fat percent loss: 0.2520
[2023-06-25 13:35:01,742] carb loss: 4.2168
[2023-06-25 13:35:01,742] carb percent loss: 0.2185
[2023-06-25 13:35:01,742] protein loss: 3.8559
[2023-06-25 13:35:01,742] protein percent loss: 0.2130
[2023-06-25 13:35:01,742] Epoch 44/150
[2023-06-25 13:35:27,411] test loss: 1.2632
[2023-06-25 13:35:27,411] cal loss: 54.0880
[2023-06-25 13:35:27,412] cal percent loss: 0.2121
[2023-06-25 13:35:27,412] mass loss: 29.1101
[2023-06-25 13:35:27,412] mass percent loss: 0.1335
[2023-06-25 13:35:27,412] fat loss: 4.1433
[2023-06-25 13:35:27,412] fat percent loss: 0.3262
[2023-06-25 13:35:27,412] carb loss: 5.7284
[2023-06-25 13:35:27,412] carb percent loss: 0.2968
[2023-06-25 13:35:27,412] protein loss: 5.5300
[2023-06-25 13:35:27,412] protein percent loss: 0.3055
[2023-06-25 13:35:27,413] Epoch 45/150
[2023-06-25 13:37:58,949] train loss: 1.0196
[2023-06-25 13:37:58,949] cal loss: 43.2768
[2023-06-25 13:37:58,949] cal percent loss: 0.1697
[2023-06-25 13:37:58,949] mass loss: 26.1126
[2023-06-25 13:37:58,950] mass percent loss: 0.1198
[2023-06-25 13:37:58,950] fat loss: 3.2867
[2023-06-25 13:37:58,950] fat percent loss: 0.2588
[2023-06-25 13:37:58,950] carb loss: 4.4136
[2023-06-25 13:37:58,950] carb percent loss: 0.2287
[2023-06-25 13:37:58,950] protein loss: 4.4525
[2023-06-25 13:37:58,950] protein percent loss: 0.2460
[2023-06-25 13:37:58,950] Epoch 45/150
[2023-06-25 13:38:21,726] test loss: 1.1990
[2023-06-25 13:38:21,727] cal loss: 47.8849
[2023-06-25 13:38:21,727] cal percent loss: 0.1878
[2023-06-25 13:38:21,727] mass loss: 30.0866
[2023-06-25 13:38:21,727] mass percent loss: 0.1380
[2023-06-25 13:38:21,728] fat loss: 3.8633
[2023-06-25 13:38:21,728] fat percent loss: 0.3042
[2023-06-25 13:38:21,728] carb loss: 5.9087
[2023-06-25 13:38:21,728] carb percent loss: 0.3061
[2023-06-25 13:38:21,728] protein loss: 4.9375
[2023-06-25 13:38:21,728] protein percent loss: 0.2728
[2023-06-25 13:38:21,729] Epoch 46/150
[2023-06-25 13:40:54,263] train loss: 0.9206
[2023-06-25 13:40:54,264] cal loss: 39.5157
[2023-06-25 13:40:54,264] cal percent loss: 0.1550
[2023-06-25 13:40:54,264] mass loss: 24.3585
[2023-06-25 13:40:54,264] mass percent loss: 0.1117
[2023-06-25 13:40:54,264] fat loss: 2.9683
[2023-06-25 13:40:54,264] fat percent loss: 0.2337
[2023-06-25 13:40:54,264] carb loss: 4.0936
[2023-06-25 13:40:54,265] carb percent loss: 0.2121
[2023-06-25 13:40:54,265] protein loss: 3.7819
[2023-06-25 13:40:54,265] protein percent loss: 0.2089
[2023-06-25 13:40:54,265] Epoch 46/150
[2023-06-25 13:41:19,511] test loss: 1.3627
[2023-06-25 13:41:19,511] cal loss: 60.3209
[2023-06-25 13:41:19,511] cal percent loss: 0.2366
[2023-06-25 13:41:19,511] mass loss: 40.5597
[2023-06-25 13:41:19,511] mass percent loss: 0.1861
[2023-06-25 13:41:19,511] fat loss: 3.8841
[2023-06-25 13:41:19,511] fat percent loss: 0.3058
[2023-06-25 13:41:19,512] carb loss: 6.3155
[2023-06-25 13:41:19,512] carb percent loss: 0.3272
[2023-06-25 13:41:19,512] protein loss: 5.4115
[2023-06-25 13:41:19,512] protein percent loss: 0.2990
[2023-06-25 13:41:19,512] Epoch 47/150
[2023-06-25 13:43:52,072] train loss: 0.9508
[2023-06-25 13:43:52,073] cal loss: 40.4438
[2023-06-25 13:43:52,073] cal percent loss: 0.1586
[2023-06-25 13:43:52,073] mass loss: 25.6595
[2023-06-25 13:43:52,073] mass percent loss: 0.1177
[2023-06-25 13:43:52,074] fat loss: 3.1086
[2023-06-25 13:43:52,074] fat percent loss: 0.2448
[2023-06-25 13:43:52,074] carb loss: 4.2017
[2023-06-25 13:43:52,074] carb percent loss: 0.2177
[2023-06-25 13:43:52,074] protein loss: 3.8383
[2023-06-25 13:43:52,074] protein percent loss: 0.2121
[2023-06-25 13:43:52,074] Epoch 47/150
[2023-06-25 13:44:15,434] test loss: 1.1638
[2023-06-25 13:44:15,435] cal loss: 48.0818
[2023-06-25 13:44:15,435] cal percent loss: 0.1886
[2023-06-25 13:44:15,435] mass loss: 30.8188
[2023-06-25 13:44:15,435] mass percent loss: 0.1414
[2023-06-25 13:44:15,435] fat loss: 3.7321
[2023-06-25 13:44:15,436] fat percent loss: 0.2939
[2023-06-25 13:44:15,436] carb loss: 5.2880
[2023-06-25 13:44:15,436] carb percent loss: 0.2740
[2023-06-25 13:44:15,436] protein loss: 4.8785
[2023-06-25 13:44:15,436] protein percent loss: 0.2695
[2023-06-25 13:44:15,436] Epoch 48/150
[2023-06-25 13:46:46,110] train loss: 0.8843
[2023-06-25 13:46:46,111] cal loss: 37.5899
[2023-06-25 13:46:46,111] cal percent loss: 0.1474
[2023-06-25 13:46:46,111] mass loss: 23.6929
[2023-06-25 13:46:46,111] mass percent loss: 0.1087
[2023-06-25 13:46:46,111] fat loss: 2.9268
[2023-06-25 13:46:46,111] fat percent loss: 0.2305
[2023-06-25 13:46:46,111] carb loss: 3.9127
[2023-06-25 13:46:46,111] carb percent loss: 0.2027
[2023-06-25 13:46:46,111] protein loss: 3.5338
[2023-06-25 13:46:46,111] protein percent loss: 0.1952
[2023-06-25 13:46:46,111] Epoch 48/150
[2023-06-25 13:47:11,143] test loss: 1.1858
[2023-06-25 13:47:11,144] cal loss: 46.1598
[2023-06-25 13:47:11,144] cal percent loss: 0.1810
[2023-06-25 13:47:11,144] mass loss: 32.9498
[2023-06-25 13:47:11,144] mass percent loss: 0.1511
[2023-06-25 13:47:11,145] fat loss: 3.8512
[2023-06-25 13:47:11,145] fat percent loss: 0.3032
[2023-06-25 13:47:11,145] carb loss: 5.6651
[2023-06-25 13:47:11,145] carb percent loss: 0.2935
[2023-06-25 13:47:11,145] protein loss: 4.7139
[2023-06-25 13:47:11,145] protein percent loss: 0.2604
[2023-06-25 13:47:11,145] Epoch 49/150
[2023-06-25 13:49:48,488] train loss: 0.8706
[2023-06-25 13:49:48,489] cal loss: 37.7223
[2023-06-25 13:49:48,489] cal percent loss: 0.1479
[2023-06-25 13:49:48,489] mass loss: 22.3904
[2023-06-25 13:49:48,489] mass percent loss: 0.1027
[2023-06-25 13:49:48,489] fat loss: 2.8718
[2023-06-25 13:49:48,489] fat percent loss: 0.2261
[2023-06-25 13:49:48,489] carb loss: 3.9400
[2023-06-25 13:49:48,489] carb percent loss: 0.2041
[2023-06-25 13:49:48,489] protein loss: 3.4655
[2023-06-25 13:49:48,489] protein percent loss: 0.1915
[2023-06-25 13:49:48,490] Epoch 49/150
[2023-06-25 13:50:14,465] test loss: 1.2383
[2023-06-25 13:50:14,465] cal loss: 53.6819
[2023-06-25 13:50:14,465] cal percent loss: 0.2105
[2023-06-25 13:50:14,466] mass loss: 28.9931
[2023-06-25 13:50:14,466] mass percent loss: 0.1330
[2023-06-25 13:50:14,466] fat loss: 4.0166
[2023-06-25 13:50:14,466] fat percent loss: 0.3163
[2023-06-25 13:50:14,466] carb loss: 6.3986
[2023-06-25 13:50:14,466] carb percent loss: 0.3315
[2023-06-25 13:50:14,466] protein loss: 4.6640
[2023-06-25 13:50:14,466] protein percent loss: 0.2577
[2023-06-25 13:50:14,467] Epoch 50/150
[2023-06-25 13:52:40,712] train loss: 0.8639
[2023-06-25 13:52:40,712] cal loss: 36.8845
[2023-06-25 13:52:40,712] cal percent loss: 0.1446
[2023-06-25 13:52:40,712] mass loss: 22.6736
[2023-06-25 13:52:40,712] mass percent loss: 0.1040
[2023-06-25 13:52:40,713] fat loss: 2.7219
[2023-06-25 13:52:40,713] fat percent loss: 0.2143
[2023-06-25 13:52:40,713] carb loss: 4.0335
[2023-06-25 13:52:40,713] carb percent loss: 0.2090
[2023-06-25 13:52:40,713] protein loss: 3.5135
[2023-06-25 13:52:40,713] protein percent loss: 0.1941
[2023-06-25 13:52:40,713] Epoch 50/150
[2023-06-25 13:53:06,885] test loss: 1.1941
[2023-06-25 13:53:06,886] cal loss: 47.6000
[2023-06-25 13:53:06,886] cal percent loss: 0.1867
[2023-06-25 13:53:06,886] mass loss: 30.8930
[2023-06-25 13:53:06,887] mass percent loss: 0.1417
[2023-06-25 13:53:06,887] fat loss: 3.9061
[2023-06-25 13:53:06,887] fat percent loss: 0.3076
[2023-06-25 13:53:06,887] carb loss: 5.4485
[2023-06-25 13:53:06,887] carb percent loss: 0.2823
[2023-06-25 13:53:06,887] protein loss: 5.1188
[2023-06-25 13:53:06,887] protein percent loss: 0.2828
[2023-06-25 13:53:06,888] Epoch 51/150
[2023-06-25 13:55:40,596] train loss: 0.8612
[2023-06-25 13:55:40,597] cal loss: 36.6997
[2023-06-25 13:55:40,597] cal percent loss: 0.1439
[2023-06-25 13:55:40,597] mass loss: 23.5804
[2023-06-25 13:55:40,597] mass percent loss: 0.1082
[2023-06-25 13:55:40,597] fat loss: 2.7681
[2023-06-25 13:55:40,597] fat percent loss: 0.2180
[2023-06-25 13:55:40,598] carb loss: 3.9244
[2023-06-25 13:55:40,598] carb percent loss: 0.2033
[2023-06-25 13:55:40,598] protein loss: 3.3919
[2023-06-25 13:55:40,598] protein percent loss: 0.1874
[2023-06-25 13:55:40,598] Epoch 51/150
[2023-06-25 13:56:04,251] test loss: 1.1852
[2023-06-25 13:56:04,252] cal loss: 48.1062
[2023-06-25 13:56:04,252] cal percent loss: 0.1887
[2023-06-25 13:56:04,252] mass loss: 28.5815
[2023-06-25 13:56:04,252] mass percent loss: 0.1311
[2023-06-25 13:56:04,253] fat loss: 3.7997
[2023-06-25 13:56:04,253] fat percent loss: 0.2992
[2023-06-25 13:56:04,253] carb loss: 5.9104
[2023-06-25 13:56:04,253] carb percent loss: 0.3062
[2023-06-25 13:56:04,253] protein loss: 4.9205
[2023-06-25 13:56:04,253] protein percent loss: 0.2719
[2023-06-25 13:56:04,253] Epoch 52/150
[2023-06-25 13:58:39,201] train loss: 0.8444
[2023-06-25 13:58:39,202] cal loss: 35.6924
[2023-06-25 13:58:39,202] cal percent loss: 0.1400
[2023-06-25 13:58:39,202] mass loss: 22.6726
[2023-06-25 13:58:39,203] mass percent loss: 0.1040
[2023-06-25 13:58:39,203] fat loss: 2.7429
[2023-06-25 13:58:39,203] fat percent loss: 0.2160
[2023-06-25 13:58:39,203] carb loss: 3.8184
[2023-06-25 13:58:39,203] carb percent loss: 0.1978
[2023-06-25 13:58:39,203] protein loss: 3.3913
[2023-06-25 13:58:39,203] protein percent loss: 0.1874
[2023-06-25 13:58:39,203] Epoch 52/150
[2023-06-25 13:59:02,469] test loss: 1.2126
[2023-06-25 13:59:02,469] cal loss: 47.2729
[2023-06-25 13:59:02,469] cal percent loss: 0.1854
[2023-06-25 13:59:02,469] mass loss: 32.3013
[2023-06-25 13:59:02,470] mass percent loss: 0.1482
[2023-06-25 13:59:02,470] fat loss: 3.6881
[2023-06-25 13:59:02,470] fat percent loss: 0.2904
[2023-06-25 13:59:02,470] carb loss: 5.7419
[2023-06-25 13:59:02,470] carb percent loss: 0.2975
[2023-06-25 13:59:02,470] protein loss: 5.4090
[2023-06-25 13:59:02,470] protein percent loss: 0.2988
[2023-06-25 13:59:02,470] Epoch 53/150
[2023-06-25 14:01:39,187] train loss: 0.8704
[2023-06-25 14:01:39,187] cal loss: 37.4129
[2023-06-25 14:01:39,187] cal percent loss: 0.1467
[2023-06-25 14:01:39,188] mass loss: 22.9429
[2023-06-25 14:01:39,188] mass percent loss: 0.1052
[2023-06-25 14:01:39,188] fat loss: 2.8778
[2023-06-25 14:01:39,188] fat percent loss: 0.2266
[2023-06-25 14:01:39,188] carb loss: 3.8613
[2023-06-25 14:01:39,188] carb percent loss: 0.2001
[2023-06-25 14:01:39,188] protein loss: 3.4839
[2023-06-25 14:01:39,188] protein percent loss: 0.1925
[2023-06-25 14:01:39,188] Epoch 53/150
[2023-06-25 14:02:04,949] test loss: 1.2112
[2023-06-25 14:02:04,950] cal loss: 48.7960
[2023-06-25 14:02:04,950] cal percent loss: 0.1914
[2023-06-25 14:02:04,950] mass loss: 27.2312
[2023-06-25 14:02:04,950] mass percent loss: 0.1249
[2023-06-25 14:02:04,950] fat loss: 4.4325
[2023-06-25 14:02:04,950] fat percent loss: 0.3490
[2023-06-25 14:02:04,951] carb loss: 5.5591
[2023-06-25 14:02:04,951] carb percent loss: 0.2880
[2023-06-25 14:02:04,951] protein loss: 4.9141
[2023-06-25 14:02:04,951] protein percent loss: 0.2715
[2023-06-25 14:02:04,951] Epoch 54/150
[2023-06-25 14:04:33,749] train loss: 0.8438
[2023-06-25 14:04:33,749] cal loss: 35.5974
[2023-06-25 14:04:33,749] cal percent loss: 0.1396
[2023-06-25 14:04:33,750] mass loss: 22.5396
[2023-06-25 14:04:33,750] mass percent loss: 0.1034
[2023-06-25 14:04:33,750] fat loss: 2.8342
[2023-06-25 14:04:33,750] fat percent loss: 0.2232
[2023-06-25 14:04:33,750] carb loss: 3.7305
[2023-06-25 14:04:33,750] carb percent loss: 0.1933
[2023-06-25 14:04:33,750] protein loss: 3.3453
[2023-06-25 14:04:33,750] protein percent loss: 0.1848
[2023-06-25 14:04:33,750] Epoch 54/150
[2023-06-25 14:04:57,846] test loss: 1.1939
[2023-06-25 14:04:57,846] cal loss: 49.1549
[2023-06-25 14:04:57,847] cal percent loss: 0.1928
[2023-06-25 14:04:57,847] mass loss: 29.2239
[2023-06-25 14:04:57,847] mass percent loss: 0.1341
[2023-06-25 14:04:57,847] fat loss: 3.9242
[2023-06-25 14:04:57,847] fat percent loss: 0.3090
[2023-06-25 14:04:57,847] carb loss: 5.9488
[2023-06-25 14:04:57,847] carb percent loss: 0.3082
[2023-06-25 14:04:57,847] protein loss: 4.6974
[2023-06-25 14:04:57,847] protein percent loss: 0.2595
[2023-06-25 14:04:57,847] Epoch 55/150
[2023-06-25 14:07:38,176] train loss: 0.8181
[2023-06-25 14:07:38,177] cal loss: 34.8419
[2023-06-25 14:07:38,177] cal percent loss: 0.1366
[2023-06-25 14:07:38,177] mass loss: 21.8412
[2023-06-25 14:07:38,178] mass percent loss: 0.1002
[2023-06-25 14:07:38,178] fat loss: 2.6597
[2023-06-25 14:07:38,178] fat percent loss: 0.2094
[2023-06-25 14:07:38,178] carb loss: 3.6500
[2023-06-25 14:07:38,178] carb percent loss: 0.1891
[2023-06-25 14:07:38,178] protein loss: 3.3189
[2023-06-25 14:07:38,178] protein percent loss: 0.1834
[2023-06-25 14:07:38,178] Epoch 55/150
[2023-06-25 14:08:02,552] test loss: 1.2193
[2023-06-25 14:08:02,553] cal loss: 53.5279
[2023-06-25 14:08:02,553] cal percent loss: 0.2099
[2023-06-25 14:08:02,553] mass loss: 28.6787
[2023-06-25 14:08:02,554] mass percent loss: 0.1316
[2023-06-25 14:08:02,554] fat loss: 4.0662
[2023-06-25 14:08:02,554] fat percent loss: 0.3202
[2023-06-25 14:08:02,554] carb loss: 5.5958
[2023-06-25 14:08:02,554] carb percent loss: 0.2899
[2023-06-25 14:08:02,554] protein loss: 4.9845
[2023-06-25 14:08:02,554] protein percent loss: 0.2754
[2023-06-25 14:08:02,554] Epoch 56/150
[2023-06-25 14:10:35,442] train loss: 0.8109
[2023-06-25 14:10:35,443] cal loss: 35.4361
[2023-06-25 14:10:35,443] cal percent loss: 0.1390
[2023-06-25 14:10:35,443] mass loss: 22.0791
[2023-06-25 14:10:35,443] mass percent loss: 0.1013
[2023-06-25 14:10:35,443] fat loss: 2.5782
[2023-06-25 14:10:35,444] fat percent loss: 0.2030
[2023-06-25 14:10:35,444] carb loss: 3.6241
[2023-06-25 14:10:35,444] carb percent loss: 0.1878
[2023-06-25 14:10:35,444] protein loss: 3.2356
[2023-06-25 14:10:35,444] protein percent loss: 0.1788
[2023-06-25 14:10:35,444] Epoch 56/150
[2023-06-25 14:11:00,011] test loss: 1.2922
[2023-06-25 14:11:00,012] cal loss: 57.2220
[2023-06-25 14:11:00,012] cal percent loss: 0.2244
[2023-06-25 14:11:00,012] mass loss: 30.1368
[2023-06-25 14:11:00,012] mass percent loss: 0.1382
[2023-06-25 14:11:00,012] fat loss: 4.3803
[2023-06-25 14:11:00,012] fat percent loss: 0.3449
[2023-06-25 14:11:00,013] carb loss: 5.4606
[2023-06-25 14:11:00,013] carb percent loss: 0.2829
[2023-06-25 14:11:00,013] protein loss: 5.5875
[2023-06-25 14:11:00,013] protein percent loss: 0.3087
[2023-06-25 14:11:00,013] Epoch 57/150
[2023-06-25 14:13:30,016] train loss: 0.8924
[2023-06-25 14:13:30,017] cal loss: 40.1534
[2023-06-25 14:13:30,017] cal percent loss: 0.1575
[2023-06-25 14:13:30,017] mass loss: 23.5193
[2023-06-25 14:13:30,017] mass percent loss: 0.1079
[2023-06-25 14:13:30,017] fat loss: 2.9281
[2023-06-25 14:13:30,017] fat percent loss: 0.2306
[2023-06-25 14:13:30,017] carb loss: 3.7690
[2023-06-25 14:13:30,017] carb percent loss: 0.1953
[2023-06-25 14:13:30,018] protein loss: 3.6146
[2023-06-25 14:13:30,018] protein percent loss: 0.1997
[2023-06-25 14:13:30,018] Epoch 57/150
[2023-06-25 14:13:53,725] test loss: 1.2146
[2023-06-25 14:13:53,726] cal loss: 51.2379
[2023-06-25 14:13:53,726] cal percent loss: 0.2009
[2023-06-25 14:13:53,726] mass loss: 28.2734
[2023-06-25 14:13:53,726] mass percent loss: 0.1297
[2023-06-25 14:13:53,726] fat loss: 4.0386
[2023-06-25 14:13:53,726] fat percent loss: 0.3180
[2023-06-25 14:13:53,727] carb loss: 5.7197
[2023-06-25 14:13:53,727] carb percent loss: 0.2964
[2023-06-25 14:13:53,727] protein loss: 5.0784
[2023-06-25 14:13:53,727] protein percent loss: 0.2806
[2023-06-25 14:13:53,727] Epoch 58/150
[2023-06-25 14:16:26,246] train loss: 0.8595
[2023-06-25 14:16:26,247] cal loss: 38.1978
[2023-06-25 14:16:26,247] cal percent loss: 0.1498
[2023-06-25 14:16:26,247] mass loss: 23.2483
[2023-06-25 14:16:26,247] mass percent loss: 0.1066
[2023-06-25 14:16:26,247] fat loss: 2.7806
[2023-06-25 14:16:26,247] fat percent loss: 0.2189
[2023-06-25 14:16:26,248] carb loss: 3.6836
[2023-06-25 14:16:26,248] carb percent loss: 0.1909
[2023-06-25 14:16:26,248] protein loss: 3.4615
[2023-06-25 14:16:26,248] protein percent loss: 0.1912
[2023-06-25 14:16:26,248] Epoch 58/150
[2023-06-25 14:16:48,446] test loss: 1.2080
[2023-06-25 14:16:48,447] cal loss: 51.2722
[2023-06-25 14:16:48,447] cal percent loss: 0.2011
[2023-06-25 14:16:48,447] mass loss: 29.2647
[2023-06-25 14:16:48,447] mass percent loss: 0.1342
[2023-06-25 14:16:48,448] fat loss: 3.8070
[2023-06-25 14:16:48,448] fat percent loss: 0.2998
[2023-06-25 14:16:48,448] carb loss: 6.2966
[2023-06-25 14:16:48,448] carb percent loss: 0.3262
[2023-06-25 14:16:48,448] protein loss: 4.6456
[2023-06-25 14:16:48,448] protein percent loss: 0.2567
[2023-06-25 14:16:48,448] Epoch 59/150
[2023-06-25 14:19:14,054] train loss: 0.8405
[2023-06-25 14:19:14,055] cal loss: 36.5638
[2023-06-25 14:19:14,055] cal percent loss: 0.1434
[2023-06-25 14:19:14,055] mass loss: 21.8700
[2023-06-25 14:19:14,056] mass percent loss: 0.1003
[2023-06-25 14:19:14,056] fat loss: 2.7603
[2023-06-25 14:19:14,056] fat percent loss: 0.2173
[2023-06-25 14:19:14,056] carb loss: 3.7410
[2023-06-25 14:19:14,056] carb percent loss: 0.1938
[2023-06-25 14:19:14,056] protein loss: 3.3765
[2023-06-25 14:19:14,056] protein percent loss: 0.1865
[2023-06-25 14:19:14,056] Epoch 59/150
[2023-06-25 14:19:36,839] test loss: 1.1046
[2023-06-25 14:19:36,840] cal loss: 44.9036
[2023-06-25 14:19:36,840] cal percent loss: 0.1761
[2023-06-25 14:19:36,840] mass loss: 26.8833
[2023-06-25 14:19:36,840] mass percent loss: 0.1233
[2023-06-25 14:19:36,840] fat loss: 3.4450
[2023-06-25 14:19:36,840] fat percent loss: 0.2713
[2023-06-25 14:19:36,841] carb loss: 5.6321
[2023-06-25 14:19:36,841] carb percent loss: 0.2918
[2023-06-25 14:19:36,841] protein loss: 4.5826
[2023-06-25 14:19:36,841] protein percent loss: 0.2532
[2023-06-25 14:19:36,841] Epoch 60/150
[2023-06-25 14:22:05,772] train loss: 0.7609
[2023-06-25 14:22:05,772] cal loss: 32.6159
[2023-06-25 14:22:05,772] cal percent loss: 0.1279
[2023-06-25 14:22:05,773] mass loss: 20.9158
[2023-06-25 14:22:05,773] mass percent loss: 0.0959
[2023-06-25 14:22:05,773] fat loss: 2.4156
[2023-06-25 14:22:05,773] fat percent loss: 0.1902
[2023-06-25 14:22:05,773] carb loss: 3.4422
[2023-06-25 14:22:05,773] carb percent loss: 0.1784
[2023-06-25 14:22:05,773] protein loss: 3.0378
[2023-06-25 14:22:05,773] protein percent loss: 0.1678
[2023-06-25 14:22:05,773] Epoch 60/150
[2023-06-25 14:22:29,517] test loss: 1.1311
[2023-06-25 14:22:29,518] cal loss: 47.4514
[2023-06-25 14:22:29,518] cal percent loss: 0.1861
[2023-06-25 14:22:29,518] mass loss: 26.4840
[2023-06-25 14:22:29,518] mass percent loss: 0.1215
[2023-06-25 14:22:29,518] fat loss: 3.4575
[2023-06-25 14:22:29,518] fat percent loss: 0.2722
[2023-06-25 14:22:29,518] carb loss: 5.6862
[2023-06-25 14:22:29,518] carb percent loss: 0.2946
[2023-06-25 14:22:29,518] protein loss: 4.8672
[2023-06-25 14:22:29,518] protein percent loss: 0.2689
[2023-06-25 14:22:29,518] Epoch 61/150
[2023-06-25 14:24:58,714] train loss: 0.7744
[2023-06-25 14:24:58,715] cal loss: 33.8880
[2023-06-25 14:24:58,715] cal percent loss: 0.1329
[2023-06-25 14:24:58,715] mass loss: 19.7754
[2023-06-25 14:24:58,715] mass percent loss: 0.0907
[2023-06-25 14:24:58,715] fat loss: 2.6122
[2023-06-25 14:24:58,715] fat percent loss: 0.2057
[2023-06-25 14:24:58,716] carb loss: 3.3560
[2023-06-25 14:24:58,716] carb percent loss: 0.1739
[2023-06-25 14:24:58,716] protein loss: 3.1171
[2023-06-25 14:24:58,716] protein percent loss: 0.1722
[2023-06-25 14:24:58,716] Epoch 61/150
[2023-06-25 14:25:24,702] test loss: 1.1095
[2023-06-25 14:25:24,702] cal loss: 48.3025
[2023-06-25 14:25:24,702] cal percent loss: 0.1894
[2023-06-25 14:25:24,703] mass loss: 25.9423
[2023-06-25 14:25:24,703] mass percent loss: 0.1190
[2023-06-25 14:25:24,703] fat loss: 3.6702
[2023-06-25 14:25:24,703] fat percent loss: 0.2890
[2023-06-25 14:25:24,703] carb loss: 5.1672
[2023-06-25 14:25:24,703] carb percent loss: 0.2677
[2023-06-25 14:25:24,703] protein loss: 4.5695
[2023-06-25 14:25:24,703] protein percent loss: 0.2525
[2023-06-25 14:25:24,704] Epoch 62/150
[2023-06-25 14:27:57,666] train loss: 0.7544
[2023-06-25 14:27:57,667] cal loss: 32.8960
[2023-06-25 14:27:57,667] cal percent loss: 0.1290
[2023-06-25 14:27:57,667] mass loss: 19.7069
[2023-06-25 14:27:57,667] mass percent loss: 0.0904
[2023-06-25 14:27:57,668] fat loss: 2.4993
[2023-06-25 14:27:57,668] fat percent loss: 0.1968
[2023-06-25 14:27:57,668] carb loss: 3.3144
[2023-06-25 14:27:57,668] carb percent loss: 0.1717
[2023-06-25 14:27:57,668] protein loss: 3.0201
[2023-06-25 14:27:57,668] protein percent loss: 0.1669
[2023-06-25 14:27:57,668] Epoch 62/150
[2023-06-25 14:28:24,005] test loss: 1.1486
[2023-06-25 14:28:24,006] cal loss: 49.1493
[2023-06-25 14:28:24,006] cal percent loss: 0.1927
[2023-06-25 14:28:24,006] mass loss: 26.6278
[2023-06-25 14:28:24,006] mass percent loss: 0.1221
[2023-06-25 14:28:24,007] fat loss: 3.8265
[2023-06-25 14:28:24,007] fat percent loss: 0.3013
[2023-06-25 14:28:24,007] carb loss: 5.3800
[2023-06-25 14:28:24,007] carb percent loss: 0.2788
[2023-06-25 14:28:24,007] protein loss: 4.7668
[2023-06-25 14:28:24,007] protein percent loss: 0.2634
[2023-06-25 14:28:24,007] Epoch 63/150
[2023-06-25 14:31:02,350] train loss: 0.7519
[2023-06-25 14:31:02,351] cal loss: 32.2578
[2023-06-25 14:31:02,351] cal percent loss: 0.1265
[2023-06-25 14:31:02,351] mass loss: 20.7166
[2023-06-25 14:31:02,351] mass percent loss: 0.0950
[2023-06-25 14:31:02,351] fat loss: 2.4476
[2023-06-25 14:31:02,351] fat percent loss: 0.1927
[2023-06-25 14:31:02,351] carb loss: 3.3794
[2023-06-25 14:31:02,351] carb percent loss: 0.1751
[2023-06-25 14:31:02,351] protein loss: 2.9227
[2023-06-25 14:31:02,352] protein percent loss: 0.1615
[2023-06-25 14:31:02,352] Epoch 63/150
[2023-06-25 14:31:28,602] test loss: 1.1473
[2023-06-25 14:31:28,602] cal loss: 47.5913
[2023-06-25 14:31:28,602] cal percent loss: 0.1866
[2023-06-25 14:31:28,602] mass loss: 28.4666
[2023-06-25 14:31:28,602] mass percent loss: 0.1306
[2023-06-25 14:31:28,603] fat loss: 3.6946
[2023-06-25 14:31:28,603] fat percent loss: 0.2909
[2023-06-25 14:31:28,603] carb loss: 5.2028
[2023-06-25 14:31:28,603] carb percent loss: 0.2696
[2023-06-25 14:31:28,603] protein loss: 5.0151
[2023-06-25 14:31:28,603] protein percent loss: 0.2771
[2023-06-25 14:31:28,603] Epoch 64/150
[2023-06-25 14:33:58,328] train loss: 0.7188
[2023-06-25 14:33:58,329] cal loss: 30.0759
[2023-06-25 14:33:58,329] cal percent loss: 0.1179
[2023-06-25 14:33:58,329] mass loss: 20.0792
[2023-06-25 14:33:58,329] mass percent loss: 0.0921
[2023-06-25 14:33:58,329] fat loss: 2.2949
[2023-06-25 14:33:58,329] fat percent loss: 0.1807
[2023-06-25 14:33:58,329] carb loss: 3.2826
[2023-06-25 14:33:58,329] carb percent loss: 0.1701
[2023-06-25 14:33:58,329] protein loss: 2.8499
[2023-06-25 14:33:58,329] protein percent loss: 0.1575
[2023-06-25 14:33:58,330] Epoch 64/150
[2023-06-25 14:34:23,942] test loss: 1.1410
[2023-06-25 14:34:23,943] cal loss: 47.4345
[2023-06-25 14:34:23,943] cal percent loss: 0.1860
[2023-06-25 14:34:23,943] mass loss: 26.6299
[2023-06-25 14:34:23,943] mass percent loss: 0.1222
[2023-06-25 14:34:23,943] fat loss: 3.7331
[2023-06-25 14:34:23,943] fat percent loss: 0.2939
[2023-06-25 14:34:23,943] carb loss: 5.5138
[2023-06-25 14:34:23,943] carb percent loss: 0.2857
[2023-06-25 14:34:23,943] protein loss: 4.7895
[2023-06-25 14:34:23,943] protein percent loss: 0.2646
[2023-06-25 14:34:23,943] Epoch 65/150
[2023-06-25 14:36:53,766] train loss: 0.7298
[2023-06-25 14:36:53,767] cal loss: 31.5762
[2023-06-25 14:36:53,767] cal percent loss: 0.1238
[2023-06-25 14:36:53,767] mass loss: 20.0562
[2023-06-25 14:36:53,767] mass percent loss: 0.0920
[2023-06-25 14:36:53,767] fat loss: 2.3563
[2023-06-25 14:36:53,768] fat percent loss: 0.1855
[2023-06-25 14:36:53,768] carb loss: 3.2130
[2023-06-25 14:36:53,768] carb percent loss: 0.1665
[2023-06-25 14:36:53,768] protein loss: 2.9085
[2023-06-25 14:36:53,768] protein percent loss: 0.1607
[2023-06-25 14:36:53,768] Epoch 65/150
[2023-06-25 14:37:20,123] test loss: 1.1248
[2023-06-25 14:37:20,123] cal loss: 47.1480
[2023-06-25 14:37:20,124] cal percent loss: 0.1849
[2023-06-25 14:37:20,124] mass loss: 25.8187
[2023-06-25 14:37:20,124] mass percent loss: 0.1184
[2023-06-25 14:37:20,124] fat loss: 3.8866
[2023-06-25 14:37:20,124] fat percent loss: 0.3060
[2023-06-25 14:37:20,124] carb loss: 5.2419
[2023-06-25 14:37:20,124] carb percent loss: 0.2716
[2023-06-25 14:37:20,124] protein loss: 4.6056
[2023-06-25 14:37:20,124] protein percent loss: 0.2545
[2023-06-25 14:37:20,124] Epoch 66/150
[2023-06-25 14:39:57,737] train loss: 0.7186
[2023-06-25 14:39:57,738] cal loss: 30.6818
[2023-06-25 14:39:57,738] cal percent loss: 0.1203
[2023-06-25 14:39:57,738] mass loss: 19.5344
[2023-06-25 14:39:57,738] mass percent loss: 0.0896
[2023-06-25 14:39:57,738] fat loss: 2.2823
[2023-06-25 14:39:57,738] fat percent loss: 0.1797
[2023-06-25 14:39:57,738] carb loss: 3.3061
[2023-06-25 14:39:57,739] carb percent loss: 0.1713
[2023-06-25 14:39:57,739] protein loss: 2.8555
[2023-06-25 14:39:57,739] protein percent loss: 0.1578
[2023-06-25 14:39:57,739] Epoch 66/150
[2023-06-25 14:40:22,499] test loss: 1.1760
[2023-06-25 14:40:22,500] cal loss: 51.5513
[2023-06-25 14:40:22,500] cal percent loss: 0.2022
[2023-06-25 14:40:22,500] mass loss: 25.7196
[2023-06-25 14:40:22,500] mass percent loss: 0.1180
[2023-06-25 14:40:22,500] fat loss: 4.1907
[2023-06-25 14:40:22,500] fat percent loss: 0.3300
[2023-06-25 14:40:22,500] carb loss: 5.2019
[2023-06-25 14:40:22,500] carb percent loss: 0.2695
[2023-06-25 14:40:22,500] protein loss: 4.8273
[2023-06-25 14:40:22,500] protein percent loss: 0.2667
[2023-06-25 14:40:22,501] Epoch 67/150
[2023-06-25 14:42:54,383] train loss: 0.7637
[2023-06-25 14:42:54,384] cal loss: 33.6368
[2023-06-25 14:42:54,384] cal percent loss: 0.1319
[2023-06-25 14:42:54,384] mass loss: 20.0777
[2023-06-25 14:42:54,384] mass percent loss: 0.0921
[2023-06-25 14:42:54,384] fat loss: 2.6260
[2023-06-25 14:42:54,385] fat percent loss: 0.2068
[2023-06-25 14:42:54,385] carb loss: 3.2772
[2023-06-25 14:42:54,385] carb percent loss: 0.1698
[2023-06-25 14:42:54,385] protein loss: 2.9363
[2023-06-25 14:42:54,385] protein percent loss: 0.1622
[2023-06-25 14:42:54,385] Epoch 67/150
[2023-06-25 14:43:19,528] test loss: 1.1618
[2023-06-25 14:43:19,528] cal loss: 50.2842
[2023-06-25 14:43:19,528] cal percent loss: 0.1972
[2023-06-25 14:43:19,529] mass loss: 28.3278
[2023-06-25 14:43:19,529] mass percent loss: 0.1299
[2023-06-25 14:43:19,529] fat loss: 3.7011
[2023-06-25 14:43:19,529] fat percent loss: 0.2914
[2023-06-25 14:43:19,529] carb loss: 5.5716
[2023-06-25 14:43:19,529] carb percent loss: 0.2887
[2023-06-25 14:43:19,529] protein loss: 4.7353
[2023-06-25 14:43:19,529] protein percent loss: 0.2616
[2023-06-25 14:43:19,529] Epoch 68/150
[2023-06-25 14:45:51,700] train loss: 0.7248
[2023-06-25 14:45:51,714] cal loss: 31.9950
[2023-06-25 14:45:51,714] cal percent loss: 0.1255
[2023-06-25 14:45:51,715] mass loss: 19.4341
[2023-06-25 14:45:51,715] mass percent loss: 0.0891
[2023-06-25 14:45:51,715] fat loss: 2.3315
[2023-06-25 14:45:51,715] fat percent loss: 0.1836
[2023-06-25 14:45:51,715] carb loss: 3.1762
[2023-06-25 14:45:51,715] carb percent loss: 0.1646
[2023-06-25 14:45:51,715] protein loss: 2.9173
[2023-06-25 14:45:51,715] protein percent loss: 0.1612
[2023-06-25 14:45:51,715] Epoch 68/150
[2023-06-25 14:46:18,300] test loss: 1.1666
[2023-06-25 14:46:18,301] cal loss: 50.1869
[2023-06-25 14:46:18,301] cal percent loss: 0.1968
[2023-06-25 14:46:18,301] mass loss: 28.4879
[2023-06-25 14:46:18,301] mass percent loss: 0.1307
[2023-06-25 14:46:18,301] fat loss: 3.7856
[2023-06-25 14:46:18,301] fat percent loss: 0.2981
[2023-06-25 14:46:18,301] carb loss: 5.2490
[2023-06-25 14:46:18,301] carb percent loss: 0.2720
[2023-06-25 14:46:18,301] protein loss: 4.9857
[2023-06-25 14:46:18,301] protein percent loss: 0.2755
[2023-06-25 14:46:18,302] Epoch 69/150
[2023-06-25 14:48:50,078] train loss: 0.7534
[2023-06-25 14:48:50,079] cal loss: 33.0700
[2023-06-25 14:48:50,079] cal percent loss: 0.1297
[2023-06-25 14:48:50,079] mass loss: 21.0299
[2023-06-25 14:48:50,079] mass percent loss: 0.0965
[2023-06-25 14:48:50,079] fat loss: 2.3951
[2023-06-25 14:48:50,079] fat percent loss: 0.1886
[2023-06-25 14:48:50,079] carb loss: 3.2002
[2023-06-25 14:48:50,079] carb percent loss: 0.1658
[2023-06-25 14:48:50,079] protein loss: 3.0800
[2023-06-25 14:48:50,079] protein percent loss: 0.1702
[2023-06-25 14:48:50,079] Epoch 69/150
[2023-06-25 14:49:15,408] test loss: 1.1259
[2023-06-25 14:49:15,408] cal loss: 49.2936
[2023-06-25 14:49:15,408] cal percent loss: 0.1933
[2023-06-25 14:49:15,408] mass loss: 25.8361
[2023-06-25 14:49:15,408] mass percent loss: 0.1185
[2023-06-25 14:49:15,408] fat loss: 3.7772
[2023-06-25 14:49:15,408] fat percent loss: 0.2974
[2023-06-25 14:49:15,409] carb loss: 5.2449
[2023-06-25 14:49:15,409] carb percent loss: 0.2718
[2023-06-25 14:49:15,409] protein loss: 4.5910
[2023-06-25 14:49:15,409] protein percent loss: 0.2536
[2023-06-25 14:49:15,409] Epoch 70/150
[2023-06-25 14:51:50,864] train loss: 0.6983
[2023-06-25 14:51:50,865] cal loss: 29.7897
[2023-06-25 14:51:50,865] cal percent loss: 0.1168
[2023-06-25 14:51:50,865] mass loss: 19.2284
[2023-06-25 14:51:50,865] mass percent loss: 0.0882
[2023-06-25 14:51:50,865] fat loss: 2.2810
[2023-06-25 14:51:50,865] fat percent loss: 0.1796
[2023-06-25 14:51:50,865] carb loss: 3.1554
[2023-06-25 14:51:50,865] carb percent loss: 0.1635
[2023-06-25 14:51:50,865] protein loss: 2.7037
[2023-06-25 14:51:50,865] protein percent loss: 0.1494
[2023-06-25 14:51:50,865] Epoch 70/150
[2023-06-25 14:52:17,601] test loss: 1.1093
[2023-06-25 14:52:17,601] cal loss: 47.1880
[2023-06-25 14:52:17,601] cal percent loss: 0.1851
[2023-06-25 14:52:17,601] mass loss: 26.9926
[2023-06-25 14:52:17,601] mass percent loss: 0.1238
[2023-06-25 14:52:17,601] fat loss: 3.6477
[2023-06-25 14:52:17,601] fat percent loss: 0.2872
[2023-06-25 14:52:17,601] carb loss: 5.1951
[2023-06-25 14:52:17,602] carb percent loss: 0.2692
[2023-06-25 14:52:17,602] protein loss: 4.5448
[2023-06-25 14:52:17,602] protein percent loss: 0.2511
[2023-06-25 14:52:17,602] Epoch 71/150
[2023-06-25 14:54:54,531] train loss: 0.7211
[2023-06-25 14:54:54,532] cal loss: 31.4050
[2023-06-25 14:54:54,532] cal percent loss: 0.1232
[2023-06-25 14:54:54,532] mass loss: 20.0294
[2023-06-25 14:54:54,532] mass percent loss: 0.0919
[2023-06-25 14:54:54,532] fat loss: 2.3279
[2023-06-25 14:54:54,532] fat percent loss: 0.1833
[2023-06-25 14:54:54,533] carb loss: 3.1611
[2023-06-25 14:54:54,533] carb percent loss: 0.1638
[2023-06-25 14:54:54,533] protein loss: 2.8412
[2023-06-25 14:54:54,533] protein percent loss: 0.1570
[2023-06-25 14:54:54,533] Epoch 71/150
[2023-06-25 14:55:18,310] test loss: 1.1682
[2023-06-25 14:55:18,310] cal loss: 51.4621
[2023-06-25 14:55:18,310] cal percent loss: 0.2018
[2023-06-25 14:55:18,311] mass loss: 27.4750
[2023-06-25 14:55:18,311] mass percent loss: 0.1260
[2023-06-25 14:55:18,311] fat loss: 3.7187
[2023-06-25 14:55:18,311] fat percent loss: 0.2928
[2023-06-25 14:55:18,311] carb loss: 5.6335
[2023-06-25 14:55:18,311] carb percent loss: 0.2919
[2023-06-25 14:55:18,311] protein loss: 4.7794
[2023-06-25 14:55:18,311] protein percent loss: 0.2641
[2023-06-25 14:55:18,311] Epoch 72/150
[2023-06-25 14:57:45,771] train loss: 0.7109
[2023-06-25 14:57:45,772] cal loss: 30.9055
[2023-06-25 14:57:45,772] cal percent loss: 0.1212
[2023-06-25 14:57:45,772] mass loss: 19.6946
[2023-06-25 14:57:45,772] mass percent loss: 0.0903
[2023-06-25 14:57:45,772] fat loss: 2.3282
[2023-06-25 14:57:45,772] fat percent loss: 0.1833
[2023-06-25 14:57:45,773] carb loss: 3.0669
[2023-06-25 14:57:45,773] carb percent loss: 0.1589
[2023-06-25 14:57:45,773] protein loss: 2.8070
[2023-06-25 14:57:45,773] protein percent loss: 0.1551
[2023-06-25 14:57:45,773] Epoch 72/150
[2023-06-25 14:58:12,161] test loss: 1.1005
[2023-06-25 14:58:12,162] cal loss: 47.8186
[2023-06-25 14:58:12,162] cal percent loss: 0.1875
[2023-06-25 14:58:12,162] mass loss: 27.1686
[2023-06-25 14:58:12,162] mass percent loss: 0.1246
[2023-06-25 14:58:12,162] fat loss: 3.5112
[2023-06-25 14:58:12,162] fat percent loss: 0.2765
[2023-06-25 14:58:12,162] carb loss: 5.0842
[2023-06-25 14:58:12,162] carb percent loss: 0.2634
[2023-06-25 14:58:12,162] protein loss: 4.5939
[2023-06-25 14:58:12,162] protein percent loss: 0.2538
[2023-06-25 14:58:12,163] Epoch 73/150
[2023-06-25 15:00:43,110] train loss: 0.6606
[2023-06-25 15:00:43,111] cal loss: 28.7330
[2023-06-25 15:00:43,111] cal percent loss: 0.1127
[2023-06-25 15:00:43,111] mass loss: 17.8774
[2023-06-25 15:00:43,111] mass percent loss: 0.0820
[2023-06-25 15:00:43,111] fat loss: 2.1592
[2023-06-25 15:00:43,111] fat percent loss: 0.1700
[2023-06-25 15:00:43,111] carb loss: 2.9248
[2023-06-25 15:00:43,111] carb percent loss: 0.1515
[2023-06-25 15:00:43,111] protein loss: 2.5973
[2023-06-25 15:00:43,111] protein percent loss: 0.1435
[2023-06-25 15:00:43,111] Epoch 73/150
[2023-06-25 15:01:10,109] test loss: 1.1505
[2023-06-25 15:01:10,109] cal loss: 46.7406
[2023-06-25 15:01:10,109] cal percent loss: 0.1833
[2023-06-25 15:01:10,109] mass loss: 28.7246
[2023-06-25 15:01:10,109] mass percent loss: 0.1318
[2023-06-25 15:01:10,109] fat loss: 3.9771
[2023-06-25 15:01:10,109] fat percent loss: 0.3132
[2023-06-25 15:01:10,110] carb loss: 5.3182
[2023-06-25 15:01:10,110] carb percent loss: 0.2756
[2023-06-25 15:01:10,110] protein loss: 4.5959
[2023-06-25 15:01:10,110] protein percent loss: 0.2539
[2023-06-25 15:01:10,110] Epoch 74/150
[2023-06-25 15:03:41,088] train loss: 0.7157
[2023-06-25 15:03:41,089] cal loss: 30.5980
[2023-06-25 15:03:41,089] cal percent loss: 0.1200
[2023-06-25 15:03:41,089] mass loss: 20.7097
[2023-06-25 15:03:41,089] mass percent loss: 0.0950
[2023-06-25 15:03:41,089] fat loss: 2.2990
[2023-06-25 15:03:41,089] fat percent loss: 0.1810
[2023-06-25 15:03:41,089] carb loss: 3.0745
[2023-06-25 15:03:41,089] carb percent loss: 0.1593
[2023-06-25 15:03:41,089] protein loss: 2.8429
[2023-06-25 15:03:41,089] protein percent loss: 0.1571
[2023-06-25 15:03:41,090] Epoch 74/150
[2023-06-25 15:04:05,788] test loss: 1.1437
[2023-06-25 15:04:05,789] cal loss: 47.8118
[2023-06-25 15:04:05,789] cal percent loss: 0.1875
[2023-06-25 15:04:05,789] mass loss: 27.3717
[2023-06-25 15:04:05,789] mass percent loss: 0.1256
[2023-06-25 15:04:05,789] fat loss: 3.8001
[2023-06-25 15:04:05,789] fat percent loss: 0.2992
[2023-06-25 15:04:05,789] carb loss: 5.3433
[2023-06-25 15:04:05,789] carb percent loss: 0.2769
[2023-06-25 15:04:05,789] protein loss: 4.7727
[2023-06-25 15:04:05,789] protein percent loss: 0.2637
[2023-06-25 15:04:05,790] Epoch 75/150
[2023-06-25 15:06:39,036] train loss: 0.6732
[2023-06-25 15:06:39,037] cal loss: 29.1634
[2023-06-25 15:06:39,037] cal percent loss: 0.1144
[2023-06-25 15:06:39,037] mass loss: 18.7367
[2023-06-25 15:06:39,037] mass percent loss: 0.0859
[2023-06-25 15:06:39,037] fat loss: 2.1510
[2023-06-25 15:06:39,037] fat percent loss: 0.1694
[2023-06-25 15:06:39,037] carb loss: 3.0055
[2023-06-25 15:06:39,037] carb percent loss: 0.1557
[2023-06-25 15:06:39,037] protein loss: 2.6462
[2023-06-25 15:06:39,037] protein percent loss: 0.1462
[2023-06-25 15:06:39,037] Epoch 75/150
[2023-06-25 15:07:03,972] test loss: 1.1766
[2023-06-25 15:07:03,972] cal loss: 51.5958
[2023-06-25 15:07:03,972] cal percent loss: 0.2023
[2023-06-25 15:07:03,972] mass loss: 28.0021
[2023-06-25 15:07:03,973] mass percent loss: 0.1285
[2023-06-25 15:07:03,973] fat loss: 3.6676
[2023-06-25 15:07:03,973] fat percent loss: 0.2888
[2023-06-25 15:07:03,973] carb loss: 5.5955
[2023-06-25 15:07:03,973] carb percent loss: 0.2899
[2023-06-25 15:07:03,973] protein loss: 4.9845
[2023-06-25 15:07:03,973] protein percent loss: 0.2754
[2023-06-25 15:07:03,973] Epoch 76/150
[2023-06-25 15:09:36,273] train loss: 0.6446
[2023-06-25 15:09:36,274] cal loss: 27.9533
[2023-06-25 15:09:36,274] cal percent loss: 0.1096
[2023-06-25 15:09:36,274] mass loss: 17.8529
[2023-06-25 15:09:36,274] mass percent loss: 0.0819
[2023-06-25 15:09:36,274] fat loss: 2.0874
[2023-06-25 15:09:36,274] fat percent loss: 0.1644
[2023-06-25 15:09:36,274] carb loss: 2.8026
[2023-06-25 15:09:36,274] carb percent loss: 0.1452
[2023-06-25 15:09:36,274] protein loss: 2.5677
[2023-06-25 15:09:36,274] protein percent loss: 0.1419
[2023-06-25 15:09:36,274] Epoch 76/150
[2023-06-25 15:10:02,424] test loss: 1.1210
[2023-06-25 15:10:02,425] cal loss: 49.2935
[2023-06-25 15:10:02,425] cal percent loss: 0.1933
[2023-06-25 15:10:02,425] mass loss: 25.7211
[2023-06-25 15:10:02,425] mass percent loss: 0.1180
[2023-06-25 15:10:02,425] fat loss: 3.7185
[2023-06-25 15:10:02,425] fat percent loss: 0.2928
[2023-06-25 15:10:02,425] carb loss: 5.4202
[2023-06-25 15:10:02,425] carb percent loss: 0.2808
[2023-06-25 15:10:02,425] protein loss: 4.4363
[2023-06-25 15:10:02,425] protein percent loss: 0.2451
[2023-06-25 15:10:02,426] Epoch 77/150
[2023-06-25 15:12:26,132] train loss: 0.6340
[2023-06-25 15:12:26,132] cal loss: 27.6530
[2023-06-25 15:12:26,132] cal percent loss: 0.1084
[2023-06-25 15:12:26,132] mass loss: 17.0207
[2023-06-25 15:12:26,132] mass percent loss: 0.0781
[2023-06-25 15:12:26,132] fat loss: 2.1073
[2023-06-25 15:12:26,132] fat percent loss: 0.1659
[2023-06-25 15:12:26,132] carb loss: 2.7807
[2023-06-25 15:12:26,132] carb percent loss: 0.1441
[2023-06-25 15:12:26,132] protein loss: 2.4747
[2023-06-25 15:12:26,132] protein percent loss: 0.1367
[2023-06-25 15:12:26,132] Epoch 77/150
[2023-06-25 15:12:52,506] test loss: 1.0994
[2023-06-25 15:12:52,506] cal loss: 49.3105
[2023-06-25 15:12:52,506] cal percent loss: 0.1934
[2023-06-25 15:12:52,506] mass loss: 26.0408
[2023-06-25 15:12:52,507] mass percent loss: 0.1195
[2023-06-25 15:12:52,507] fat loss: 3.4914
[2023-06-25 15:12:52,507] fat percent loss: 0.2749
[2023-06-25 15:12:52,507] carb loss: 5.4016
[2023-06-25 15:12:52,507] carb percent loss: 0.2799
[2023-06-25 15:12:52,507] protein loss: 4.3182
[2023-06-25 15:12:52,507] protein percent loss: 0.2386
[2023-06-25 15:12:52,507] Epoch 78/150
[2023-06-25 15:15:27,977] train loss: 0.6261
[2023-06-25 15:15:27,977] cal loss: 27.2230
[2023-06-25 15:15:27,977] cal percent loss: 0.1068
[2023-06-25 15:15:27,977] mass loss: 17.4691
[2023-06-25 15:15:27,978] mass percent loss: 0.0801
[2023-06-25 15:15:27,978] fat loss: 2.0360
[2023-06-25 15:15:27,978] fat percent loss: 0.1603
[2023-06-25 15:15:27,978] carb loss: 2.7382
[2023-06-25 15:15:27,978] carb percent loss: 0.1419
[2023-06-25 15:15:27,978] protein loss: 2.4437
[2023-06-25 15:15:27,978] protein percent loss: 0.1350
[2023-06-25 15:15:27,978] Epoch 78/150
[2023-06-25 15:15:56,214] test loss: 1.1731
[2023-06-25 15:15:56,214] cal loss: 52.4140
[2023-06-25 15:15:56,214] cal percent loss: 0.2055
[2023-06-25 15:15:56,214] mass loss: 25.2949
[2023-06-25 15:15:56,214] mass percent loss: 0.1160
[2023-06-25 15:15:56,214] fat loss: 4.0599
[2023-06-25 15:15:56,215] fat percent loss: 0.3197
[2023-06-25 15:15:56,215] carb loss: 5.1882
[2023-06-25 15:15:56,215] carb percent loss: 0.2688
[2023-06-25 15:15:56,215] protein loss: 4.9507
[2023-06-25 15:15:56,215] protein percent loss: 0.2735
[2023-06-25 15:15:56,215] Epoch 79/150
[2023-06-25 15:18:29,466] train loss: 0.6519
[2023-06-25 15:18:29,467] cal loss: 27.3893
[2023-06-25 15:18:29,467] cal percent loss: 0.1074
[2023-06-25 15:18:29,467] mass loss: 18.0963
[2023-06-25 15:18:29,467] mass percent loss: 0.0830
[2023-06-25 15:18:29,467] fat loss: 2.0879
[2023-06-25 15:18:29,467] fat percent loss: 0.1644
[2023-06-25 15:18:29,467] carb loss: 2.9037
[2023-06-25 15:18:29,467] carb percent loss: 0.1505
[2023-06-25 15:18:29,467] protein loss: 2.6439
[2023-06-25 15:18:29,467] protein percent loss: 0.1461
[2023-06-25 15:18:29,467] Epoch 79/150
[2023-06-25 15:18:54,239] test loss: 1.0894
[2023-06-25 15:18:54,239] cal loss: 45.5563
[2023-06-25 15:18:54,239] cal percent loss: 0.1787
[2023-06-25 15:18:54,240] mass loss: 25.2101
[2023-06-25 15:18:54,240] mass percent loss: 0.1156
[2023-06-25 15:18:54,240] fat loss: 3.6030
[2023-06-25 15:18:54,240] fat percent loss: 0.2837
[2023-06-25 15:18:54,240] carb loss: 5.3240
[2023-06-25 15:18:54,240] carb percent loss: 0.2759
[2023-06-25 15:18:54,240] protein loss: 4.4638
[2023-06-25 15:18:54,240] protein percent loss: 0.2466
[2023-06-25 15:18:54,240] Epoch 80/150
[2023-06-25 15:21:15,644] train loss: 0.6466
[2023-06-25 15:21:15,645] cal loss: 27.8809
[2023-06-25 15:21:15,645] cal percent loss: 0.1093
[2023-06-25 15:21:15,646] mass loss: 17.6865
[2023-06-25 15:21:15,646] mass percent loss: 0.0811
[2023-06-25 15:21:15,646] fat loss: 2.1444
[2023-06-25 15:21:15,646] fat percent loss: 0.1688
[2023-06-25 15:21:15,646] carb loss: 2.8598
[2023-06-25 15:21:15,646] carb percent loss: 0.1482
[2023-06-25 15:21:15,646] protein loss: 2.4987
[2023-06-25 15:21:15,646] protein percent loss: 0.1381
[2023-06-25 15:21:15,646] Epoch 80/150
[2023-06-25 15:21:38,700] test loss: 1.1556
[2023-06-25 15:21:38,701] cal loss: 50.2092
[2023-06-25 15:21:38,701] cal percent loss: 0.1969
[2023-06-25 15:21:38,701] mass loss: 26.1650
[2023-06-25 15:21:38,701] mass percent loss: 0.1200
[2023-06-25 15:21:38,701] fat loss: 4.0305
[2023-06-25 15:21:38,701] fat percent loss: 0.3174
[2023-06-25 15:21:38,701] carb loss: 4.9529
[2023-06-25 15:21:38,701] carb percent loss: 0.2566
[2023-06-25 15:21:38,702] protein loss: 4.9497
[2023-06-25 15:21:38,702] protein percent loss: 0.2735
[2023-06-25 15:21:38,702] Epoch 81/150
[2023-06-25 15:24:14,649] train loss: 0.6217
[2023-06-25 15:24:14,650] cal loss: 26.7823
[2023-06-25 15:24:14,650] cal percent loss: 0.1050
[2023-06-25 15:24:14,650] mass loss: 17.5332
[2023-06-25 15:24:14,651] mass percent loss: 0.0804
[2023-06-25 15:24:14,651] fat loss: 2.0153
[2023-06-25 15:24:14,651] fat percent loss: 0.1587
[2023-06-25 15:24:14,651] carb loss: 2.7076
[2023-06-25 15:24:14,651] carb percent loss: 0.1403
[2023-06-25 15:24:14,651] protein loss: 2.4472
[2023-06-25 15:24:14,651] protein percent loss: 0.1352
[2023-06-25 15:24:14,651] Epoch 81/150
[2023-06-25 15:24:40,494] test loss: 1.1300
[2023-06-25 15:24:40,495] cal loss: 51.0846
[2023-06-25 15:24:40,495] cal percent loss: 0.2003
[2023-06-25 15:24:40,495] mass loss: 25.3032
[2023-06-25 15:24:40,495] mass percent loss: 0.1161
[2023-06-25 15:24:40,495] fat loss: 3.7485
[2023-06-25 15:24:40,495] fat percent loss: 0.2952
[2023-06-25 15:24:40,495] carb loss: 5.4576
[2023-06-25 15:24:40,495] carb percent loss: 0.2828
[2023-06-25 15:24:40,495] protein loss: 4.4270
[2023-06-25 15:24:40,495] protein percent loss: 0.2446
[2023-06-25 15:24:40,496] Epoch 82/150
[2023-06-25 15:27:07,034] train loss: 0.6404
[2023-06-25 15:27:07,040] cal loss: 28.1358
[2023-06-25 15:27:07,040] cal percent loss: 0.1103
[2023-06-25 15:27:07,040] mass loss: 17.6482
[2023-06-25 15:27:07,040] mass percent loss: 0.0810
[2023-06-25 15:27:07,041] fat loss: 2.0498
[2023-06-25 15:27:07,041] fat percent loss: 0.1614
[2023-06-25 15:27:07,041] carb loss: 2.9100
[2023-06-25 15:27:07,041] carb percent loss: 0.1508
[2023-06-25 15:27:07,041] protein loss: 2.4518
[2023-06-25 15:27:07,041] protein percent loss: 0.1355
[2023-06-25 15:27:07,041] Epoch 82/150
[2023-06-25 15:27:34,493] test loss: 1.1138
[2023-06-25 15:27:34,493] cal loss: 48.9016
[2023-06-25 15:27:34,493] cal percent loss: 0.1918
[2023-06-25 15:27:34,493] mass loss: 26.2456
[2023-06-25 15:27:34,494] mass percent loss: 0.1204
[2023-06-25 15:27:34,494] fat loss: 3.6569
[2023-06-25 15:27:34,494] fat percent loss: 0.2879
[2023-06-25 15:27:34,494] carb loss: 5.3547
[2023-06-25 15:27:34,494] carb percent loss: 0.2774
[2023-06-25 15:27:34,494] protein loss: 4.4132
[2023-06-25 15:27:34,494] protein percent loss: 0.2438
[2023-06-25 15:27:34,494] Epoch 83/150
[2023-06-25 15:30:07,065] train loss: 0.6438
[2023-06-25 15:30:07,066] cal loss: 28.4888
[2023-06-25 15:30:07,066] cal percent loss: 0.1117
[2023-06-25 15:30:07,066] mass loss: 18.0728
[2023-06-25 15:30:07,067] mass percent loss: 0.0829
[2023-06-25 15:30:07,067] fat loss: 2.0732
[2023-06-25 15:30:07,067] fat percent loss: 0.1632
[2023-06-25 15:30:07,067] carb loss: 2.7992
[2023-06-25 15:30:07,067] carb percent loss: 0.1450
[2023-06-25 15:30:07,067] protein loss: 2.5000
[2023-06-25 15:30:07,067] protein percent loss: 0.1381
[2023-06-25 15:30:07,067] Epoch 83/150
[2023-06-25 15:30:32,995] test loss: 1.0994
[2023-06-25 15:30:32,995] cal loss: 47.7366
[2023-06-25 15:30:32,995] cal percent loss: 0.1872
[2023-06-25 15:30:32,995] mass loss: 25.6347
[2023-06-25 15:30:32,995] mass percent loss: 0.1176
[2023-06-25 15:30:32,995] fat loss: 3.5107
[2023-06-25 15:30:32,995] fat percent loss: 0.2764
[2023-06-25 15:30:32,996] carb loss: 5.2831
[2023-06-25 15:30:32,996] carb percent loss: 0.2737
[2023-06-25 15:30:32,996] protein loss: 4.5891
[2023-06-25 15:30:32,996] protein percent loss: 0.2535
[2023-06-25 15:30:32,996] Epoch 84/150
[2023-06-25 15:33:03,516] train loss: 0.6070
[2023-06-25 15:33:03,521] cal loss: 25.9905
[2023-06-25 15:33:03,521] cal percent loss: 0.1019
[2023-06-25 15:33:03,521] mass loss: 16.6503
[2023-06-25 15:33:03,521] mass percent loss: 0.0764
[2023-06-25 15:33:03,521] fat loss: 1.9686
[2023-06-25 15:33:03,521] fat percent loss: 0.1550
[2023-06-25 15:33:03,521] carb loss: 2.7404
[2023-06-25 15:33:03,521] carb percent loss: 0.1420
[2023-06-25 15:33:03,521] protein loss: 2.3732
[2023-06-25 15:33:03,522] protein percent loss: 0.1311
[2023-06-25 15:33:03,522] Epoch 84/150
[2023-06-25 15:33:29,158] test loss: 1.1382
[2023-06-25 15:33:29,159] cal loss: 49.9358
[2023-06-25 15:33:29,159] cal percent loss: 0.1958
[2023-06-25 15:33:29,159] mass loss: 27.2638
[2023-06-25 15:33:29,159] mass percent loss: 0.1251
[2023-06-25 15:33:29,159] fat loss: 3.7081
[2023-06-25 15:33:29,159] fat percent loss: 0.2920
[2023-06-25 15:33:29,159] carb loss: 5.5336
[2023-06-25 15:33:29,159] carb percent loss: 0.2867
[2023-06-25 15:33:29,159] protein loss: 4.4461
[2023-06-25 15:33:29,160] protein percent loss: 0.2456
[2023-06-25 15:33:29,160] Epoch 85/150
[2023-06-25 15:36:03,612] train loss: 0.5997
[2023-06-25 15:36:03,623] cal loss: 25.3599
[2023-06-25 15:36:03,623] cal percent loss: 0.0995
[2023-06-25 15:36:03,623] mass loss: 17.8114
[2023-06-25 15:36:03,623] mass percent loss: 0.0817
[2023-06-25 15:36:03,623] fat loss: 1.8788
[2023-06-25 15:36:03,623] fat percent loss: 0.1479
[2023-06-25 15:36:03,623] carb loss: 2.6671
[2023-06-25 15:36:03,623] carb percent loss: 0.1382
[2023-06-25 15:36:03,623] protein loss: 2.3414
[2023-06-25 15:36:03,623] protein percent loss: 0.1294
[2023-06-25 15:36:03,623] Epoch 85/150
[2023-06-25 15:36:30,151] test loss: 1.1407
[2023-06-25 15:36:30,152] cal loss: 50.7173
[2023-06-25 15:36:30,152] cal percent loss: 0.1989
[2023-06-25 15:36:30,152] mass loss: 26.6884
[2023-06-25 15:36:30,152] mass percent loss: 0.1224
[2023-06-25 15:36:30,152] fat loss: 3.8034
[2023-06-25 15:36:30,152] fat percent loss: 0.2995
[2023-06-25 15:36:30,152] carb loss: 5.2662
[2023-06-25 15:36:30,152] carb percent loss: 0.2729
[2023-06-25 15:36:30,152] protein loss: 4.5951
[2023-06-25 15:36:30,152] protein percent loss: 0.2539
[2023-06-25 15:36:30,153] Epoch 86/150
[2023-06-25 15:39:01,152] train loss: 0.5885
[2023-06-25 15:39:01,156] cal loss: 25.3245
[2023-06-25 15:39:01,157] cal percent loss: 0.0993
[2023-06-25 15:39:01,157] mass loss: 16.5366
[2023-06-25 15:39:01,157] mass percent loss: 0.0759
[2023-06-25 15:39:01,157] fat loss: 1.8975
[2023-06-25 15:39:01,157] fat percent loss: 0.1494
[2023-06-25 15:39:01,157] carb loss: 2.5545
[2023-06-25 15:39:01,157] carb percent loss: 0.1324
[2023-06-25 15:39:01,157] protein loss: 2.3499
[2023-06-25 15:39:01,157] protein percent loss: 0.1298
[2023-06-25 15:39:01,157] Epoch 86/150
[2023-06-25 15:39:26,165] test loss: 1.1159
[2023-06-25 15:39:26,165] cal loss: 48.3401
[2023-06-25 15:39:26,165] cal percent loss: 0.1896
[2023-06-25 15:39:26,165] mass loss: 25.2431
[2023-06-25 15:39:26,165] mass percent loss: 0.1158
[2023-06-25 15:39:26,166] fat loss: 3.7139
[2023-06-25 15:39:26,166] fat percent loss: 0.2924
[2023-06-25 15:39:26,166] carb loss: 5.2512
[2023-06-25 15:39:26,166] carb percent loss: 0.2721
[2023-06-25 15:39:26,166] protein loss: 4.6387
[2023-06-25 15:39:26,166] protein percent loss: 0.2563
[2023-06-25 15:39:26,166] Epoch 87/150
[2023-06-25 15:42:03,791] train loss: 0.5590
[2023-06-25 15:42:03,793] cal loss: 23.8454
[2023-06-25 15:42:03,793] cal percent loss: 0.0935
[2023-06-25 15:42:03,793] mass loss: 16.2097
[2023-06-25 15:42:03,793] mass percent loss: 0.0744
[2023-06-25 15:42:03,793] fat loss: 1.7855
[2023-06-25 15:42:03,793] fat percent loss: 0.1406
[2023-06-25 15:42:03,793] carb loss: 2.4513
[2023-06-25 15:42:03,793] carb percent loss: 0.1270
[2023-06-25 15:42:03,793] protein loss: 2.1913
[2023-06-25 15:42:03,793] protein percent loss: 0.1211
[2023-06-25 15:42:03,793] Epoch 87/150
[2023-06-25 15:42:31,732] test loss: 1.0903
[2023-06-25 15:42:31,732] cal loss: 45.6530
[2023-06-25 15:42:31,732] cal percent loss: 0.1790
[2023-06-25 15:42:31,732] mass loss: 27.7829
[2023-06-25 15:42:31,732] mass percent loss: 0.1274
[2023-06-25 15:42:31,732] fat loss: 3.3751
[2023-06-25 15:42:31,733] fat percent loss: 0.2658
[2023-06-25 15:42:31,733] carb loss: 5.3575
[2023-06-25 15:42:31,733] carb percent loss: 0.2776
[2023-06-25 15:42:31,733] protein loss: 4.4677
[2023-06-25 15:42:31,733] protein percent loss: 0.2468
[2023-06-25 15:42:31,733] Epoch 88/150
[2023-06-25 15:45:06,564] train loss: 0.5914
[2023-06-25 15:45:06,570] cal loss: 25.7354
[2023-06-25 15:45:06,570] cal percent loss: 0.1009
[2023-06-25 15:45:06,570] mass loss: 16.8953
[2023-06-25 15:45:06,571] mass percent loss: 0.0775
[2023-06-25 15:45:06,571] fat loss: 1.8721
[2023-06-25 15:45:06,571] fat percent loss: 0.1474
[2023-06-25 15:45:06,571] carb loss: 2.6132
[2023-06-25 15:45:06,571] carb percent loss: 0.1354
[2023-06-25 15:45:06,571] protein loss: 2.3113
[2023-06-25 15:45:06,571] protein percent loss: 0.1277
[2023-06-25 15:45:06,571] Epoch 88/150
[2023-06-25 15:45:29,332] test loss: 1.1552
[2023-06-25 15:45:29,333] cal loss: 48.7858
[2023-06-25 15:45:29,333] cal percent loss: 0.1913
[2023-06-25 15:45:29,333] mass loss: 27.6040
[2023-06-25 15:45:29,333] mass percent loss: 0.1266
[2023-06-25 15:45:29,333] fat loss: 3.6488
[2023-06-25 15:45:29,333] fat percent loss: 0.2873
[2023-06-25 15:45:29,333] carb loss: 5.5254
[2023-06-25 15:45:29,333] carb percent loss: 0.2863
[2023-06-25 15:45:29,333] protein loss: 4.9497
[2023-06-25 15:45:29,334] protein percent loss: 0.2735
[2023-06-25 15:45:29,334] Epoch 89/150
[2023-06-25 15:48:03,915] train loss: 0.5774
[2023-06-25 15:48:03,916] cal loss: 24.6893
[2023-06-25 15:48:03,916] cal percent loss: 0.0968
[2023-06-25 15:48:03,916] mass loss: 16.0959
[2023-06-25 15:48:03,916] mass percent loss: 0.0738
[2023-06-25 15:48:03,916] fat loss: 1.8596
[2023-06-25 15:48:03,916] fat percent loss: 0.1464
[2023-06-25 15:48:03,916] carb loss: 2.5714
[2023-06-25 15:48:03,917] carb percent loss: 0.1332
[2023-06-25 15:48:03,917] protein loss: 2.2795
[2023-06-25 15:48:03,917] protein percent loss: 0.1259
[2023-06-25 15:48:03,917] Epoch 89/150
[2023-06-25 15:48:27,559] test loss: 1.0735
[2023-06-25 15:48:27,559] cal loss: 46.7227
[2023-06-25 15:48:27,559] cal percent loss: 0.1832
[2023-06-25 15:48:27,559] mass loss: 24.2319
[2023-06-25 15:48:27,559] mass percent loss: 0.1112
[2023-06-25 15:48:27,559] fat loss: 3.3861
[2023-06-25 15:48:27,559] fat percent loss: 0.2666
[2023-06-25 15:48:27,559] carb loss: 5.2804
[2023-06-25 15:48:27,559] carb percent loss: 0.2736
[2023-06-25 15:48:27,559] protein loss: 4.5226
[2023-06-25 15:48:27,559] protein percent loss: 0.2499
[2023-06-25 15:48:27,559] Epoch 90/150
[2023-06-25 15:50:49,739] train loss: 0.5630
[2023-06-25 15:50:49,740] cal loss: 24.6068
[2023-06-25 15:50:49,740] cal percent loss: 0.0965
[2023-06-25 15:50:49,740] mass loss: 15.9827
[2023-06-25 15:50:49,740] mass percent loss: 0.0733
[2023-06-25 15:50:49,740] fat loss: 1.7472
[2023-06-25 15:50:49,740] fat percent loss: 0.1376
[2023-06-25 15:50:49,741] carb loss: 2.5129
[2023-06-25 15:50:49,741] carb percent loss: 0.1302
[2023-06-25 15:50:49,741] protein loss: 2.2326
[2023-06-25 15:50:49,741] protein percent loss: 0.1233
[2023-06-25 15:50:49,741] Epoch 90/150
[2023-06-25 15:51:14,256] test loss: 1.0900
[2023-06-25 15:51:14,256] cal loss: 46.0146
[2023-06-25 15:51:14,256] cal percent loss: 0.1804
[2023-06-25 15:51:14,256] mass loss: 26.4838
[2023-06-25 15:51:14,256] mass percent loss: 0.1215
[2023-06-25 15:51:14,256] fat loss: 3.3166
[2023-06-25 15:51:14,256] fat percent loss: 0.2612
[2023-06-25 15:51:14,256] carb loss: 5.5924
[2023-06-25 15:51:14,256] carb percent loss: 0.2898
[2023-06-25 15:51:14,256] protein loss: 4.4650
[2023-06-25 15:51:14,256] protein percent loss: 0.2467
[2023-06-25 15:51:14,257] Epoch 91/150
[2023-06-25 15:53:46,723] train loss: 0.5885
[2023-06-25 15:53:46,724] cal loss: 26.1114
[2023-06-25 15:53:46,724] cal percent loss: 0.1024
[2023-06-25 15:53:46,724] mass loss: 16.4919
[2023-06-25 15:53:46,724] mass percent loss: 0.0757
[2023-06-25 15:53:46,724] fat loss: 1.8684
[2023-06-25 15:53:46,725] fat percent loss: 0.1471
[2023-06-25 15:53:46,725] carb loss: 2.5899
[2023-06-25 15:53:46,725] carb percent loss: 0.1342
[2023-06-25 15:53:46,725] protein loss: 2.2949
[2023-06-25 15:53:46,725] protein percent loss: 0.1268
[2023-06-25 15:53:46,725] Epoch 91/150
[2023-06-25 15:54:10,391] test loss: 1.1523
[2023-06-25 15:54:10,392] cal loss: 49.8679
[2023-06-25 15:54:10,392] cal percent loss: 0.1956
[2023-06-25 15:54:10,392] mass loss: 28.0384
[2023-06-25 15:54:10,392] mass percent loss: 0.1286
[2023-06-25 15:54:10,392] fat loss: 3.8027
[2023-06-25 15:54:10,392] fat percent loss: 0.2994
[2023-06-25 15:54:10,392] carb loss: 5.4371
[2023-06-25 15:54:10,392] carb percent loss: 0.2817
[2023-06-25 15:54:10,392] protein loss: 4.5861
[2023-06-25 15:54:10,392] protein percent loss: 0.2534
[2023-06-25 15:54:10,392] Epoch 92/150
[2023-06-25 15:56:41,190] train loss: 0.5790
[2023-06-25 15:56:41,191] cal loss: 25.6606
[2023-06-25 15:56:41,191] cal percent loss: 0.1006
[2023-06-25 15:56:41,191] mass loss: 16.8773
[2023-06-25 15:56:41,191] mass percent loss: 0.0774
[2023-06-25 15:56:41,191] fat loss: 1.7758
[2023-06-25 15:56:41,191] fat percent loss: 0.1398
[2023-06-25 15:56:41,191] carb loss: 2.5473
[2023-06-25 15:56:41,191] carb percent loss: 0.1320
[2023-06-25 15:56:41,191] protein loss: 2.2738
[2023-06-25 15:56:41,191] protein percent loss: 0.1256
[2023-06-25 15:56:41,191] Epoch 92/150
[2023-06-25 15:57:08,684] test loss: 1.1198
[2023-06-25 15:57:08,684] cal loss: 49.6084
[2023-06-25 15:57:08,684] cal percent loss: 0.1945
[2023-06-25 15:57:08,684] mass loss: 25.4557
[2023-06-25 15:57:08,684] mass percent loss: 0.1168
[2023-06-25 15:57:08,684] fat loss: 3.5550
[2023-06-25 15:57:08,685] fat percent loss: 0.2799
[2023-06-25 15:57:08,685] carb loss: 5.4119
[2023-06-25 15:57:08,685] carb percent loss: 0.2804
[2023-06-25 15:57:08,685] protein loss: 4.6695
[2023-06-25 15:57:08,685] protein percent loss: 0.2580
[2023-06-25 15:57:08,685] Epoch 93/150
[2023-06-25 15:59:39,894] train loss: 0.5394
[2023-06-25 15:59:39,895] cal loss: 23.2677
[2023-06-25 15:59:39,895] cal percent loss: 0.0912
[2023-06-25 15:59:39,895] mass loss: 15.4723
[2023-06-25 15:59:39,895] mass percent loss: 0.0710
[2023-06-25 15:59:39,896] fat loss: 1.7329
[2023-06-25 15:59:39,896] fat percent loss: 0.1364
[2023-06-25 15:59:39,896] carb loss: 2.4217
[2023-06-25 15:59:39,896] carb percent loss: 0.1255
[2023-06-25 15:59:39,896] protein loss: 2.0462
[2023-06-25 15:59:39,896] protein percent loss: 0.1130
[2023-06-25 15:59:39,896] Epoch 93/150
[2023-06-25 16:00:04,703] test loss: 1.1243
[2023-06-25 16:00:04,704] cal loss: 48.7660
[2023-06-25 16:00:04,704] cal percent loss: 0.1912
[2023-06-25 16:00:04,704] mass loss: 26.4636
[2023-06-25 16:00:04,704] mass percent loss: 0.1214
[2023-06-25 16:00:04,704] fat loss: 3.6454
[2023-06-25 16:00:04,704] fat percent loss: 0.2870
[2023-06-25 16:00:04,704] carb loss: 5.3475
[2023-06-25 16:00:04,704] carb percent loss: 0.2771
[2023-06-25 16:00:04,704] protein loss: 4.6357
[2023-06-25 16:00:04,704] protein percent loss: 0.2561
[2023-06-25 16:00:04,705] Epoch 94/150
[2023-06-25 16:02:45,654] train loss: 0.5329
[2023-06-25 16:02:45,655] cal loss: 22.7485
[2023-06-25 16:02:45,655] cal percent loss: 0.0892
[2023-06-25 16:02:45,655] mass loss: 15.4301
[2023-06-25 16:02:45,656] mass percent loss: 0.0708
[2023-06-25 16:02:45,656] fat loss: 1.6719
[2023-06-25 16:02:45,656] fat percent loss: 0.1316
[2023-06-25 16:02:45,656] carb loss: 2.3838
[2023-06-25 16:02:45,656] carb percent loss: 0.1235
[2023-06-25 16:02:45,656] protein loss: 2.0927
[2023-06-25 16:02:45,656] protein percent loss: 0.1156
[2023-06-25 16:02:45,656] Epoch 94/150
[2023-06-25 16:03:12,613] test loss: 1.1523
[2023-06-25 16:03:12,613] cal loss: 51.4311
[2023-06-25 16:03:12,613] cal percent loss: 0.2017
[2023-06-25 16:03:12,613] mass loss: 27.2388
[2023-06-25 16:03:12,613] mass percent loss: 0.1249
[2023-06-25 16:03:12,613] fat loss: 3.7476
[2023-06-25 16:03:12,613] fat percent loss: 0.2951
[2023-06-25 16:03:12,613] carb loss: 5.2441
[2023-06-25 16:03:12,613] carb percent loss: 0.2717
[2023-06-25 16:03:12,613] protein loss: 4.8001
[2023-06-25 16:03:12,613] protein percent loss: 0.2652
[2023-06-25 16:03:12,613] Epoch 95/150
[2023-06-25 16:05:47,308] train loss: 0.6069
[2023-06-25 16:05:47,309] cal loss: 26.5219
[2023-06-25 16:05:47,309] cal percent loss: 0.1040
[2023-06-25 16:05:47,309] mass loss: 16.7413
[2023-06-25 16:05:47,309] mass percent loss: 0.0768
[2023-06-25 16:05:47,309] fat loss: 1.9888
[2023-06-25 16:05:47,309] fat percent loss: 0.1566
[2023-06-25 16:05:47,309] carb loss: 2.6786
[2023-06-25 16:05:47,309] carb percent loss: 0.1388
[2023-06-25 16:05:47,309] protein loss: 2.3364
[2023-06-25 16:05:47,309] protein percent loss: 0.1291
[2023-06-25 16:05:47,310] Epoch 95/150
[2023-06-25 16:06:10,681] test loss: 1.0953
[2023-06-25 16:06:10,682] cal loss: 47.3753
[2023-06-25 16:06:10,682] cal percent loss: 0.1858
[2023-06-25 16:06:10,682] mass loss: 24.8266
[2023-06-25 16:06:10,682] mass percent loss: 0.1139
[2023-06-25 16:06:10,682] fat loss: 3.5751
[2023-06-25 16:06:10,682] fat percent loss: 0.2815
[2023-06-25 16:06:10,682] carb loss: 5.1881
[2023-06-25 16:06:10,682] carb percent loss: 0.2688
[2023-06-25 16:06:10,682] protein loss: 4.6300
[2023-06-25 16:06:10,683] protein percent loss: 0.2558
[2023-06-25 16:06:10,683] Epoch 96/150
[2023-06-25 16:08:42,436] train loss: 0.5533
[2023-06-25 16:08:42,443] cal loss: 24.3214
[2023-06-25 16:08:42,443] cal percent loss: 0.0954
[2023-06-25 16:08:42,443] mass loss: 15.5326
[2023-06-25 16:08:42,443] mass percent loss: 0.0713
[2023-06-25 16:08:42,443] fat loss: 1.7998
[2023-06-25 16:08:42,443] fat percent loss: 0.1417
[2023-06-25 16:08:42,443] carb loss: 2.4000
[2023-06-25 16:08:42,443] carb percent loss: 0.1244
[2023-06-25 16:08:42,443] protein loss: 2.1412
[2023-06-25 16:08:42,443] protein percent loss: 0.1183
[2023-06-25 16:08:42,443] Epoch 96/150
[2023-06-25 16:09:05,928] test loss: 1.0731
[2023-06-25 16:09:05,928] cal loss: 44.8324
[2023-06-25 16:09:05,928] cal percent loss: 0.1758
[2023-06-25 16:09:05,928] mass loss: 25.5023
[2023-06-25 16:09:05,928] mass percent loss: 0.1170
[2023-06-25 16:09:05,928] fat loss: 3.6318
[2023-06-25 16:09:05,928] fat percent loss: 0.2860
[2023-06-25 16:09:05,929] carb loss: 5.0228
[2023-06-25 16:09:05,929] carb percent loss: 0.2602
[2023-06-25 16:09:05,929] protein loss: 4.3937
[2023-06-25 16:09:05,929] protein percent loss: 0.2427
[2023-06-25 16:09:05,929] Epoch 97/150
[2023-06-25 16:11:39,212] train loss: 0.5353
[2023-06-25 16:11:39,214] cal loss: 23.1665
[2023-06-25 16:11:39,214] cal percent loss: 0.0908
[2023-06-25 16:11:39,215] mass loss: 15.2181
[2023-06-25 16:11:39,215] mass percent loss: 0.0698
[2023-06-25 16:11:39,215] fat loss: 1.7468
[2023-06-25 16:11:39,215] fat percent loss: 0.1375
[2023-06-25 16:11:39,215] carb loss: 2.3639
[2023-06-25 16:11:39,215] carb percent loss: 0.1225
[2023-06-25 16:11:39,215] protein loss: 2.0342
[2023-06-25 16:11:39,215] protein percent loss: 0.1124
[2023-06-25 16:11:39,215] Epoch 97/150
[2023-06-25 16:12:04,686] test loss: 1.0798
[2023-06-25 16:12:04,686] cal loss: 46.9887
[2023-06-25 16:12:04,686] cal percent loss: 0.1843
[2023-06-25 16:12:04,687] mass loss: 25.0863
[2023-06-25 16:12:04,687] mass percent loss: 0.1151
[2023-06-25 16:12:04,687] fat loss: 3.4797
[2023-06-25 16:12:04,687] fat percent loss: 0.2740
[2023-06-25 16:12:04,687] carb loss: 5.1593
[2023-06-25 16:12:04,687] carb percent loss: 0.2673
[2023-06-25 16:12:04,687] protein loss: 4.4893
[2023-06-25 16:12:04,687] protein percent loss: 0.2480
[2023-06-25 16:12:04,687] Epoch 98/150
[2023-06-25 16:14:38,204] train loss: 0.5265
[2023-06-25 16:14:38,205] cal loss: 22.4390
[2023-06-25 16:14:38,205] cal percent loss: 0.0880
[2023-06-25 16:14:38,205] mass loss: 15.0063
[2023-06-25 16:14:38,205] mass percent loss: 0.0688
[2023-06-25 16:14:38,205] fat loss: 1.6810
[2023-06-25 16:14:38,206] fat percent loss: 0.1324
[2023-06-25 16:14:38,206] carb loss: 2.3919
[2023-06-25 16:14:38,206] carb percent loss: 0.1239
[2023-06-25 16:14:38,206] protein loss: 2.0234
[2023-06-25 16:14:38,206] protein percent loss: 0.1118
[2023-06-25 16:14:38,206] Epoch 98/150
[2023-06-25 16:15:04,658] test loss: 1.0945
[2023-06-25 16:15:04,658] cal loss: 47.5417
[2023-06-25 16:15:04,658] cal percent loss: 0.1864
[2023-06-25 16:15:04,658] mass loss: 25.2262
[2023-06-25 16:15:04,658] mass percent loss: 0.1157
[2023-06-25 16:15:04,658] fat loss: 3.6086
[2023-06-25 16:15:04,658] fat percent loss: 0.2841
[2023-06-25 16:15:04,658] carb loss: 5.2175
[2023-06-25 16:15:04,658] carb percent loss: 0.2703
[2023-06-25 16:15:04,658] protein loss: 4.4714
[2023-06-25 16:15:04,658] protein percent loss: 0.2470
[2023-06-25 16:15:04,658] Epoch 99/150
[2023-06-25 16:17:36,448] train loss: 0.5396
[2023-06-25 16:17:36,449] cal loss: 23.4557
[2023-06-25 16:17:36,449] cal percent loss: 0.0920
[2023-06-25 16:17:36,450] mass loss: 14.8455
[2023-06-25 16:17:36,450] mass percent loss: 0.0681
[2023-06-25 16:17:36,450] fat loss: 1.7638
[2023-06-25 16:17:36,450] fat percent loss: 0.1389
[2023-06-25 16:17:36,450] carb loss: 2.3696
[2023-06-25 16:17:36,450] carb percent loss: 0.1228
[2023-06-25 16:17:36,450] protein loss: 2.1103
[2023-06-25 16:17:36,450] protein percent loss: 0.1166
[2023-06-25 16:17:36,450] Epoch 99/150
[2023-06-25 16:17:59,323] test loss: 1.0730
[2023-06-25 16:17:59,324] cal loss: 46.3390
[2023-06-25 16:17:59,324] cal percent loss: 0.1817
[2023-06-25 16:17:59,324] mass loss: 24.9914
[2023-06-25 16:17:59,324] mass percent loss: 0.1146
[2023-06-25 16:17:59,324] fat loss: 3.4782
[2023-06-25 16:17:59,324] fat percent loss: 0.2739
[2023-06-25 16:17:59,325] carb loss: 5.1676
[2023-06-25 16:17:59,325] carb percent loss: 0.2678
[2023-06-25 16:17:59,325] protein loss: 4.4170
[2023-06-25 16:17:59,325] protein percent loss: 0.2440
[2023-06-25 16:17:59,325] Epoch 100/150
[2023-06-25 16:20:34,577] train loss: 0.5116
[2023-06-25 16:20:34,584] cal loss: 21.9611
[2023-06-25 16:20:34,585] cal percent loss: 0.0861
[2023-06-25 16:20:34,585] mass loss: 14.3618
[2023-06-25 16:20:34,585] mass percent loss: 0.0659
[2023-06-25 16:20:34,585] fat loss: 1.6110
[2023-06-25 16:20:34,585] fat percent loss: 0.1269
[2023-06-25 16:20:34,585] carb loss: 2.3295
[2023-06-25 16:20:34,585] carb percent loss: 0.1207
[2023-06-25 16:20:34,585] protein loss: 2.0078
[2023-06-25 16:20:34,585] protein percent loss: 0.1109
[2023-06-25 16:20:34,585] Epoch 100/150
[2023-06-25 16:20:59,248] test loss: 1.0918
[2023-06-25 16:20:59,248] cal loss: 46.0999
[2023-06-25 16:20:59,249] cal percent loss: 0.1808
[2023-06-25 16:20:59,249] mass loss: 24.9658
[2023-06-25 16:20:59,249] mass percent loss: 0.1145
[2023-06-25 16:20:59,249] fat loss: 3.5828
[2023-06-25 16:20:59,249] fat percent loss: 0.2821
[2023-06-25 16:20:59,249] carb loss: 5.2160
[2023-06-25 16:20:59,249] carb percent loss: 0.2703
[2023-06-25 16:20:59,249] protein loss: 4.6221
[2023-06-25 16:20:59,249] protein percent loss: 0.2554
[2023-06-25 16:20:59,249] Epoch 101/150
[2023-06-25 16:23:29,069] train loss: 0.5134
[2023-06-25 16:23:29,075] cal loss: 21.9721
[2023-06-25 16:23:29,075] cal percent loss: 0.0862
[2023-06-25 16:23:29,075] mass loss: 14.7447
[2023-06-25 16:23:29,075] mass percent loss: 0.0676
[2023-06-25 16:23:29,075] fat loss: 1.6406
[2023-06-25 16:23:29,075] fat percent loss: 0.1292
[2023-06-25 16:23:29,076] carb loss: 2.2931
[2023-06-25 16:23:29,076] carb percent loss: 0.1188
[2023-06-25 16:23:29,076] protein loss: 1.9850
[2023-06-25 16:23:29,076] protein percent loss: 0.1097
[2023-06-25 16:23:29,076] Epoch 101/150
[2023-06-25 16:23:52,764] test loss: 1.0883
[2023-06-25 16:23:52,764] cal loss: 47.6391
[2023-06-25 16:23:52,765] cal percent loss: 0.1868
[2023-06-25 16:23:52,765] mass loss: 25.7034
[2023-06-25 16:23:52,765] mass percent loss: 0.1179
[2023-06-25 16:23:52,765] fat loss: 3.4815
[2023-06-25 16:23:52,765] fat percent loss: 0.2741
[2023-06-25 16:23:52,765] carb loss: 5.1706
[2023-06-25 16:23:52,765] carb percent loss: 0.2679
[2023-06-25 16:23:52,765] protein loss: 4.5117
[2023-06-25 16:23:52,765] protein percent loss: 0.2493
[2023-06-25 16:23:52,765] Epoch 102/150
[2023-06-25 16:26:19,576] train loss: 0.5737
[2023-06-25 16:26:19,583] cal loss: 23.7711
[2023-06-25 16:26:19,583] cal percent loss: 0.0932
[2023-06-25 16:26:19,584] mass loss: 15.7165
[2023-06-25 16:26:19,584] mass percent loss: 0.0721
[2023-06-25 16:26:19,584] fat loss: 1.7251
[2023-06-25 16:26:19,584] fat percent loss: 0.1358
[2023-06-25 16:26:19,584] carb loss: 2.3541
[2023-06-25 16:26:19,584] carb percent loss: 0.1220
[2023-06-25 16:26:19,584] protein loss: 2.7344
[2023-06-25 16:26:19,584] protein percent loss: 0.1511
[2023-06-25 16:26:19,584] Epoch 102/150
[2023-06-25 16:26:45,151] test loss: 1.0943
[2023-06-25 16:26:45,152] cal loss: 47.8119
[2023-06-25 16:26:45,152] cal percent loss: 0.1875
[2023-06-25 16:26:45,152] mass loss: 26.0753
[2023-06-25 16:26:45,152] mass percent loss: 0.1196
[2023-06-25 16:26:45,152] fat loss: 3.4796
[2023-06-25 16:26:45,152] fat percent loss: 0.2740
[2023-06-25 16:26:45,152] carb loss: 5.2247
[2023-06-25 16:26:45,152] carb percent loss: 0.2707
[2023-06-25 16:26:45,152] protein loss: 4.5252
[2023-06-25 16:26:45,152] protein percent loss: 0.2500
[2023-06-25 16:26:45,152] Epoch 103/150
[2023-06-25 16:29:12,491] train loss: 0.5301
[2023-06-25 16:29:12,491] cal loss: 22.6761
[2023-06-25 16:29:12,492] cal percent loss: 0.0889
[2023-06-25 16:29:12,492] mass loss: 14.7609
[2023-06-25 16:29:12,492] mass percent loss: 0.0677
[2023-06-25 16:29:12,492] fat loss: 1.6550
[2023-06-25 16:29:12,492] fat percent loss: 0.1303
[2023-06-25 16:29:12,492] carb loss: 2.3386
[2023-06-25 16:29:12,492] carb percent loss: 0.1212
[2023-06-25 16:29:12,492] protein loss: 2.1933
[2023-06-25 16:29:12,492] protein percent loss: 0.1212
[2023-06-25 16:29:12,492] Epoch 103/150
[2023-06-25 16:29:37,663] test loss: 1.0920
[2023-06-25 16:29:37,663] cal loss: 47.2254
[2023-06-25 16:29:37,663] cal percent loss: 0.1852
[2023-06-25 16:29:37,663] mass loss: 25.6619
[2023-06-25 16:29:37,663] mass percent loss: 0.1177
[2023-06-25 16:29:37,663] fat loss: 3.5178
[2023-06-25 16:29:37,663] fat percent loss: 0.2770
[2023-06-25 16:29:37,663] carb loss: 5.5070
[2023-06-25 16:29:37,663] carb percent loss: 0.2853
[2023-06-25 16:29:37,663] protein loss: 4.2704
[2023-06-25 16:29:37,663] protein percent loss: 0.2359
[2023-06-25 16:29:37,664] Epoch 104/150
[2023-06-25 16:32:12,815] train loss: 0.5071
[2023-06-25 16:32:12,815] cal loss: 22.2406
[2023-06-25 16:32:12,815] cal percent loss: 0.0872
[2023-06-25 16:32:12,815] mass loss: 14.6351
[2023-06-25 16:32:12,816] mass percent loss: 0.0671
[2023-06-25 16:32:12,816] fat loss: 1.5789
[2023-06-25 16:32:12,816] fat percent loss: 0.1243
[2023-06-25 16:32:12,816] carb loss: 2.2735
[2023-06-25 16:32:12,816] carb percent loss: 0.1178
[2023-06-25 16:32:12,816] protein loss: 1.9569
[2023-06-25 16:32:12,816] protein percent loss: 0.1081
[2023-06-25 16:32:12,816] Epoch 104/150
[2023-06-25 16:32:37,758] test loss: 1.0843
[2023-06-25 16:32:37,759] cal loss: 47.2349
[2023-06-25 16:32:37,759] cal percent loss: 0.1852
[2023-06-25 16:32:37,759] mass loss: 25.5105
[2023-06-25 16:32:37,759] mass percent loss: 0.1170
[2023-06-25 16:32:37,759] fat loss: 3.6007
[2023-06-25 16:32:37,759] fat percent loss: 0.2835
[2023-06-25 16:32:37,759] carb loss: 5.1482
[2023-06-25 16:32:37,759] carb percent loss: 0.2667
[2023-06-25 16:32:37,759] protein loss: 4.3334
[2023-06-25 16:32:37,759] protein percent loss: 0.2394
[2023-06-25 16:32:37,760] Epoch 105/150
[2023-06-25 16:35:13,288] train loss: 0.5106
[2023-06-25 16:35:13,289] cal loss: 22.3057
[2023-06-25 16:35:13,289] cal percent loss: 0.0875
[2023-06-25 16:35:13,289] mass loss: 14.1299
[2023-06-25 16:35:13,289] mass percent loss: 0.0648
[2023-06-25 16:35:13,289] fat loss: 1.6487
[2023-06-25 16:35:13,289] fat percent loss: 0.1298
[2023-06-25 16:35:13,289] carb loss: 2.2712
[2023-06-25 16:35:13,289] carb percent loss: 0.1177
[2023-06-25 16:35:13,289] protein loss: 1.9810
[2023-06-25 16:35:13,289] protein percent loss: 0.1094
[2023-06-25 16:35:13,289] Epoch 105/150
[2023-06-25 16:35:39,479] test loss: 1.1315
[2023-06-25 16:35:39,479] cal loss: 50.1583
[2023-06-25 16:35:39,479] cal percent loss: 0.1967
[2023-06-25 16:35:39,479] mass loss: 27.9564
[2023-06-25 16:35:39,479] mass percent loss: 0.1282
[2023-06-25 16:35:39,479] fat loss: 3.5317
[2023-06-25 16:35:39,479] fat percent loss: 0.2781
[2023-06-25 16:35:39,479] carb loss: 5.5206
[2023-06-25 16:35:39,479] carb percent loss: 0.2860
[2023-06-25 16:35:39,479] protein loss: 4.4827
[2023-06-25 16:35:39,479] protein percent loss: 0.2477
[2023-06-25 16:35:39,479] Epoch 106/150
[2023-06-25 16:38:17,117] train loss: 0.5008
[2023-06-25 16:38:17,118] cal loss: 22.2681
[2023-06-25 16:38:17,118] cal percent loss: 0.0873
[2023-06-25 16:38:17,118] mass loss: 14.0133
[2023-06-25 16:38:17,118] mass percent loss: 0.0643
[2023-06-25 16:38:17,118] fat loss: 1.5941
[2023-06-25 16:38:17,118] fat percent loss: 0.1255
[2023-06-25 16:38:17,118] carb loss: 2.2150
[2023-06-25 16:38:17,118] carb percent loss: 0.1148
[2023-06-25 16:38:17,119] protein loss: 1.9355
[2023-06-25 16:38:17,119] protein percent loss: 0.1069
[2023-06-25 16:38:17,119] Epoch 106/150
[2023-06-25 16:38:43,576] test loss: 1.0532
[2023-06-25 16:38:43,576] cal loss: 45.7161
[2023-06-25 16:38:43,576] cal percent loss: 0.1793
[2023-06-25 16:38:43,576] mass loss: 24.4871
[2023-06-25 16:38:43,576] mass percent loss: 0.1123
[2023-06-25 16:38:43,576] fat loss: 3.4886
[2023-06-25 16:38:43,577] fat percent loss: 0.2747
[2023-06-25 16:38:43,577] carb loss: 4.9383
[2023-06-25 16:38:43,577] carb percent loss: 0.2559
[2023-06-25 16:38:43,577] protein loss: 4.3294
[2023-06-25 16:38:43,577] protein percent loss: 0.2392
[2023-06-25 16:38:43,577] Epoch 107/150
[2023-06-25 16:41:12,168] train loss: 0.4900
[2023-06-25 16:41:12,178] cal loss: 21.5637
[2023-06-25 16:41:12,178] cal percent loss: 0.0846
[2023-06-25 16:41:12,178] mass loss: 13.9966
[2023-06-25 16:41:12,178] mass percent loss: 0.0642
[2023-06-25 16:41:12,178] fat loss: 1.5594
[2023-06-25 16:41:12,178] fat percent loss: 0.1228
[2023-06-25 16:41:12,178] carb loss: 2.1794
[2023-06-25 16:41:12,178] carb percent loss: 0.1129
[2023-06-25 16:41:12,178] protein loss: 1.8676
[2023-06-25 16:41:12,178] protein percent loss: 0.1032
[2023-06-25 16:41:12,178] Epoch 107/150
[2023-06-25 16:41:38,338] test loss: 1.0854
[2023-06-25 16:41:38,339] cal loss: 47.1970
[2023-06-25 16:41:38,339] cal percent loss: 0.1851
[2023-06-25 16:41:38,339] mass loss: 25.3988
[2023-06-25 16:41:38,339] mass percent loss: 0.1165
[2023-06-25 16:41:38,339] fat loss: 3.6170
[2023-06-25 16:41:38,339] fat percent loss: 0.2848
[2023-06-25 16:41:38,339] carb loss: 5.0146
[2023-06-25 16:41:38,339] carb percent loss: 0.2598
[2023-06-25 16:41:38,339] protein loss: 4.4696
[2023-06-25 16:41:38,339] protein percent loss: 0.2469
[2023-06-25 16:41:38,340] Epoch 108/150
[2023-06-25 16:44:12,992] train loss: 0.5080
[2023-06-25 16:44:12,992] cal loss: 21.5035
[2023-06-25 16:44:12,992] cal percent loss: 0.0843
[2023-06-25 16:44:12,993] mass loss: 14.5854
[2023-06-25 16:44:12,993] mass percent loss: 0.0669
[2023-06-25 16:44:12,993] fat loss: 1.5782
[2023-06-25 16:44:12,993] fat percent loss: 0.1243
[2023-06-25 16:44:12,993] carb loss: 2.1705
[2023-06-25 16:44:12,993] carb percent loss: 0.1125
[2023-06-25 16:44:12,993] protein loss: 2.1425
[2023-06-25 16:44:12,993] protein percent loss: 0.1184
[2023-06-25 16:44:12,993] Epoch 108/150
[2023-06-25 16:44:39,727] test loss: 1.1312
[2023-06-25 16:44:39,727] cal loss: 49.5823
[2023-06-25 16:44:39,728] cal percent loss: 0.1944
[2023-06-25 16:44:39,728] mass loss: 25.6618
[2023-06-25 16:44:39,728] mass percent loss: 0.1177
[2023-06-25 16:44:39,728] fat loss: 3.7879
[2023-06-25 16:44:39,728] fat percent loss: 0.2983
[2023-06-25 16:44:39,728] carb loss: 5.2963
[2023-06-25 16:44:39,728] carb percent loss: 0.2744
[2023-06-25 16:44:39,728] protein loss: 4.6310
[2023-06-25 16:44:39,728] protein percent loss: 0.2559
[2023-06-25 16:44:39,728] Epoch 109/150
[2023-06-25 16:47:11,300] train loss: 0.4822
[2023-06-25 16:47:11,301] cal loss: 20.6659
[2023-06-25 16:47:11,301] cal percent loss: 0.0810
[2023-06-25 16:47:11,301] mass loss: 13.7037
[2023-06-25 16:47:11,301] mass percent loss: 0.0629
[2023-06-25 16:47:11,301] fat loss: 1.5404
[2023-06-25 16:47:11,301] fat percent loss: 0.1213
[2023-06-25 16:47:11,301] carb loss: 2.1938
[2023-06-25 16:47:11,301] carb percent loss: 0.1137
[2023-06-25 16:47:11,301] protein loss: 1.8443
[2023-06-25 16:47:11,301] protein percent loss: 0.1019
[2023-06-25 16:47:11,302] Epoch 109/150
[2023-06-25 16:47:36,257] test loss: 1.0634
[2023-06-25 16:47:36,258] cal loss: 45.7613
[2023-06-25 16:47:36,258] cal percent loss: 0.1795
[2023-06-25 16:47:36,258] mass loss: 25.2612
[2023-06-25 16:47:36,258] mass percent loss: 0.1159
[2023-06-25 16:47:36,258] fat loss: 3.3748
[2023-06-25 16:47:36,258] fat percent loss: 0.2657
[2023-06-25 16:47:36,258] carb loss: 5.1108
[2023-06-25 16:47:36,258] carb percent loss: 0.2648
[2023-06-25 16:47:36,258] protein loss: 4.4503
[2023-06-25 16:47:36,258] protein percent loss: 0.2459
[2023-06-25 16:47:36,259] Epoch 110/150
[2023-06-25 16:50:11,886] train loss: 0.4718
[2023-06-25 16:50:11,887] cal loss: 20.3834
[2023-06-25 16:50:11,887] cal percent loss: 0.0799
[2023-06-25 16:50:11,887] mass loss: 13.7410
[2023-06-25 16:50:11,887] mass percent loss: 0.0630
[2023-06-25 16:50:11,887] fat loss: 1.4912
[2023-06-25 16:50:11,887] fat percent loss: 0.1174
[2023-06-25 16:50:11,887] carb loss: 2.0840
[2023-06-25 16:50:11,887] carb percent loss: 0.1080
[2023-06-25 16:50:11,887] protein loss: 1.8296
[2023-06-25 16:50:11,887] protein percent loss: 0.1011
[2023-06-25 16:50:11,887] Epoch 110/150
[2023-06-25 16:50:37,071] test loss: 1.0574
[2023-06-25 16:50:37,071] cal loss: 45.0682
[2023-06-25 16:50:37,071] cal percent loss: 0.1767
[2023-06-25 16:50:37,071] mass loss: 24.9375
[2023-06-25 16:50:37,072] mass percent loss: 0.1144
[2023-06-25 16:50:37,072] fat loss: 3.4887
[2023-06-25 16:50:37,072] fat percent loss: 0.2747
[2023-06-25 16:50:37,072] carb loss: 4.9894
[2023-06-25 16:50:37,072] carb percent loss: 0.2585
[2023-06-25 16:50:37,072] protein loss: 4.3706
[2023-06-25 16:50:37,072] protein percent loss: 0.2415
[2023-06-25 16:50:37,072] Epoch 111/150
[2023-06-25 16:53:12,996] train loss: 0.4661
[2023-06-25 16:53:12,999] cal loss: 19.9300
[2023-06-25 16:53:12,999] cal percent loss: 0.0782
[2023-06-25 16:53:12,999] mass loss: 13.2625
[2023-06-25 16:53:12,999] mass percent loss: 0.0608
[2023-06-25 16:53:12,999] fat loss: 1.4900
[2023-06-25 16:53:12,999] fat percent loss: 0.1173
[2023-06-25 16:53:12,999] carb loss: 2.0544
[2023-06-25 16:53:12,999] carb percent loss: 0.1064
[2023-06-25 16:53:12,999] protein loss: 1.8431
[2023-06-25 16:53:12,999] protein percent loss: 0.1018
[2023-06-25 16:53:12,999] Epoch 111/150
[2023-06-25 16:53:39,555] test loss: 1.0957
[2023-06-25 16:53:39,556] cal loss: 47.8434
[2023-06-25 16:53:39,556] cal percent loss: 0.1876
[2023-06-25 16:53:39,556] mass loss: 26.1858
[2023-06-25 16:53:39,556] mass percent loss: 0.1201
[2023-06-25 16:53:39,556] fat loss: 3.4476
[2023-06-25 16:53:39,556] fat percent loss: 0.2715
[2023-06-25 16:53:39,556] carb loss: 5.2398
[2023-06-25 16:53:39,556] carb percent loss: 0.2715
[2023-06-25 16:53:39,556] protein loss: 4.5724
[2023-06-25 16:53:39,556] protein percent loss: 0.2526
[2023-06-25 16:53:39,557] Epoch 112/150
[2023-06-25 16:56:13,058] train loss: 0.4576
[2023-06-25 16:56:13,058] cal loss: 20.0066
[2023-06-25 16:56:13,058] cal percent loss: 0.0785
[2023-06-25 16:56:13,058] mass loss: 13.1171
[2023-06-25 16:56:13,058] mass percent loss: 0.0602
[2023-06-25 16:56:13,058] fat loss: 1.4662
[2023-06-25 16:56:13,058] fat percent loss: 0.1155
[2023-06-25 16:56:13,059] carb loss: 2.0088
[2023-06-25 16:56:13,059] carb percent loss: 0.1041
[2023-06-25 16:56:13,059] protein loss: 1.7598
[2023-06-25 16:56:13,059] protein percent loss: 0.0972
[2023-06-25 16:56:13,059] Epoch 112/150
[2023-06-25 16:56:37,454] test loss: 1.0828
[2023-06-25 16:56:37,454] cal loss: 48.3360
[2023-06-25 16:56:37,454] cal percent loss: 0.1896
[2023-06-25 16:56:37,454] mass loss: 24.2943
[2023-06-25 16:56:37,454] mass percent loss: 0.1114
[2023-06-25 16:56:37,454] fat loss: 3.6127
[2023-06-25 16:56:37,454] fat percent loss: 0.2845
[2023-06-25 16:56:37,455] carb loss: 4.9621
[2023-06-25 16:56:37,455] carb percent loss: 0.2571
[2023-06-25 16:56:37,455] protein loss: 4.5038
[2023-06-25 16:56:37,455] protein percent loss: 0.2488
[2023-06-25 16:56:37,455] Epoch 113/150
[2023-06-25 16:59:11,679] train loss: 0.4497
[2023-06-25 16:59:11,679] cal loss: 19.3364
[2023-06-25 16:59:11,680] cal percent loss: 0.0758
[2023-06-25 16:59:11,680] mass loss: 13.4475
[2023-06-25 16:59:11,680] mass percent loss: 0.0617
[2023-06-25 16:59:11,680] fat loss: 1.4192
[2023-06-25 16:59:11,680] fat percent loss: 0.1118
[2023-06-25 16:59:11,680] carb loss: 1.9833
[2023-06-25 16:59:11,680] carb percent loss: 0.1028
[2023-06-25 16:59:11,680] protein loss: 1.7136
[2023-06-25 16:59:11,680] protein percent loss: 0.0947
[2023-06-25 16:59:11,680] Epoch 113/150
[2023-06-25 16:59:36,898] test loss: 1.0566
[2023-06-25 16:59:36,899] cal loss: 45.5687
[2023-06-25 16:59:36,899] cal percent loss: 0.1787
[2023-06-25 16:59:36,899] mass loss: 24.2283
[2023-06-25 16:59:36,899] mass percent loss: 0.1111
[2023-06-25 16:59:36,899] fat loss: 3.4266
[2023-06-25 16:59:36,899] fat percent loss: 0.2698
[2023-06-25 16:59:36,899] carb loss: 5.1560
[2023-06-25 16:59:36,899] carb percent loss: 0.2671
[2023-06-25 16:59:36,899] protein loss: 4.3403
[2023-06-25 16:59:36,899] protein percent loss: 0.2398
[2023-06-25 16:59:36,900] Epoch 114/150
[2023-06-25 17:02:12,455] train loss: 0.4508
[2023-06-25 17:02:12,456] cal loss: 19.3615
[2023-06-25 17:02:12,456] cal percent loss: 0.0759
[2023-06-25 17:02:12,456] mass loss: 13.3727
[2023-06-25 17:02:12,456] mass percent loss: 0.0613
[2023-06-25 17:02:12,456] fat loss: 1.4203
[2023-06-25 17:02:12,456] fat percent loss: 0.1118
[2023-06-25 17:02:12,456] carb loss: 1.9712
[2023-06-25 17:02:12,456] carb percent loss: 0.1021
[2023-06-25 17:02:12,456] protein loss: 1.7527
[2023-06-25 17:02:12,456] protein percent loss: 0.0968
[2023-06-25 17:02:12,456] Epoch 114/150
[2023-06-25 17:02:36,625] test loss: 1.0657
[2023-06-25 17:02:36,626] cal loss: 45.7359
[2023-06-25 17:02:36,626] cal percent loss: 0.1794
[2023-06-25 17:02:36,626] mass loss: 25.2497
[2023-06-25 17:02:36,626] mass percent loss: 0.1158
[2023-06-25 17:02:36,626] fat loss: 3.4624
[2023-06-25 17:02:36,626] fat percent loss: 0.2726
[2023-06-25 17:02:36,626] carb loss: 4.9705
[2023-06-25 17:02:36,626] carb percent loss: 0.2575
[2023-06-25 17:02:36,626] protein loss: 4.4951
[2023-06-25 17:02:36,626] protein percent loss: 0.2483
[2023-06-25 17:02:36,627] Epoch 115/150
[2023-06-25 17:05:07,454] train loss: 0.4546
[2023-06-25 17:05:07,455] cal loss: 19.6734
[2023-06-25 17:05:07,455] cal percent loss: 0.0772
[2023-06-25 17:05:07,455] mass loss: 13.1918
[2023-06-25 17:05:07,455] mass percent loss: 0.0605
[2023-06-25 17:05:07,455] fat loss: 1.4652
[2023-06-25 17:05:07,455] fat percent loss: 0.1154
[2023-06-25 17:05:07,455] carb loss: 2.0084
[2023-06-25 17:05:07,455] carb percent loss: 0.1041
[2023-06-25 17:05:07,456] protein loss: 1.7212
[2023-06-25 17:05:07,456] protein percent loss: 0.0951
[2023-06-25 17:05:07,456] Epoch 115/150
[2023-06-25 17:05:35,392] test loss: 1.0800
[2023-06-25 17:05:35,392] cal loss: 44.7904
[2023-06-25 17:05:35,392] cal percent loss: 0.1756
[2023-06-25 17:05:35,392] mass loss: 25.3838
[2023-06-25 17:05:35,392] mass percent loss: 0.1164
[2023-06-25 17:05:35,392] fat loss: 3.5625
[2023-06-25 17:05:35,393] fat percent loss: 0.2805
[2023-06-25 17:05:35,393] carb loss: 5.1925
[2023-06-25 17:05:35,393] carb percent loss: 0.2690
[2023-06-25 17:05:35,393] protein loss: 4.5032
[2023-06-25 17:05:35,393] protein percent loss: 0.2488
[2023-06-25 17:05:35,393] Epoch 116/150
[2023-06-25 17:08:15,759] train loss: 0.4394
[2023-06-25 17:08:15,760] cal loss: 18.5329
[2023-06-25 17:08:15,760] cal percent loss: 0.0727
[2023-06-25 17:08:15,762] mass loss: 12.7818
[2023-06-25 17:08:15,762] mass percent loss: 0.0586
[2023-06-25 17:08:15,762] fat loss: 1.3911
[2023-06-25 17:08:15,762] fat percent loss: 0.1095
[2023-06-25 17:08:15,762] carb loss: 1.9397
[2023-06-25 17:08:15,762] carb percent loss: 0.1005
[2023-06-25 17:08:15,762] protein loss: 1.7437
[2023-06-25 17:08:15,762] protein percent loss: 0.0963
[2023-06-25 17:08:15,762] Epoch 116/150
[2023-06-25 17:08:42,368] test loss: 1.0867
[2023-06-25 17:08:42,368] cal loss: 46.7322
[2023-06-25 17:08:42,369] cal percent loss: 0.1833
[2023-06-25 17:08:42,369] mass loss: 24.4925
[2023-06-25 17:08:42,369] mass percent loss: 0.1124
[2023-06-25 17:08:42,369] fat loss: 3.5915
[2023-06-25 17:08:42,369] fat percent loss: 0.2828
[2023-06-25 17:08:42,369] carb loss: 5.1767
[2023-06-25 17:08:42,369] carb percent loss: 0.2682
[2023-06-25 17:08:42,369] protein loss: 4.5413
[2023-06-25 17:08:42,369] protein percent loss: 0.2509
[2023-06-25 17:08:42,369] Epoch 117/150
[2023-06-25 17:11:11,196] train loss: 0.4485
[2023-06-25 17:11:11,197] cal loss: 19.3426
[2023-06-25 17:11:11,197] cal percent loss: 0.0759
[2023-06-25 17:11:11,197] mass loss: 12.8597
[2023-06-25 17:11:11,197] mass percent loss: 0.0590
[2023-06-25 17:11:11,197] fat loss: 1.4475
[2023-06-25 17:11:11,197] fat percent loss: 0.1140
[2023-06-25 17:11:11,197] carb loss: 2.0022
[2023-06-25 17:11:11,197] carb percent loss: 0.1037
[2023-06-25 17:11:11,197] protein loss: 1.7018
[2023-06-25 17:11:11,197] protein percent loss: 0.0940
[2023-06-25 17:11:11,197] Epoch 117/150
[2023-06-25 17:11:36,392] test loss: 1.0415
[2023-06-25 17:11:36,392] cal loss: 45.2964
[2023-06-25 17:11:36,392] cal percent loss: 0.1776
[2023-06-25 17:11:36,392] mass loss: 23.7463
[2023-06-25 17:11:36,392] mass percent loss: 0.1089
[2023-06-25 17:11:36,392] fat loss: 3.3888
[2023-06-25 17:11:36,393] fat percent loss: 0.2668
[2023-06-25 17:11:36,393] carb loss: 4.9674
[2023-06-25 17:11:36,393] carb percent loss: 0.2574
[2023-06-25 17:11:36,393] protein loss: 4.3479
[2023-06-25 17:11:36,393] protein percent loss: 0.2402
[2023-06-25 17:11:36,393] Epoch 118/150
[2023-06-25 17:14:08,053] train loss: 0.4391
[2023-06-25 17:14:08,053] cal loss: 18.9457
[2023-06-25 17:14:08,054] cal percent loss: 0.0743
[2023-06-25 17:14:08,054] mass loss: 12.5837
[2023-06-25 17:14:08,054] mass percent loss: 0.0577
[2023-06-25 17:14:08,054] fat loss: 1.4343
[2023-06-25 17:14:08,054] fat percent loss: 0.1129
[2023-06-25 17:14:08,054] carb loss: 1.9725
[2023-06-25 17:14:08,054] carb percent loss: 0.1022
[2023-06-25 17:14:08,054] protein loss: 1.6298
[2023-06-25 17:14:08,054] protein percent loss: 0.0900
[2023-06-25 17:14:08,054] Epoch 118/150
[2023-06-25 17:14:33,315] test loss: 1.0734
[2023-06-25 17:14:33,315] cal loss: 46.1136
[2023-06-25 17:14:33,315] cal percent loss: 0.1808
[2023-06-25 17:14:33,315] mass loss: 25.8712
[2023-06-25 17:14:33,315] mass percent loss: 0.1187
[2023-06-25 17:14:33,315] fat loss: 3.4719
[2023-06-25 17:14:33,315] fat percent loss: 0.2734
[2023-06-25 17:14:33,316] carb loss: 5.0180
[2023-06-25 17:14:33,316] carb percent loss: 0.2600
[2023-06-25 17:14:33,316] protein loss: 4.4822
[2023-06-25 17:14:33,316] protein percent loss: 0.2476
[2023-06-25 17:14:33,316] Epoch 119/150
[2023-06-25 17:17:04,416] train loss: 0.4449
[2023-06-25 17:17:04,417] cal loss: 19.2219
[2023-06-25 17:17:04,417] cal percent loss: 0.0754
[2023-06-25 17:17:04,417] mass loss: 12.6814
[2023-06-25 17:17:04,417] mass percent loss: 0.0582
[2023-06-25 17:17:04,417] fat loss: 1.4171
[2023-06-25 17:17:04,417] fat percent loss: 0.1116
[2023-06-25 17:17:04,417] carb loss: 1.9667
[2023-06-25 17:17:04,417] carb percent loss: 0.1019
[2023-06-25 17:17:04,417] protein loss: 1.7417
[2023-06-25 17:17:04,417] protein percent loss: 0.0962
[2023-06-25 17:17:04,417] Epoch 119/150
[2023-06-25 17:17:28,230] test loss: 1.0704
[2023-06-25 17:17:28,231] cal loss: 46.0929
[2023-06-25 17:17:28,231] cal percent loss: 0.1808
[2023-06-25 17:17:28,231] mass loss: 24.9507
[2023-06-25 17:17:28,231] mass percent loss: 0.1145
[2023-06-25 17:17:28,231] fat loss: 3.5215
[2023-06-25 17:17:28,231] fat percent loss: 0.2773
[2023-06-25 17:17:28,231] carb loss: 5.0699
[2023-06-25 17:17:28,231] carb percent loss: 0.2627
[2023-06-25 17:17:28,231] protein loss: 4.4155
[2023-06-25 17:17:28,231] protein percent loss: 0.2439
[2023-06-25 17:17:28,232] Epoch 120/150
[2023-06-25 17:20:11,126] train loss: 0.4274
[2023-06-25 17:20:11,127] cal loss: 18.8658
[2023-06-25 17:20:11,127] cal percent loss: 0.0740
[2023-06-25 17:20:11,127] mass loss: 12.1792
[2023-06-25 17:20:11,127] mass percent loss: 0.0559
[2023-06-25 17:20:11,127] fat loss: 1.3540
[2023-06-25 17:20:11,127] fat percent loss: 0.1066
[2023-06-25 17:20:11,127] carb loss: 1.9144
[2023-06-25 17:20:11,127] carb percent loss: 0.0992
[2023-06-25 17:20:11,127] protein loss: 1.6247
[2023-06-25 17:20:11,127] protein percent loss: 0.0898
[2023-06-25 17:20:11,127] Epoch 120/150
[2023-06-25 17:20:34,303] test loss: 1.0553
[2023-06-25 17:20:34,303] cal loss: 46.3804
[2023-06-25 17:20:34,303] cal percent loss: 0.1819
[2023-06-25 17:20:34,303] mass loss: 24.5867
[2023-06-25 17:20:34,304] mass percent loss: 0.1128
[2023-06-25 17:20:34,304] fat loss: 3.4297
[2023-06-25 17:20:34,304] fat percent loss: 0.2701
[2023-06-25 17:20:34,304] carb loss: 4.9901
[2023-06-25 17:20:34,304] carb percent loss: 0.2586
[2023-06-25 17:20:34,304] protein loss: 4.3410
[2023-06-25 17:20:34,304] protein percent loss: 0.2398
[2023-06-25 17:20:34,304] Epoch 121/150
[2023-06-25 17:23:00,165] train loss: 0.4491
[2023-06-25 17:23:00,166] cal loss: 19.5078
[2023-06-25 17:23:00,166] cal percent loss: 0.0765
[2023-06-25 17:23:00,166] mass loss: 12.5139
[2023-06-25 17:23:00,166] mass percent loss: 0.0574
[2023-06-25 17:23:00,166] fat loss: 1.4455
[2023-06-25 17:23:00,166] fat percent loss: 0.1138
[2023-06-25 17:23:00,167] carb loss: 1.9760
[2023-06-25 17:23:00,167] carb percent loss: 0.1024
[2023-06-25 17:23:00,167] protein loss: 1.7697
[2023-06-25 17:23:00,167] protein percent loss: 0.0978
[2023-06-25 17:23:00,167] Epoch 121/150
[2023-06-25 17:23:25,236] test loss: 1.0729
[2023-06-25 17:23:25,236] cal loss: 45.5655
[2023-06-25 17:23:25,236] cal percent loss: 0.1787
[2023-06-25 17:23:25,236] mass loss: 25.7495
[2023-06-25 17:23:25,236] mass percent loss: 0.1181
[2023-06-25 17:23:25,236] fat loss: 3.5420
[2023-06-25 17:23:25,236] fat percent loss: 0.2789
[2023-06-25 17:23:25,236] carb loss: 5.0604
[2023-06-25 17:23:25,237] carb percent loss: 0.2622
[2023-06-25 17:23:25,237] protein loss: 4.3925
[2023-06-25 17:23:25,237] protein percent loss: 0.2427
[2023-06-25 17:23:25,237] Epoch 122/150
[2023-06-25 17:25:55,706] train loss: 0.4336
[2023-06-25 17:25:55,706] cal loss: 18.3755
[2023-06-25 17:25:55,706] cal percent loss: 0.0721
[2023-06-25 17:25:55,706] mass loss: 12.4520
[2023-06-25 17:25:55,707] mass percent loss: 0.0571
[2023-06-25 17:25:55,707] fat loss: 1.3977
[2023-06-25 17:25:55,707] fat percent loss: 0.1101
[2023-06-25 17:25:55,707] carb loss: 1.9267
[2023-06-25 17:25:55,707] carb percent loss: 0.0998
[2023-06-25 17:25:55,707] protein loss: 1.6846
[2023-06-25 17:25:55,707] protein percent loss: 0.0931
[2023-06-25 17:25:55,707] Epoch 122/150
[2023-06-25 17:26:19,791] test loss: 1.0745
[2023-06-25 17:26:19,792] cal loss: 46.5921
[2023-06-25 17:26:19,792] cal percent loss: 0.1827
[2023-06-25 17:26:19,792] mass loss: 24.9270
[2023-06-25 17:26:19,792] mass percent loss: 0.1143
[2023-06-25 17:26:19,792] fat loss: 3.5006
[2023-06-25 17:26:19,792] fat percent loss: 0.2756
[2023-06-25 17:26:19,792] carb loss: 5.1039
[2023-06-25 17:26:19,792] carb percent loss: 0.2645
[2023-06-25 17:26:19,792] protein loss: 4.4563
[2023-06-25 17:26:19,792] protein percent loss: 0.2462
[2023-06-25 17:26:19,793] Epoch 123/150
[2023-06-25 17:28:55,883] train loss: 0.4271
[2023-06-25 17:28:55,883] cal loss: 18.0443
[2023-06-25 17:28:55,883] cal percent loss: 0.0708
[2023-06-25 17:28:55,884] mass loss: 12.6219
[2023-06-25 17:28:55,884] mass percent loss: 0.0579
[2023-06-25 17:28:55,884] fat loss: 1.3623
[2023-06-25 17:28:55,884] fat percent loss: 0.1073
[2023-06-25 17:28:55,884] carb loss: 1.9268
[2023-06-25 17:28:55,884] carb percent loss: 0.0998
[2023-06-25 17:28:55,884] protein loss: 1.6149
[2023-06-25 17:28:55,884] protein percent loss: 0.0892
[2023-06-25 17:28:55,884] Epoch 123/150
[2023-06-25 17:29:21,285] test loss: 1.0467
[2023-06-25 17:29:21,286] cal loss: 44.5445
[2023-06-25 17:29:21,286] cal percent loss: 0.1747
[2023-06-25 17:29:21,286] mass loss: 24.6614
[2023-06-25 17:29:21,286] mass percent loss: 0.1131
[2023-06-25 17:29:21,286] fat loss: 3.4159
[2023-06-25 17:29:21,286] fat percent loss: 0.2690
[2023-06-25 17:29:21,287] carb loss: 5.0189
[2023-06-25 17:29:21,287] carb percent loss: 0.2600
[2023-06-25 17:29:21,287] protein loss: 4.3203
[2023-06-25 17:29:21,287] protein percent loss: 0.2387
[2023-06-25 17:29:21,287] Epoch 124/150
[2023-06-25 17:32:01,891] train loss: 0.4200
[2023-06-25 17:32:01,892] cal loss: 17.8374
[2023-06-25 17:32:01,892] cal percent loss: 0.0700
[2023-06-25 17:32:01,892] mass loss: 12.2818
[2023-06-25 17:32:01,892] mass percent loss: 0.0563
[2023-06-25 17:32:01,893] fat loss: 1.3398
[2023-06-25 17:32:01,893] fat percent loss: 0.1055
[2023-06-25 17:32:01,893] carb loss: 1.8843
[2023-06-25 17:32:01,893] carb percent loss: 0.0976
[2023-06-25 17:32:01,893] protein loss: 1.6058
[2023-06-25 17:32:01,893] protein percent loss: 0.0887
[2023-06-25 17:32:01,893] Epoch 124/150
[2023-06-25 17:32:30,459] test loss: 1.0805
[2023-06-25 17:32:30,460] cal loss: 45.7593
[2023-06-25 17:32:30,460] cal percent loss: 0.1794
[2023-06-25 17:32:30,460] mass loss: 25.0174
[2023-06-25 17:32:30,460] mass percent loss: 0.1148
[2023-06-25 17:32:30,460] fat loss: 3.5385
[2023-06-25 17:32:30,460] fat percent loss: 0.2786
[2023-06-25 17:32:30,460] carb loss: 5.2389
[2023-06-25 17:32:30,460] carb percent loss: 0.2714
[2023-06-25 17:32:30,461] protein loss: 4.4632
[2023-06-25 17:32:30,461] protein percent loss: 0.2466
[2023-06-25 17:32:30,461] Epoch 125/150
[2023-06-25 17:34:58,322] train loss: 0.4267
[2023-06-25 17:34:58,323] cal loss: 18.5295
[2023-06-25 17:34:58,323] cal percent loss: 0.0727
[2023-06-25 17:34:58,323] mass loss: 12.3034
[2023-06-25 17:34:58,323] mass percent loss: 0.0564
[2023-06-25 17:34:58,323] fat loss: 1.3563
[2023-06-25 17:34:58,323] fat percent loss: 0.1068
[2023-06-25 17:34:58,323] carb loss: 1.8829
[2023-06-25 17:34:58,323] carb percent loss: 0.0976
[2023-06-25 17:34:58,323] protein loss: 1.6503
[2023-06-25 17:34:58,323] protein percent loss: 0.0912
[2023-06-25 17:34:58,323] Epoch 125/150
[2023-06-25 17:35:25,056] test loss: 1.0825
[2023-06-25 17:35:25,057] cal loss: 46.8511
[2023-06-25 17:35:25,057] cal percent loss: 0.1837
[2023-06-25 17:35:25,057] mass loss: 24.9700
[2023-06-25 17:35:25,057] mass percent loss: 0.1145
[2023-06-25 17:35:25,057] fat loss: 3.5431
[2023-06-25 17:35:25,057] fat percent loss: 0.2790
[2023-06-25 17:35:25,057] carb loss: 5.2360
[2023-06-25 17:35:25,057] carb percent loss: 0.2713
[2023-06-25 17:35:25,057] protein loss: 4.4055
[2023-06-25 17:35:25,057] protein percent loss: 0.2434
[2023-06-25 17:35:25,058] Epoch 126/150
[2023-06-25 17:37:54,111] train loss: 0.4333
[2023-06-25 17:37:54,112] cal loss: 18.8227
[2023-06-25 17:37:54,112] cal percent loss: 0.0738
[2023-06-25 17:37:54,112] mass loss: 12.7559
[2023-06-25 17:37:54,112] mass percent loss: 0.0585
[2023-06-25 17:37:54,112] fat loss: 1.3625
[2023-06-25 17:37:54,112] fat percent loss: 0.1073
[2023-06-25 17:37:54,112] carb loss: 1.9124
[2023-06-25 17:37:54,112] carb percent loss: 0.0991
[2023-06-25 17:37:54,112] protein loss: 1.6642
[2023-06-25 17:37:54,112] protein percent loss: 0.0919
[2023-06-25 17:37:54,112] Epoch 126/150
[2023-06-25 17:38:20,577] test loss: 1.0389
[2023-06-25 17:38:20,578] cal loss: 43.4572
[2023-06-25 17:38:20,578] cal percent loss: 0.1704
[2023-06-25 17:38:20,578] mass loss: 24.2422
[2023-06-25 17:38:20,578] mass percent loss: 0.1112
[2023-06-25 17:38:20,578] fat loss: 3.4087
[2023-06-25 17:38:20,578] fat percent loss: 0.2684
[2023-06-25 17:38:20,578] carb loss: 5.1034
[2023-06-25 17:38:20,578] carb percent loss: 0.2644
[2023-06-25 17:38:20,578] protein loss: 4.2484
[2023-06-25 17:38:20,578] protein percent loss: 0.2347
[2023-06-25 17:38:20,578] Epoch 127/150
[2023-06-25 17:40:49,845] train loss: 0.4174
[2023-06-25 17:40:49,846] cal loss: 17.8547
[2023-06-25 17:40:49,846] cal percent loss: 0.0700
[2023-06-25 17:40:49,846] mass loss: 12.3919
[2023-06-25 17:40:49,846] mass percent loss: 0.0568
[2023-06-25 17:40:49,846] fat loss: 1.3004
[2023-06-25 17:40:49,846] fat percent loss: 0.1024
[2023-06-25 17:40:49,846] carb loss: 1.8938
[2023-06-25 17:40:49,846] carb percent loss: 0.0981
[2023-06-25 17:40:49,846] protein loss: 1.5877
[2023-06-25 17:40:49,846] protein percent loss: 0.0877
[2023-06-25 17:40:49,846] Epoch 127/150
[2023-06-25 17:41:15,360] test loss: 1.0503
[2023-06-25 17:41:15,361] cal loss: 45.8691
[2023-06-25 17:41:15,361] cal percent loss: 0.1799
[2023-06-25 17:41:15,361] mass loss: 23.6673
[2023-06-25 17:41:15,361] mass percent loss: 0.1086
[2023-06-25 17:41:15,361] fat loss: 3.4035
[2023-06-25 17:41:15,361] fat percent loss: 0.2680
[2023-06-25 17:41:15,361] carb loss: 5.1643
[2023-06-25 17:41:15,361] carb percent loss: 0.2676
[2023-06-25 17:41:15,361] protein loss: 4.2826
[2023-06-25 17:41:15,361] protein percent loss: 0.2366
[2023-06-25 17:41:15,362] Epoch 128/150
[2023-06-25 17:43:47,191] train loss: 0.4120
[2023-06-25 17:43:47,192] cal loss: 17.4545
[2023-06-25 17:43:47,192] cal percent loss: 0.0684
[2023-06-25 17:43:47,192] mass loss: 11.8830
[2023-06-25 17:43:47,192] mass percent loss: 0.0545
[2023-06-25 17:43:47,192] fat loss: 1.3268
[2023-06-25 17:43:47,192] fat percent loss: 0.1045
[2023-06-25 17:43:47,192] carb loss: 1.8445
[2023-06-25 17:43:47,192] carb percent loss: 0.0956
[2023-06-25 17:43:47,192] protein loss: 1.5828
[2023-06-25 17:43:47,193] protein percent loss: 0.0874
[2023-06-25 17:43:47,193] Epoch 128/150
[2023-06-25 17:44:13,054] test loss: 1.0708
[2023-06-25 17:44:13,054] cal loss: 45.3063
[2023-06-25 17:44:13,055] cal percent loss: 0.1777
[2023-06-25 17:44:13,055] mass loss: 25.0128
[2023-06-25 17:44:13,055] mass percent loss: 0.1147
[2023-06-25 17:44:13,055] fat loss: 3.5270
[2023-06-25 17:44:13,055] fat percent loss: 0.2777
[2023-06-25 17:44:13,055] carb loss: 5.0713
[2023-06-25 17:44:13,055] carb percent loss: 0.2628
[2023-06-25 17:44:13,055] protein loss: 4.4782
[2023-06-25 17:44:13,055] protein percent loss: 0.2474
[2023-06-25 17:44:13,055] Epoch 129/150
[2023-06-25 17:46:47,227] train loss: 0.4160
[2023-06-25 17:46:47,228] cal loss: 18.1840
[2023-06-25 17:46:47,228] cal percent loss: 0.0713
[2023-06-25 17:46:47,228] mass loss: 12.0376
[2023-06-25 17:46:47,228] mass percent loss: 0.0552
[2023-06-25 17:46:47,228] fat loss: 1.3330
[2023-06-25 17:46:47,228] fat percent loss: 0.1050
[2023-06-25 17:46:47,228] carb loss: 1.8767
[2023-06-25 17:46:47,228] carb percent loss: 0.0972
[2023-06-25 17:46:47,228] protein loss: 1.5400
[2023-06-25 17:46:47,228] protein percent loss: 0.0851
[2023-06-25 17:46:47,228] Epoch 129/150
[2023-06-25 17:47:11,170] test loss: 1.0469
[2023-06-25 17:47:11,171] cal loss: 44.8655
[2023-06-25 17:47:11,171] cal percent loss: 0.1759
[2023-06-25 17:47:11,171] mass loss: 25.0628
[2023-06-25 17:47:11,171] mass percent loss: 0.1150
[2023-06-25 17:47:11,171] fat loss: 3.4071
[2023-06-25 17:47:11,171] fat percent loss: 0.2683
[2023-06-25 17:47:11,171] carb loss: 5.0066
[2023-06-25 17:47:11,171] carb percent loss: 0.2594
[2023-06-25 17:47:11,171] protein loss: 4.2703
[2023-06-25 17:47:11,171] protein percent loss: 0.2359
[2023-06-25 17:47:11,172] Epoch 130/150
[2023-06-25 17:49:43,615] train loss: 0.4137
[2023-06-25 17:49:43,615] cal loss: 17.6761
[2023-06-25 17:49:43,616] cal percent loss: 0.0693
[2023-06-25 17:49:43,616] mass loss: 11.9081
[2023-06-25 17:49:43,616] mass percent loss: 0.0546
[2023-06-25 17:49:43,616] fat loss: 1.3197
[2023-06-25 17:49:43,616] fat percent loss: 0.1039
[2023-06-25 17:49:43,616] carb loss: 1.8840
[2023-06-25 17:49:43,616] carb percent loss: 0.0976
[2023-06-25 17:49:43,616] protein loss: 1.5688
[2023-06-25 17:49:43,616] protein percent loss: 0.0867
[2023-06-25 17:49:43,616] Epoch 130/150
[2023-06-25 17:50:08,190] test loss: 1.0294
[2023-06-25 17:50:08,190] cal loss: 44.5613
[2023-06-25 17:50:08,190] cal percent loss: 0.1748
[2023-06-25 17:50:08,191] mass loss: 23.6069
[2023-06-25 17:50:08,191] mass percent loss: 0.1083
[2023-06-25 17:50:08,191] fat loss: 3.2832
[2023-06-25 17:50:08,191] fat percent loss: 0.2585
[2023-06-25 17:50:08,191] carb loss: 5.0994
[2023-06-25 17:50:08,191] carb percent loss: 0.2642
[2023-06-25 17:50:08,191] protein loss: 4.2277
[2023-06-25 17:50:08,191] protein percent loss: 0.2336
[2023-06-25 17:50:08,191] Epoch 131/150
[2023-06-25 17:52:37,960] train loss: 0.4105
[2023-06-25 17:52:37,961] cal loss: 17.3824
[2023-06-25 17:52:37,961] cal percent loss: 0.0682
[2023-06-25 17:52:37,961] mass loss: 11.9384
[2023-06-25 17:52:37,961] mass percent loss: 0.0548
[2023-06-25 17:52:37,961] fat loss: 1.3063
[2023-06-25 17:52:37,961] fat percent loss: 0.1029
[2023-06-25 17:52:37,961] carb loss: 1.8708
[2023-06-25 17:52:37,961] carb percent loss: 0.0969
[2023-06-25 17:52:37,962] protein loss: 1.5594
[2023-06-25 17:52:37,962] protein percent loss: 0.0862
[2023-06-25 17:52:37,962] Epoch 131/150
[2023-06-25 17:53:04,650] test loss: 1.0642
[2023-06-25 17:53:04,650] cal loss: 46.1587
[2023-06-25 17:53:04,651] cal percent loss: 0.1810
[2023-06-25 17:53:04,651] mass loss: 24.4156
[2023-06-25 17:53:04,651] mass percent loss: 0.1120
[2023-06-25 17:53:04,651] fat loss: 3.4567
[2023-06-25 17:53:04,651] fat percent loss: 0.2722
[2023-06-25 17:53:04,651] carb loss: 5.1629
[2023-06-25 17:53:04,651] carb percent loss: 0.2675
[2023-06-25 17:53:04,651] protein loss: 4.3649
[2023-06-25 17:53:04,651] protein percent loss: 0.2412
[2023-06-25 17:53:04,651] Epoch 132/150
[2023-06-25 17:55:28,891] train loss: 0.4152
[2023-06-25 17:55:28,892] cal loss: 18.1943
[2023-06-25 17:55:28,892] cal percent loss: 0.0714
[2023-06-25 17:55:28,892] mass loss: 11.7558
[2023-06-25 17:55:28,892] mass percent loss: 0.0539
[2023-06-25 17:55:28,892] fat loss: 1.3386
[2023-06-25 17:55:28,892] fat percent loss: 0.1054
[2023-06-25 17:55:28,892] carb loss: 1.8323
[2023-06-25 17:55:28,892] carb percent loss: 0.0949
[2023-06-25 17:55:28,892] protein loss: 1.5900
[2023-06-25 17:55:28,892] protein percent loss: 0.0878
[2023-06-25 17:55:28,892] Epoch 132/150
[2023-06-25 17:55:54,255] test loss: 1.0749
[2023-06-25 17:55:54,255] cal loss: 46.3303
[2023-06-25 17:55:54,255] cal percent loss: 0.1817
[2023-06-25 17:55:54,255] mass loss: 25.3755
[2023-06-25 17:55:54,255] mass percent loss: 0.1164
[2023-06-25 17:55:54,256] fat loss: 3.4398
[2023-06-25 17:55:54,256] fat percent loss: 0.2709
[2023-06-25 17:55:54,256] carb loss: 5.2156
[2023-06-25 17:55:54,256] carb percent loss: 0.2702
[2023-06-25 17:55:54,256] protein loss: 4.4230
[2023-06-25 17:55:54,256] protein percent loss: 0.2444
[2023-06-25 17:55:54,256] Epoch 133/150
[2023-06-25 17:58:23,023] train loss: 0.4062
[2023-06-25 17:58:23,024] cal loss: 17.3283
[2023-06-25 17:58:23,024] cal percent loss: 0.0680
[2023-06-25 17:58:23,024] mass loss: 11.8948
[2023-06-25 17:58:23,024] mass percent loss: 0.0546
[2023-06-25 17:58:23,024] fat loss: 1.2752
[2023-06-25 17:58:23,024] fat percent loss: 0.1004
[2023-06-25 17:58:23,024] carb loss: 1.8533
[2023-06-25 17:58:23,024] carb percent loss: 0.0960
[2023-06-25 17:58:23,024] protein loss: 1.5473
[2023-06-25 17:58:23,024] protein percent loss: 0.0855
[2023-06-25 17:58:23,024] Epoch 133/150
[2023-06-25 17:58:50,647] test loss: 1.0750
[2023-06-25 17:58:50,647] cal loss: 46.9337
[2023-06-25 17:58:50,647] cal percent loss: 0.1841
[2023-06-25 17:58:50,647] mass loss: 24.4565
[2023-06-25 17:58:50,647] mass percent loss: 0.1122
[2023-06-25 17:58:50,647] fat loss: 3.5101
[2023-06-25 17:58:50,647] fat percent loss: 0.2764
[2023-06-25 17:58:50,648] carb loss: 5.1919
[2023-06-25 17:58:50,648] carb percent loss: 0.2690
[2023-06-25 17:58:50,648] protein loss: 4.4005
[2023-06-25 17:58:50,648] protein percent loss: 0.2431
[2023-06-25 17:58:50,648] Epoch 134/150
[2023-06-25 18:01:19,385] train loss: 0.4011
[2023-06-25 18:01:19,386] cal loss: 17.1850
[2023-06-25 18:01:19,386] cal percent loss: 0.0674
[2023-06-25 18:01:19,386] mass loss: 11.5790
[2023-06-25 18:01:19,386] mass percent loss: 0.0531
[2023-06-25 18:01:19,386] fat loss: 1.2802
[2023-06-25 18:01:19,386] fat percent loss: 0.1008
[2023-06-25 18:01:19,386] carb loss: 1.7949
[2023-06-25 18:01:19,386] carb percent loss: 0.0930
[2023-06-25 18:01:19,386] protein loss: 1.5398
[2023-06-25 18:01:19,386] protein percent loss: 0.0851
[2023-06-25 18:01:19,386] Epoch 134/150
[2023-06-25 18:01:44,300] test loss: 1.0564
[2023-06-25 18:01:44,300] cal loss: 45.7287
[2023-06-25 18:01:44,300] cal percent loss: 0.1793
[2023-06-25 18:01:44,300] mass loss: 25.2846
[2023-06-25 18:01:44,300] mass percent loss: 0.1160
[2023-06-25 18:01:44,301] fat loss: 3.4300
[2023-06-25 18:01:44,301] fat percent loss: 0.2701
[2023-06-25 18:01:44,301] carb loss: 4.9015
[2023-06-25 18:01:44,301] carb percent loss: 0.2540
[2023-06-25 18:01:44,301] protein loss: 4.4154
[2023-06-25 18:01:44,301] protein percent loss: 0.2439
[2023-06-25 18:01:44,301] Epoch 135/150
[2023-06-25 18:04:12,415] train loss: 0.4073
[2023-06-25 18:04:12,416] cal loss: 17.4558
[2023-06-25 18:04:12,416] cal percent loss: 0.0685
[2023-06-25 18:04:12,416] mass loss: 11.9616
[2023-06-25 18:04:12,416] mass percent loss: 0.0549
[2023-06-25 18:04:12,416] fat loss: 1.2774
[2023-06-25 18:04:12,416] fat percent loss: 0.1006
[2023-06-25 18:04:12,416] carb loss: 1.7987
[2023-06-25 18:04:12,416] carb percent loss: 0.0932
[2023-06-25 18:04:12,417] protein loss: 1.5938
[2023-06-25 18:04:12,417] protein percent loss: 0.0881
[2023-06-25 18:04:12,417] Epoch 135/150
[2023-06-25 18:04:37,685] test loss: 1.0515
[2023-06-25 18:04:37,685] cal loss: 45.8199
[2023-06-25 18:04:37,685] cal percent loss: 0.1797
[2023-06-25 18:04:37,685] mass loss: 24.1944
[2023-06-25 18:04:37,685] mass percent loss: 0.1110
[2023-06-25 18:04:37,685] fat loss: 3.4384
[2023-06-25 18:04:37,686] fat percent loss: 0.2707
[2023-06-25 18:04:37,686] carb loss: 4.9727
[2023-06-25 18:04:37,686] carb percent loss: 0.2577
[2023-06-25 18:04:37,686] protein loss: 4.3653
[2023-06-25 18:04:37,686] protein percent loss: 0.2412
[2023-06-25 18:04:37,686] Epoch 136/150
[2023-06-25 18:07:12,330] train loss: 0.4028
[2023-06-25 18:07:12,331] cal loss: 17.5735
[2023-06-25 18:07:12,331] cal percent loss: 0.0689
[2023-06-25 18:07:12,331] mass loss: 11.5486
[2023-06-25 18:07:12,331] mass percent loss: 0.0530
[2023-06-25 18:07:12,331] fat loss: 1.2695
[2023-06-25 18:07:12,331] fat percent loss: 0.1000
[2023-06-25 18:07:12,331] carb loss: 1.8241
[2023-06-25 18:07:12,331] carb percent loss: 0.0945
[2023-06-25 18:07:12,331] protein loss: 1.5324
[2023-06-25 18:07:12,331] protein percent loss: 0.0847
[2023-06-25 18:07:12,331] Epoch 136/150
[2023-06-25 18:07:38,574] test loss: 1.0648
[2023-06-25 18:07:38,574] cal loss: 46.8610
[2023-06-25 18:07:38,574] cal percent loss: 0.1838
[2023-06-25 18:07:38,575] mass loss: 23.5505
[2023-06-25 18:07:38,575] mass percent loss: 0.1080
[2023-06-25 18:07:38,575] fat loss: 3.4554
[2023-06-25 18:07:38,575] fat percent loss: 0.2721
[2023-06-25 18:07:38,575] carb loss: 5.1352
[2023-06-25 18:07:38,575] carb percent loss: 0.2661
[2023-06-25 18:07:38,575] protein loss: 4.4475
[2023-06-25 18:07:38,575] protein percent loss: 0.2457
[2023-06-25 18:07:38,575] Epoch 137/150
[2023-06-25 18:10:09,558] train loss: 0.4077
[2023-06-25 18:10:09,559] cal loss: 17.6627
[2023-06-25 18:10:09,559] cal percent loss: 0.0693
[2023-06-25 18:10:09,559] mass loss: 11.9724
[2023-06-25 18:10:09,559] mass percent loss: 0.0549
[2023-06-25 18:10:09,559] fat loss: 1.2947
[2023-06-25 18:10:09,559] fat percent loss: 0.1019
[2023-06-25 18:10:09,559] carb loss: 1.7930
[2023-06-25 18:10:09,559] carb percent loss: 0.0929
[2023-06-25 18:10:09,559] protein loss: 1.5614
[2023-06-25 18:10:09,559] protein percent loss: 0.0863
[2023-06-25 18:10:09,559] Epoch 137/150
[2023-06-25 18:10:35,384] test loss: 1.0619
[2023-06-25 18:10:35,385] cal loss: 46.2871
[2023-06-25 18:10:35,385] cal percent loss: 0.1815
[2023-06-25 18:10:35,385] mass loss: 24.7974
[2023-06-25 18:10:35,385] mass percent loss: 0.1137
[2023-06-25 18:10:35,385] fat loss: 3.4632
[2023-06-25 18:10:35,385] fat percent loss: 0.2727
[2023-06-25 18:10:35,385] carb loss: 4.9480
[2023-06-25 18:10:35,386] carb percent loss: 0.2564
[2023-06-25 18:10:35,386] protein loss: 4.4447
[2023-06-25 18:10:35,386] protein percent loss: 0.2456
[2023-06-25 18:10:35,386] Epoch 138/150
[2023-06-25 18:13:06,015] train loss: 0.4037
[2023-06-25 18:13:06,016] cal loss: 17.6887
[2023-06-25 18:13:06,016] cal percent loss: 0.0694
[2023-06-25 18:13:06,016] mass loss: 11.6185
[2023-06-25 18:13:06,016] mass percent loss: 0.0533
[2023-06-25 18:13:06,016] fat loss: 1.2712
[2023-06-25 18:13:06,016] fat percent loss: 0.1001
[2023-06-25 18:13:06,016] carb loss: 1.7963
[2023-06-25 18:13:06,016] carb percent loss: 0.0931
[2023-06-25 18:13:06,016] protein loss: 1.5556
[2023-06-25 18:13:06,016] protein percent loss: 0.0859
[2023-06-25 18:13:06,016] Epoch 138/150
[2023-06-25 18:13:32,452] test loss: 1.0522
[2023-06-25 18:13:32,452] cal loss: 44.4694
[2023-06-25 18:13:32,452] cal percent loss: 0.1744
[2023-06-25 18:13:32,453] mass loss: 25.1993
[2023-06-25 18:13:32,453] mass percent loss: 0.1156
[2023-06-25 18:13:32,453] fat loss: 3.3754
[2023-06-25 18:13:32,453] fat percent loss: 0.2658
[2023-06-25 18:13:32,453] carb loss: 4.9516
[2023-06-25 18:13:32,453] carb percent loss: 0.2566
[2023-06-25 18:13:32,453] protein loss: 4.4933
[2023-06-25 18:13:32,453] protein percent loss: 0.2483
[2023-06-25 18:13:32,453] Epoch 139/150
[2023-06-25 18:16:04,317] train loss: 0.3972
[2023-06-25 18:16:04,318] cal loss: 16.9874
[2023-06-25 18:16:04,318] cal percent loss: 0.0666
[2023-06-25 18:16:04,318] mass loss: 11.7380
[2023-06-25 18:16:04,318] mass percent loss: 0.0538
[2023-06-25 18:16:04,318] fat loss: 1.2505
[2023-06-25 18:16:04,319] fat percent loss: 0.0985
[2023-06-25 18:16:04,319] carb loss: 1.7537
[2023-06-25 18:16:04,319] carb percent loss: 0.0909
[2023-06-25 18:16:04,319] protein loss: 1.5416
[2023-06-25 18:16:04,319] protein percent loss: 0.0852
[2023-06-25 18:16:04,319] Epoch 139/150
[2023-06-25 18:16:30,123] test loss: 1.0289
[2023-06-25 18:16:30,123] cal loss: 43.7938
[2023-06-25 18:16:30,123] cal percent loss: 0.1717
[2023-06-25 18:16:30,123] mass loss: 24.3831
[2023-06-25 18:16:30,123] mass percent loss: 0.1118
[2023-06-25 18:16:30,123] fat loss: 3.4068
[2023-06-25 18:16:30,123] fat percent loss: 0.2683
[2023-06-25 18:16:30,123] carb loss: 4.8918
[2023-06-25 18:16:30,124] carb percent loss: 0.2535
[2023-06-25 18:16:30,124] protein loss: 4.1934
[2023-06-25 18:16:30,124] protein percent loss: 0.2317
[2023-06-25 18:16:30,124] Epoch 140/150
[2023-06-25 18:19:01,095] train loss: 0.3991
[2023-06-25 18:19:01,096] cal loss: 16.9779
[2023-06-25 18:19:01,096] cal percent loss: 0.0666
[2023-06-25 18:19:01,096] mass loss: 11.4284
[2023-06-25 18:19:01,096] mass percent loss: 0.0524
[2023-06-25 18:19:01,096] fat loss: 1.2992
[2023-06-25 18:19:01,096] fat percent loss: 0.1023
[2023-06-25 18:19:01,097] carb loss: 1.7659
[2023-06-25 18:19:01,097] carb percent loss: 0.0915
[2023-06-25 18:19:01,097] protein loss: 1.5366
[2023-06-25 18:19:01,097] protein percent loss: 0.0849
[2023-06-25 18:19:01,097] Epoch 140/150
[2023-06-25 18:19:23,681] test loss: 1.0595
[2023-06-25 18:19:23,682] cal loss: 46.4963
[2023-06-25 18:19:23,682] cal percent loss: 0.1823
[2023-06-25 18:19:23,682] mass loss: 24.5980
[2023-06-25 18:19:23,682] mass percent loss: 0.1128
[2023-06-25 18:19:23,682] fat loss: 3.4396
[2023-06-25 18:19:23,682] fat percent loss: 0.2708
[2023-06-25 18:19:23,682] carb loss: 5.0170
[2023-06-25 18:19:23,682] carb percent loss: 0.2600
[2023-06-25 18:19:23,682] protein loss: 4.3731
[2023-06-25 18:19:23,683] protein percent loss: 0.2416
[2023-06-25 18:19:23,683] Epoch 141/150
[2023-06-25 18:21:54,775] train loss: 0.3967
[2023-06-25 18:21:54,776] cal loss: 17.0060
[2023-06-25 18:21:54,776] cal percent loss: 0.0667
[2023-06-25 18:21:54,776] mass loss: 11.5239
[2023-06-25 18:21:54,776] mass percent loss: 0.0529
[2023-06-25 18:21:54,776] fat loss: 1.2396
[2023-06-25 18:21:54,776] fat percent loss: 0.0976
[2023-06-25 18:21:54,776] carb loss: 1.7885
[2023-06-25 18:21:54,777] carb percent loss: 0.0927
[2023-06-25 18:21:54,777] protein loss: 1.5422
[2023-06-25 18:21:54,777] protein percent loss: 0.0852
[2023-06-25 18:21:54,777] Epoch 141/150
[2023-06-25 18:22:20,213] test loss: 1.0720
[2023-06-25 18:22:20,214] cal loss: 46.0514
[2023-06-25 18:22:20,214] cal percent loss: 0.1806
[2023-06-25 18:22:20,214] mass loss: 25.2197
[2023-06-25 18:22:20,214] mass percent loss: 0.1157
[2023-06-25 18:22:20,214] fat loss: 3.4728
[2023-06-25 18:22:20,214] fat percent loss: 0.2735
[2023-06-25 18:22:20,214] carb loss: 5.1175
[2023-06-25 18:22:20,214] carb percent loss: 0.2652
[2023-06-25 18:22:20,214] protein loss: 4.4493
[2023-06-25 18:22:20,214] protein percent loss: 0.2458
[2023-06-25 18:22:20,214] Epoch 142/150
[2023-06-25 18:24:53,641] train loss: 0.3959
[2023-06-25 18:24:53,642] cal loss: 17.0613
[2023-06-25 18:24:53,642] cal percent loss: 0.0669
[2023-06-25 18:24:53,642] mass loss: 11.7066
[2023-06-25 18:24:53,642] mass percent loss: 0.0537
[2023-06-25 18:24:53,642] fat loss: 1.2445
[2023-06-25 18:24:53,642] fat percent loss: 0.0980
[2023-06-25 18:24:53,642] carb loss: 1.7821
[2023-06-25 18:24:53,642] carb percent loss: 0.0923
[2023-06-25 18:24:53,642] protein loss: 1.4964
[2023-06-25 18:24:53,642] protein percent loss: 0.0827
[2023-06-25 18:24:53,642] Epoch 142/150
[2023-06-25 18:25:21,940] test loss: 1.0690
[2023-06-25 18:25:21,940] cal loss: 46.0760
[2023-06-25 18:25:21,940] cal percent loss: 0.1807
[2023-06-25 18:25:21,940] mass loss: 25.4919
[2023-06-25 18:25:21,941] mass percent loss: 0.1169
[2023-06-25 18:25:21,941] fat loss: 3.4114
[2023-06-25 18:25:21,941] fat percent loss: 0.2686
[2023-06-25 18:25:21,941] carb loss: 5.1424
[2023-06-25 18:25:21,941] carb percent loss: 0.2664
[2023-06-25 18:25:21,941] protein loss: 4.4223
[2023-06-25 18:25:21,941] protein percent loss: 0.2443
[2023-06-25 18:25:21,941] Epoch 143/150
[2023-06-25 18:27:57,913] train loss: 0.3978
[2023-06-25 18:27:57,913] cal loss: 16.9154
[2023-06-25 18:27:57,913] cal percent loss: 0.0663
[2023-06-25 18:27:57,913] mass loss: 11.5943
[2023-06-25 18:27:57,913] mass percent loss: 0.0532
[2023-06-25 18:27:57,913] fat loss: 1.2567
[2023-06-25 18:27:57,914] fat percent loss: 0.0990
[2023-06-25 18:27:57,914] carb loss: 1.8170
[2023-06-25 18:27:57,914] carb percent loss: 0.0941
[2023-06-25 18:27:57,914] protein loss: 1.5128
[2023-06-25 18:27:57,914] protein percent loss: 0.0836
[2023-06-25 18:27:57,914] Epoch 143/150
[2023-06-25 18:28:23,119] test loss: 1.0453
[2023-06-25 18:28:23,119] cal loss: 44.8833
[2023-06-25 18:28:23,119] cal percent loss: 0.1760
[2023-06-25 18:28:23,119] mass loss: 23.7620
[2023-06-25 18:28:23,119] mass percent loss: 0.1090
[2023-06-25 18:28:23,119] fat loss: 3.4299
[2023-06-25 18:28:23,119] fat percent loss: 0.2701
[2023-06-25 18:28:23,119] carb loss: 5.0406
[2023-06-25 18:28:23,119] carb percent loss: 0.2612
[2023-06-25 18:28:23,119] protein loss: 4.3320
[2023-06-25 18:28:23,119] protein percent loss: 0.2393
[2023-06-25 18:28:23,119] Epoch 144/150
[2023-06-25 18:30:57,481] train loss: 0.3989
[2023-06-25 18:30:57,482] cal loss: 16.9246
[2023-06-25 18:30:57,482] cal percent loss: 0.0664
[2023-06-25 18:30:57,482] mass loss: 11.5925
[2023-06-25 18:30:57,482] mass percent loss: 0.0532
[2023-06-25 18:30:57,482] fat loss: 1.2808
[2023-06-25 18:30:57,482] fat percent loss: 0.1008
[2023-06-25 18:30:57,482] carb loss: 1.8047
[2023-06-25 18:30:57,482] carb percent loss: 0.0935
[2023-06-25 18:30:57,482] protein loss: 1.5097
[2023-06-25 18:30:57,482] protein percent loss: 0.0834
[2023-06-25 18:30:57,483] Epoch 144/150
[2023-06-25 18:31:18,836] test loss: 1.0511
[2023-06-25 18:31:18,837] cal loss: 44.9393
[2023-06-25 18:31:18,837] cal percent loss: 0.1762
[2023-06-25 18:31:18,837] mass loss: 24.6741
[2023-06-25 18:31:18,837] mass percent loss: 0.1132
[2023-06-25 18:31:18,837] fat loss: 3.3378
[2023-06-25 18:31:18,837] fat percent loss: 0.2628
[2023-06-25 18:31:18,837] carb loss: 5.2263
[2023-06-25 18:31:18,837] carb percent loss: 0.2708
[2023-06-25 18:31:18,837] protein loss: 4.3005
[2023-06-25 18:31:18,837] protein percent loss: 0.2376
[2023-06-25 18:31:18,837] Epoch 145/150
[2023-06-25 18:33:48,487] train loss: 0.3999
[2023-06-25 18:33:48,488] cal loss: 17.3296
[2023-06-25 18:33:48,488] cal percent loss: 0.0680
[2023-06-25 18:33:48,488] mass loss: 11.5513
[2023-06-25 18:33:48,488] mass percent loss: 0.0530
[2023-06-25 18:33:48,488] fat loss: 1.3084
[2023-06-25 18:33:48,488] fat percent loss: 0.1030
[2023-06-25 18:33:48,488] carb loss: 1.7337
[2023-06-25 18:33:48,488] carb percent loss: 0.0898
[2023-06-25 18:33:48,488] protein loss: 1.5204
[2023-06-25 18:33:48,488] protein percent loss: 0.0840
[2023-06-25 18:33:48,488] Epoch 145/150
[2023-06-25 18:34:12,830] test loss: 1.0670
[2023-06-25 18:34:12,831] cal loss: 46.0915
[2023-06-25 18:34:12,831] cal percent loss: 0.1808
[2023-06-25 18:34:12,831] mass loss: 24.6513
[2023-06-25 18:34:12,831] mass percent loss: 0.1131
[2023-06-25 18:34:12,831] fat loss: 3.4273
[2023-06-25 18:34:12,831] fat percent loss: 0.2699
[2023-06-25 18:34:12,831] carb loss: 5.2092
[2023-06-25 18:34:12,831] carb percent loss: 0.2699
[2023-06-25 18:34:12,832] protein loss: 4.4011
[2023-06-25 18:34:12,832] protein percent loss: 0.2432
[2023-06-25 18:34:12,832] Epoch 146/150
[2023-06-25 18:36:52,737] train loss: 0.3946
[2023-06-25 18:36:52,737] cal loss: 16.8772
[2023-06-25 18:36:52,738] cal percent loss: 0.0662
[2023-06-25 18:36:52,738] mass loss: 11.5999
[2023-06-25 18:36:52,738] mass percent loss: 0.0532
[2023-06-25 18:36:52,738] fat loss: 1.2330
[2023-06-25 18:36:52,738] fat percent loss: 0.0971
[2023-06-25 18:36:52,738] carb loss: 1.7627
[2023-06-25 18:36:52,738] carb percent loss: 0.0913
[2023-06-25 18:36:52,738] protein loss: 1.5364
[2023-06-25 18:36:52,738] protein percent loss: 0.0849
[2023-06-25 18:36:52,738] Epoch 146/150
[2023-06-25 18:37:16,853] test loss: 1.0888
[2023-06-25 18:37:16,854] cal loss: 48.1910
[2023-06-25 18:37:16,854] cal percent loss: 0.1890
[2023-06-25 18:37:16,854] mass loss: 25.5699
[2023-06-25 18:37:16,854] mass percent loss: 0.1173
[2023-06-25 18:37:16,854] fat loss: 3.5027
[2023-06-25 18:37:16,854] fat percent loss: 0.2758
[2023-06-25 18:37:16,854] carb loss: 5.1266
[2023-06-25 18:37:16,854] carb percent loss: 0.2656
[2023-06-25 18:37:16,854] protein loss: 4.4960
[2023-06-25 18:37:16,854] protein percent loss: 0.2484
[2023-06-25 18:37:16,855] Epoch 147/150
[2023-06-25 18:39:47,852] train loss: 0.3961
[2023-06-25 18:39:47,853] cal loss: 17.0609
[2023-06-25 18:39:47,853] cal percent loss: 0.0669
[2023-06-25 18:39:47,853] mass loss: 11.6939
[2023-06-25 18:39:47,853] mass percent loss: 0.0536
[2023-06-25 18:39:47,853] fat loss: 1.2645
[2023-06-25 18:39:47,853] fat percent loss: 0.0996
[2023-06-25 18:39:47,853] carb loss: 1.7651
[2023-06-25 18:39:47,853] carb percent loss: 0.0915
[2023-06-25 18:39:47,854] protein loss: 1.4884
[2023-06-25 18:39:47,854] protein percent loss: 0.0822
[2023-06-25 18:39:47,854] Epoch 147/150
[2023-06-25 18:40:13,947] test loss: 1.0667
[2023-06-25 18:40:13,947] cal loss: 45.5456
[2023-06-25 18:40:13,947] cal percent loss: 0.1786
[2023-06-25 18:40:13,947] mass loss: 24.8568
[2023-06-25 18:40:13,947] mass percent loss: 0.1140
[2023-06-25 18:40:13,947] fat loss: 3.4918
[2023-06-25 18:40:13,948] fat percent loss: 0.2749
[2023-06-25 18:40:13,948] carb loss: 5.1264
[2023-06-25 18:40:13,948] carb percent loss: 0.2656
[2023-06-25 18:40:13,948] protein loss: 4.3971
[2023-06-25 18:40:13,948] protein percent loss: 0.2429
[2023-06-25 18:40:13,948] Epoch 148/150
[2023-06-25 18:42:51,674] train loss: 0.3971
[2023-06-25 18:42:51,674] cal loss: 16.9267
[2023-06-25 18:42:51,675] cal percent loss: 0.0664
[2023-06-25 18:42:51,675] mass loss: 11.6711
[2023-06-25 18:42:51,675] mass percent loss: 0.0535
[2023-06-25 18:42:51,675] fat loss: 1.2507
[2023-06-25 18:42:51,675] fat percent loss: 0.0985
[2023-06-25 18:42:51,675] carb loss: 1.8053
[2023-06-25 18:42:51,675] carb percent loss: 0.0935
[2023-06-25 18:42:51,675] protein loss: 1.5068
[2023-06-25 18:42:51,675] protein percent loss: 0.0833
[2023-06-25 18:42:51,675] Epoch 148/150
[2023-06-25 18:43:19,940] test loss: 1.0583
[2023-06-25 18:43:19,941] cal loss: 46.5783
[2023-06-25 18:43:19,941] cal percent loss: 0.1827
[2023-06-25 18:43:19,941] mass loss: 24.6474
[2023-06-25 18:43:19,941] mass percent loss: 0.1131
[2023-06-25 18:43:19,941] fat loss: 3.4646
[2023-06-25 18:43:19,941] fat percent loss: 0.2728
[2023-06-25 18:43:19,941] carb loss: 4.9520
[2023-06-25 18:43:19,941] carb percent loss: 0.2566
[2023-06-25 18:43:19,941] protein loss: 4.3566
[2023-06-25 18:43:19,941] protein percent loss: 0.2407
[2023-06-25 18:43:19,941] Epoch 149/150
[2023-06-25 18:45:52,978] train loss: 0.3932
[2023-06-25 18:45:52,979] cal loss: 16.1609
[2023-06-25 18:45:52,979] cal percent loss: 0.0634
[2023-06-25 18:45:52,979] mass loss: 11.8020
[2023-06-25 18:45:52,979] mass percent loss: 0.0541
[2023-06-25 18:45:52,979] fat loss: 1.2277
[2023-06-25 18:45:52,979] fat percent loss: 0.0967
[2023-06-25 18:45:52,979] carb loss: 1.7736
[2023-06-25 18:45:52,979] carb percent loss: 0.0919
[2023-06-25 18:45:52,979] protein loss: 1.5464
[2023-06-25 18:45:52,979] protein percent loss: 0.0854
[2023-06-25 18:45:52,979] Epoch 149/150
[2023-06-25 18:46:19,541] test loss: 1.0451
[2023-06-25 18:46:19,542] cal loss: 44.8274
[2023-06-25 18:46:19,542] cal percent loss: 0.1758
[2023-06-25 18:46:19,542] mass loss: 24.2668
[2023-06-25 18:46:19,542] mass percent loss: 0.1113
[2023-06-25 18:46:19,542] fat loss: 3.4588
[2023-06-25 18:46:19,542] fat percent loss: 0.2724
[2023-06-25 18:46:19,542] carb loss: 4.9623
[2023-06-25 18:46:19,542] carb percent loss: 0.2571
[2023-06-25 18:46:19,542] protein loss: 4.2976
[2023-06-25 18:46:19,542] protein percent loss: 0.2374
[2023-06-25 18:46:19,542] Epoch 150/150
[2023-06-25 18:48:55,427] train loss: 0.3998
[2023-06-25 18:48:55,428] cal loss: 16.9620
[2023-06-25 18:48:55,428] cal percent loss: 0.0665
[2023-06-25 18:48:55,428] mass loss: 11.3578
[2023-06-25 18:48:55,428] mass percent loss: 0.0521
[2023-06-25 18:48:55,428] fat loss: 1.2664
[2023-06-25 18:48:55,428] fat percent loss: 0.0997
[2023-06-25 18:48:55,428] carb loss: 1.8337
[2023-06-25 18:48:55,428] carb percent loss: 0.0950
[2023-06-25 18:48:55,429] protein loss: 1.5485
[2023-06-25 18:48:55,429] protein percent loss: 0.0856
[2023-06-25 18:48:55,429] Epoch 150/150
[2023-06-25 18:49:21,826] test loss: 1.0584
[2023-06-25 18:49:21,827] cal loss: 46.1043
[2023-06-25 18:49:21,827] cal percent loss: 0.1808
[2023-06-25 18:49:21,827] mass loss: 25.5383
[2023-06-25 18:49:21,827] mass percent loss: 0.1171
[2023-06-25 18:49:21,827] fat loss: 3.4233
[2023-06-25 18:49:21,827] fat percent loss: 0.2695
[2023-06-25 18:49:21,827] carb loss: 5.0127
[2023-06-25 18:49:21,828] carb percent loss: 0.2597
[2023-06-25 18:49:21,828] protein loss: 4.3004
[2023-06-25 18:49:21,828] protein percent loss: 0.2376
