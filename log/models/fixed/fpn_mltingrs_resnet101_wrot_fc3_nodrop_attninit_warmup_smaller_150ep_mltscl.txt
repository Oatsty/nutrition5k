[2023-06-24 11:05:30,446] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  NAME: resnet101-ingrs
  PRETRAINED: microsoft/resnet-101
SAVE_PATH: models/fixed/fpn_mltingrs_resnet101_wrot_fc3_nodrop_attninit_warmup_smaller_150ep_mltscl.pt
TITLE:
- fpn multi ingrs with aug+rot fc 3 no dropout smaller new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi_ingrs
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.001

[2023-06-24 11:05:35,456] Epoch 1/150
[2023-06-24 11:07:33,122] train loss: 4.8569
[2023-06-24 11:07:33,122] cal loss: 171.5223
[2023-06-24 11:07:33,122] cal percent loss: 0.6726
[2023-06-24 11:07:33,123] mass loss: 137.4519
[2023-06-24 11:07:33,123] mass percent loss: 0.6305
[2023-06-24 11:07:33,123] fat loss: 10.2288
[2023-06-24 11:07:33,123] fat percent loss: 0.8054
[2023-06-24 11:07:33,123] carb loss: 13.8030
[2023-06-24 11:07:33,123] carb percent loss: 0.7152
[2023-06-24 11:07:33,123] protein loss: 14.9608
[2023-06-24 11:07:33,123] protein percent loss: 0.8266
[2023-06-24 11:07:33,124] ingrs percent loss: 1.1145
[2023-06-24 11:07:33,124] Epoch 1/150
[2023-06-24 11:07:42,677] test loss: 4.9623
[2023-06-24 11:07:42,678] cal loss: 171.9628
[2023-06-24 11:07:42,678] cal percent loss: 0.6744
[2023-06-24 11:07:42,678] mass loss: 141.8755
[2023-06-24 11:07:42,678] mass percent loss: 0.6508
[2023-06-24 11:07:42,678] fat loss: 10.7123
[2023-06-24 11:07:42,678] fat percent loss: 0.8435
[2023-06-24 11:07:42,679] carb loss: 15.0487
[2023-06-24 11:07:42,679] carb percent loss: 0.7797
[2023-06-24 11:07:42,679] protein loss: 14.6279
[2023-06-24 11:07:42,679] protein percent loss: 0.8082
[2023-06-24 11:07:42,679] ingrs percent loss: 1.1154
[2023-06-24 11:07:42,679] Epoch 2/150
[2023-06-24 11:09:43,235] train loss: 4.2807
[2023-06-24 11:09:43,236] cal loss: 161.6880
[2023-06-24 11:09:43,236] cal percent loss: 0.6341
[2023-06-24 11:09:43,237] mass loss: 119.6082
[2023-06-24 11:09:43,237] mass percent loss: 0.5487
[2023-06-24 11:09:43,237] fat loss: 9.9120
[2023-06-24 11:09:43,237] fat percent loss: 0.7805
[2023-06-24 11:09:43,237] carb loss: 12.4179
[2023-06-24 11:09:43,237] carb percent loss: 0.6434
[2023-06-24 11:09:43,237] protein loss: 14.2719
[2023-06-24 11:09:43,237] protein percent loss: 0.7885
[2023-06-24 11:09:43,237] ingrs percent loss: 0.8122
[2023-06-24 11:09:43,237] Epoch 2/150
[2023-06-24 11:09:51,858] test loss: 3.9846
[2023-06-24 11:09:51,859] cal loss: 153.7260
[2023-06-24 11:09:51,859] cal percent loss: 0.6028
[2023-06-24 11:09:51,859] mass loss: 100.1155
[2023-06-24 11:09:51,860] mass percent loss: 0.4592
[2023-06-24 11:09:51,860] fat loss: 9.6197
[2023-06-24 11:09:51,860] fat percent loss: 0.7575
[2023-06-24 11:09:51,860] carb loss: 12.6978
[2023-06-24 11:09:51,860] carb percent loss: 0.6579
[2023-06-24 11:09:51,860] protein loss: 13.3269
[2023-06-24 11:09:51,860] protein percent loss: 0.7363
[2023-06-24 11:09:51,860] ingrs percent loss: 0.7277
[2023-06-24 11:09:51,860] Epoch 3/150
[2023-06-24 11:11:52,340] train loss: 3.9155
[2023-06-24 11:11:52,341] cal loss: 148.6570
[2023-06-24 11:11:52,341] cal percent loss: 0.5830
[2023-06-24 11:11:52,341] mass loss: 106.5223
[2023-06-24 11:11:52,341] mass percent loss: 0.4886
[2023-06-24 11:11:52,342] fat loss: 9.1649
[2023-06-24 11:11:52,342] fat percent loss: 0.7216
[2023-06-24 11:11:52,342] carb loss: 11.9028
[2023-06-24 11:11:52,342] carb percent loss: 0.6167
[2023-06-24 11:11:52,342] protein loss: 13.4617
[2023-06-24 11:11:52,342] protein percent loss: 0.7437
[2023-06-24 11:11:52,342] ingrs percent loss: 0.7052
[2023-06-24 11:11:52,342] Epoch 3/150
[2023-06-24 11:12:01,569] test loss: 3.9529
[2023-06-24 11:12:01,570] cal loss: 147.4066
[2023-06-24 11:12:01,570] cal percent loss: 0.5781
[2023-06-24 11:12:01,570] mass loss: 84.9519
[2023-06-24 11:12:01,570] mass percent loss: 0.3897
[2023-06-24 11:12:01,570] fat loss: 9.7948
[2023-06-24 11:12:01,571] fat percent loss: 0.7712
[2023-06-24 11:12:01,571] carb loss: 12.3998
[2023-06-24 11:12:01,571] carb percent loss: 0.6425
[2023-06-24 11:12:01,571] protein loss: 15.6124
[2023-06-24 11:12:01,571] protein percent loss: 0.8626
[2023-06-24 11:12:01,571] ingrs percent loss: 0.7049
[2023-06-24 11:12:01,571] Epoch 4/150
[2023-06-24 11:14:01,865] train loss: 3.5661
[2023-06-24 11:14:01,866] cal loss: 131.5164
[2023-06-24 11:14:01,867] cal percent loss: 0.5158
[2023-06-24 11:14:01,867] mass loss: 84.9297
[2023-06-24 11:14:01,867] mass percent loss: 0.3896
[2023-06-24 11:14:01,867] fat loss: 8.5544
[2023-06-24 11:14:01,867] fat percent loss: 0.6736
[2023-06-24 11:14:01,867] carb loss: 11.1111
[2023-06-24 11:14:01,867] carb percent loss: 0.5757
[2023-06-24 11:14:01,867] protein loss: 12.5365
[2023-06-24 11:14:01,867] protein percent loss: 0.6926
[2023-06-24 11:14:01,868] ingrs percent loss: 0.6927
[2023-06-24 11:14:01,868] Epoch 4/150
[2023-06-24 11:14:12,093] test loss: 3.4914
[2023-06-24 11:14:12,093] cal loss: 123.5768
[2023-06-24 11:14:12,094] cal percent loss: 0.4846
[2023-06-24 11:14:12,094] mass loss: 70.6351
[2023-06-24 11:14:12,094] mass percent loss: 0.3240
[2023-06-24 11:14:12,094] fat loss: 8.5523
[2023-06-24 11:14:12,094] fat percent loss: 0.6734
[2023-06-24 11:14:12,094] carb loss: 13.0727
[2023-06-24 11:14:12,094] carb percent loss: 0.6773
[2023-06-24 11:14:12,094] protein loss: 11.6831
[2023-06-24 11:14:12,094] protein percent loss: 0.6455
[2023-06-24 11:14:12,094] ingrs percent loss: 0.6961
[2023-06-24 11:14:12,095] Epoch 5/150
[2023-06-24 11:16:11,567] train loss: 3.0901
[2023-06-24 11:16:11,568] cal loss: 106.2272
[2023-06-24 11:16:11,568] cal percent loss: 0.4166
[2023-06-24 11:16:11,568] mass loss: 68.9732
[2023-06-24 11:16:11,568] mass percent loss: 0.3164
[2023-06-24 11:16:11,568] fat loss: 7.5160
[2023-06-24 11:16:11,568] fat percent loss: 0.5918
[2023-06-24 11:16:11,568] carb loss: 10.3109
[2023-06-24 11:16:11,568] carb percent loss: 0.5342
[2023-06-24 11:16:11,569] protein loss: 9.8802
[2023-06-24 11:16:11,569] protein percent loss: 0.5459
[2023-06-24 11:16:11,569] ingrs percent loss: 0.6739
[2023-06-24 11:16:11,569] Epoch 5/150
[2023-06-24 11:16:21,747] test loss: 3.2677
[2023-06-24 11:16:21,748] cal loss: 117.8453
[2023-06-24 11:16:21,748] cal percent loss: 0.4621
[2023-06-24 11:16:21,748] mass loss: 68.0837
[2023-06-24 11:16:21,748] mass percent loss: 0.3123
[2023-06-24 11:16:21,749] fat loss: 8.4627
[2023-06-24 11:16:21,749] fat percent loss: 0.6664
[2023-06-24 11:16:21,749] carb loss: 10.6900
[2023-06-24 11:16:21,749] carb percent loss: 0.5539
[2023-06-24 11:16:21,749] protein loss: 10.7167
[2023-06-24 11:16:21,749] protein percent loss: 0.5921
[2023-06-24 11:16:21,749] ingrs percent loss: 0.6754
[2023-06-24 11:16:21,750] Epoch 6/150
[2023-06-24 11:18:17,208] train loss: 2.9416
[2023-06-24 11:18:17,209] cal loss: 98.5222
[2023-06-24 11:18:17,209] cal percent loss: 0.3864
[2023-06-24 11:18:17,209] mass loss: 66.3660
[2023-06-24 11:18:17,209] mass percent loss: 0.3044
[2023-06-24 11:18:17,209] fat loss: 7.1474
[2023-06-24 11:18:17,209] fat percent loss: 0.5628
[2023-06-24 11:18:17,209] carb loss: 10.0812
[2023-06-24 11:18:17,210] carb percent loss: 0.5223
[2023-06-24 11:18:17,210] protein loss: 9.0784
[2023-06-24 11:18:17,210] protein percent loss: 0.5016
[2023-06-24 11:18:17,210] ingrs percent loss: 0.6538
[2023-06-24 11:18:17,210] Epoch 6/150
[2023-06-24 11:18:26,086] test loss: 2.9408
[2023-06-24 11:18:26,087] cal loss: 82.5604
[2023-06-24 11:18:26,087] cal percent loss: 0.3238
[2023-06-24 11:18:26,087] mass loss: 70.7216
[2023-06-24 11:18:26,087] mass percent loss: 0.3244
[2023-06-24 11:18:26,087] fat loss: 7.3044
[2023-06-24 11:18:26,087] fat percent loss: 0.5751
[2023-06-24 11:18:26,087] carb loss: 10.1553
[2023-06-24 11:18:26,087] carb percent loss: 0.5262
[2023-06-24 11:18:26,087] protein loss: 9.6529
[2023-06-24 11:18:26,087] protein percent loss: 0.5333
[2023-06-24 11:18:26,087] ingrs percent loss: 0.6550
[2023-06-24 11:18:26,087] Epoch 7/150
[2023-06-24 11:20:23,275] train loss: 2.8523
[2023-06-24 11:20:23,275] cal loss: 94.8455
[2023-06-24 11:20:23,276] cal percent loss: 0.3719
[2023-06-24 11:20:23,276] mass loss: 66.5061
[2023-06-24 11:20:23,276] mass percent loss: 0.3051
[2023-06-24 11:20:23,276] fat loss: 6.9899
[2023-06-24 11:20:23,276] fat percent loss: 0.5504
[2023-06-24 11:20:23,276] carb loss: 9.7962
[2023-06-24 11:20:23,276] carb percent loss: 0.5076
[2023-06-24 11:20:23,276] protein loss: 8.5275
[2023-06-24 11:20:23,276] protein percent loss: 0.4711
[2023-06-24 11:20:23,276] ingrs percent loss: 0.6321
[2023-06-24 11:20:23,277] Epoch 7/150
[2023-06-24 11:20:32,395] test loss: 2.7476
[2023-06-24 11:20:32,395] cal loss: 82.5344
[2023-06-24 11:20:32,395] cal percent loss: 0.3237
[2023-06-24 11:20:32,395] mass loss: 54.0751
[2023-06-24 11:20:32,395] mass percent loss: 0.2481
[2023-06-24 11:20:32,396] fat loss: 7.4731
[2023-06-24 11:20:32,396] fat percent loss: 0.5884
[2023-06-24 11:20:32,396] carb loss: 9.6748
[2023-06-24 11:20:32,396] carb percent loss: 0.5013
[2023-06-24 11:20:32,396] protein loss: 8.5529
[2023-06-24 11:20:32,396] protein percent loss: 0.4725
[2023-06-24 11:20:32,396] ingrs percent loss: 0.6274
[2023-06-24 11:20:32,396] Epoch 8/150
[2023-06-24 11:22:35,324] train loss: 2.7181
[2023-06-24 11:22:35,325] cal loss: 88.9035
[2023-06-24 11:22:35,325] cal percent loss: 0.3486
[2023-06-24 11:22:35,325] mass loss: 61.4512
[2023-06-24 11:22:35,325] mass percent loss: 0.2819
[2023-06-24 11:22:35,326] fat loss: 6.6632
[2023-06-24 11:22:35,326] fat percent loss: 0.5247
[2023-06-24 11:22:35,326] carb loss: 9.3187
[2023-06-24 11:22:35,326] carb percent loss: 0.4828
[2023-06-24 11:22:35,326] protein loss: 8.4311
[2023-06-24 11:22:35,326] protein percent loss: 0.4658
[2023-06-24 11:22:35,326] ingrs percent loss: 0.6063
[2023-06-24 11:22:35,326] Epoch 8/150
[2023-06-24 11:22:44,339] test loss: 2.8407
[2023-06-24 11:22:44,339] cal loss: 96.6112
[2023-06-24 11:22:44,339] cal percent loss: 0.3789
[2023-06-24 11:22:44,340] mass loss: 57.3924
[2023-06-24 11:22:44,340] mass percent loss: 0.2633
[2023-06-24 11:22:44,340] fat loss: 8.0133
[2023-06-24 11:22:44,340] fat percent loss: 0.6310
[2023-06-24 11:22:44,340] carb loss: 9.0648
[2023-06-24 11:22:44,340] carb percent loss: 0.4697
[2023-06-24 11:22:44,340] protein loss: 9.0668
[2023-06-24 11:22:44,340] protein percent loss: 0.5009
[2023-06-24 11:22:44,340] ingrs percent loss: 0.5981
[2023-06-24 11:22:44,341] Epoch 9/150
[2023-06-24 11:24:41,372] train loss: 2.5527
[2023-06-24 11:24:41,372] cal loss: 82.0046
[2023-06-24 11:24:41,372] cal percent loss: 0.3216
[2023-06-24 11:24:41,373] mass loss: 56.0928
[2023-06-24 11:24:41,373] mass percent loss: 0.2573
[2023-06-24 11:24:41,373] fat loss: 6.4053
[2023-06-24 11:24:41,373] fat percent loss: 0.5044
[2023-06-24 11:24:41,373] carb loss: 8.8561
[2023-06-24 11:24:41,373] carb percent loss: 0.4589
[2023-06-24 11:24:41,373] protein loss: 7.8709
[2023-06-24 11:24:41,373] protein percent loss: 0.4349
[2023-06-24 11:24:41,373] ingrs percent loss: 0.5727
[2023-06-24 11:24:41,373] Epoch 9/150
[2023-06-24 11:24:50,906] test loss: 2.7061
[2023-06-24 11:24:50,907] cal loss: 82.4689
[2023-06-24 11:24:50,907] cal percent loss: 0.3234
[2023-06-24 11:24:50,907] mass loss: 67.4827
[2023-06-24 11:24:50,908] mass percent loss: 0.3096
[2023-06-24 11:24:50,908] fat loss: 6.8716
[2023-06-24 11:24:50,908] fat percent loss: 0.5411
[2023-06-24 11:24:50,908] carb loss: 8.1641
[2023-06-24 11:24:50,908] carb percent loss: 0.4230
[2023-06-24 11:24:50,908] protein loss: 9.5507
[2023-06-24 11:24:50,908] protein percent loss: 0.5277
[2023-06-24 11:24:50,908] ingrs percent loss: 0.5672
[2023-06-24 11:24:50,909] Epoch 10/150
[2023-06-24 11:26:51,612] train loss: 2.3733
[2023-06-24 11:26:51,613] cal loss: 76.6168
[2023-06-24 11:26:51,613] cal percent loss: 0.3005
[2023-06-24 11:26:51,613] mass loss: 54.6040
[2023-06-24 11:26:51,613] mass percent loss: 0.2505
[2023-06-24 11:26:51,613] fat loss: 5.8994
[2023-06-24 11:26:51,613] fat percent loss: 0.4645
[2023-06-24 11:26:51,613] carb loss: 8.0340
[2023-06-24 11:26:51,613] carb percent loss: 0.4163
[2023-06-24 11:26:51,613] protein loss: 7.2079
[2023-06-24 11:26:51,613] protein percent loss: 0.3982
[2023-06-24 11:26:51,613] ingrs percent loss: 0.5342
[2023-06-24 11:26:51,613] Epoch 10/150
[2023-06-24 11:27:00,875] test loss: 2.4124
[2023-06-24 11:27:00,876] cal loss: 66.9666
[2023-06-24 11:27:00,876] cal percent loss: 0.2626
[2023-06-24 11:27:00,877] mass loss: 71.3725
[2023-06-24 11:27:00,877] mass percent loss: 0.3274
[2023-06-24 11:27:00,877] fat loss: 5.9196
[2023-06-24 11:27:00,877] fat percent loss: 0.4661
[2023-06-24 11:27:00,877] carb loss: 8.3918
[2023-06-24 11:27:00,877] carb percent loss: 0.4348
[2023-06-24 11:27:00,877] protein loss: 6.3736
[2023-06-24 11:27:00,877] protein percent loss: 0.3521
[2023-06-24 11:27:00,877] ingrs percent loss: 0.5379
[2023-06-24 11:27:00,878] Epoch 11/150
[2023-06-24 11:28:57,726] train loss: 2.2675
[2023-06-24 11:28:57,727] cal loss: 74.6424
[2023-06-24 11:28:57,728] cal percent loss: 0.2927
[2023-06-24 11:28:57,728] mass loss: 51.3691
[2023-06-24 11:28:57,728] mass percent loss: 0.2356
[2023-06-24 11:28:57,728] fat loss: 5.7155
[2023-06-24 11:28:57,728] fat percent loss: 0.4500
[2023-06-24 11:28:57,728] carb loss: 7.3970
[2023-06-24 11:28:57,728] carb percent loss: 0.3833
[2023-06-24 11:28:57,728] protein loss: 7.0576
[2023-06-24 11:28:57,729] protein percent loss: 0.3899
[2023-06-24 11:28:57,729] ingrs percent loss: 0.5070
[2023-06-24 11:28:57,729] Epoch 11/150
[2023-06-24 11:29:07,499] test loss: 3.3492
[2023-06-24 11:29:07,500] cal loss: 131.9510
[2023-06-24 11:29:07,500] cal percent loss: 0.5175
[2023-06-24 11:29:07,500] mass loss: 92.6036
[2023-06-24 11:29:07,500] mass percent loss: 0.4248
[2023-06-24 11:29:07,500] fat loss: 9.1698
[2023-06-24 11:29:07,500] fat percent loss: 0.7220
[2023-06-24 11:29:07,500] carb loss: 8.7483
[2023-06-24 11:29:07,501] carb percent loss: 0.4533
[2023-06-24 11:29:07,501] protein loss: 11.7968
[2023-06-24 11:29:07,501] protein percent loss: 0.6518
[2023-06-24 11:29:07,501] ingrs percent loss: 0.5234
[2023-06-24 11:29:07,501] Epoch 12/150
[2023-06-24 11:31:08,271] train loss: 2.3206
[2023-06-24 11:31:08,271] cal loss: 78.8028
[2023-06-24 11:31:08,272] cal percent loss: 0.3090
[2023-06-24 11:31:08,272] mass loss: 53.1397
[2023-06-24 11:31:08,272] mass percent loss: 0.2438
[2023-06-24 11:31:08,272] fat loss: 5.9534
[2023-06-24 11:31:08,272] fat percent loss: 0.4688
[2023-06-24 11:31:08,272] carb loss: 7.3740
[2023-06-24 11:31:08,272] carb percent loss: 0.3821
[2023-06-24 11:31:08,273] protein loss: 7.4507
[2023-06-24 11:31:08,273] protein percent loss: 0.4116
[2023-06-24 11:31:08,273] ingrs percent loss: 0.4942
[2023-06-24 11:31:08,273] Epoch 12/150
[2023-06-24 11:31:17,206] test loss: 2.2314
[2023-06-24 11:31:17,207] cal loss: 62.7952
[2023-06-24 11:31:17,207] cal percent loss: 0.2463
[2023-06-24 11:31:17,207] mass loss: 51.4288
[2023-06-24 11:31:17,207] mass percent loss: 0.2359
[2023-06-24 11:31:17,207] fat loss: 5.6286
[2023-06-24 11:31:17,207] fat percent loss: 0.4432
[2023-06-24 11:31:17,208] carb loss: 7.6829
[2023-06-24 11:31:17,208] carb percent loss: 0.3981
[2023-06-24 11:31:17,208] protein loss: 7.0020
[2023-06-24 11:31:17,208] protein percent loss: 0.3868
[2023-06-24 11:31:17,208] ingrs percent loss: 0.5206
[2023-06-24 11:31:17,208] Epoch 13/150
[2023-06-24 11:33:20,608] train loss: 2.1995
[2023-06-24 11:33:20,609] cal loss: 73.9544
[2023-06-24 11:33:20,609] cal percent loss: 0.2900
[2023-06-24 11:33:20,609] mass loss: 46.8882
[2023-06-24 11:33:20,609] mass percent loss: 0.2151
[2023-06-24 11:33:20,610] fat loss: 5.7058
[2023-06-24 11:33:20,610] fat percent loss: 0.4493
[2023-06-24 11:33:20,610] carb loss: 7.0512
[2023-06-24 11:33:20,610] carb percent loss: 0.3653
[2023-06-24 11:33:20,610] protein loss: 7.2418
[2023-06-24 11:33:20,610] protein percent loss: 0.4001
[2023-06-24 11:33:20,610] ingrs percent loss: 0.4767
[2023-06-24 11:33:20,610] Epoch 13/150
[2023-06-24 11:33:29,295] test loss: 2.1686
[2023-06-24 11:33:29,296] cal loss: 69.9040
[2023-06-24 11:33:29,296] cal percent loss: 0.2741
[2023-06-24 11:33:29,296] mass loss: 42.5393
[2023-06-24 11:33:29,296] mass percent loss: 0.1951
[2023-06-24 11:33:29,296] fat loss: 5.9796
[2023-06-24 11:33:29,297] fat percent loss: 0.4708
[2023-06-24 11:33:29,297] carb loss: 7.3760
[2023-06-24 11:33:29,297] carb percent loss: 0.3822
[2023-06-24 11:33:29,297] protein loss: 6.2946
[2023-06-24 11:33:29,297] protein percent loss: 0.3478
[2023-06-24 11:33:29,297] ingrs percent loss: 0.5027
[2023-06-24 11:33:29,297] Epoch 14/150
[2023-06-24 11:35:32,186] train loss: 2.0486
[2023-06-24 11:35:32,188] cal loss: 66.9852
[2023-06-24 11:35:32,188] cal percent loss: 0.2627
[2023-06-24 11:35:32,188] mass loss: 44.8953
[2023-06-24 11:35:32,189] mass percent loss: 0.2059
[2023-06-24 11:35:32,189] fat loss: 5.1541
[2023-06-24 11:35:32,189] fat percent loss: 0.4058
[2023-06-24 11:35:32,189] carb loss: 6.9500
[2023-06-24 11:35:32,189] carb percent loss: 0.3601
[2023-06-24 11:35:32,189] protein loss: 6.5570
[2023-06-24 11:35:32,189] protein percent loss: 0.3623
[2023-06-24 11:35:32,189] ingrs percent loss: 0.4492
[2023-06-24 11:35:32,189] Epoch 14/150
[2023-06-24 11:35:41,094] test loss: 2.0196
[2023-06-24 11:35:41,095] cal loss: 60.7689
[2023-06-24 11:35:41,095] cal percent loss: 0.2383
[2023-06-24 11:35:41,095] mass loss: 42.6540
[2023-06-24 11:35:41,095] mass percent loss: 0.1957
[2023-06-24 11:35:41,096] fat loss: 4.8513
[2023-06-24 11:35:41,096] fat percent loss: 0.3820
[2023-06-24 11:35:41,096] carb loss: 7.3023
[2023-06-24 11:35:41,096] carb percent loss: 0.3784
[2023-06-24 11:35:41,096] protein loss: 6.4869
[2023-06-24 11:35:41,096] protein percent loss: 0.3584
[2023-06-24 11:35:41,096] ingrs percent loss: 0.4724
[2023-06-24 11:35:41,096] Epoch 15/150
[2023-06-24 11:37:37,704] train loss: 1.9554
[2023-06-24 11:37:37,705] cal loss: 63.9177
[2023-06-24 11:37:37,706] cal percent loss: 0.2507
[2023-06-24 11:37:37,706] mass loss: 44.0556
[2023-06-24 11:37:37,706] mass percent loss: 0.2021
[2023-06-24 11:37:37,706] fat loss: 4.8698
[2023-06-24 11:37:37,706] fat percent loss: 0.3834
[2023-06-24 11:37:37,706] carb loss: 6.4511
[2023-06-24 11:37:37,707] carb percent loss: 0.3343
[2023-06-24 11:37:37,707] protein loss: 6.3413
[2023-06-24 11:37:37,707] protein percent loss: 0.3503
[2023-06-24 11:37:37,707] ingrs percent loss: 0.4292
[2023-06-24 11:37:37,707] Epoch 15/150
[2023-06-24 11:37:46,958] test loss: 2.9200
[2023-06-24 11:37:46,959] cal loss: 120.7956
[2023-06-24 11:37:46,959] cal percent loss: 0.4737
[2023-06-24 11:37:46,959] mass loss: 69.2421
[2023-06-24 11:37:46,959] mass percent loss: 0.3176
[2023-06-24 11:37:46,959] fat loss: 6.5905
[2023-06-24 11:37:46,959] fat percent loss: 0.5189
[2023-06-24 11:37:46,959] carb loss: 9.8988
[2023-06-24 11:37:46,959] carb percent loss: 0.5129
[2023-06-24 11:37:46,959] protein loss: 10.9431
[2023-06-24 11:37:46,959] protein percent loss: 0.6046
[2023-06-24 11:37:46,960] ingrs percent loss: 0.4712
[2023-06-24 11:37:46,960] Epoch 16/150
[2023-06-24 11:39:47,953] train loss: 2.0640
[2023-06-24 11:39:47,954] cal loss: 71.3563
[2023-06-24 11:39:47,954] cal percent loss: 0.2798
[2023-06-24 11:39:47,954] mass loss: 48.2864
[2023-06-24 11:39:47,954] mass percent loss: 0.2215
[2023-06-24 11:39:47,955] fat loss: 5.1052
[2023-06-24 11:39:47,955] fat percent loss: 0.4020
[2023-06-24 11:39:47,955] carb loss: 7.0315
[2023-06-24 11:39:47,955] carb percent loss: 0.3643
[2023-06-24 11:39:47,955] protein loss: 6.6389
[2023-06-24 11:39:47,955] protein percent loss: 0.3668
[2023-06-24 11:39:47,955] ingrs percent loss: 0.4199
[2023-06-24 11:39:47,955] Epoch 16/150
[2023-06-24 11:39:57,495] test loss: 2.2788
[2023-06-24 11:39:57,496] cal loss: 84.3743
[2023-06-24 11:39:57,496] cal percent loss: 0.3309
[2023-06-24 11:39:57,496] mass loss: 37.8600
[2023-06-24 11:39:57,496] mass percent loss: 0.1737
[2023-06-24 11:39:57,496] fat loss: 7.3508
[2023-06-24 11:39:57,497] fat percent loss: 0.5788
[2023-06-24 11:39:57,497] carb loss: 7.7192
[2023-06-24 11:39:57,497] carb percent loss: 0.4000
[2023-06-24 11:39:57,497] protein loss: 6.2180
[2023-06-24 11:39:57,497] protein percent loss: 0.3435
[2023-06-24 11:39:57,497] ingrs percent loss: 0.4622
[2023-06-24 11:39:57,498] Epoch 17/150
[2023-06-24 11:41:59,151] train loss: 1.9377
[2023-06-24 11:41:59,152] cal loss: 65.2265
[2023-06-24 11:41:59,152] cal percent loss: 0.2558
[2023-06-24 11:41:59,152] mass loss: 43.3071
[2023-06-24 11:41:59,152] mass percent loss: 0.1987
[2023-06-24 11:41:59,153] fat loss: 4.9821
[2023-06-24 11:41:59,153] fat percent loss: 0.3923
[2023-06-24 11:41:59,153] carb loss: 6.2586
[2023-06-24 11:41:59,153] carb percent loss: 0.3243
[2023-06-24 11:41:59,153] protein loss: 6.3823
[2023-06-24 11:41:59,153] protein percent loss: 0.3526
[2023-06-24 11:41:59,153] ingrs percent loss: 0.4085
[2023-06-24 11:41:59,153] Epoch 17/150
[2023-06-24 11:42:08,303] test loss: 1.8637
[2023-06-24 11:42:08,304] cal loss: 57.5170
[2023-06-24 11:42:08,304] cal percent loss: 0.2256
[2023-06-24 11:42:08,304] mass loss: 39.7687
[2023-06-24 11:42:08,304] mass percent loss: 0.1824
[2023-06-24 11:42:08,305] fat loss: 4.3838
[2023-06-24 11:42:08,305] fat percent loss: 0.3452
[2023-06-24 11:42:08,305] carb loss: 6.8321
[2023-06-24 11:42:08,305] carb percent loss: 0.3540
[2023-06-24 11:42:08,305] protein loss: 5.6427
[2023-06-24 11:42:08,305] protein percent loss: 0.3117
[2023-06-24 11:42:08,305] ingrs percent loss: 0.4466
[2023-06-24 11:42:08,305] Epoch 18/150
[2023-06-24 11:44:12,307] train loss: 1.8356
[2023-06-24 11:44:12,308] cal loss: 60.2488
[2023-06-24 11:44:12,308] cal percent loss: 0.2363
[2023-06-24 11:44:12,308] mass loss: 42.1634
[2023-06-24 11:44:12,308] mass percent loss: 0.1934
[2023-06-24 11:44:12,308] fat loss: 4.5805
[2023-06-24 11:44:12,309] fat percent loss: 0.3607
[2023-06-24 11:44:12,309] carb loss: 6.1598
[2023-06-24 11:44:12,309] carb percent loss: 0.3192
[2023-06-24 11:44:12,309] protein loss: 5.9678
[2023-06-24 11:44:12,309] protein percent loss: 0.3297
[2023-06-24 11:44:12,309] ingrs percent loss: 0.3908
[2023-06-24 11:44:12,309] Epoch 18/150
[2023-06-24 11:44:21,454] test loss: 2.2795
[2023-06-24 11:44:21,455] cal loss: 62.5646
[2023-06-24 11:44:21,455] cal percent loss: 0.2454
[2023-06-24 11:44:21,455] mass loss: 47.1008
[2023-06-24 11:44:21,455] mass percent loss: 0.2161
[2023-06-24 11:44:21,455] fat loss: 7.4967
[2023-06-24 11:44:21,455] fat percent loss: 0.5903
[2023-06-24 11:44:21,456] carb loss: 7.9899
[2023-06-24 11:44:21,456] carb percent loss: 0.4140
[2023-06-24 11:44:21,456] protein loss: 6.6177
[2023-06-24 11:44:21,456] protein percent loss: 0.3656
[2023-06-24 11:44:21,456] ingrs percent loss: 0.4621
[2023-06-24 11:44:21,456] Epoch 19/150
[2023-06-24 11:46:16,852] train loss: 1.8595
[2023-06-24 11:46:16,853] cal loss: 61.8630
[2023-06-24 11:46:16,853] cal percent loss: 0.2426
[2023-06-24 11:46:16,853] mass loss: 41.7016
[2023-06-24 11:46:16,854] mass percent loss: 0.1913
[2023-06-24 11:46:16,854] fat loss: 4.7396
[2023-06-24 11:46:16,854] fat percent loss: 0.3732
[2023-06-24 11:46:16,854] carb loss: 6.3721
[2023-06-24 11:46:16,854] carb percent loss: 0.3302
[2023-06-24 11:46:16,854] protein loss: 6.0104
[2023-06-24 11:46:16,854] protein percent loss: 0.3321
[2023-06-24 11:46:16,855] ingrs percent loss: 0.3867
[2023-06-24 11:46:16,855] Epoch 19/150
[2023-06-24 11:46:26,728] test loss: 2.1460
[2023-06-24 11:46:26,728] cal loss: 62.6112
[2023-06-24 11:46:26,728] cal percent loss: 0.2455
[2023-06-24 11:46:26,728] mass loss: 67.8335
[2023-06-24 11:46:26,728] mass percent loss: 0.3112
[2023-06-24 11:46:26,728] fat loss: 5.1305
[2023-06-24 11:46:26,728] fat percent loss: 0.4040
[2023-06-24 11:46:26,728] carb loss: 7.3718
[2023-06-24 11:46:26,729] carb percent loss: 0.3820
[2023-06-24 11:46:26,729] protein loss: 6.0191
[2023-06-24 11:46:26,729] protein percent loss: 0.3325
[2023-06-24 11:46:26,729] ingrs percent loss: 0.4351
[2023-06-24 11:46:26,729] Epoch 20/150
[2023-06-24 11:48:27,718] train loss: 1.7788
[2023-06-24 11:48:27,719] cal loss: 55.6538
[2023-06-24 11:48:27,719] cal percent loss: 0.2183
[2023-06-24 11:48:27,719] mass loss: 42.5099
[2023-06-24 11:48:27,719] mass percent loss: 0.1950
[2023-06-24 11:48:27,719] fat loss: 4.4264
[2023-06-24 11:48:27,719] fat percent loss: 0.3485
[2023-06-24 11:48:27,720] carb loss: 6.2671
[2023-06-24 11:48:27,720] carb percent loss: 0.3247
[2023-06-24 11:48:27,720] protein loss: 5.6801
[2023-06-24 11:48:27,720] protein percent loss: 0.3138
[2023-06-24 11:48:27,720] ingrs percent loss: 0.3736
[2023-06-24 11:48:27,720] Epoch 20/150
[2023-06-24 11:48:37,016] test loss: 2.0204
[2023-06-24 11:48:37,016] cal loss: 75.2133
[2023-06-24 11:48:37,016] cal percent loss: 0.2950
[2023-06-24 11:48:37,016] mass loss: 48.8492
[2023-06-24 11:48:37,017] mass percent loss: 0.2241
[2023-06-24 11:48:37,017] fat loss: 5.1703
[2023-06-24 11:48:37,017] fat percent loss: 0.4071
[2023-06-24 11:48:37,017] carb loss: 6.3870
[2023-06-24 11:48:37,017] carb percent loss: 0.3309
[2023-06-24 11:48:37,017] protein loss: 5.9100
[2023-06-24 11:48:37,017] protein percent loss: 0.3265
[2023-06-24 11:48:37,017] ingrs percent loss: 0.4155
[2023-06-24 11:48:37,018] Epoch 21/150
[2023-06-24 11:50:38,493] train loss: 1.7137
[2023-06-24 11:50:38,493] cal loss: 57.9131
[2023-06-24 11:50:38,494] cal percent loss: 0.2271
[2023-06-24 11:50:38,494] mass loss: 38.4090
[2023-06-24 11:50:38,494] mass percent loss: 0.1762
[2023-06-24 11:50:38,494] fat loss: 4.4965
[2023-06-24 11:50:38,494] fat percent loss: 0.3541
[2023-06-24 11:50:38,494] carb loss: 5.5641
[2023-06-24 11:50:38,494] carb percent loss: 0.2883
[2023-06-24 11:50:38,495] protein loss: 5.6319
[2023-06-24 11:50:38,495] protein percent loss: 0.3112
[2023-06-24 11:50:38,495] ingrs percent loss: 0.3522
[2023-06-24 11:50:38,495] Epoch 21/150
[2023-06-24 11:50:48,156] test loss: 2.0578
[2023-06-24 11:50:48,157] cal loss: 62.3210
[2023-06-24 11:50:48,157] cal percent loss: 0.2444
[2023-06-24 11:50:48,157] mass loss: 60.7741
[2023-06-24 11:50:48,157] mass percent loss: 0.2788
[2023-06-24 11:50:48,157] fat loss: 4.6632
[2023-06-24 11:50:48,157] fat percent loss: 0.3672
[2023-06-24 11:50:48,157] carb loss: 7.5525
[2023-06-24 11:50:48,157] carb percent loss: 0.3913
[2023-06-24 11:50:48,157] protein loss: 6.0553
[2023-06-24 11:50:48,157] protein percent loss: 0.3345
[2023-06-24 11:50:48,157] ingrs percent loss: 0.4165
[2023-06-24 11:50:48,157] Epoch 22/150
[2023-06-24 11:52:52,101] train loss: 1.6740
[2023-06-24 11:52:52,101] cal loss: 56.4551
[2023-06-24 11:52:52,102] cal percent loss: 0.2214
[2023-06-24 11:52:52,102] mass loss: 38.2661
[2023-06-24 11:52:52,102] mass percent loss: 0.1755
[2023-06-24 11:52:52,102] fat loss: 4.1872
[2023-06-24 11:52:52,102] fat percent loss: 0.3297
[2023-06-24 11:52:52,102] carb loss: 5.6005
[2023-06-24 11:52:52,102] carb percent loss: 0.2902
[2023-06-24 11:52:52,102] protein loss: 5.6013
[2023-06-24 11:52:52,102] protein percent loss: 0.3095
[2023-06-24 11:52:52,103] ingrs percent loss: 0.3429
[2023-06-24 11:52:52,103] Epoch 22/150
[2023-06-24 11:53:01,093] test loss: 1.8926
[2023-06-24 11:53:01,094] cal loss: 62.4211
[2023-06-24 11:53:01,094] cal percent loss: 0.2448
[2023-06-24 11:53:01,094] mass loss: 45.5065
[2023-06-24 11:53:01,094] mass percent loss: 0.2087
[2023-06-24 11:53:01,094] fat loss: 4.9082
[2023-06-24 11:53:01,094] fat percent loss: 0.3865
[2023-06-24 11:53:01,094] carb loss: 6.4703
[2023-06-24 11:53:01,094] carb percent loss: 0.3353
[2023-06-24 11:53:01,094] protein loss: 5.3914
[2023-06-24 11:53:01,094] protein percent loss: 0.2979
[2023-06-24 11:53:01,094] ingrs percent loss: 0.4077
[2023-06-24 11:53:01,095] Epoch 23/150
[2023-06-24 11:55:04,645] train loss: 1.6149
[2023-06-24 11:55:04,646] cal loss: 52.4672
[2023-06-24 11:55:04,646] cal percent loss: 0.2058
[2023-06-24 11:55:04,646] mass loss: 35.0332
[2023-06-24 11:55:04,647] mass percent loss: 0.1607
[2023-06-24 11:55:04,647] fat loss: 4.1196
[2023-06-24 11:55:04,647] fat percent loss: 0.3244
[2023-06-24 11:55:04,647] carb loss: 5.5821
[2023-06-24 11:55:04,647] carb percent loss: 0.2892
[2023-06-24 11:55:04,647] protein loss: 5.2790
[2023-06-24 11:55:04,647] protein percent loss: 0.2917
[2023-06-24 11:55:04,647] ingrs percent loss: 0.3435
[2023-06-24 11:55:04,647] Epoch 23/150
[2023-06-24 11:55:13,875] test loss: 1.9730
[2023-06-24 11:55:13,876] cal loss: 70.7556
[2023-06-24 11:55:13,876] cal percent loss: 0.2775
[2023-06-24 11:55:13,876] mass loss: 40.7224
[2023-06-24 11:55:13,877] mass percent loss: 0.1868
[2023-06-24 11:55:13,877] fat loss: 4.6443
[2023-06-24 11:55:13,877] fat percent loss: 0.3657
[2023-06-24 11:55:13,877] carb loss: 8.8639
[2023-06-24 11:55:13,877] carb percent loss: 0.4593
[2023-06-24 11:55:13,877] protein loss: 5.5005
[2023-06-24 11:55:13,877] protein percent loss: 0.3039
[2023-06-24 11:55:13,877] ingrs percent loss: 0.3866
[2023-06-24 11:55:13,877] Epoch 24/150
[2023-06-24 11:57:12,715] train loss: 1.5994
[2023-06-24 11:57:12,716] cal loss: 53.2640
[2023-06-24 11:57:12,716] cal percent loss: 0.2089
[2023-06-24 11:57:12,716] mass loss: 34.0974
[2023-06-24 11:57:12,716] mass percent loss: 0.1564
[2023-06-24 11:57:12,716] fat loss: 4.0519
[2023-06-24 11:57:12,717] fat percent loss: 0.3190
[2023-06-24 11:57:12,717] carb loss: 5.5876
[2023-06-24 11:57:12,717] carb percent loss: 0.2895
[2023-06-24 11:57:12,717] protein loss: 5.3691
[2023-06-24 11:57:12,717] protein percent loss: 0.2966
[2023-06-24 11:57:12,717] ingrs percent loss: 0.3305
[2023-06-24 11:57:12,717] Epoch 24/150
[2023-06-24 11:57:22,483] test loss: 1.9676
[2023-06-24 11:57:22,483] cal loss: 67.2219
[2023-06-24 11:57:22,484] cal percent loss: 0.2636
[2023-06-24 11:57:22,484] mass loss: 40.3907
[2023-06-24 11:57:22,484] mass percent loss: 0.1853
[2023-06-24 11:57:22,484] fat loss: 4.9646
[2023-06-24 11:57:22,484] fat percent loss: 0.3909
[2023-06-24 11:57:22,484] carb loss: 6.8602
[2023-06-24 11:57:22,484] carb percent loss: 0.3555
[2023-06-24 11:57:22,484] protein loss: 6.4026
[2023-06-24 11:57:22,484] protein percent loss: 0.3537
[2023-06-24 11:57:22,485] ingrs percent loss: 0.4206
[2023-06-24 11:57:22,485] Epoch 25/150
[2023-06-24 11:59:21,257] train loss: 1.5110
[2023-06-24 11:59:21,257] cal loss: 48.8714
[2023-06-24 11:59:21,258] cal percent loss: 0.1917
[2023-06-24 11:59:21,258] mass loss: 33.6710
[2023-06-24 11:59:21,258] mass percent loss: 0.1545
[2023-06-24 11:59:21,258] fat loss: 3.8100
[2023-06-24 11:59:21,258] fat percent loss: 0.3000
[2023-06-24 11:59:21,259] carb loss: 5.1624
[2023-06-24 11:59:21,259] carb percent loss: 0.2675
[2023-06-24 11:59:21,259] protein loss: 4.9581
[2023-06-24 11:59:21,259] protein percent loss: 0.2739
[2023-06-24 11:59:21,259] ingrs percent loss: 0.3221
[2023-06-24 11:59:21,259] Epoch 25/150
[2023-06-24 11:59:31,269] test loss: 2.0865
[2023-06-24 11:59:31,270] cal loss: 82.2821
[2023-06-24 11:59:31,271] cal percent loss: 0.3227
[2023-06-24 11:59:31,271] mass loss: 39.6774
[2023-06-24 11:59:31,271] mass percent loss: 0.1820
[2023-06-24 11:59:31,271] fat loss: 5.0746
[2023-06-24 11:59:31,271] fat percent loss: 0.3996
[2023-06-24 11:59:31,271] carb loss: 8.3252
[2023-06-24 11:59:31,271] carb percent loss: 0.4314
[2023-06-24 11:59:31,271] protein loss: 6.3824
[2023-06-24 11:59:31,271] protein percent loss: 0.3526
[2023-06-24 11:59:31,271] ingrs percent loss: 0.4027
[2023-06-24 11:59:31,272] Epoch 26/150
[2023-06-24 12:01:36,943] train loss: 1.5823
[2023-06-24 12:01:36,944] cal loss: 53.5674
[2023-06-24 12:01:36,944] cal percent loss: 0.2101
[2023-06-24 12:01:36,944] mass loss: 35.7164
[2023-06-24 12:01:36,944] mass percent loss: 0.1638
[2023-06-24 12:01:36,944] fat loss: 4.0056
[2023-06-24 12:01:36,944] fat percent loss: 0.3154
[2023-06-24 12:01:36,945] carb loss: 5.5817
[2023-06-24 12:01:36,945] carb percent loss: 0.2892
[2023-06-24 12:01:36,945] protein loss: 5.0498
[2023-06-24 12:01:36,945] protein percent loss: 0.2790
[2023-06-24 12:01:36,945] ingrs percent loss: 0.3216
[2023-06-24 12:01:36,945] Epoch 26/150
[2023-06-24 12:01:45,916] test loss: 1.8258
[2023-06-24 12:01:45,918] cal loss: 57.5624
[2023-06-24 12:01:45,918] cal percent loss: 0.2257
[2023-06-24 12:01:45,919] mass loss: 39.1018
[2023-06-24 12:01:45,919] mass percent loss: 0.1794
[2023-06-24 12:01:45,919] fat loss: 3.9750
[2023-06-24 12:01:45,919] fat percent loss: 0.3130
[2023-06-24 12:01:45,919] carb loss: 6.1519
[2023-06-24 12:01:45,919] carb percent loss: 0.3187
[2023-06-24 12:01:45,919] protein loss: 7.3332
[2023-06-24 12:01:45,919] protein percent loss: 0.4051
[2023-06-24 12:01:45,919] ingrs percent loss: 0.3899
[2023-06-24 12:01:45,920] Epoch 27/150
[2023-06-24 12:03:48,868] train loss: 1.5029
[2023-06-24 12:03:48,869] cal loss: 50.3175
[2023-06-24 12:03:48,869] cal percent loss: 0.1973
[2023-06-24 12:03:48,869] mass loss: 34.7522
[2023-06-24 12:03:48,869] mass percent loss: 0.1594
[2023-06-24 12:03:48,869] fat loss: 3.7998
[2023-06-24 12:03:48,870] fat percent loss: 0.2992
[2023-06-24 12:03:48,870] carb loss: 5.0290
[2023-06-24 12:03:48,870] carb percent loss: 0.2606
[2023-06-24 12:03:48,870] protein loss: 4.9560
[2023-06-24 12:03:48,870] protein percent loss: 0.2738
[2023-06-24 12:03:48,870] ingrs percent loss: 0.3076
[2023-06-24 12:03:48,870] Epoch 27/150
[2023-06-24 12:03:58,490] test loss: 1.8503
[2023-06-24 12:03:58,490] cal loss: 55.8018
[2023-06-24 12:03:58,491] cal percent loss: 0.2188
[2023-06-24 12:03:58,491] mass loss: 43.3432
[2023-06-24 12:03:58,491] mass percent loss: 0.1988
[2023-06-24 12:03:58,491] fat loss: 4.4005
[2023-06-24 12:03:58,491] fat percent loss: 0.3465
[2023-06-24 12:03:58,491] carb loss: 6.2612
[2023-06-24 12:03:58,491] carb percent loss: 0.3244
[2023-06-24 12:03:58,491] protein loss: 6.5488
[2023-06-24 12:03:58,492] protein percent loss: 0.3618
[2023-06-24 12:03:58,492] ingrs percent loss: 0.3986
[2023-06-24 12:03:58,492] Epoch 28/150
[2023-06-24 12:05:53,547] train loss: 1.4681
[2023-06-24 12:05:53,547] cal loss: 47.6545
[2023-06-24 12:05:53,547] cal percent loss: 0.1869
[2023-06-24 12:05:53,547] mass loss: 32.6789
[2023-06-24 12:05:53,548] mass percent loss: 0.1499
[2023-06-24 12:05:53,548] fat loss: 3.7447
[2023-06-24 12:05:53,548] fat percent loss: 0.2949
[2023-06-24 12:05:53,548] carb loss: 5.0602
[2023-06-24 12:05:53,548] carb percent loss: 0.2622
[2023-06-24 12:05:53,548] protein loss: 4.8870
[2023-06-24 12:05:53,548] protein percent loss: 0.2700
[2023-06-24 12:05:53,548] ingrs percent loss: 0.3037
[2023-06-24 12:05:53,548] Epoch 28/150
[2023-06-24 12:06:03,471] test loss: 1.8996
[2023-06-24 12:06:03,472] cal loss: 64.6675
[2023-06-24 12:06:03,472] cal percent loss: 0.2536
[2023-06-24 12:06:03,473] mass loss: 50.8456
[2023-06-24 12:06:03,473] mass percent loss: 0.2332
[2023-06-24 12:06:03,473] fat loss: 4.3187
[2023-06-24 12:06:03,473] fat percent loss: 0.3401
[2023-06-24 12:06:03,473] carb loss: 6.5962
[2023-06-24 12:06:03,473] carb percent loss: 0.3418
[2023-06-24 12:06:03,473] protein loss: 5.8497
[2023-06-24 12:06:03,473] protein percent loss: 0.3232
[2023-06-24 12:06:03,473] ingrs percent loss: 0.3873
[2023-06-24 12:06:03,474] Epoch 29/150
[2023-06-24 12:08:00,543] train loss: 1.4602
[2023-06-24 12:08:00,544] cal loss: 49.4149
[2023-06-24 12:08:00,544] cal percent loss: 0.1938
[2023-06-24 12:08:00,544] mass loss: 33.2462
[2023-06-24 12:08:00,544] mass percent loss: 0.1525
[2023-06-24 12:08:00,544] fat loss: 3.7324
[2023-06-24 12:08:00,544] fat percent loss: 0.2939
[2023-06-24 12:08:00,544] carb loss: 4.9790
[2023-06-24 12:08:00,544] carb percent loss: 0.2580
[2023-06-24 12:08:00,544] protein loss: 4.7070
[2023-06-24 12:08:00,544] protein percent loss: 0.2601
[2023-06-24 12:08:00,544] ingrs percent loss: 0.2978
[2023-06-24 12:08:00,544] Epoch 29/150
[2023-06-24 12:08:10,352] test loss: 2.0068
[2023-06-24 12:08:10,353] cal loss: 69.7410
[2023-06-24 12:08:10,353] cal percent loss: 0.2735
[2023-06-24 12:08:10,353] mass loss: 36.8767
[2023-06-24 12:08:10,353] mass percent loss: 0.1692
[2023-06-24 12:08:10,353] fat loss: 5.9748
[2023-06-24 12:08:10,353] fat percent loss: 0.4705
[2023-06-24 12:08:10,353] carb loss: 6.4376
[2023-06-24 12:08:10,353] carb percent loss: 0.3336
[2023-06-24 12:08:10,354] protein loss: 6.8044
[2023-06-24 12:08:10,354] protein percent loss: 0.3759
[2023-06-24 12:08:10,354] ingrs percent loss: 0.3936
[2023-06-24 12:08:10,354] Epoch 30/150
[2023-06-24 12:10:16,869] train loss: 1.4958
[2023-06-24 12:10:16,870] cal loss: 50.0145
[2023-06-24 12:10:16,870] cal percent loss: 0.1961
[2023-06-24 12:10:16,870] mass loss: 33.7003
[2023-06-24 12:10:16,870] mass percent loss: 0.1546
[2023-06-24 12:10:16,871] fat loss: 3.9415
[2023-06-24 12:10:16,871] fat percent loss: 0.3104
[2023-06-24 12:10:16,871] carb loss: 4.9618
[2023-06-24 12:10:16,871] carb percent loss: 0.2571
[2023-06-24 12:10:16,871] protein loss: 4.8871
[2023-06-24 12:10:16,871] protein percent loss: 0.2700
[2023-06-24 12:10:16,871] ingrs percent loss: 0.3042
[2023-06-24 12:10:16,871] Epoch 30/150
[2023-06-24 12:10:25,751] test loss: 1.8570
[2023-06-24 12:10:25,752] cal loss: 54.5959
[2023-06-24 12:10:25,752] cal percent loss: 0.2141
[2023-06-24 12:10:25,752] mass loss: 50.0878
[2023-06-24 12:10:25,752] mass percent loss: 0.2298
[2023-06-24 12:10:25,753] fat loss: 4.6147
[2023-06-24 12:10:25,753] fat percent loss: 0.3634
[2023-06-24 12:10:25,753] carb loss: 6.8167
[2023-06-24 12:10:25,753] carb percent loss: 0.3532
[2023-06-24 12:10:25,753] protein loss: 5.1701
[2023-06-24 12:10:25,753] protein percent loss: 0.2856
[2023-06-24 12:10:25,753] ingrs percent loss: 0.3967
[2023-06-24 12:10:25,753] Epoch 31/150
[2023-06-24 12:12:26,344] train loss: 1.3991
[2023-06-24 12:12:26,345] cal loss: 46.0963
[2023-06-24 12:12:26,345] cal percent loss: 0.1808
[2023-06-24 12:12:26,345] mass loss: 31.6084
[2023-06-24 12:12:26,345] mass percent loss: 0.1450
[2023-06-24 12:12:26,345] fat loss: 3.5430
[2023-06-24 12:12:26,345] fat percent loss: 0.2790
[2023-06-24 12:12:26,346] carb loss: 4.9141
[2023-06-24 12:12:26,346] carb percent loss: 0.2546
[2023-06-24 12:12:26,346] protein loss: 4.4790
[2023-06-24 12:12:26,346] protein percent loss: 0.2475
[2023-06-24 12:12:26,346] ingrs percent loss: 0.2901
[2023-06-24 12:12:26,346] Epoch 31/150
[2023-06-24 12:12:36,170] test loss: 1.7933
[2023-06-24 12:12:36,171] cal loss: 59.0769
[2023-06-24 12:12:36,171] cal percent loss: 0.2317
[2023-06-24 12:12:36,171] mass loss: 34.3524
[2023-06-24 12:12:36,171] mass percent loss: 0.1576
[2023-06-24 12:12:36,172] fat loss: 4.9006
[2023-06-24 12:12:36,172] fat percent loss: 0.3859
[2023-06-24 12:12:36,172] carb loss: 5.9580
[2023-06-24 12:12:36,172] carb percent loss: 0.3087
[2023-06-24 12:12:36,172] protein loss: 5.7456
[2023-06-24 12:12:36,172] protein percent loss: 0.3174
[2023-06-24 12:12:36,172] ingrs percent loss: 0.3979
[2023-06-24 12:12:36,173] Epoch 32/150
[2023-06-24 12:14:36,742] train loss: 1.3473
[2023-06-24 12:14:36,743] cal loss: 43.7822
[2023-06-24 12:14:36,743] cal percent loss: 0.1717
[2023-06-24 12:14:36,743] mass loss: 28.9721
[2023-06-24 12:14:36,743] mass percent loss: 0.1329
[2023-06-24 12:14:36,743] fat loss: 3.4871
[2023-06-24 12:14:36,743] fat percent loss: 0.2746
[2023-06-24 12:14:36,743] carb loss: 4.5248
[2023-06-24 12:14:36,743] carb percent loss: 0.2344
[2023-06-24 12:14:36,743] protein loss: 4.5101
[2023-06-24 12:14:36,743] protein percent loss: 0.2492
[2023-06-24 12:14:36,744] ingrs percent loss: 0.2850
[2023-06-24 12:14:36,744] Epoch 32/150
[2023-06-24 12:14:45,977] test loss: 2.2053
[2023-06-24 12:14:45,978] cal loss: 84.1551
[2023-06-24 12:14:45,978] cal percent loss: 0.3300
[2023-06-24 12:14:45,978] mass loss: 56.4318
[2023-06-24 12:14:45,978] mass percent loss: 0.2589
[2023-06-24 12:14:45,978] fat loss: 5.1219
[2023-06-24 12:14:45,979] fat percent loss: 0.4033
[2023-06-24 12:14:45,979] carb loss: 7.3481
[2023-06-24 12:14:45,979] carb percent loss: 0.3807
[2023-06-24 12:14:45,979] protein loss: 7.6999
[2023-06-24 12:14:45,979] protein percent loss: 0.4254
[2023-06-24 12:14:45,979] ingrs percent loss: 0.3854
[2023-06-24 12:14:45,979] Epoch 33/150
[2023-06-24 12:16:49,184] train loss: 1.3994
[2023-06-24 12:16:49,186] cal loss: 46.5224
[2023-06-24 12:16:49,186] cal percent loss: 0.1824
[2023-06-24 12:16:49,186] mass loss: 33.1164
[2023-06-24 12:16:49,186] mass percent loss: 0.1519
[2023-06-24 12:16:49,187] fat loss: 3.6094
[2023-06-24 12:16:49,187] fat percent loss: 0.2842
[2023-06-24 12:16:49,187] carb loss: 4.8221
[2023-06-24 12:16:49,187] carb percent loss: 0.2499
[2023-06-24 12:16:49,187] protein loss: 4.3874
[2023-06-24 12:16:49,187] protein percent loss: 0.2424
[2023-06-24 12:16:49,187] ingrs percent loss: 0.2829
[2023-06-24 12:16:49,187] Epoch 33/150
[2023-06-24 12:16:58,234] test loss: 1.8129
[2023-06-24 12:16:58,235] cal loss: 63.2258
[2023-06-24 12:16:58,235] cal percent loss: 0.2479
[2023-06-24 12:16:58,235] mass loss: 41.8827
[2023-06-24 12:16:58,235] mass percent loss: 0.1921
[2023-06-24 12:16:58,235] fat loss: 4.0912
[2023-06-24 12:16:58,235] fat percent loss: 0.3221
[2023-06-24 12:16:58,235] carb loss: 6.2045
[2023-06-24 12:16:58,235] carb percent loss: 0.3215
[2023-06-24 12:16:58,236] protein loss: 5.7402
[2023-06-24 12:16:58,236] protein percent loss: 0.3171
[2023-06-24 12:16:58,236] ingrs percent loss: 0.4021
[2023-06-24 12:16:58,236] Epoch 34/150
[2023-06-24 12:19:03,566] train loss: 1.2908
[2023-06-24 12:19:03,567] cal loss: 42.5283
[2023-06-24 12:19:03,567] cal percent loss: 0.1668
[2023-06-24 12:19:03,567] mass loss: 28.0935
[2023-06-24 12:19:03,567] mass percent loss: 0.1289
[2023-06-24 12:19:03,567] fat loss: 3.3510
[2023-06-24 12:19:03,567] fat percent loss: 0.2639
[2023-06-24 12:19:03,567] carb loss: 4.4980
[2023-06-24 12:19:03,567] carb percent loss: 0.2331
[2023-06-24 12:19:03,567] protein loss: 4.0451
[2023-06-24 12:19:03,567] protein percent loss: 0.2235
[2023-06-24 12:19:03,567] ingrs percent loss: 0.2740
[2023-06-24 12:19:03,567] Epoch 34/150
[2023-06-24 12:19:13,707] test loss: 1.7132
[2023-06-24 12:19:13,708] cal loss: 52.3476
[2023-06-24 12:19:13,708] cal percent loss: 0.2053
[2023-06-24 12:19:13,708] mass loss: 34.9397
[2023-06-24 12:19:13,708] mass percent loss: 0.1603
[2023-06-24 12:19:13,708] fat loss: 4.3157
[2023-06-24 12:19:13,708] fat percent loss: 0.3398
[2023-06-24 12:19:13,708] carb loss: 6.1623
[2023-06-24 12:19:13,708] carb percent loss: 0.3193
[2023-06-24 12:19:13,708] protein loss: 5.9059
[2023-06-24 12:19:13,708] protein percent loss: 0.3263
[2023-06-24 12:19:13,709] ingrs percent loss: 0.3712
[2023-06-24 12:19:13,709] Epoch 35/150
[2023-06-24 12:21:20,803] train loss: 1.3430
[2023-06-24 12:21:20,804] cal loss: 45.1532
[2023-06-24 12:21:20,804] cal percent loss: 0.1771
[2023-06-24 12:21:20,804] mass loss: 30.9449
[2023-06-24 12:21:20,804] mass percent loss: 0.1419
[2023-06-24 12:21:20,804] fat loss: 3.4461
[2023-06-24 12:21:20,804] fat percent loss: 0.2713
[2023-06-24 12:21:20,804] carb loss: 4.5561
[2023-06-24 12:21:20,804] carb percent loss: 0.2361
[2023-06-24 12:21:20,804] protein loss: 4.2548
[2023-06-24 12:21:20,805] protein percent loss: 0.2351
[2023-06-24 12:21:20,805] ingrs percent loss: 0.2767
[2023-06-24 12:21:20,805] Epoch 35/150
[2023-06-24 12:21:30,135] test loss: 1.7327
[2023-06-24 12:21:30,136] cal loss: 57.6657
[2023-06-24 12:21:30,136] cal percent loss: 0.2261
[2023-06-24 12:21:30,136] mass loss: 31.2629
[2023-06-24 12:21:30,136] mass percent loss: 0.1434
[2023-06-24 12:21:30,136] fat loss: 4.5336
[2023-06-24 12:21:30,136] fat percent loss: 0.3570
[2023-06-24 12:21:30,136] carb loss: 6.3223
[2023-06-24 12:21:30,136] carb percent loss: 0.3276
[2023-06-24 12:21:30,136] protein loss: 5.6910
[2023-06-24 12:21:30,136] protein percent loss: 0.3144
[2023-06-24 12:21:30,137] ingrs percent loss: 0.3764
[2023-06-24 12:21:30,137] Epoch 36/150
[2023-06-24 12:23:33,409] train loss: 1.2793
[2023-06-24 12:23:33,410] cal loss: 42.3662
[2023-06-24 12:23:33,410] cal percent loss: 0.1661
[2023-06-24 12:23:33,410] mass loss: 28.0872
[2023-06-24 12:23:33,410] mass percent loss: 0.1288
[2023-06-24 12:23:33,411] fat loss: 3.2590
[2023-06-24 12:23:33,411] fat percent loss: 0.2566
[2023-06-24 12:23:33,411] carb loss: 4.3969
[2023-06-24 12:23:33,411] carb percent loss: 0.2278
[2023-06-24 12:23:33,411] protein loss: 4.0492
[2023-06-24 12:23:33,411] protein percent loss: 0.2237
[2023-06-24 12:23:33,411] ingrs percent loss: 0.2745
[2023-06-24 12:23:33,411] Epoch 36/150
[2023-06-24 12:23:43,073] test loss: 1.7650
[2023-06-24 12:23:43,074] cal loss: 60.2442
[2023-06-24 12:23:43,074] cal percent loss: 0.2363
[2023-06-24 12:23:43,074] mass loss: 37.3119
[2023-06-24 12:23:43,074] mass percent loss: 0.1712
[2023-06-24 12:23:43,074] fat loss: 4.1601
[2023-06-24 12:23:43,074] fat percent loss: 0.3276
[2023-06-24 12:23:43,075] carb loss: 7.1108
[2023-06-24 12:23:43,075] carb percent loss: 0.3684
[2023-06-24 12:23:43,075] protein loss: 5.4298
[2023-06-24 12:23:43,075] protein percent loss: 0.3000
[2023-06-24 12:23:43,075] ingrs percent loss: 0.3654
[2023-06-24 12:23:43,075] Epoch 37/150
[2023-06-24 12:25:48,407] train loss: 1.2614
[2023-06-24 12:25:48,408] cal loss: 41.6345
[2023-06-24 12:25:48,408] cal percent loss: 0.1633
[2023-06-24 12:25:48,408] mass loss: 28.4619
[2023-06-24 12:25:48,408] mass percent loss: 0.1306
[2023-06-24 12:25:48,408] fat loss: 3.1654
[2023-06-24 12:25:48,408] fat percent loss: 0.2492
[2023-06-24 12:25:48,409] carb loss: 4.3485
[2023-06-24 12:25:48,409] carb percent loss: 0.2253
[2023-06-24 12:25:48,409] protein loss: 3.9797
[2023-06-24 12:25:48,409] protein percent loss: 0.2199
[2023-06-24 12:25:48,409] ingrs percent loss: 0.2702
[2023-06-24 12:25:48,409] Epoch 37/150
[2023-06-24 12:25:57,931] test loss: 1.6719
[2023-06-24 12:25:57,932] cal loss: 53.1098
[2023-06-24 12:25:57,932] cal percent loss: 0.2083
[2023-06-24 12:25:57,933] mass loss: 34.3809
[2023-06-24 12:25:57,933] mass percent loss: 0.1577
[2023-06-24 12:25:57,933] fat loss: 4.2849
[2023-06-24 12:25:57,933] fat percent loss: 0.3374
[2023-06-24 12:25:57,933] carb loss: 6.3740
[2023-06-24 12:25:57,933] carb percent loss: 0.3303
[2023-06-24 12:25:57,933] protein loss: 4.9991
[2023-06-24 12:25:57,934] protein percent loss: 0.2762
[2023-06-24 12:25:57,934] ingrs percent loss: 0.3675
[2023-06-24 12:25:57,934] Epoch 38/150
[2023-06-24 12:27:59,263] train loss: 1.2477
[2023-06-24 12:27:59,264] cal loss: 40.9201
[2023-06-24 12:27:59,265] cal percent loss: 0.1605
[2023-06-24 12:27:59,265] mass loss: 27.9798
[2023-06-24 12:27:59,265] mass percent loss: 0.1283
[2023-06-24 12:27:59,265] fat loss: 3.2013
[2023-06-24 12:27:59,265] fat percent loss: 0.2521
[2023-06-24 12:27:59,265] carb loss: 4.2974
[2023-06-24 12:27:59,265] carb percent loss: 0.2227
[2023-06-24 12:27:59,265] protein loss: 3.8538
[2023-06-24 12:27:59,265] protein percent loss: 0.2129
[2023-06-24 12:27:59,265] ingrs percent loss: 0.2685
[2023-06-24 12:27:59,265] Epoch 38/150
[2023-06-24 12:28:08,700] test loss: 1.7533
[2023-06-24 12:28:08,701] cal loss: 60.5533
[2023-06-24 12:28:08,701] cal percent loss: 0.2375
[2023-06-24 12:28:08,701] mass loss: 35.7482
[2023-06-24 12:28:08,701] mass percent loss: 0.1640
[2023-06-24 12:28:08,701] fat loss: 4.5383
[2023-06-24 12:28:08,701] fat percent loss: 0.3573
[2023-06-24 12:28:08,702] carb loss: 5.8465
[2023-06-24 12:28:08,702] carb percent loss: 0.3029
[2023-06-24 12:28:08,702] protein loss: 5.5876
[2023-06-24 12:28:08,702] protein percent loss: 0.3087
[2023-06-24 12:28:08,702] ingrs percent loss: 0.3826
[2023-06-24 12:28:08,702] Epoch 39/150
[2023-06-24 12:30:10,110] train loss: 1.2535
[2023-06-24 12:30:10,111] cal loss: 42.3380
[2023-06-24 12:30:10,111] cal percent loss: 0.1660
[2023-06-24 12:30:10,111] mass loss: 29.1492
[2023-06-24 12:30:10,111] mass percent loss: 0.1337
[2023-06-24 12:30:10,111] fat loss: 3.1404
[2023-06-24 12:30:10,111] fat percent loss: 0.2473
[2023-06-24 12:30:10,111] carb loss: 4.2472
[2023-06-24 12:30:10,111] carb percent loss: 0.2201
[2023-06-24 12:30:10,111] protein loss: 3.9320
[2023-06-24 12:30:10,111] protein percent loss: 0.2172
[2023-06-24 12:30:10,112] ingrs percent loss: 0.2636
[2023-06-24 12:30:10,112] Epoch 39/150
[2023-06-24 12:30:18,905] test loss: 1.6374
[2023-06-24 12:30:18,906] cal loss: 55.0276
[2023-06-24 12:30:18,906] cal percent loss: 0.2158
[2023-06-24 12:30:18,906] mass loss: 32.3718
[2023-06-24 12:30:18,906] mass percent loss: 0.1485
[2023-06-24 12:30:18,907] fat loss: 4.0189
[2023-06-24 12:30:18,907] fat percent loss: 0.3164
[2023-06-24 12:30:18,907] carb loss: 5.8051
[2023-06-24 12:30:18,907] carb percent loss: 0.3008
[2023-06-24 12:30:18,907] protein loss: 5.2823
[2023-06-24 12:30:18,907] protein percent loss: 0.2918
[2023-06-24 12:30:18,907] ingrs percent loss: 0.3681
[2023-06-24 12:30:18,908] Epoch 40/150
[2023-06-24 12:32:19,937] train loss: 1.1956
[2023-06-24 12:32:19,937] cal loss: 39.2122
[2023-06-24 12:32:19,937] cal percent loss: 0.1538
[2023-06-24 12:32:19,938] mass loss: 26.9460
[2023-06-24 12:32:19,938] mass percent loss: 0.1236
[2023-06-24 12:32:19,938] fat loss: 3.0202
[2023-06-24 12:32:19,938] fat percent loss: 0.2378
[2023-06-24 12:32:19,938] carb loss: 4.1953
[2023-06-24 12:32:19,938] carb percent loss: 0.2174
[2023-06-24 12:32:19,938] protein loss: 3.6044
[2023-06-24 12:32:19,938] protein percent loss: 0.1991
[2023-06-24 12:32:19,938] ingrs percent loss: 0.2609
[2023-06-24 12:32:19,938] Epoch 40/150
[2023-06-24 12:32:29,646] test loss: 1.9951
[2023-06-24 12:32:29,647] cal loss: 83.0015
[2023-06-24 12:32:29,647] cal percent loss: 0.3255
[2023-06-24 12:32:29,647] mass loss: 28.7549
[2023-06-24 12:32:29,647] mass percent loss: 0.1319
[2023-06-24 12:32:29,647] fat loss: 6.3333
[2023-06-24 12:32:29,648] fat percent loss: 0.4987
[2023-06-24 12:32:29,648] carb loss: 6.3377
[2023-06-24 12:32:29,648] carb percent loss: 0.3284
[2023-06-24 12:32:29,648] protein loss: 6.3019
[2023-06-24 12:32:29,648] protein percent loss: 0.3482
[2023-06-24 12:32:29,648] ingrs percent loss: 0.3743
[2023-06-24 12:32:29,648] Epoch 41/150
[2023-06-24 12:34:33,181] train loss: 1.3998
[2023-06-24 12:34:33,182] cal loss: 48.8274
[2023-06-24 12:34:33,182] cal percent loss: 0.1915
[2023-06-24 12:34:33,182] mass loss: 32.2831
[2023-06-24 12:34:33,182] mass percent loss: 0.1481
[2023-06-24 12:34:33,182] fat loss: 3.8189
[2023-06-24 12:34:33,182] fat percent loss: 0.3007
[2023-06-24 12:34:33,182] carb loss: 4.5116
[2023-06-24 12:34:33,182] carb percent loss: 0.2338
[2023-06-24 12:34:33,182] protein loss: 4.5296
[2023-06-24 12:34:33,183] protein percent loss: 0.2503
[2023-06-24 12:34:33,183] ingrs percent loss: 0.2692
[2023-06-24 12:34:33,183] Epoch 41/150
[2023-06-24 12:34:42,619] test loss: 1.5811
[2023-06-24 12:34:42,619] cal loss: 52.0319
[2023-06-24 12:34:42,619] cal percent loss: 0.2040
[2023-06-24 12:34:42,619] mass loss: 31.4734
[2023-06-24 12:34:42,619] mass percent loss: 0.1444
[2023-06-24 12:34:42,619] fat loss: 3.8583
[2023-06-24 12:34:42,619] fat percent loss: 0.3038
[2023-06-24 12:34:42,619] carb loss: 5.7785
[2023-06-24 12:34:42,619] carb percent loss: 0.2994
[2023-06-24 12:34:42,619] protein loss: 4.7579
[2023-06-24 12:34:42,619] protein percent loss: 0.2629
[2023-06-24 12:34:42,620] ingrs percent loss: 0.3700
[2023-06-24 12:34:42,620] Epoch 42/150
[2023-06-24 12:36:41,041] train loss: 1.1558
[2023-06-24 12:36:41,041] cal loss: 37.9137
[2023-06-24 12:36:41,041] cal percent loss: 0.1487
[2023-06-24 12:36:41,041] mass loss: 27.3194
[2023-06-24 12:36:41,042] mass percent loss: 0.1253
[2023-06-24 12:36:41,042] fat loss: 2.7917
[2023-06-24 12:36:41,042] fat percent loss: 0.2198
[2023-06-24 12:36:41,042] carb loss: 4.0641
[2023-06-24 12:36:41,042] carb percent loss: 0.2106
[2023-06-24 12:36:41,042] protein loss: 3.4909
[2023-06-24 12:36:41,042] protein percent loss: 0.1929
[2023-06-24 12:36:41,042] ingrs percent loss: 0.2533
[2023-06-24 12:36:41,042] Epoch 42/150
[2023-06-24 12:36:50,329] test loss: 1.7525
[2023-06-24 12:36:50,330] cal loss: 61.1098
[2023-06-24 12:36:50,331] cal percent loss: 0.2396
[2023-06-24 12:36:50,331] mass loss: 38.4602
[2023-06-24 12:36:50,331] mass percent loss: 0.1764
[2023-06-24 12:36:50,331] fat loss: 4.2880
[2023-06-24 12:36:50,331] fat percent loss: 0.3376
[2023-06-24 12:36:50,331] carb loss: 5.7405
[2023-06-24 12:36:50,331] carb percent loss: 0.2974
[2023-06-24 12:36:50,331] protein loss: 5.8113
[2023-06-24 12:36:50,331] protein percent loss: 0.3211
[2023-06-24 12:36:50,332] ingrs percent loss: 0.3749
[2023-06-24 12:36:50,332] Epoch 43/150
[2023-06-24 12:38:56,314] train loss: 1.1625
[2023-06-24 12:38:56,315] cal loss: 39.0570
[2023-06-24 12:38:56,315] cal percent loss: 0.1532
[2023-06-24 12:38:56,315] mass loss: 26.7371
[2023-06-24 12:38:56,315] mass percent loss: 0.1226
[2023-06-24 12:38:56,315] fat loss: 2.9592
[2023-06-24 12:38:56,315] fat percent loss: 0.2330
[2023-06-24 12:38:56,315] carb loss: 3.9430
[2023-06-24 12:38:56,315] carb percent loss: 0.2043
[2023-06-24 12:38:56,316] protein loss: 3.5186
[2023-06-24 12:38:56,316] protein percent loss: 0.1944
[2023-06-24 12:38:56,316] ingrs percent loss: 0.2499
[2023-06-24 12:38:56,316] Epoch 43/150
[2023-06-24 12:39:06,485] test loss: 1.7957
[2023-06-24 12:39:06,486] cal loss: 60.6286
[2023-06-24 12:39:06,487] cal percent loss: 0.2378
[2023-06-24 12:39:06,487] mass loss: 39.6513
[2023-06-24 12:39:06,487] mass percent loss: 0.1819
[2023-06-24 12:39:06,487] fat loss: 4.6212
[2023-06-24 12:39:06,487] fat percent loss: 0.3639
[2023-06-24 12:39:06,487] carb loss: 6.1262
[2023-06-24 12:39:06,487] carb percent loss: 0.3174
[2023-06-24 12:39:06,487] protein loss: 5.4859
[2023-06-24 12:39:06,487] protein percent loss: 0.3031
[2023-06-24 12:39:06,487] ingrs percent loss: 0.3869
[2023-06-24 12:39:06,488] Epoch 44/150
[2023-06-24 12:41:06,099] train loss: 1.1281
[2023-06-24 12:41:06,100] cal loss: 37.1487
[2023-06-24 12:41:06,101] cal percent loss: 0.1457
[2023-06-24 12:41:06,101] mass loss: 24.8983
[2023-06-24 12:41:06,101] mass percent loss: 0.1142
[2023-06-24 12:41:06,101] fat loss: 2.8549
[2023-06-24 12:41:06,101] fat percent loss: 0.2248
[2023-06-24 12:41:06,102] carb loss: 3.8259
[2023-06-24 12:41:06,102] carb percent loss: 0.1982
[2023-06-24 12:41:06,102] protein loss: 3.4431
[2023-06-24 12:41:06,102] protein percent loss: 0.1902
[2023-06-24 12:41:06,102] ingrs percent loss: 0.2521
[2023-06-24 12:41:06,102] Epoch 44/150
[2023-06-24 12:41:15,746] test loss: 1.5934
[2023-06-24 12:41:15,747] cal loss: 52.3618
[2023-06-24 12:41:15,747] cal percent loss: 0.2053
[2023-06-24 12:41:15,747] mass loss: 31.1856
[2023-06-24 12:41:15,747] mass percent loss: 0.1431
[2023-06-24 12:41:15,748] fat loss: 3.9956
[2023-06-24 12:41:15,748] fat percent loss: 0.3146
[2023-06-24 12:41:15,748] carb loss: 5.9809
[2023-06-24 12:41:15,748] carb percent loss: 0.3099
[2023-06-24 12:41:15,748] protein loss: 4.7144
[2023-06-24 12:41:15,748] protein percent loss: 0.2605
[2023-06-24 12:41:15,748] ingrs percent loss: 0.3654
[2023-06-24 12:41:15,749] Epoch 45/150
[2023-06-24 12:43:16,554] train loss: 1.1430
[2023-06-24 12:43:16,555] cal loss: 37.7387
[2023-06-24 12:43:16,555] cal percent loss: 0.1480
[2023-06-24 12:43:16,555] mass loss: 26.3540
[2023-06-24 12:43:16,555] mass percent loss: 0.1209
[2023-06-24 12:43:16,555] fat loss: 2.7663
[2023-06-24 12:43:16,555] fat percent loss: 0.2178
[2023-06-24 12:43:16,555] carb loss: 3.8632
[2023-06-24 12:43:16,556] carb percent loss: 0.2002
[2023-06-24 12:43:16,556] protein loss: 3.6813
[2023-06-24 12:43:16,556] protein percent loss: 0.2034
[2023-06-24 12:43:16,556] ingrs percent loss: 0.2486
[2023-06-24 12:43:16,556] Epoch 45/150
[2023-06-24 12:43:25,193] test loss: 1.6749
[2023-06-24 12:43:25,194] cal loss: 54.1867
[2023-06-24 12:43:25,194] cal percent loss: 0.2125
[2023-06-24 12:43:25,194] mass loss: 33.7082
[2023-06-24 12:43:25,194] mass percent loss: 0.1546
[2023-06-24 12:43:25,194] fat loss: 4.0647
[2023-06-24 12:43:25,194] fat percent loss: 0.3201
[2023-06-24 12:43:25,194] carb loss: 6.1264
[2023-06-24 12:43:25,195] carb percent loss: 0.3174
[2023-06-24 12:43:25,195] protein loss: 5.0977
[2023-06-24 12:43:25,195] protein percent loss: 0.2816
[2023-06-24 12:43:25,195] ingrs percent loss: 0.3925
[2023-06-24 12:43:25,195] Epoch 46/150
[2023-06-24 12:45:27,065] train loss: 1.1241
[2023-06-24 12:45:27,066] cal loss: 37.7733
[2023-06-24 12:45:27,066] cal percent loss: 0.1481
[2023-06-24 12:45:27,066] mass loss: 23.8688
[2023-06-24 12:45:27,066] mass percent loss: 0.1095
[2023-06-24 12:45:27,066] fat loss: 2.9789
[2023-06-24 12:45:27,066] fat percent loss: 0.2346
[2023-06-24 12:45:27,066] carb loss: 3.6695
[2023-06-24 12:45:27,067] carb percent loss: 0.1901
[2023-06-24 12:45:27,067] protein loss: 3.4437
[2023-06-24 12:45:27,067] protein percent loss: 0.1903
[2023-06-24 12:45:27,067] ingrs percent loss: 0.2494
[2023-06-24 12:45:27,067] Epoch 46/150
[2023-06-24 12:45:36,541] test loss: 1.6579
[2023-06-24 12:45:36,542] cal loss: 55.1037
[2023-06-24 12:45:36,542] cal percent loss: 0.2161
[2023-06-24 12:45:36,542] mass loss: 33.1331
[2023-06-24 12:45:36,542] mass percent loss: 0.1520
[2023-06-24 12:45:36,542] fat loss: 3.9042
[2023-06-24 12:45:36,543] fat percent loss: 0.3074
[2023-06-24 12:45:36,543] carb loss: 6.3582
[2023-06-24 12:45:36,543] carb percent loss: 0.3294
[2023-06-24 12:45:36,543] protein loss: 5.4477
[2023-06-24 12:45:36,543] protein percent loss: 0.3010
[2023-06-24 12:45:36,543] ingrs percent loss: 0.3592
[2023-06-24 12:45:36,543] Epoch 47/150
[2023-06-24 12:47:37,797] train loss: 1.0651
[2023-06-24 12:47:37,798] cal loss: 34.6285
[2023-06-24 12:47:37,798] cal percent loss: 0.1358
[2023-06-24 12:47:37,798] mass loss: 24.7287
[2023-06-24 12:47:37,798] mass percent loss: 0.1134
[2023-06-24 12:47:37,798] fat loss: 2.7193
[2023-06-24 12:47:37,799] fat percent loss: 0.2141
[2023-06-24 12:47:37,799] carb loss: 3.5161
[2023-06-24 12:47:37,799] carb percent loss: 0.1822
[2023-06-24 12:47:37,799] protein loss: 3.1549
[2023-06-24 12:47:37,799] protein percent loss: 0.1743
[2023-06-24 12:47:37,799] ingrs percent loss: 0.2399
[2023-06-24 12:47:37,799] Epoch 47/150
[2023-06-24 12:47:46,670] test loss: 1.5565
[2023-06-24 12:47:46,671] cal loss: 52.6054
[2023-06-24 12:47:46,671] cal percent loss: 0.2063
[2023-06-24 12:47:46,671] mass loss: 28.9395
[2023-06-24 12:47:46,671] mass percent loss: 0.1327
[2023-06-24 12:47:46,671] fat loss: 3.7621
[2023-06-24 12:47:46,672] fat percent loss: 0.2962
[2023-06-24 12:47:46,672] carb loss: 5.9117
[2023-06-24 12:47:46,672] carb percent loss: 0.3063
[2023-06-24 12:47:46,672] protein loss: 4.7619
[2023-06-24 12:47:46,672] protein percent loss: 0.2631
[2023-06-24 12:47:46,672] ingrs percent loss: 0.3593
[2023-06-24 12:47:46,672] Epoch 48/150
[2023-06-24 12:49:45,950] train loss: 1.0596
[2023-06-24 12:49:45,951] cal loss: 35.7663
[2023-06-24 12:49:45,951] cal percent loss: 0.1403
[2023-06-24 12:49:45,951] mass loss: 23.6531
[2023-06-24 12:49:45,951] mass percent loss: 0.1085
[2023-06-24 12:49:45,951] fat loss: 2.6435
[2023-06-24 12:49:45,951] fat percent loss: 0.2081
[2023-06-24 12:49:45,952] carb loss: 3.5335
[2023-06-24 12:49:45,952] carb percent loss: 0.1831
[2023-06-24 12:49:45,952] protein loss: 3.2408
[2023-06-24 12:49:45,952] protein percent loss: 0.1790
[2023-06-24 12:49:45,952] ingrs percent loss: 0.2364
[2023-06-24 12:49:45,952] Epoch 48/150
[2023-06-24 12:49:55,308] test loss: 1.6588
[2023-06-24 12:49:55,309] cal loss: 55.5928
[2023-06-24 12:49:55,309] cal percent loss: 0.2180
[2023-06-24 12:49:55,309] mass loss: 35.4478
[2023-06-24 12:49:55,309] mass percent loss: 0.1626
[2023-06-24 12:49:55,309] fat loss: 4.0225
[2023-06-24 12:49:55,309] fat percent loss: 0.3167
[2023-06-24 12:49:55,310] carb loss: 6.4651
[2023-06-24 12:49:55,310] carb percent loss: 0.3350
[2023-06-24 12:49:55,310] protein loss: 4.8214
[2023-06-24 12:49:55,310] protein percent loss: 0.2664
[2023-06-24 12:49:55,310] ingrs percent loss: 0.3610
[2023-06-24 12:49:55,310] Epoch 49/150
[2023-06-24 12:52:01,142] train loss: 1.0378
[2023-06-24 12:52:01,143] cal loss: 33.5872
[2023-06-24 12:52:01,143] cal percent loss: 0.1317
[2023-06-24 12:52:01,143] mass loss: 22.8523
[2023-06-24 12:52:01,143] mass percent loss: 0.1048
[2023-06-24 12:52:01,144] fat loss: 2.6426
[2023-06-24 12:52:01,144] fat percent loss: 0.2081
[2023-06-24 12:52:01,144] carb loss: 3.5849
[2023-06-24 12:52:01,144] carb percent loss: 0.1857
[2023-06-24 12:52:01,144] protein loss: 3.0931
[2023-06-24 12:52:01,144] protein percent loss: 0.1709
[2023-06-24 12:52:01,144] ingrs percent loss: 0.2346
[2023-06-24 12:52:01,144] Epoch 49/150
[2023-06-24 12:52:11,040] test loss: 1.6157
[2023-06-24 12:52:11,041] cal loss: 53.7620
[2023-06-24 12:52:11,041] cal percent loss: 0.2108
[2023-06-24 12:52:11,041] mass loss: 29.2055
[2023-06-24 12:52:11,042] mass percent loss: 0.1340
[2023-06-24 12:52:11,042] fat loss: 3.9625
[2023-06-24 12:52:11,042] fat percent loss: 0.3120
[2023-06-24 12:52:11,042] carb loss: 5.8593
[2023-06-24 12:52:11,042] carb percent loss: 0.3036
[2023-06-24 12:52:11,042] protein loss: 5.1796
[2023-06-24 12:52:11,042] protein percent loss: 0.2862
[2023-06-24 12:52:11,042] ingrs percent loss: 0.3784
[2023-06-24 12:52:11,043] Epoch 50/150
[2023-06-24 12:54:06,633] train loss: 1.0573
[2023-06-24 12:54:06,634] cal loss: 34.3050
[2023-06-24 12:54:06,634] cal percent loss: 0.1345
[2023-06-24 12:54:06,634] mass loss: 23.3654
[2023-06-24 12:54:06,634] mass percent loss: 0.1072
[2023-06-24 12:54:06,634] fat loss: 2.5286
[2023-06-24 12:54:06,634] fat percent loss: 0.1991
[2023-06-24 12:54:06,634] carb loss: 3.5149
[2023-06-24 12:54:06,634] carb percent loss: 0.1821
[2023-06-24 12:54:06,635] protein loss: 3.2656
[2023-06-24 12:54:06,635] protein percent loss: 0.1804
[2023-06-24 12:54:06,635] ingrs percent loss: 0.2508
[2023-06-24 12:54:06,635] Epoch 50/150
[2023-06-24 12:54:16,365] test loss: 1.7675
[2023-06-24 12:54:16,366] cal loss: 60.4277
[2023-06-24 12:54:16,366] cal percent loss: 0.2370
[2023-06-24 12:54:16,366] mass loss: 43.7971
[2023-06-24 12:54:16,366] mass percent loss: 0.2009
[2023-06-24 12:54:16,366] fat loss: 4.2385
[2023-06-24 12:54:16,366] fat percent loss: 0.3337
[2023-06-24 12:54:16,366] carb loss: 6.3743
[2023-06-24 12:54:16,367] carb percent loss: 0.3303
[2023-06-24 12:54:16,367] protein loss: 5.0323
[2023-06-24 12:54:16,367] protein percent loss: 0.2780
[2023-06-24 12:54:16,367] ingrs percent loss: 0.3742
[2023-06-24 12:54:16,367] Epoch 51/150
[2023-06-24 12:56:18,103] train loss: 1.0341
[2023-06-24 12:56:18,104] cal loss: 32.6934
[2023-06-24 12:56:18,104] cal percent loss: 0.1282
[2023-06-24 12:56:18,104] mass loss: 23.8932
[2023-06-24 12:56:18,104] mass percent loss: 0.1096
[2023-06-24 12:56:18,105] fat loss: 2.5255
[2023-06-24 12:56:18,105] fat percent loss: 0.1989
[2023-06-24 12:56:18,105] carb loss: 3.4574
[2023-06-24 12:56:18,105] carb percent loss: 0.1791
[2023-06-24 12:56:18,105] protein loss: 2.9980
[2023-06-24 12:56:18,105] protein percent loss: 0.1656
[2023-06-24 12:56:18,105] ingrs percent loss: 0.2476
[2023-06-24 12:56:18,105] Epoch 51/150
[2023-06-24 12:56:26,996] test loss: 1.5699
[2023-06-24 12:56:26,997] cal loss: 55.5567
[2023-06-24 12:56:26,997] cal percent loss: 0.2179
[2023-06-24 12:56:26,997] mass loss: 27.6437
[2023-06-24 12:56:26,997] mass percent loss: 0.1268
[2023-06-24 12:56:26,997] fat loss: 3.9049
[2023-06-24 12:56:26,997] fat percent loss: 0.3075
[2023-06-24 12:56:26,997] carb loss: 5.7955
[2023-06-24 12:56:26,998] carb percent loss: 0.3003
[2023-06-24 12:56:26,998] protein loss: 4.7605
[2023-06-24 12:56:26,998] protein percent loss: 0.2630
[2023-06-24 12:56:26,998] ingrs percent loss: 0.3619
[2023-06-24 12:56:26,998] Epoch 52/150
[2023-06-24 12:58:29,911] train loss: 1.0768
[2023-06-24 12:58:29,912] cal loss: 35.4151
[2023-06-24 12:58:29,912] cal percent loss: 0.1389
[2023-06-24 12:58:29,912] mass loss: 24.5479
[2023-06-24 12:58:29,912] mass percent loss: 0.1126
[2023-06-24 12:58:29,912] fat loss: 2.7209
[2023-06-24 12:58:29,912] fat percent loss: 0.2142
[2023-06-24 12:58:29,912] carb loss: 3.5446
[2023-06-24 12:58:29,913] carb percent loss: 0.1837
[2023-06-24 12:58:29,913] protein loss: 3.3191
[2023-06-24 12:58:29,913] protein percent loss: 0.1834
[2023-06-24 12:58:29,913] ingrs percent loss: 0.2396
[2023-06-24 12:58:29,913] Epoch 52/150
[2023-06-24 12:58:38,704] test loss: 1.5780
[2023-06-24 12:58:38,705] cal loss: 50.7813
[2023-06-24 12:58:38,705] cal percent loss: 0.1991
[2023-06-24 12:58:38,705] mass loss: 32.9558
[2023-06-24 12:58:38,705] mass percent loss: 0.1512
[2023-06-24 12:58:38,705] fat loss: 3.7388
[2023-06-24 12:58:38,705] fat percent loss: 0.2944
[2023-06-24 12:58:38,705] carb loss: 5.7255
[2023-06-24 12:58:38,705] carb percent loss: 0.2967
[2023-06-24 12:58:38,705] protein loss: 4.7934
[2023-06-24 12:58:38,705] protein percent loss: 0.2648
[2023-06-24 12:58:38,705] ingrs percent loss: 0.3729
[2023-06-24 12:58:38,705] Epoch 53/150
[2023-06-24 13:00:43,272] train loss: 1.0740
[2023-06-24 13:00:43,273] cal loss: 36.2995
[2023-06-24 13:00:43,273] cal percent loss: 0.1424
[2023-06-24 13:00:43,273] mass loss: 24.3229
[2023-06-24 13:00:43,273] mass percent loss: 0.1116
[2023-06-24 13:00:43,273] fat loss: 2.7644
[2023-06-24 13:00:43,273] fat percent loss: 0.2177
[2023-06-24 13:00:43,274] carb loss: 3.4268
[2023-06-24 13:00:43,274] carb percent loss: 0.1776
[2023-06-24 13:00:43,274] protein loss: 3.3477
[2023-06-24 13:00:43,274] protein percent loss: 0.1850
[2023-06-24 13:00:43,274] ingrs percent loss: 0.2349
[2023-06-24 13:00:43,274] Epoch 53/150
[2023-06-24 13:00:52,940] test loss: 1.6672
[2023-06-24 13:00:52,941] cal loss: 59.2604
[2023-06-24 13:00:52,941] cal percent loss: 0.2324
[2023-06-24 13:00:52,942] mass loss: 32.6188
[2023-06-24 13:00:52,942] mass percent loss: 0.1496
[2023-06-24 13:00:52,942] fat loss: 4.0553
[2023-06-24 13:00:52,942] fat percent loss: 0.3193
[2023-06-24 13:00:52,942] carb loss: 5.8611
[2023-06-24 13:00:52,942] carb percent loss: 0.3037
[2023-06-24 13:00:52,942] protein loss: 5.5370
[2023-06-24 13:00:52,942] protein percent loss: 0.3059
[2023-06-24 13:00:52,942] ingrs percent loss: 0.3593
[2023-06-24 13:00:52,943] Epoch 54/150
[2023-06-24 13:02:50,914] train loss: 1.0394
[2023-06-24 13:02:50,915] cal loss: 34.2963
[2023-06-24 13:02:50,915] cal percent loss: 0.1345
[2023-06-24 13:02:50,915] mass loss: 24.6530
[2023-06-24 13:02:50,915] mass percent loss: 0.1131
[2023-06-24 13:02:50,915] fat loss: 2.5264
[2023-06-24 13:02:50,915] fat percent loss: 0.1989
[2023-06-24 13:02:50,915] carb loss: 3.4437
[2023-06-24 13:02:50,915] carb percent loss: 0.1784
[2023-06-24 13:02:50,915] protein loss: 3.1879
[2023-06-24 13:02:50,915] protein percent loss: 0.1761
[2023-06-24 13:02:50,915] ingrs percent loss: 0.2322
[2023-06-24 13:02:50,916] Epoch 54/150
[2023-06-24 13:02:59,879] test loss: 1.5694
[2023-06-24 13:02:59,880] cal loss: 50.9331
[2023-06-24 13:02:59,880] cal percent loss: 0.1997
[2023-06-24 13:02:59,880] mass loss: 31.4427
[2023-06-24 13:02:59,880] mass percent loss: 0.1442
[2023-06-24 13:02:59,880] fat loss: 3.6762
[2023-06-24 13:02:59,881] fat percent loss: 0.2895
[2023-06-24 13:02:59,881] carb loss: 5.7196
[2023-06-24 13:02:59,881] carb percent loss: 0.2964
[2023-06-24 13:02:59,881] protein loss: 4.6007
[2023-06-24 13:02:59,881] protein percent loss: 0.2542
[2023-06-24 13:02:59,881] ingrs percent loss: 0.3874
[2023-06-24 13:02:59,881] Epoch 55/150
[2023-06-24 13:05:07,620] train loss: 1.0021
[2023-06-24 13:05:07,621] cal loss: 32.2183
[2023-06-24 13:05:07,621] cal percent loss: 0.1263
[2023-06-24 13:05:07,621] mass loss: 23.4609
[2023-06-24 13:05:07,621] mass percent loss: 0.1076
[2023-06-24 13:05:07,621] fat loss: 2.4604
[2023-06-24 13:05:07,621] fat percent loss: 0.1937
[2023-06-24 13:05:07,621] carb loss: 3.3241
[2023-06-24 13:05:07,621] carb percent loss: 0.1722
[2023-06-24 13:05:07,621] protein loss: 2.9957
[2023-06-24 13:05:07,621] protein percent loss: 0.1655
[2023-06-24 13:05:07,621] ingrs percent loss: 0.2314
[2023-06-24 13:05:07,621] Epoch 55/150
[2023-06-24 13:05:16,652] test loss: 1.5192
[2023-06-24 13:05:16,652] cal loss: 50.8376
[2023-06-24 13:05:16,652] cal percent loss: 0.1994
[2023-06-24 13:05:16,653] mass loss: 27.4612
[2023-06-24 13:05:16,653] mass percent loss: 0.1260
[2023-06-24 13:05:16,653] fat loss: 3.7036
[2023-06-24 13:05:16,653] fat percent loss: 0.2916
[2023-06-24 13:05:16,653] carb loss: 5.7270
[2023-06-24 13:05:16,653] carb percent loss: 0.2967
[2023-06-24 13:05:16,653] protein loss: 4.6504
[2023-06-24 13:05:16,653] protein percent loss: 0.2569
[2023-06-24 13:05:16,653] ingrs percent loss: 0.3573
[2023-06-24 13:05:16,654] Epoch 56/150
[2023-06-24 13:07:18,174] train loss: 1.0140
[2023-06-24 13:07:18,174] cal loss: 32.6405
[2023-06-24 13:07:18,174] cal percent loss: 0.1280
[2023-06-24 13:07:18,174] mass loss: 22.2003
[2023-06-24 13:07:18,175] mass percent loss: 0.1018
[2023-06-24 13:07:18,175] fat loss: 2.5531
[2023-06-24 13:07:18,175] fat percent loss: 0.2010
[2023-06-24 13:07:18,175] carb loss: 3.4043
[2023-06-24 13:07:18,175] carb percent loss: 0.1764
[2023-06-24 13:07:18,175] protein loss: 3.0726
[2023-06-24 13:07:18,175] protein percent loss: 0.1698
[2023-06-24 13:07:18,175] ingrs percent loss: 0.2348
[2023-06-24 13:07:18,175] Epoch 56/150
[2023-06-24 13:07:27,513] test loss: 1.7997
[2023-06-24 13:07:27,514] cal loss: 64.2161
[2023-06-24 13:07:27,514] cal percent loss: 0.2518
[2023-06-24 13:07:27,514] mass loss: 43.6458
[2023-06-24 13:07:27,515] mass percent loss: 0.2002
[2023-06-24 13:07:27,515] fat loss: 4.2360
[2023-06-24 13:07:27,515] fat percent loss: 0.3335
[2023-06-24 13:07:27,515] carb loss: 5.9932
[2023-06-24 13:07:27,515] carb percent loss: 0.3105
[2023-06-24 13:07:27,515] protein loss: 5.7956
[2023-06-24 13:07:27,515] protein percent loss: 0.3202
[2023-06-24 13:07:27,515] ingrs percent loss: 0.3696
[2023-06-24 13:07:27,515] Epoch 57/150
[2023-06-24 13:09:26,655] train loss: 1.0411
[2023-06-24 13:09:26,656] cal loss: 35.4895
[2023-06-24 13:09:26,656] cal percent loss: 0.1392
[2023-06-24 13:09:26,656] mass loss: 23.4696
[2023-06-24 13:09:26,656] mass percent loss: 0.1077
[2023-06-24 13:09:26,656] fat loss: 2.6047
[2023-06-24 13:09:26,656] fat percent loss: 0.2051
[2023-06-24 13:09:26,657] carb loss: 3.3755
[2023-06-24 13:09:26,657] carb percent loss: 0.1749
[2023-06-24 13:09:26,657] protein loss: 3.2496
[2023-06-24 13:09:26,657] protein percent loss: 0.1795
[2023-06-24 13:09:26,657] ingrs percent loss: 0.2299
[2023-06-24 13:09:26,657] Epoch 57/150
[2023-06-24 13:09:35,574] test loss: 1.5718
[2023-06-24 13:09:35,575] cal loss: 49.4841
[2023-06-24 13:09:35,575] cal percent loss: 0.1941
[2023-06-24 13:09:35,575] mass loss: 29.6568
[2023-06-24 13:09:35,575] mass percent loss: 0.1360
[2023-06-24 13:09:35,575] fat loss: 3.8982
[2023-06-24 13:09:35,575] fat percent loss: 0.3069
[2023-06-24 13:09:35,575] carb loss: 5.7569
[2023-06-24 13:09:35,576] carb percent loss: 0.2983
[2023-06-24 13:09:35,576] protein loss: 5.1104
[2023-06-24 13:09:35,576] protein percent loss: 0.2823
[2023-06-24 13:09:35,576] ingrs percent loss: 0.3639
[2023-06-24 13:09:35,576] Epoch 58/150
[2023-06-24 13:11:36,772] train loss: 0.9688
[2023-06-24 13:11:36,772] cal loss: 31.0925
[2023-06-24 13:11:36,772] cal percent loss: 0.1219
[2023-06-24 13:11:36,773] mass loss: 20.8819
[2023-06-24 13:11:36,773] mass percent loss: 0.0958
[2023-06-24 13:11:36,773] fat loss: 2.5180
[2023-06-24 13:11:36,773] fat percent loss: 0.1983
[2023-06-24 13:11:36,773] carb loss: 3.0988
[2023-06-24 13:11:36,773] carb percent loss: 0.1606
[2023-06-24 13:11:36,773] protein loss: 2.8847
[2023-06-24 13:11:36,773] protein percent loss: 0.1594
[2023-06-24 13:11:36,773] ingrs percent loss: 0.2304
[2023-06-24 13:11:36,773] Epoch 58/150
[2023-06-24 13:11:45,402] test loss: 1.5437
[2023-06-24 13:11:45,403] cal loss: 47.9901
[2023-06-24 13:11:45,403] cal percent loss: 0.1882
[2023-06-24 13:11:45,403] mass loss: 32.7245
[2023-06-24 13:11:45,403] mass percent loss: 0.1501
[2023-06-24 13:11:45,404] fat loss: 3.7578
[2023-06-24 13:11:45,404] fat percent loss: 0.2959
[2023-06-24 13:11:45,404] carb loss: 5.4958
[2023-06-24 13:11:45,404] carb percent loss: 0.2848
[2023-06-24 13:11:45,404] protein loss: 4.8380
[2023-06-24 13:11:45,404] protein percent loss: 0.2673
[2023-06-24 13:11:45,404] ingrs percent loss: 0.3594
[2023-06-24 13:11:45,405] Epoch 59/150
[2023-06-24 13:13:40,452] train loss: 0.9445
[2023-06-24 13:13:40,452] cal loss: 30.4879
[2023-06-24 13:13:40,453] cal percent loss: 0.1196
[2023-06-24 13:13:40,453] mass loss: 21.3295
[2023-06-24 13:13:40,453] mass percent loss: 0.0978
[2023-06-24 13:13:40,453] fat loss: 2.3036
[2023-06-24 13:13:40,453] fat percent loss: 0.1814
[2023-06-24 13:13:40,453] carb loss: 3.1860
[2023-06-24 13:13:40,453] carb percent loss: 0.1651
[2023-06-24 13:13:40,453] protein loss: 2.7841
[2023-06-24 13:13:40,454] protein percent loss: 0.1538
[2023-06-24 13:13:40,454] ingrs percent loss: 0.2231
[2023-06-24 13:13:40,454] Epoch 59/150
[2023-06-24 13:13:49,118] test loss: 1.5065
[2023-06-24 13:13:49,119] cal loss: 46.2269
[2023-06-24 13:13:49,119] cal percent loss: 0.1813
[2023-06-24 13:13:49,119] mass loss: 29.6510
[2023-06-24 13:13:49,119] mass percent loss: 0.1360
[2023-06-24 13:13:49,120] fat loss: 3.5001
[2023-06-24 13:13:49,120] fat percent loss: 0.2756
[2023-06-24 13:13:49,120] carb loss: 5.4081
[2023-06-24 13:13:49,120] carb percent loss: 0.2802
[2023-06-24 13:13:49,121] protein loss: 5.0375
[2023-06-24 13:13:49,121] protein percent loss: 0.2783
[2023-06-24 13:13:49,121] ingrs percent loss: 0.3624
[2023-06-24 13:13:49,121] Epoch 60/150
[2023-06-24 13:15:46,899] train loss: 0.9289
[2023-06-24 13:15:46,899] cal loss: 30.6711
[2023-06-24 13:15:46,900] cal percent loss: 0.1203
[2023-06-24 13:15:46,900] mass loss: 20.3773
[2023-06-24 13:15:46,900] mass percent loss: 0.0935
[2023-06-24 13:15:46,900] fat loss: 2.2618
[2023-06-24 13:15:46,900] fat percent loss: 0.1781
[2023-06-24 13:15:46,900] carb loss: 3.0266
[2023-06-24 13:15:46,900] carb percent loss: 0.1568
[2023-06-24 13:15:46,900] protein loss: 2.8185
[2023-06-24 13:15:46,900] protein percent loss: 0.1557
[2023-06-24 13:15:46,900] ingrs percent loss: 0.2211
[2023-06-24 13:15:46,900] Epoch 60/150
[2023-06-24 13:15:55,895] test loss: 1.5216
[2023-06-24 13:15:55,896] cal loss: 47.2530
[2023-06-24 13:15:55,896] cal percent loss: 0.1853
[2023-06-24 13:15:55,896] mass loss: 27.6445
[2023-06-24 13:15:55,896] mass percent loss: 0.1268
[2023-06-24 13:15:55,897] fat loss: 3.6561
[2023-06-24 13:15:55,897] fat percent loss: 0.2879
[2023-06-24 13:15:55,897] carb loss: 6.0548
[2023-06-24 13:15:55,897] carb percent loss: 0.3137
[2023-06-24 13:15:55,897] protein loss: 4.7108
[2023-06-24 13:15:55,897] protein percent loss: 0.2603
[2023-06-24 13:15:55,897] ingrs percent loss: 0.3606
[2023-06-24 13:15:55,897] Epoch 61/150
[2023-06-24 13:17:54,239] train loss: 0.9201
[2023-06-24 13:17:54,240] cal loss: 29.1245
[2023-06-24 13:17:54,240] cal percent loss: 0.1142
[2023-06-24 13:17:54,240] mass loss: 21.0875
[2023-06-24 13:17:54,240] mass percent loss: 0.0967
[2023-06-24 13:17:54,240] fat loss: 2.2609
[2023-06-24 13:17:54,240] fat percent loss: 0.1780
[2023-06-24 13:17:54,240] carb loss: 3.0234
[2023-06-24 13:17:54,240] carb percent loss: 0.1567
[2023-06-24 13:17:54,240] protein loss: 2.6745
[2023-06-24 13:17:54,240] protein percent loss: 0.1478
[2023-06-24 13:17:54,240] ingrs percent loss: 0.2222
[2023-06-24 13:17:54,241] Epoch 61/150
[2023-06-24 13:18:04,064] test loss: 1.7045
[2023-06-24 13:18:04,065] cal loss: 54.4726
[2023-06-24 13:18:04,065] cal percent loss: 0.2136
[2023-06-24 13:18:04,066] mass loss: 38.3965
[2023-06-24 13:18:04,066] mass percent loss: 0.1761
[2023-06-24 13:18:04,066] fat loss: 3.8570
[2023-06-24 13:18:04,066] fat percent loss: 0.3037
[2023-06-24 13:18:04,066] carb loss: 7.1847
[2023-06-24 13:18:04,066] carb percent loss: 0.3723
[2023-06-24 13:18:04,066] protein loss: 4.7190
[2023-06-24 13:18:04,066] protein percent loss: 0.2607
[2023-06-24 13:18:04,067] ingrs percent loss: 0.3788
[2023-06-24 13:18:04,067] Epoch 62/150
[2023-06-24 13:20:05,813] train loss: 0.9418
[2023-06-24 13:20:05,814] cal loss: 30.5048
[2023-06-24 13:20:05,814] cal percent loss: 0.1196
[2023-06-24 13:20:05,814] mass loss: 20.7363
[2023-06-24 13:20:05,814] mass percent loss: 0.0951
[2023-06-24 13:20:05,814] fat loss: 2.2947
[2023-06-24 13:20:05,814] fat percent loss: 0.1807
[2023-06-24 13:20:05,814] carb loss: 3.1394
[2023-06-24 13:20:05,814] carb percent loss: 0.1627
[2023-06-24 13:20:05,814] protein loss: 2.9335
[2023-06-24 13:20:05,815] protein percent loss: 0.1621
[2023-06-24 13:20:05,815] ingrs percent loss: 0.2193
[2023-06-24 13:20:05,815] Epoch 62/150
[2023-06-24 13:20:15,620] test loss: 1.6188
[2023-06-24 13:20:15,620] cal loss: 54.2248
[2023-06-24 13:20:15,620] cal percent loss: 0.2126
[2023-06-24 13:20:15,620] mass loss: 31.0305
[2023-06-24 13:20:15,621] mass percent loss: 0.1423
[2023-06-24 13:20:15,621] fat loss: 4.0681
[2023-06-24 13:20:15,621] fat percent loss: 0.3203
[2023-06-24 13:20:15,621] carb loss: 5.5489
[2023-06-24 13:20:15,621] carb percent loss: 0.2875
[2023-06-24 13:20:15,621] protein loss: 5.4489
[2023-06-24 13:20:15,621] protein percent loss: 0.3010
[2023-06-24 13:20:15,621] ingrs percent loss: 0.3609
[2023-06-24 13:20:15,621] Epoch 63/150
[2023-06-24 13:22:21,754] train loss: 0.9511
[2023-06-24 13:22:21,755] cal loss: 29.9028
[2023-06-24 13:22:21,755] cal percent loss: 0.1173
[2023-06-24 13:22:21,755] mass loss: 22.7464
[2023-06-24 13:22:21,755] mass percent loss: 0.1043
[2023-06-24 13:22:21,755] fat loss: 2.3028
[2023-06-24 13:22:21,755] fat percent loss: 0.1813
[2023-06-24 13:22:21,755] carb loss: 3.2082
[2023-06-24 13:22:21,755] carb percent loss: 0.1662
[2023-06-24 13:22:21,755] protein loss: 2.8373
[2023-06-24 13:22:21,755] protein percent loss: 0.1568
[2023-06-24 13:22:21,755] ingrs percent loss: 0.2201
[2023-06-24 13:22:21,755] Epoch 63/150
[2023-06-24 13:22:31,399] test loss: 1.8013
[2023-06-24 13:22:31,400] cal loss: 61.8779
[2023-06-24 13:22:31,400] cal percent loss: 0.2427
[2023-06-24 13:22:31,400] mass loss: 45.1940
[2023-06-24 13:22:31,401] mass percent loss: 0.2073
[2023-06-24 13:22:31,401] fat loss: 4.3715
[2023-06-24 13:22:31,401] fat percent loss: 0.3442
[2023-06-24 13:22:31,401] carb loss: 6.3447
[2023-06-24 13:22:31,401] carb percent loss: 0.3287
[2023-06-24 13:22:31,401] protein loss: 5.4991
[2023-06-24 13:22:31,401] protein percent loss: 0.3038
[2023-06-24 13:22:31,401] ingrs percent loss: 0.3611
[2023-06-24 13:22:31,402] Epoch 64/150
[2023-06-24 13:24:30,011] train loss: 0.8825
[2023-06-24 13:24:30,012] cal loss: 29.1609
[2023-06-24 13:24:30,012] cal percent loss: 0.1144
[2023-06-24 13:24:30,012] mass loss: 19.6755
[2023-06-24 13:24:30,012] mass percent loss: 0.0903
[2023-06-24 13:24:30,012] fat loss: 2.1544
[2023-06-24 13:24:30,012] fat percent loss: 0.1696
[2023-06-24 13:24:30,012] carb loss: 2.7749
[2023-06-24 13:24:30,012] carb percent loss: 0.1438
[2023-06-24 13:24:30,013] protein loss: 2.5594
[2023-06-24 13:24:30,013] protein percent loss: 0.1414
[2023-06-24 13:24:30,015] ingrs percent loss: 0.2180
[2023-06-24 13:24:30,015] Epoch 64/150
[2023-06-24 13:24:39,493] test loss: 1.5583
[2023-06-24 13:24:39,494] cal loss: 49.6407
[2023-06-24 13:24:39,494] cal percent loss: 0.1947
[2023-06-24 13:24:39,495] mass loss: 28.5282
[2023-06-24 13:24:39,495] mass percent loss: 0.1309
[2023-06-24 13:24:39,495] fat loss: 4.2033
[2023-06-24 13:24:39,495] fat percent loss: 0.3310
[2023-06-24 13:24:39,495] carb loss: 5.8612
[2023-06-24 13:24:39,495] carb percent loss: 0.3037
[2023-06-24 13:24:39,495] protein loss: 4.6255
[2023-06-24 13:24:39,495] protein percent loss: 0.2556
[2023-06-24 13:24:39,495] ingrs percent loss: 0.3532
[2023-06-24 13:24:39,496] Epoch 65/150
[2023-06-24 13:26:38,474] train loss: 0.8820
[2023-06-24 13:26:38,475] cal loss: 27.4965
[2023-06-24 13:26:38,475] cal percent loss: 0.1078
[2023-06-24 13:26:38,475] mass loss: 19.2668
[2023-06-24 13:26:38,475] mass percent loss: 0.0884
[2023-06-24 13:26:38,475] fat loss: 2.1832
[2023-06-24 13:26:38,475] fat percent loss: 0.1719
[2023-06-24 13:26:38,475] carb loss: 2.9506
[2023-06-24 13:26:38,475] carb percent loss: 0.1529
[2023-06-24 13:26:38,475] protein loss: 2.5328
[2023-06-24 13:26:38,476] protein percent loss: 0.1399
[2023-06-24 13:26:38,476] ingrs percent loss: 0.2188
[2023-06-24 13:26:38,476] Epoch 65/150
[2023-06-24 13:26:48,271] test loss: 1.5807
[2023-06-24 13:26:48,272] cal loss: 54.7514
[2023-06-24 13:26:48,272] cal percent loss: 0.2147
[2023-06-24 13:26:48,272] mass loss: 30.6638
[2023-06-24 13:26:48,272] mass percent loss: 0.1407
[2023-06-24 13:26:48,272] fat loss: 3.7931
[2023-06-24 13:26:48,272] fat percent loss: 0.2987
[2023-06-24 13:26:48,273] carb loss: 5.4085
[2023-06-24 13:26:48,273] carb percent loss: 0.2802
[2023-06-24 13:26:48,273] protein loss: 5.2821
[2023-06-24 13:26:48,273] protein percent loss: 0.2918
[2023-06-24 13:26:48,273] ingrs percent loss: 0.3578
[2023-06-24 13:26:48,274] Epoch 66/150
[2023-06-24 13:28:53,929] train loss: 0.8422
[2023-06-24 13:28:53,930] cal loss: 27.3834
[2023-06-24 13:28:53,930] cal percent loss: 0.1074
[2023-06-24 13:28:53,930] mass loss: 18.7986
[2023-06-24 13:28:53,930] mass percent loss: 0.0862
[2023-06-24 13:28:53,930] fat loss: 1.9875
[2023-06-24 13:28:53,930] fat percent loss: 0.1565
[2023-06-24 13:28:53,930] carb loss: 2.7569
[2023-06-24 13:28:53,930] carb percent loss: 0.1428
[2023-06-24 13:28:53,931] protein loss: 2.3840
[2023-06-24 13:28:53,931] protein percent loss: 0.1317
[2023-06-24 13:28:53,931] ingrs percent loss: 0.2129
[2023-06-24 13:28:53,931] Epoch 66/150
[2023-06-24 13:29:03,267] test loss: 1.7745
[2023-06-24 13:29:03,268] cal loss: 63.9567
[2023-06-24 13:29:03,268] cal percent loss: 0.2508
[2023-06-24 13:29:03,269] mass loss: 40.0327
[2023-06-24 13:29:03,269] mass percent loss: 0.1836
[2023-06-24 13:29:03,269] fat loss: 4.1770
[2023-06-24 13:29:03,269] fat percent loss: 0.3289
[2023-06-24 13:29:03,269] carb loss: 5.6596
[2023-06-24 13:29:03,269] carb percent loss: 0.2932
[2023-06-24 13:29:03,269] protein loss: 6.3359
[2023-06-24 13:29:03,269] protein percent loss: 0.3501
[2023-06-24 13:29:03,269] ingrs percent loss: 0.3603
[2023-06-24 13:29:03,269] Epoch 67/150
[2023-06-24 13:31:03,246] train loss: 0.8620
[2023-06-24 13:31:03,246] cal loss: 27.8318
[2023-06-24 13:31:03,247] cal percent loss: 0.1091
[2023-06-24 13:31:03,247] mass loss: 19.1064
[2023-06-24 13:31:03,247] mass percent loss: 0.0876
[2023-06-24 13:31:03,247] fat loss: 2.0941
[2023-06-24 13:31:03,247] fat percent loss: 0.1649
[2023-06-24 13:31:03,247] carb loss: 2.6867
[2023-06-24 13:31:03,247] carb percent loss: 0.1392
[2023-06-24 13:31:03,247] protein loss: 2.5412
[2023-06-24 13:31:03,247] protein percent loss: 0.1404
[2023-06-24 13:31:03,247] ingrs percent loss: 0.2163
[2023-06-24 13:31:03,247] Epoch 67/150
[2023-06-24 13:31:12,560] test loss: 1.5811
[2023-06-24 13:31:12,560] cal loss: 56.1934
[2023-06-24 13:31:12,561] cal percent loss: 0.2204
[2023-06-24 13:31:12,561] mass loss: 32.3610
[2023-06-24 13:31:12,561] mass percent loss: 0.1484
[2023-06-24 13:31:12,561] fat loss: 3.9328
[2023-06-24 13:31:12,561] fat percent loss: 0.3097
[2023-06-24 13:31:12,561] carb loss: 5.4257
[2023-06-24 13:31:12,561] carb percent loss: 0.2811
[2023-06-24 13:31:12,561] protein loss: 4.8730
[2023-06-24 13:31:12,561] protein percent loss: 0.2692
[2023-06-24 13:31:12,561] ingrs percent loss: 0.3503
[2023-06-24 13:31:12,561] Epoch 68/150
[2023-06-24 13:33:12,376] train loss: 0.8562
[2023-06-24 13:33:12,377] cal loss: 26.6222
[2023-06-24 13:33:12,377] cal percent loss: 0.1044
[2023-06-24 13:33:12,377] mass loss: 19.9457
[2023-06-24 13:33:12,377] mass percent loss: 0.0915
[2023-06-24 13:33:12,377] fat loss: 2.0153
[2023-06-24 13:33:12,377] fat percent loss: 0.1587
[2023-06-24 13:33:12,378] carb loss: 2.7776
[2023-06-24 13:33:12,378] carb percent loss: 0.1439
[2023-06-24 13:33:12,378] protein loss: 2.4904
[2023-06-24 13:33:12,378] protein percent loss: 0.1376
[2023-06-24 13:33:12,378] ingrs percent loss: 0.2151
[2023-06-24 13:33:12,378] Epoch 68/150
[2023-06-24 13:33:22,284] test loss: 1.5774
[2023-06-24 13:33:22,285] cal loss: 49.4794
[2023-06-24 13:33:22,285] cal percent loss: 0.1940
[2023-06-24 13:33:22,285] mass loss: 36.9057
[2023-06-24 13:33:22,286] mass percent loss: 0.1693
[2023-06-24 13:33:22,286] fat loss: 3.6719
[2023-06-24 13:33:22,286] fat percent loss: 0.2891
[2023-06-24 13:33:22,286] carb loss: 5.9634
[2023-06-24 13:33:22,286] carb percent loss: 0.3090
[2023-06-24 13:33:22,286] protein loss: 4.7523
[2023-06-24 13:33:22,286] protein percent loss: 0.2626
[2023-06-24 13:33:22,286] ingrs percent loss: 0.3504
[2023-06-24 13:33:22,287] Epoch 69/150
[2023-06-24 13:35:22,483] train loss: 0.8347
[2023-06-24 13:35:22,484] cal loss: 26.1213
[2023-06-24 13:35:22,484] cal percent loss: 0.1024
[2023-06-24 13:35:22,484] mass loss: 18.4126
[2023-06-24 13:35:22,484] mass percent loss: 0.0845
[2023-06-24 13:35:22,484] fat loss: 1.9644
[2023-06-24 13:35:22,484] fat percent loss: 0.1547
[2023-06-24 13:35:22,484] carb loss: 2.7363
[2023-06-24 13:35:22,484] carb percent loss: 0.1418
[2023-06-24 13:35:22,485] protein loss: 2.4529
[2023-06-24 13:35:22,485] protein percent loss: 0.1355
[2023-06-24 13:35:22,485] ingrs percent loss: 0.2128
[2023-06-24 13:35:22,485] Epoch 69/150
[2023-06-24 13:35:31,857] test loss: 1.4696
[2023-06-24 13:35:31,858] cal loss: 46.4279
[2023-06-24 13:35:31,858] cal percent loss: 0.1821
[2023-06-24 13:35:31,858] mass loss: 29.1225
[2023-06-24 13:35:31,858] mass percent loss: 0.1336
[2023-06-24 13:35:31,858] fat loss: 3.6269
[2023-06-24 13:35:31,858] fat percent loss: 0.2856
[2023-06-24 13:35:31,858] carb loss: 5.5627
[2023-06-24 13:35:31,858] carb percent loss: 0.2882
[2023-06-24 13:35:31,858] protein loss: 4.3190
[2023-06-24 13:35:31,859] protein percent loss: 0.2386
[2023-06-24 13:35:31,859] ingrs percent loss: 0.3469
[2023-06-24 13:35:31,859] Epoch 70/150
[2023-06-24 13:37:35,731] train loss: 0.8480
[2023-06-24 13:37:35,731] cal loss: 26.3361
[2023-06-24 13:37:35,732] cal percent loss: 0.1033
[2023-06-24 13:37:35,732] mass loss: 19.3465
[2023-06-24 13:37:35,732] mass percent loss: 0.0887
[2023-06-24 13:37:35,732] fat loss: 2.0242
[2023-06-24 13:37:35,732] fat percent loss: 0.1594
[2023-06-24 13:37:35,732] carb loss: 2.7212
[2023-06-24 13:37:35,732] carb percent loss: 0.1410
[2023-06-24 13:37:35,732] protein loss: 2.5411
[2023-06-24 13:37:35,732] protein percent loss: 0.1404
[2023-06-24 13:37:35,732] ingrs percent loss: 0.2112
[2023-06-24 13:37:35,732] Epoch 70/150
[2023-06-24 13:37:45,470] test loss: 1.4817
[2023-06-24 13:37:45,471] cal loss: 48.5704
[2023-06-24 13:37:45,471] cal percent loss: 0.1905
[2023-06-24 13:37:45,471] mass loss: 28.3810
[2023-06-24 13:37:45,471] mass percent loss: 0.1302
[2023-06-24 13:37:45,471] fat loss: 3.7076
[2023-06-24 13:37:45,471] fat percent loss: 0.2919
[2023-06-24 13:37:45,471] carb loss: 5.3634
[2023-06-24 13:37:45,471] carb percent loss: 0.2779
[2023-06-24 13:37:45,471] protein loss: 4.4571
[2023-06-24 13:37:45,471] protein percent loss: 0.2462
[2023-06-24 13:37:45,472] ingrs percent loss: 0.3499
[2023-06-24 13:37:45,472] Epoch 71/150
[2023-06-24 13:39:50,518] train loss: 0.8340
[2023-06-24 13:39:50,518] cal loss: 26.7001
[2023-06-24 13:39:50,518] cal percent loss: 0.1047
[2023-06-24 13:39:50,519] mass loss: 18.5202
[2023-06-24 13:39:50,519] mass percent loss: 0.0850
[2023-06-24 13:39:50,519] fat loss: 1.9956
[2023-06-24 13:39:50,519] fat percent loss: 0.1571
[2023-06-24 13:39:50,519] carb loss: 2.6223
[2023-06-24 13:39:50,519] carb percent loss: 0.1359
[2023-06-24 13:39:50,519] protein loss: 2.4930
[2023-06-24 13:39:50,519] protein percent loss: 0.1377
[2023-06-24 13:39:50,519] ingrs percent loss: 0.2097
[2023-06-24 13:39:50,520] Epoch 71/150
[2023-06-24 13:39:59,292] test loss: 1.6906
[2023-06-24 13:39:59,292] cal loss: 61.3877
[2023-06-24 13:39:59,293] cal percent loss: 0.2407
[2023-06-24 13:39:59,293] mass loss: 33.3638
[2023-06-24 13:39:59,293] mass percent loss: 0.1530
[2023-06-24 13:39:59,293] fat loss: 4.1588
[2023-06-24 13:39:59,293] fat percent loss: 0.3275
[2023-06-24 13:39:59,293] carb loss: 5.6054
[2023-06-24 13:39:59,293] carb percent loss: 0.2904
[2023-06-24 13:39:59,293] protein loss: 5.8859
[2023-06-24 13:39:59,294] protein percent loss: 0.3252
[2023-06-24 13:39:59,294] ingrs percent loss: 0.3551
[2023-06-24 13:39:59,294] Epoch 72/150
[2023-06-24 13:41:55,088] train loss: 0.8051
[2023-06-24 13:41:55,089] cal loss: 25.2584
[2023-06-24 13:41:55,089] cal percent loss: 0.0991
[2023-06-24 13:41:55,090] mass loss: 18.7410
[2023-06-24 13:41:55,090] mass percent loss: 0.0860
[2023-06-24 13:41:55,090] fat loss: 1.8742
[2023-06-24 13:41:55,090] fat percent loss: 0.1476
[2023-06-24 13:41:55,090] carb loss: 2.5601
[2023-06-24 13:41:55,090] carb percent loss: 0.1326
[2023-06-24 13:41:55,090] protein loss: 2.3345
[2023-06-24 13:41:55,090] protein percent loss: 0.1290
[2023-06-24 13:41:55,090] ingrs percent loss: 0.2056
[2023-06-24 13:41:55,090] Epoch 72/150
[2023-06-24 13:42:04,771] test loss: 1.5005
[2023-06-24 13:42:04,772] cal loss: 47.9172
[2023-06-24 13:42:04,772] cal percent loss: 0.1879
[2023-06-24 13:42:04,772] mass loss: 27.5638
[2023-06-24 13:42:04,772] mass percent loss: 0.1264
[2023-06-24 13:42:04,773] fat loss: 3.6491
[2023-06-24 13:42:04,773] fat percent loss: 0.2873
[2023-06-24 13:42:04,773] carb loss: 5.5905
[2023-06-24 13:42:04,773] carb percent loss: 0.2897
[2023-06-24 13:42:04,773] protein loss: 4.9087
[2023-06-24 13:42:04,773] protein percent loss: 0.2712
[2023-06-24 13:42:04,773] ingrs percent loss: 0.3485
[2023-06-24 13:42:04,773] Epoch 73/150
[2023-06-24 13:44:03,982] train loss: 0.8018
[2023-06-24 13:44:03,983] cal loss: 25.2081
[2023-06-24 13:44:03,983] cal percent loss: 0.0989
[2023-06-24 13:44:03,983] mass loss: 18.7063
[2023-06-24 13:44:03,983] mass percent loss: 0.0858
[2023-06-24 13:44:03,983] fat loss: 1.8770
[2023-06-24 13:44:03,983] fat percent loss: 0.1478
[2023-06-24 13:44:03,984] carb loss: 2.5489
[2023-06-24 13:44:03,984] carb percent loss: 0.1321
[2023-06-24 13:44:03,984] protein loss: 2.3236
[2023-06-24 13:44:03,984] protein percent loss: 0.1284
[2023-06-24 13:44:03,984] ingrs percent loss: 0.2035
[2023-06-24 13:44:03,984] Epoch 73/150
[2023-06-24 13:44:13,898] test loss: 1.4663
[2023-06-24 13:44:13,899] cal loss: 47.9172
[2023-06-24 13:44:13,899] cal percent loss: 0.1879
[2023-06-24 13:44:13,899] mass loss: 27.0966
[2023-06-24 13:44:13,899] mass percent loss: 0.1243
[2023-06-24 13:44:13,900] fat loss: 3.6614
[2023-06-24 13:44:13,900] fat percent loss: 0.2883
[2023-06-24 13:44:13,900] carb loss: 5.2899
[2023-06-24 13:44:13,900] carb percent loss: 0.2741
[2023-06-24 13:44:13,900] protein loss: 4.4757
[2023-06-24 13:44:13,900] protein percent loss: 0.2473
[2023-06-24 13:44:13,900] ingrs percent loss: 0.3512
[2023-06-24 13:44:13,900] Epoch 74/150
[2023-06-24 13:46:13,303] train loss: 0.7904
[2023-06-24 13:46:13,304] cal loss: 24.9646
[2023-06-24 13:46:13,304] cal percent loss: 0.0979
[2023-06-24 13:46:13,304] mass loss: 17.4322
[2023-06-24 13:46:13,304] mass percent loss: 0.0800
[2023-06-24 13:46:13,304] fat loss: 1.8557
[2023-06-24 13:46:13,304] fat percent loss: 0.1461
[2023-06-24 13:46:13,304] carb loss: 2.5894
[2023-06-24 13:46:13,305] carb percent loss: 0.1342
[2023-06-24 13:46:13,305] protein loss: 2.2365
[2023-06-24 13:46:13,305] protein percent loss: 0.1236
[2023-06-24 13:46:13,305] ingrs percent loss: 0.2052
[2023-06-24 13:46:13,305] Epoch 74/150
[2023-06-24 13:46:22,489] test loss: 1.6468
[2023-06-24 13:46:22,490] cal loss: 57.0172
[2023-06-24 13:46:22,490] cal percent loss: 0.2236
[2023-06-24 13:46:22,490] mass loss: 38.7423
[2023-06-24 13:46:22,490] mass percent loss: 0.1777
[2023-06-24 13:46:22,491] fat loss: 4.0820
[2023-06-24 13:46:22,491] fat percent loss: 0.3214
[2023-06-24 13:46:22,491] carb loss: 5.3465
[2023-06-24 13:46:22,491] carb percent loss: 0.2770
[2023-06-24 13:46:22,491] protein loss: 5.0710
[2023-06-24 13:46:22,491] protein percent loss: 0.2802
[2023-06-24 13:46:22,491] ingrs percent loss: 0.3557
[2023-06-24 13:46:22,491] Epoch 75/150
[2023-06-24 13:48:24,008] train loss: 0.8087
[2023-06-24 13:48:24,009] cal loss: 25.9392
[2023-06-24 13:48:24,009] cal percent loss: 0.1017
[2023-06-24 13:48:24,009] mass loss: 18.2701
[2023-06-24 13:48:24,010] mass percent loss: 0.0838
[2023-06-24 13:48:24,010] fat loss: 1.9301
[2023-06-24 13:48:24,010] fat percent loss: 0.1520
[2023-06-24 13:48:24,010] carb loss: 2.4059
[2023-06-24 13:48:24,010] carb percent loss: 0.1247
[2023-06-24 13:48:24,010] protein loss: 2.4579
[2023-06-24 13:48:24,010] protein percent loss: 0.1358
[2023-06-24 13:48:24,010] ingrs percent loss: 0.2057
[2023-06-24 13:48:24,010] Epoch 75/150
[2023-06-24 13:48:33,650] test loss: 1.7050
[2023-06-24 13:48:33,650] cal loss: 61.2381
[2023-06-24 13:48:33,650] cal percent loss: 0.2401
[2023-06-24 13:48:33,651] mass loss: 42.1168
[2023-06-24 13:48:33,651] mass percent loss: 0.1932
[2023-06-24 13:48:33,651] fat loss: 4.4394
[2023-06-24 13:48:33,651] fat percent loss: 0.3496
[2023-06-24 13:48:33,651] carb loss: 5.6105
[2023-06-24 13:48:33,651] carb percent loss: 0.2907
[2023-06-24 13:48:33,651] protein loss: 4.7845
[2023-06-24 13:48:33,651] protein percent loss: 0.2643
[2023-06-24 13:48:33,651] ingrs percent loss: 0.3498
[2023-06-24 13:48:33,651] Epoch 76/150
[2023-06-24 13:50:33,896] train loss: 0.8114
[2023-06-24 13:50:33,897] cal loss: 25.7603
[2023-06-24 13:50:33,897] cal percent loss: 0.1010
[2023-06-24 13:50:33,897] mass loss: 18.5021
[2023-06-24 13:50:33,897] mass percent loss: 0.0849
[2023-06-24 13:50:33,897] fat loss: 2.0002
[2023-06-24 13:50:33,898] fat percent loss: 0.1575
[2023-06-24 13:50:33,898] carb loss: 2.4932
[2023-06-24 13:50:33,898] carb percent loss: 0.1292
[2023-06-24 13:50:33,898] protein loss: 2.3192
[2023-06-24 13:50:33,898] protein percent loss: 0.1281
[2023-06-24 13:50:33,898] ingrs percent loss: 0.2055
[2023-06-24 13:50:33,898] Epoch 76/150
[2023-06-24 13:50:43,485] test loss: 1.5171
[2023-06-24 13:50:43,486] cal loss: 54.6045
[2023-06-24 13:50:43,486] cal percent loss: 0.2141
[2023-06-24 13:50:43,486] mass loss: 25.1876
[2023-06-24 13:50:43,486] mass percent loss: 0.1155
[2023-06-24 13:50:43,486] fat loss: 4.0261
[2023-06-24 13:50:43,487] fat percent loss: 0.3170
[2023-06-24 13:50:43,487] carb loss: 5.3833
[2023-06-24 13:50:43,487] carb percent loss: 0.2789
[2023-06-24 13:50:43,487] protein loss: 4.5450
[2023-06-24 13:50:43,487] protein percent loss: 0.2511
[2023-06-24 13:50:43,487] ingrs percent loss: 0.3486
[2023-06-24 13:50:43,487] Epoch 77/150
[2023-06-24 13:52:36,520] train loss: 0.7651
[2023-06-24 13:52:36,521] cal loss: 24.7726
[2023-06-24 13:52:36,521] cal percent loss: 0.0971
[2023-06-24 13:52:36,521] mass loss: 17.6815
[2023-06-24 13:52:36,522] mass percent loss: 0.0811
[2023-06-24 13:52:36,522] fat loss: 1.7598
[2023-06-24 13:52:36,522] fat percent loss: 0.1386
[2023-06-24 13:52:36,522] carb loss: 2.3434
[2023-06-24 13:52:36,522] carb percent loss: 0.1214
[2023-06-24 13:52:36,522] protein loss: 2.1583
[2023-06-24 13:52:36,522] protein percent loss: 0.1192
[2023-06-24 13:52:36,522] ingrs percent loss: 0.2013
[2023-06-24 13:52:36,522] Epoch 77/150
[2023-06-24 13:52:46,220] test loss: 1.5670
[2023-06-24 13:52:46,220] cal loss: 54.1224
[2023-06-24 13:52:46,221] cal percent loss: 0.2122
[2023-06-24 13:52:46,221] mass loss: 31.4053
[2023-06-24 13:52:46,221] mass percent loss: 0.1441
[2023-06-24 13:52:46,221] fat loss: 3.7831
[2023-06-24 13:52:46,221] fat percent loss: 0.2979
[2023-06-24 13:52:46,221] carb loss: 5.2048
[2023-06-24 13:52:46,221] carb percent loss: 0.2697
[2023-06-24 13:52:46,221] protein loss: 5.2508
[2023-06-24 13:52:46,221] protein percent loss: 0.2901
[2023-06-24 13:52:46,221] ingrs percent loss: 0.3538
[2023-06-24 13:52:46,221] Epoch 78/150
[2023-06-24 13:54:50,152] train loss: 0.7595
[2023-06-24 13:54:50,153] cal loss: 22.9695
[2023-06-24 13:54:50,153] cal percent loss: 0.0901
[2023-06-24 13:54:50,153] mass loss: 17.8389
[2023-06-24 13:54:50,154] mass percent loss: 0.0818
[2023-06-24 13:54:50,154] fat loss: 1.7597
[2023-06-24 13:54:50,154] fat percent loss: 0.1386
[2023-06-24 13:54:50,154] carb loss: 2.4015
[2023-06-24 13:54:50,155] carb percent loss: 0.1244
[2023-06-24 13:54:50,155] protein loss: 2.1080
[2023-06-24 13:54:50,155] protein percent loss: 0.1165
[2023-06-24 13:54:50,156] ingrs percent loss: 0.2028
[2023-06-24 13:54:50,156] Epoch 78/150
[2023-06-24 13:55:00,271] test loss: 1.5910
[2023-06-24 13:55:00,272] cal loss: 50.6969
[2023-06-24 13:55:00,272] cal percent loss: 0.1988
[2023-06-24 13:55:00,273] mass loss: 38.7903
[2023-06-24 13:55:00,273] mass percent loss: 0.1779
[2023-06-24 13:55:00,273] fat loss: 3.5367
[2023-06-24 13:55:00,273] fat percent loss: 0.2785
[2023-06-24 13:55:00,273] carb loss: 5.9152
[2023-06-24 13:55:00,273] carb percent loss: 0.3065
[2023-06-24 13:55:00,273] protein loss: 4.9818
[2023-06-24 13:55:00,273] protein percent loss: 0.2752
[2023-06-24 13:55:00,273] ingrs percent loss: 0.3478
[2023-06-24 13:55:00,274] Epoch 79/150
[2023-06-24 13:57:01,917] train loss: 0.7727
[2023-06-24 13:57:01,918] cal loss: 24.5181
[2023-06-24 13:57:01,918] cal percent loss: 0.0961
[2023-06-24 13:57:01,918] mass loss: 17.6739
[2023-06-24 13:57:01,918] mass percent loss: 0.0811
[2023-06-24 13:57:01,918] fat loss: 1.8271
[2023-06-24 13:57:01,918] fat percent loss: 0.1439
[2023-06-24 13:57:01,919] carb loss: 2.3610
[2023-06-24 13:57:01,919] carb percent loss: 0.1223
[2023-06-24 13:57:01,919] protein loss: 2.1687
[2023-06-24 13:57:01,919] protein percent loss: 0.1198
[2023-06-24 13:57:01,919] ingrs percent loss: 0.2038
[2023-06-24 13:57:01,919] Epoch 79/150
[2023-06-24 13:57:11,048] test loss: 1.5643
[2023-06-24 13:57:11,048] cal loss: 55.9072
[2023-06-24 13:57:11,048] cal percent loss: 0.2192
[2023-06-24 13:57:11,049] mass loss: 30.8982
[2023-06-24 13:57:11,049] mass percent loss: 0.1417
[2023-06-24 13:57:11,049] fat loss: 3.7275
[2023-06-24 13:57:11,049] fat percent loss: 0.2935
[2023-06-24 13:57:11,049] carb loss: 5.6509
[2023-06-24 13:57:11,049] carb percent loss: 0.2928
[2023-06-24 13:57:11,049] protein loss: 4.8571
[2023-06-24 13:57:11,049] protein percent loss: 0.2683
[2023-06-24 13:57:11,050] ingrs percent loss: 0.3497
[2023-06-24 13:57:11,050] Epoch 80/150
[2023-06-24 13:59:01,625] train loss: 0.7901
[2023-06-24 13:59:01,626] cal loss: 25.7916
[2023-06-24 13:59:01,626] cal percent loss: 0.1011
[2023-06-24 13:59:01,626] mass loss: 18.4714
[2023-06-24 13:59:01,626] mass percent loss: 0.0847
[2023-06-24 13:59:01,627] fat loss: 1.8216
[2023-06-24 13:59:01,627] fat percent loss: 0.1434
[2023-06-24 13:59:01,627] carb loss: 2.4504
[2023-06-24 13:59:01,627] carb percent loss: 0.1270
[2023-06-24 13:59:01,627] protein loss: 2.2629
[2023-06-24 13:59:01,627] protein percent loss: 0.1250
[2023-06-24 13:59:01,627] ingrs percent loss: 0.2022
[2023-06-24 13:59:01,627] Epoch 80/150
[2023-06-24 13:59:10,108] test loss: 1.6653
[2023-06-24 13:59:10,108] cal loss: 61.2405
[2023-06-24 13:59:10,108] cal percent loss: 0.2402
[2023-06-24 13:59:10,108] mass loss: 35.4814
[2023-06-24 13:59:10,108] mass percent loss: 0.1628
[2023-06-24 13:59:10,109] fat loss: 4.1792
[2023-06-24 13:59:10,109] fat percent loss: 0.3291
[2023-06-24 13:59:10,109] carb loss: 5.6097
[2023-06-24 13:59:10,109] carb percent loss: 0.2907
[2023-06-24 13:59:10,109] protein loss: 5.0749
[2023-06-24 13:59:10,109] protein percent loss: 0.2804
[2023-06-24 13:59:10,109] ingrs percent loss: 0.3558
[2023-06-24 13:59:10,109] Epoch 81/150
[2023-06-24 14:01:13,864] train loss: 0.7663
[2023-06-24 14:01:13,864] cal loss: 24.3599
[2023-06-24 14:01:13,865] cal percent loss: 0.0955
[2023-06-24 14:01:13,865] mass loss: 16.6950
[2023-06-24 14:01:13,865] mass percent loss: 0.0766
[2023-06-24 14:01:13,865] fat loss: 1.7954
[2023-06-24 14:01:13,865] fat percent loss: 0.1414
[2023-06-24 14:01:13,865] carb loss: 2.3245
[2023-06-24 14:01:13,865] carb percent loss: 0.1204
[2023-06-24 14:01:13,865] protein loss: 2.0588
[2023-06-24 14:01:13,865] protein percent loss: 0.1137
[2023-06-24 14:01:13,865] ingrs percent loss: 0.2135
[2023-06-24 14:01:13,866] Epoch 81/150
[2023-06-24 14:01:23,374] test loss: 1.4417
[2023-06-24 14:01:23,374] cal loss: 48.1031
[2023-06-24 14:01:23,374] cal percent loss: 0.1886
[2023-06-24 14:01:23,374] mass loss: 26.8197
[2023-06-24 14:01:23,374] mass percent loss: 0.1230
[2023-06-24 14:01:23,374] fat loss: 3.6033
[2023-06-24 14:01:23,375] fat percent loss: 0.2837
[2023-06-24 14:01:23,375] carb loss: 5.1586
[2023-06-24 14:01:23,375] carb percent loss: 0.2673
[2023-06-24 14:01:23,375] protein loss: 4.4978
[2023-06-24 14:01:23,375] protein percent loss: 0.2485
[2023-06-24 14:01:23,375] ingrs percent loss: 0.3366
[2023-06-24 14:01:23,375] Epoch 82/150
[2023-06-24 14:03:19,244] train loss: 0.7292
[2023-06-24 14:03:19,244] cal loss: 22.5045
[2023-06-24 14:03:19,244] cal percent loss: 0.0883
[2023-06-24 14:03:19,244] mass loss: 16.8530
[2023-06-24 14:03:19,244] mass percent loss: 0.0773
[2023-06-24 14:03:19,244] fat loss: 1.6083
[2023-06-24 14:03:19,245] fat percent loss: 0.1266
[2023-06-24 14:03:19,245] carb loss: 2.2422
[2023-06-24 14:03:19,245] carb percent loss: 0.1162
[2023-06-24 14:03:19,245] protein loss: 2.1314
[2023-06-24 14:03:19,245] protein percent loss: 0.1178
[2023-06-24 14:03:19,245] ingrs percent loss: 0.1979
[2023-06-24 14:03:19,245] Epoch 82/150
[2023-06-24 14:03:29,284] test loss: 1.4801
[2023-06-24 14:03:29,285] cal loss: 48.5025
[2023-06-24 14:03:29,285] cal percent loss: 0.1902
[2023-06-24 14:03:29,285] mass loss: 30.1924
[2023-06-24 14:03:29,286] mass percent loss: 0.1385
[2023-06-24 14:03:29,286] fat loss: 3.5619
[2023-06-24 14:03:29,286] fat percent loss: 0.2805
[2023-06-24 14:03:29,286] carb loss: 5.3708
[2023-06-24 14:03:29,286] carb percent loss: 0.2783
[2023-06-24 14:03:29,286] protein loss: 4.4531
[2023-06-24 14:03:29,286] protein percent loss: 0.2460
[2023-06-24 14:03:29,287] ingrs percent loss: 0.3483
[2023-06-24 14:03:29,287] Epoch 83/150
[2023-06-24 14:05:30,167] train loss: 0.7227
[2023-06-24 14:05:30,168] cal loss: 21.8823
[2023-06-24 14:05:30,168] cal percent loss: 0.0858
[2023-06-24 14:05:30,168] mass loss: 16.9099
[2023-06-24 14:05:30,168] mass percent loss: 0.0776
[2023-06-24 14:05:30,168] fat loss: 1.6502
[2023-06-24 14:05:30,169] fat percent loss: 0.1299
[2023-06-24 14:05:30,169] carb loss: 2.2958
[2023-06-24 14:05:30,169] carb percent loss: 0.1190
[2023-06-24 14:05:30,169] protein loss: 1.8992
[2023-06-24 14:05:30,169] protein percent loss: 0.1049
[2023-06-24 14:05:30,169] ingrs percent loss: 0.1998
[2023-06-24 14:05:30,169] Epoch 83/150
[2023-06-24 14:05:39,757] test loss: 1.4699
[2023-06-24 14:05:39,758] cal loss: 48.3501
[2023-06-24 14:05:39,758] cal percent loss: 0.1896
[2023-06-24 14:05:39,758] mass loss: 30.6384
[2023-06-24 14:05:39,758] mass percent loss: 0.1405
[2023-06-24 14:05:39,758] fat loss: 3.5621
[2023-06-24 14:05:39,759] fat percent loss: 0.2805
[2023-06-24 14:05:39,759] carb loss: 5.1601
[2023-06-24 14:05:39,759] carb percent loss: 0.2674
[2023-06-24 14:05:39,759] protein loss: 4.3995
[2023-06-24 14:05:39,759] protein percent loss: 0.2431
[2023-06-24 14:05:39,759] ingrs percent loss: 0.3482
[2023-06-24 14:05:39,759] Epoch 84/150
[2023-06-24 14:07:38,986] train loss: 0.7261
[2023-06-24 14:07:38,986] cal loss: 22.6798
[2023-06-24 14:07:38,986] cal percent loss: 0.0889
[2023-06-24 14:07:38,986] mass loss: 16.9642
[2023-06-24 14:07:38,987] mass percent loss: 0.0778
[2023-06-24 14:07:38,987] fat loss: 1.6225
[2023-06-24 14:07:38,987] fat percent loss: 0.1278
[2023-06-24 14:07:38,987] carb loss: 2.2674
[2023-06-24 14:07:38,987] carb percent loss: 0.1175
[2023-06-24 14:07:38,987] protein loss: 1.9297
[2023-06-24 14:07:38,987] protein percent loss: 0.1066
[2023-06-24 14:07:38,987] ingrs percent loss: 0.2012
[2023-06-24 14:07:38,988] Epoch 84/150
[2023-06-24 14:07:48,218] test loss: 1.4695
[2023-06-24 14:07:48,219] cal loss: 47.7316
[2023-06-24 14:07:48,219] cal percent loss: 0.1872
[2023-06-24 14:07:48,219] mass loss: 30.0229
[2023-06-24 14:07:48,219] mass percent loss: 0.1377
[2023-06-24 14:07:48,219] fat loss: 3.6109
[2023-06-24 14:07:48,219] fat percent loss: 0.2843
[2023-06-24 14:07:48,219] carb loss: 5.5872
[2023-06-24 14:07:48,219] carb percent loss: 0.2895
[2023-06-24 14:07:48,219] protein loss: 4.1002
[2023-06-24 14:07:48,219] protein percent loss: 0.2265
[2023-06-24 14:07:48,220] ingrs percent loss: 0.3463
[2023-06-24 14:07:48,220] Epoch 85/150
[2023-06-24 14:09:50,193] train loss: 0.7487
[2023-06-24 14:09:50,194] cal loss: 23.2887
[2023-06-24 14:09:50,194] cal percent loss: 0.0913
[2023-06-24 14:09:50,194] mass loss: 17.0870
[2023-06-24 14:09:50,195] mass percent loss: 0.0784
[2023-06-24 14:09:50,195] fat loss: 1.6837
[2023-06-24 14:09:50,195] fat percent loss: 0.1326
[2023-06-24 14:09:50,195] carb loss: 2.3304
[2023-06-24 14:09:50,195] carb percent loss: 0.1207
[2023-06-24 14:09:50,195] protein loss: 2.0659
[2023-06-24 14:09:50,195] protein percent loss: 0.1141
[2023-06-24 14:09:50,195] ingrs percent loss: 0.2060
[2023-06-24 14:09:50,196] Epoch 85/150
[2023-06-24 14:09:59,890] test loss: 1.4648
[2023-06-24 14:09:59,890] cal loss: 48.3379
[2023-06-24 14:09:59,891] cal percent loss: 0.1896
[2023-06-24 14:09:59,891] mass loss: 28.2458
[2023-06-24 14:09:59,891] mass percent loss: 0.1296
[2023-06-24 14:09:59,891] fat loss: 3.6311
[2023-06-24 14:09:59,891] fat percent loss: 0.2859
[2023-06-24 14:09:59,891] carb loss: 5.3064
[2023-06-24 14:09:59,891] carb percent loss: 0.2749
[2023-06-24 14:09:59,891] protein loss: 4.5102
[2023-06-24 14:09:59,891] protein percent loss: 0.2492
[2023-06-24 14:09:59,891] ingrs percent loss: 0.3406
[2023-06-24 14:09:59,892] Epoch 86/150
[2023-06-24 14:11:59,100] train loss: 0.6820
[2023-06-24 14:11:59,102] cal loss: 20.7472
[2023-06-24 14:11:59,102] cal percent loss: 0.0814
[2023-06-24 14:11:59,102] mass loss: 14.7490
[2023-06-24 14:11:59,102] mass percent loss: 0.0677
[2023-06-24 14:11:59,102] fat loss: 1.5562
[2023-06-24 14:11:59,102] fat percent loss: 0.1225
[2023-06-24 14:11:59,102] carb loss: 2.1234
[2023-06-24 14:11:59,103] carb percent loss: 0.1100
[2023-06-24 14:11:59,103] protein loss: 1.8554
[2023-06-24 14:11:59,103] protein percent loss: 0.1025
[2023-06-24 14:11:59,103] ingrs percent loss: 0.1944
[2023-06-24 14:11:59,103] Epoch 86/150
[2023-06-24 14:12:08,505] test loss: 1.6033
[2023-06-24 14:12:08,506] cal loss: 56.5864
[2023-06-24 14:12:08,506] cal percent loss: 0.2219
[2023-06-24 14:12:08,507] mass loss: 36.3801
[2023-06-24 14:12:08,507] mass percent loss: 0.1669
[2023-06-24 14:12:08,507] fat loss: 3.7899
[2023-06-24 14:12:08,507] fat percent loss: 0.2984
[2023-06-24 14:12:08,507] carb loss: 5.5328
[2023-06-24 14:12:08,507] carb percent loss: 0.2867
[2023-06-24 14:12:08,507] protein loss: 4.9023
[2023-06-24 14:12:08,507] protein percent loss: 0.2708
[2023-06-24 14:12:08,507] ingrs percent loss: 0.3505
[2023-06-24 14:12:08,507] Epoch 87/150
[2023-06-24 14:14:14,037] train loss: 0.6795
[2023-06-24 14:14:14,038] cal loss: 21.0499
[2023-06-24 14:14:14,038] cal percent loss: 0.0825
[2023-06-24 14:14:14,038] mass loss: 15.7069
[2023-06-24 14:14:14,039] mass percent loss: 0.0721
[2023-06-24 14:14:14,039] fat loss: 1.5341
[2023-06-24 14:14:14,039] fat percent loss: 0.1208
[2023-06-24 14:14:14,039] carb loss: 2.0171
[2023-06-24 14:14:14,039] carb percent loss: 0.1045
[2023-06-24 14:14:14,039] protein loss: 1.8366
[2023-06-24 14:14:14,039] protein percent loss: 0.1015
[2023-06-24 14:14:14,039] ingrs percent loss: 0.1920
[2023-06-24 14:14:14,039] Epoch 87/150
[2023-06-24 14:14:24,072] test loss: 1.5351
[2023-06-24 14:14:24,073] cal loss: 50.5702
[2023-06-24 14:14:24,073] cal percent loss: 0.1983
[2023-06-24 14:14:24,073] mass loss: 33.6777
[2023-06-24 14:14:24,073] mass percent loss: 0.1545
[2023-06-24 14:14:24,074] fat loss: 3.6340
[2023-06-24 14:14:24,074] fat percent loss: 0.2861
[2023-06-24 14:14:24,074] carb loss: 5.5701
[2023-06-24 14:14:24,074] carb percent loss: 0.2886
[2023-06-24 14:14:24,074] protein loss: 4.6627
[2023-06-24 14:14:24,074] protein percent loss: 0.2576
[2023-06-24 14:14:24,074] ingrs percent loss: 0.3479
[2023-06-24 14:14:24,075] Epoch 88/150
[2023-06-24 14:16:27,069] train loss: 0.6730
[2023-06-24 14:16:27,070] cal loss: 20.6892
[2023-06-24 14:16:27,070] cal percent loss: 0.0811
[2023-06-24 14:16:27,070] mass loss: 15.2798
[2023-06-24 14:16:27,070] mass percent loss: 0.0701
[2023-06-24 14:16:27,070] fat loss: 1.5249
[2023-06-24 14:16:27,070] fat percent loss: 0.1201
[2023-06-24 14:16:27,070] carb loss: 1.9936
[2023-06-24 14:16:27,071] carb percent loss: 0.1033
[2023-06-24 14:16:27,071] protein loss: 1.8274
[2023-06-24 14:16:27,071] protein percent loss: 0.1010
[2023-06-24 14:16:27,071] ingrs percent loss: 0.1920
[2023-06-24 14:16:27,071] Epoch 88/150
[2023-06-24 14:16:35,548] test loss: 1.4592
[2023-06-24 14:16:35,548] cal loss: 47.2985
[2023-06-24 14:16:35,548] cal percent loss: 0.1855
[2023-06-24 14:16:35,549] mass loss: 29.4554
[2023-06-24 14:16:35,549] mass percent loss: 0.1351
[2023-06-24 14:16:35,549] fat loss: 3.7221
[2023-06-24 14:16:35,549] fat percent loss: 0.2931
[2023-06-24 14:16:35,549] carb loss: 5.1143
[2023-06-24 14:16:35,549] carb percent loss: 0.2650
[2023-06-24 14:16:35,549] protein loss: 4.3175
[2023-06-24 14:16:35,549] protein percent loss: 0.2385
[2023-06-24 14:16:35,549] ingrs percent loss: 0.3436
[2023-06-24 14:16:35,550] Epoch 89/150
[2023-06-24 14:18:37,701] train loss: 0.6949
[2023-06-24 14:18:37,701] cal loss: 21.7026
[2023-06-24 14:18:37,701] cal percent loss: 0.0851
[2023-06-24 14:18:37,701] mass loss: 15.7623
[2023-06-24 14:18:37,701] mass percent loss: 0.0723
[2023-06-24 14:18:37,701] fat loss: 1.6119
[2023-06-24 14:18:37,701] fat percent loss: 0.1269
[2023-06-24 14:18:37,702] carb loss: 2.0559
[2023-06-24 14:18:37,702] carb percent loss: 0.1065
[2023-06-24 14:18:37,702] protein loss: 1.8151
[2023-06-24 14:18:37,702] protein percent loss: 0.1003
[2023-06-24 14:18:37,702] ingrs percent loss: 0.1976
[2023-06-24 14:18:37,702] Epoch 89/150
[2023-06-24 14:18:46,461] test loss: 1.4604
[2023-06-24 14:18:46,462] cal loss: 48.9501
[2023-06-24 14:18:46,462] cal percent loss: 0.1920
[2023-06-24 14:18:46,462] mass loss: 28.7387
[2023-06-24 14:18:46,462] mass percent loss: 0.1318
[2023-06-24 14:18:46,462] fat loss: 3.6086
[2023-06-24 14:18:46,462] fat percent loss: 0.2841
[2023-06-24 14:18:46,462] carb loss: 5.3656
[2023-06-24 14:18:46,462] carb percent loss: 0.2780
[2023-06-24 14:18:46,463] protein loss: 4.2753
[2023-06-24 14:18:46,463] protein percent loss: 0.2362
[2023-06-24 14:18:46,463] ingrs percent loss: 0.3410
[2023-06-24 14:18:46,463] Epoch 90/150
[2023-06-24 14:20:38,278] train loss: 0.6742
[2023-06-24 14:20:38,278] cal loss: 20.8804
[2023-06-24 14:20:38,279] cal percent loss: 0.0819
[2023-06-24 14:20:38,279] mass loss: 15.1659
[2023-06-24 14:20:38,279] mass percent loss: 0.0696
[2023-06-24 14:20:38,279] fat loss: 1.5931
[2023-06-24 14:20:38,279] fat percent loss: 0.1254
[2023-06-24 14:20:38,279] carb loss: 1.8622
[2023-06-24 14:20:38,279] carb percent loss: 0.0965
[2023-06-24 14:20:38,279] protein loss: 1.8160
[2023-06-24 14:20:38,279] protein percent loss: 0.1003
[2023-06-24 14:20:38,279] ingrs percent loss: 0.1944
[2023-06-24 14:20:38,280] Epoch 90/150
[2023-06-24 14:20:47,422] test loss: 1.4658
[2023-06-24 14:20:47,422] cal loss: 47.5260
[2023-06-24 14:20:47,422] cal percent loss: 0.1864
[2023-06-24 14:20:47,422] mass loss: 30.4958
[2023-06-24 14:20:47,423] mass percent loss: 0.1399
[2023-06-24 14:20:47,423] fat loss: 3.5001
[2023-06-24 14:20:47,423] fat percent loss: 0.2756
[2023-06-24 14:20:47,423] carb loss: 5.2566
[2023-06-24 14:20:47,423] carb percent loss: 0.2724
[2023-06-24 14:20:47,423] protein loss: 4.2590
[2023-06-24 14:20:47,423] protein percent loss: 0.2353
[2023-06-24 14:20:47,423] ingrs percent loss: 0.3559
[2023-06-24 14:20:47,423] Epoch 91/150
[2023-06-24 14:22:47,967] train loss: 0.6616
[2023-06-24 14:22:47,968] cal loss: 19.3469
[2023-06-24 14:22:47,968] cal percent loss: 0.0759
[2023-06-24 14:22:47,968] mass loss: 14.7222
[2023-06-24 14:22:47,968] mass percent loss: 0.0675
[2023-06-24 14:22:47,968] fat loss: 1.4548
[2023-06-24 14:22:47,968] fat percent loss: 0.1145
[2023-06-24 14:22:47,970] carb loss: 1.9496
[2023-06-24 14:22:47,970] carb percent loss: 0.1010
[2023-06-24 14:22:47,970] protein loss: 1.7555
[2023-06-24 14:22:47,970] protein percent loss: 0.0970
[2023-06-24 14:22:47,970] ingrs percent loss: 0.2009
[2023-06-24 14:22:47,970] Epoch 91/150
[2023-06-24 14:22:56,868] test loss: 1.4169
[2023-06-24 14:22:56,869] cal loss: 44.7664
[2023-06-24 14:22:56,869] cal percent loss: 0.1756
[2023-06-24 14:22:56,869] mass loss: 25.1291
[2023-06-24 14:22:56,869] mass percent loss: 0.1153
[2023-06-24 14:22:56,870] fat loss: 3.5179
[2023-06-24 14:22:56,870] fat percent loss: 0.2770
[2023-06-24 14:22:56,870] carb loss: 5.3680
[2023-06-24 14:22:56,870] carb percent loss: 0.2781
[2023-06-24 14:22:56,870] protein loss: 4.3153
[2023-06-24 14:22:56,870] protein percent loss: 0.2384
[2023-06-24 14:22:56,870] ingrs percent loss: 0.3433
[2023-06-24 14:22:56,870] Epoch 92/150
[2023-06-24 14:24:56,366] train loss: 0.6485
[2023-06-24 14:24:56,366] cal loss: 19.5338
[2023-06-24 14:24:56,366] cal percent loss: 0.0766
[2023-06-24 14:24:56,366] mass loss: 14.2861
[2023-06-24 14:24:56,366] mass percent loss: 0.0655
[2023-06-24 14:24:56,366] fat loss: 1.4220
[2023-06-24 14:24:56,367] fat percent loss: 0.1120
[2023-06-24 14:24:56,367] carb loss: 1.9473
[2023-06-24 14:24:56,367] carb percent loss: 0.1009
[2023-06-24 14:24:56,367] protein loss: 1.7026
[2023-06-24 14:24:56,367] protein percent loss: 0.0941
[2023-06-24 14:24:56,367] ingrs percent loss: 0.1948
[2023-06-24 14:24:56,367] Epoch 92/150
[2023-06-24 14:25:06,356] test loss: 1.7194
[2023-06-24 14:25:06,357] cal loss: 61.9695
[2023-06-24 14:25:06,357] cal percent loss: 0.2430
[2023-06-24 14:25:06,357] mass loss: 42.8508
[2023-06-24 14:25:06,357] mass percent loss: 0.1966
[2023-06-24 14:25:06,358] fat loss: 3.8733
[2023-06-24 14:25:06,358] fat percent loss: 0.3050
[2023-06-24 14:25:06,358] carb loss: 5.4710
[2023-06-24 14:25:06,358] carb percent loss: 0.2835
[2023-06-24 14:25:06,358] protein loss: 5.8835
[2023-06-24 14:25:06,358] protein percent loss: 0.3251
[2023-06-24 14:25:06,358] ingrs percent loss: 0.3505
[2023-06-24 14:25:06,358] Epoch 93/150
[2023-06-24 14:27:06,610] train loss: 0.6466
[2023-06-24 14:27:06,610] cal loss: 19.7038
[2023-06-24 14:27:06,610] cal percent loss: 0.0773
[2023-06-24 14:27:06,610] mass loss: 13.9623
[2023-06-24 14:27:06,610] mass percent loss: 0.0640
[2023-06-24 14:27:06,611] fat loss: 1.4568
[2023-06-24 14:27:06,611] fat percent loss: 0.1147
[2023-06-24 14:27:06,611] carb loss: 1.8539
[2023-06-24 14:27:06,611] carb percent loss: 0.0961
[2023-06-24 14:27:06,611] protein loss: 1.7873
[2023-06-24 14:27:06,611] protein percent loss: 0.0987
[2023-06-24 14:27:06,611] ingrs percent loss: 0.1914
[2023-06-24 14:27:06,611] Epoch 93/150
[2023-06-24 14:27:15,710] test loss: 1.4125
[2023-06-24 14:27:15,710] cal loss: 44.8573
[2023-06-24 14:27:15,710] cal percent loss: 0.1759
[2023-06-24 14:27:15,710] mass loss: 27.2714
[2023-06-24 14:27:15,711] mass percent loss: 0.1251
[2023-06-24 14:27:15,711] fat loss: 3.4828
[2023-06-24 14:27:15,711] fat percent loss: 0.2742
[2023-06-24 14:27:15,711] carb loss: 5.0863
[2023-06-24 14:27:15,711] carb percent loss: 0.2635
[2023-06-24 14:27:15,711] protein loss: 4.2861
[2023-06-24 14:27:15,711] protein percent loss: 0.2368
[2023-06-24 14:27:15,712] ingrs percent loss: 0.3421
[2023-06-24 14:27:15,712] Epoch 94/150
[2023-06-24 14:29:24,500] train loss: 0.6500
[2023-06-24 14:29:24,501] cal loss: 20.1849
[2023-06-24 14:29:24,501] cal percent loss: 0.0792
[2023-06-24 14:29:24,501] mass loss: 14.4534
[2023-06-24 14:29:24,501] mass percent loss: 0.0663
[2023-06-24 14:29:24,501] fat loss: 1.4186
[2023-06-24 14:29:24,501] fat percent loss: 0.1117
[2023-06-24 14:29:24,501] carb loss: 1.9721
[2023-06-24 14:29:24,501] carb percent loss: 0.1022
[2023-06-24 14:29:24,501] protein loss: 1.7263
[2023-06-24 14:29:24,501] protein percent loss: 0.0954
[2023-06-24 14:29:24,502] ingrs percent loss: 0.1903
[2023-06-24 14:29:24,502] Epoch 94/150
[2023-06-24 14:29:34,517] test loss: 1.5254
[2023-06-24 14:29:34,518] cal loss: 51.5081
[2023-06-24 14:29:34,518] cal percent loss: 0.2020
[2023-06-24 14:29:34,518] mass loss: 31.7237
[2023-06-24 14:29:34,518] mass percent loss: 0.1455
[2023-06-24 14:29:34,518] fat loss: 3.6692
[2023-06-24 14:29:34,519] fat percent loss: 0.2889
[2023-06-24 14:29:34,519] carb loss: 5.1204
[2023-06-24 14:29:34,519] carb percent loss: 0.2653
[2023-06-24 14:29:34,519] protein loss: 5.0251
[2023-06-24 14:29:34,519] protein percent loss: 0.2776
[2023-06-24 14:29:34,519] ingrs percent loss: 0.3455
[2023-06-24 14:29:34,519] Epoch 95/150
[2023-06-24 14:31:37,049] train loss: 0.6434
[2023-06-24 14:31:37,050] cal loss: 19.3475
[2023-06-24 14:31:37,050] cal percent loss: 0.0759
[2023-06-24 14:31:37,050] mass loss: 14.5013
[2023-06-24 14:31:37,050] mass percent loss: 0.0665
[2023-06-24 14:31:37,050] fat loss: 1.4028
[2023-06-24 14:31:37,050] fat percent loss: 0.1105
[2023-06-24 14:31:37,050] carb loss: 1.8654
[2023-06-24 14:31:37,050] carb percent loss: 0.0967
[2023-06-24 14:31:37,050] protein loss: 1.6913
[2023-06-24 14:31:37,050] protein percent loss: 0.0934
[2023-06-24 14:31:37,050] ingrs percent loss: 0.1949
[2023-06-24 14:31:37,050] Epoch 95/150
[2023-06-24 14:31:45,874] test loss: 1.4234
[2023-06-24 14:31:45,875] cal loss: 46.5889
[2023-06-24 14:31:45,875] cal percent loss: 0.1827
[2023-06-24 14:31:45,875] mass loss: 26.2801
[2023-06-24 14:31:45,876] mass percent loss: 0.1206
[2023-06-24 14:31:45,876] fat loss: 3.4903
[2023-06-24 14:31:45,876] fat percent loss: 0.2748
[2023-06-24 14:31:45,876] carb loss: 5.2861
[2023-06-24 14:31:45,876] carb percent loss: 0.2739
[2023-06-24 14:31:45,876] protein loss: 4.2912
[2023-06-24 14:31:45,876] protein percent loss: 0.2371
[2023-06-24 14:31:45,876] ingrs percent loss: 0.3414
[2023-06-24 14:31:45,877] Epoch 96/150
[2023-06-24 14:33:45,742] train loss: 0.6349
[2023-06-24 14:33:45,743] cal loss: 19.1961
[2023-06-24 14:33:45,743] cal percent loss: 0.0753
[2023-06-24 14:33:45,743] mass loss: 14.0250
[2023-06-24 14:33:45,743] mass percent loss: 0.0643
[2023-06-24 14:33:45,744] fat loss: 1.3613
[2023-06-24 14:33:45,744] fat percent loss: 0.1072
[2023-06-24 14:33:45,744] carb loss: 1.9110
[2023-06-24 14:33:45,744] carb percent loss: 0.0990
[2023-06-24 14:33:45,744] protein loss: 1.6604
[2023-06-24 14:33:45,744] protein percent loss: 0.0917
[2023-06-24 14:33:45,744] ingrs percent loss: 0.1925
[2023-06-24 14:33:45,744] Epoch 96/150
[2023-06-24 14:33:54,405] test loss: 1.4874
[2023-06-24 14:33:54,405] cal loss: 48.6825
[2023-06-24 14:33:54,405] cal percent loss: 0.1909
[2023-06-24 14:33:54,406] mass loss: 32.4233
[2023-06-24 14:33:54,406] mass percent loss: 0.1487
[2023-06-24 14:33:54,406] fat loss: 3.5239
[2023-06-24 14:33:54,406] fat percent loss: 0.2775
[2023-06-24 14:33:54,406] carb loss: 5.1882
[2023-06-24 14:33:54,406] carb percent loss: 0.2688
[2023-06-24 14:33:54,406] protein loss: 4.5834
[2023-06-24 14:33:54,406] protein percent loss: 0.2532
[2023-06-24 14:33:54,406] ingrs percent loss: 0.3456
[2023-06-24 14:33:54,406] Epoch 97/150
[2023-06-24 14:35:55,767] train loss: 0.6244
[2023-06-24 14:35:55,768] cal loss: 18.6862
[2023-06-24 14:35:55,769] cal percent loss: 0.0733
[2023-06-24 14:35:55,769] mass loss: 13.7316
[2023-06-24 14:35:55,769] mass percent loss: 0.0630
[2023-06-24 14:35:55,769] fat loss: 1.3569
[2023-06-24 14:35:55,769] fat percent loss: 0.1068
[2023-06-24 14:35:55,769] carb loss: 1.7959
[2023-06-24 14:35:55,769] carb percent loss: 0.0931
[2023-06-24 14:35:55,769] protein loss: 1.6400
[2023-06-24 14:35:55,769] protein percent loss: 0.0906
[2023-06-24 14:35:55,770] ingrs percent loss: 0.1926
[2023-06-24 14:35:55,770] Epoch 97/150
[2023-06-24 14:36:05,069] test loss: 1.4678
[2023-06-24 14:36:05,070] cal loss: 49.9889
[2023-06-24 14:36:05,070] cal percent loss: 0.1960
[2023-06-24 14:36:05,070] mass loss: 28.4956
[2023-06-24 14:36:05,070] mass percent loss: 0.1307
[2023-06-24 14:36:05,070] fat loss: 3.7899
[2023-06-24 14:36:05,070] fat percent loss: 0.2984
[2023-06-24 14:36:05,070] carb loss: 5.0251
[2023-06-24 14:36:05,070] carb percent loss: 0.2604
[2023-06-24 14:36:05,071] protein loss: 4.4217
[2023-06-24 14:36:05,071] protein percent loss: 0.2443
[2023-06-24 14:36:05,071] ingrs percent loss: 0.3397
[2023-06-24 14:36:05,071] Epoch 98/150
[2023-06-24 14:38:05,721] train loss: 0.6063
[2023-06-24 14:38:05,722] cal loss: 18.0598
[2023-06-24 14:38:05,722] cal percent loss: 0.0708
[2023-06-24 14:38:05,722] mass loss: 13.0800
[2023-06-24 14:38:05,722] mass percent loss: 0.0600
[2023-06-24 14:38:05,722] fat loss: 1.3539
[2023-06-24 14:38:05,723] fat percent loss: 0.1066
[2023-06-24 14:38:05,723] carb loss: 1.7329
[2023-06-24 14:38:05,723] carb percent loss: 0.0898
[2023-06-24 14:38:05,723] protein loss: 1.5556
[2023-06-24 14:38:05,723] protein percent loss: 0.0859
[2023-06-24 14:38:05,723] ingrs percent loss: 0.1886
[2023-06-24 14:38:05,723] Epoch 98/150
[2023-06-24 14:38:15,337] test loss: 1.4105
[2023-06-24 14:38:15,338] cal loss: 45.9593
[2023-06-24 14:38:15,338] cal percent loss: 0.1802
[2023-06-24 14:38:15,338] mass loss: 26.1969
[2023-06-24 14:38:15,338] mass percent loss: 0.1202
[2023-06-24 14:38:15,338] fat loss: 3.3771
[2023-06-24 14:38:15,339] fat percent loss: 0.2659
[2023-06-24 14:38:15,339] carb loss: 5.1594
[2023-06-24 14:38:15,339] carb percent loss: 0.2673
[2023-06-24 14:38:15,339] protein loss: 4.3294
[2023-06-24 14:38:15,339] protein percent loss: 0.2392
[2023-06-24 14:38:15,339] ingrs percent loss: 0.3442
[2023-06-24 14:38:15,339] Epoch 99/150
[2023-06-24 14:40:15,515] train loss: 0.6086
[2023-06-24 14:40:15,515] cal loss: 18.0509
[2023-06-24 14:40:15,515] cal percent loss: 0.0708
[2023-06-24 14:40:15,515] mass loss: 13.4320
[2023-06-24 14:40:15,516] mass percent loss: 0.0616
[2023-06-24 14:40:15,516] fat loss: 1.3421
[2023-06-24 14:40:15,516] fat percent loss: 0.1057
[2023-06-24 14:40:15,516] carb loss: 1.7374
[2023-06-24 14:40:15,516] carb percent loss: 0.0900
[2023-06-24 14:40:15,516] protein loss: 1.5551
[2023-06-24 14:40:15,516] protein percent loss: 0.0859
[2023-06-24 14:40:15,516] ingrs percent loss: 0.1895
[2023-06-24 14:40:15,516] Epoch 99/150
[2023-06-24 14:40:23,946] test loss: 1.5285
[2023-06-24 14:40:23,947] cal loss: 50.0429
[2023-06-24 14:40:23,947] cal percent loss: 0.1962
[2023-06-24 14:40:23,947] mass loss: 33.0244
[2023-06-24 14:40:23,947] mass percent loss: 0.1515
[2023-06-24 14:40:23,947] fat loss: 3.6064
[2023-06-24 14:40:23,947] fat percent loss: 0.2840
[2023-06-24 14:40:23,947] carb loss: 5.3368
[2023-06-24 14:40:23,947] carb percent loss: 0.2765
[2023-06-24 14:40:23,947] protein loss: 4.8500
[2023-06-24 14:40:23,947] protein percent loss: 0.2680
[2023-06-24 14:40:23,947] ingrs percent loss: 0.3509
[2023-06-24 14:40:23,948] Epoch 100/150
[2023-06-24 14:42:26,764] train loss: 0.6053
[2023-06-24 14:42:26,764] cal loss: 18.4908
[2023-06-24 14:42:26,764] cal percent loss: 0.0725
[2023-06-24 14:42:26,765] mass loss: 13.5073
[2023-06-24 14:42:26,765] mass percent loss: 0.0620
[2023-06-24 14:42:26,765] fat loss: 1.3444
[2023-06-24 14:42:26,765] fat percent loss: 0.1059
[2023-06-24 14:42:26,765] carb loss: 1.7013
[2023-06-24 14:42:26,765] carb percent loss: 0.0881
[2023-06-24 14:42:26,765] protein loss: 1.5100
[2023-06-24 14:42:26,765] protein percent loss: 0.0834
[2023-06-24 14:42:26,765] ingrs percent loss: 0.1874
[2023-06-24 14:42:26,766] Epoch 100/150
[2023-06-24 14:42:35,694] test loss: 1.5057
[2023-06-24 14:42:35,695] cal loss: 51.6164
[2023-06-24 14:42:35,695] cal percent loss: 0.2024
[2023-06-24 14:42:35,695] mass loss: 29.5601
[2023-06-24 14:42:35,695] mass percent loss: 0.1356
[2023-06-24 14:42:35,695] fat loss: 3.7383
[2023-06-24 14:42:35,695] fat percent loss: 0.2944
[2023-06-24 14:42:35,695] carb loss: 5.2568
[2023-06-24 14:42:35,695] carb percent loss: 0.2724
[2023-06-24 14:42:35,695] protein loss: 4.5533
[2023-06-24 14:42:35,695] protein percent loss: 0.2516
[2023-06-24 14:42:35,695] ingrs percent loss: 0.3507
[2023-06-24 14:42:35,695] Epoch 101/150
[2023-06-24 14:44:33,338] train loss: 0.5999
[2023-06-24 14:44:33,338] cal loss: 17.9238
[2023-06-24 14:44:33,338] cal percent loss: 0.0703
[2023-06-24 14:44:33,339] mass loss: 13.5100
[2023-06-24 14:44:33,339] mass percent loss: 0.0620
[2023-06-24 14:44:33,339] fat loss: 1.2860
[2023-06-24 14:44:33,339] fat percent loss: 0.1013
[2023-06-24 14:44:33,339] carb loss: 1.7347
[2023-06-24 14:44:33,339] carb percent loss: 0.0899
[2023-06-24 14:44:33,339] protein loss: 1.5337
[2023-06-24 14:44:33,339] protein percent loss: 0.0847
[2023-06-24 14:44:33,339] ingrs percent loss: 0.1863
[2023-06-24 14:44:33,340] Epoch 101/150
[2023-06-24 14:44:42,065] test loss: 1.5244
[2023-06-24 14:44:42,066] cal loss: 49.6643
[2023-06-24 14:44:42,066] cal percent loss: 0.1948
[2023-06-24 14:44:42,066] mass loss: 36.9639
[2023-06-24 14:44:42,066] mass percent loss: 0.1696
[2023-06-24 14:44:42,067] fat loss: 3.5055
[2023-06-24 14:44:42,067] fat percent loss: 0.2760
[2023-06-24 14:44:42,067] carb loss: 5.2701
[2023-06-24 14:44:42,067] carb percent loss: 0.2731
[2023-06-24 14:44:42,067] protein loss: 4.5326
[2023-06-24 14:44:42,067] protein percent loss: 0.2504
[2023-06-24 14:44:42,067] ingrs percent loss: 0.3505
[2023-06-24 14:44:42,067] Epoch 102/150
[2023-06-24 14:46:37,893] train loss: 0.5979
[2023-06-24 14:46:37,894] cal loss: 17.5405
[2023-06-24 14:46:37,894] cal percent loss: 0.0688
[2023-06-24 14:46:37,894] mass loss: 13.0281
[2023-06-24 14:46:37,894] mass percent loss: 0.0598
[2023-06-24 14:46:37,895] fat loss: 1.2452
[2023-06-24 14:46:37,895] fat percent loss: 0.0980
[2023-06-24 14:46:37,895] carb loss: 1.6597
[2023-06-24 14:46:37,895] carb percent loss: 0.0860
[2023-06-24 14:46:37,895] protein loss: 1.4968
[2023-06-24 14:46:37,895] protein percent loss: 0.0827
[2023-06-24 14:46:37,895] ingrs percent loss: 0.1971
[2023-06-24 14:46:37,896] Epoch 102/150
[2023-06-24 14:46:47,202] test loss: 1.4432
[2023-06-24 14:46:47,203] cal loss: 47.8428
[2023-06-24 14:46:47,203] cal percent loss: 0.1876
[2023-06-24 14:46:47,203] mass loss: 27.5320
[2023-06-24 14:46:47,203] mass percent loss: 0.1263
[2023-06-24 14:46:47,203] fat loss: 3.6000
[2023-06-24 14:46:47,203] fat percent loss: 0.2835
[2023-06-24 14:46:47,203] carb loss: 5.0012
[2023-06-24 14:46:47,204] carb percent loss: 0.2591
[2023-06-24 14:46:47,204] protein loss: 4.3932
[2023-06-24 14:46:47,204] protein percent loss: 0.2427
[2023-06-24 14:46:47,204] ingrs percent loss: 0.3474
[2023-06-24 14:46:47,204] Epoch 103/150
[2023-06-24 14:48:42,897] train loss: 0.6073
[2023-06-24 14:48:42,898] cal loss: 18.3185
[2023-06-24 14:48:42,898] cal percent loss: 0.0718
[2023-06-24 14:48:42,898] mass loss: 12.7267
[2023-06-24 14:48:42,898] mass percent loss: 0.0584
[2023-06-24 14:48:42,898] fat loss: 1.3501
[2023-06-24 14:48:42,898] fat percent loss: 0.1063
[2023-06-24 14:48:42,898] carb loss: 1.7228
[2023-06-24 14:48:42,898] carb percent loss: 0.0893
[2023-06-24 14:48:42,898] protein loss: 1.6153
[2023-06-24 14:48:42,898] protein percent loss: 0.0892
[2023-06-24 14:48:42,898] ingrs percent loss: 0.1884
[2023-06-24 14:48:42,899] Epoch 103/150
[2023-06-24 14:48:52,026] test loss: 1.5168
[2023-06-24 14:48:52,027] cal loss: 51.1687
[2023-06-24 14:48:52,027] cal percent loss: 0.2007
[2023-06-24 14:48:52,027] mass loss: 31.7403
[2023-06-24 14:48:52,027] mass percent loss: 0.1456
[2023-06-24 14:48:52,027] fat loss: 3.6834
[2023-06-24 14:48:52,028] fat percent loss: 0.2900
[2023-06-24 14:48:52,028] carb loss: 5.2925
[2023-06-24 14:48:52,028] carb percent loss: 0.2742
[2023-06-24 14:48:52,028] protein loss: 4.6910
[2023-06-24 14:48:52,028] protein percent loss: 0.2592
[2023-06-24 14:48:52,028] ingrs percent loss: 0.3461
[2023-06-24 14:48:52,028] Epoch 104/150
[2023-06-24 14:50:54,787] train loss: 0.5691
[2023-06-24 14:50:54,788] cal loss: 16.2251
[2023-06-24 14:50:54,788] cal percent loss: 0.0636
[2023-06-24 14:50:54,788] mass loss: 12.4569
[2023-06-24 14:50:54,788] mass percent loss: 0.0571
[2023-06-24 14:50:54,788] fat loss: 1.1955
[2023-06-24 14:50:54,789] fat percent loss: 0.0941
[2023-06-24 14:50:54,789] carb loss: 1.5996
[2023-06-24 14:50:54,789] carb percent loss: 0.0829
[2023-06-24 14:50:54,789] protein loss: 1.4533
[2023-06-24 14:50:54,789] protein percent loss: 0.0803
[2023-06-24 14:50:54,789] ingrs percent loss: 0.1864
[2023-06-24 14:50:54,789] Epoch 104/150
[2023-06-24 14:51:03,898] test loss: 1.5942
[2023-06-24 14:51:03,898] cal loss: 54.5315
[2023-06-24 14:51:03,899] cal percent loss: 0.2138
[2023-06-24 14:51:03,899] mass loss: 37.8677
[2023-06-24 14:51:03,899] mass percent loss: 0.1737
[2023-06-24 14:51:03,899] fat loss: 3.6344
[2023-06-24 14:51:03,899] fat percent loss: 0.2862
[2023-06-24 14:51:03,899] carb loss: 5.6213
[2023-06-24 14:51:03,899] carb percent loss: 0.2913
[2023-06-24 14:51:03,899] protein loss: 4.9792
[2023-06-24 14:51:03,899] protein percent loss: 0.2751
[2023-06-24 14:51:03,900] ingrs percent loss: 0.3454
[2023-06-24 14:51:03,900] Epoch 105/150
[2023-06-24 14:53:06,067] train loss: 0.5694
[2023-06-24 14:53:06,068] cal loss: 16.1032
[2023-06-24 14:53:06,068] cal percent loss: 0.0631
[2023-06-24 14:53:06,068] mass loss: 12.9817
[2023-06-24 14:53:06,068] mass percent loss: 0.0595
[2023-06-24 14:53:06,068] fat loss: 1.1803
[2023-06-24 14:53:06,068] fat percent loss: 0.0929
[2023-06-24 14:53:06,069] carb loss: 1.6533
[2023-06-24 14:53:06,069] carb percent loss: 0.0857
[2023-06-24 14:53:06,069] protein loss: 1.4093
[2023-06-24 14:53:06,069] protein percent loss: 0.0779
[2023-06-24 14:53:06,069] ingrs percent loss: 0.1850
[2023-06-24 14:53:06,069] Epoch 105/150
[2023-06-24 14:53:15,414] test loss: 1.4667
[2023-06-24 14:53:15,414] cal loss: 49.4698
[2023-06-24 14:53:15,414] cal percent loss: 0.1940
[2023-06-24 14:53:15,414] mass loss: 29.6791
[2023-06-24 14:53:15,414] mass percent loss: 0.1361
[2023-06-24 14:53:15,414] fat loss: 3.4661
[2023-06-24 14:53:15,414] fat percent loss: 0.2729
[2023-06-24 14:53:15,414] carb loss: 5.1066
[2023-06-24 14:53:15,414] carb percent loss: 0.2646
[2023-06-24 14:53:15,414] protein loss: 4.6492
[2023-06-24 14:53:15,414] protein percent loss: 0.2569
[2023-06-24 14:53:15,414] ingrs percent loss: 0.3430
[2023-06-24 14:53:15,415] Epoch 106/150
[2023-06-24 14:55:19,626] train loss: 0.5621
[2023-06-24 14:55:19,627] cal loss: 16.2487
[2023-06-24 14:55:19,627] cal percent loss: 0.0637
[2023-06-24 14:55:19,627] mass loss: 12.5882
[2023-06-24 14:55:19,627] mass percent loss: 0.0577
[2023-06-24 14:55:19,627] fat loss: 1.1524
[2023-06-24 14:55:19,627] fat percent loss: 0.0907
[2023-06-24 14:55:19,627] carb loss: 1.5614
[2023-06-24 14:55:19,627] carb percent loss: 0.0809
[2023-06-24 14:55:19,627] protein loss: 1.4406
[2023-06-24 14:55:19,627] protein percent loss: 0.0796
[2023-06-24 14:55:19,628] ingrs percent loss: 0.1840
[2023-06-24 14:55:19,628] Epoch 106/150
[2023-06-24 14:55:29,152] test loss: 1.3922
[2023-06-24 14:55:29,152] cal loss: 44.7733
[2023-06-24 14:55:29,153] cal percent loss: 0.1756
[2023-06-24 14:55:29,153] mass loss: 24.4494
[2023-06-24 14:55:29,153] mass percent loss: 0.1122
[2023-06-24 14:55:29,153] fat loss: 3.4769
[2023-06-24 14:55:29,153] fat percent loss: 0.2738
[2023-06-24 14:55:29,153] carb loss: 5.0120
[2023-06-24 14:55:29,154] carb percent loss: 0.2597
[2023-06-24 14:55:29,154] protein loss: 4.2612
[2023-06-24 14:55:29,154] protein percent loss: 0.2354
[2023-06-24 14:55:29,154] ingrs percent loss: 0.3444
[2023-06-24 14:55:29,154] Epoch 107/150
[2023-06-24 14:57:26,014] train loss: 0.5464
[2023-06-24 14:57:26,014] cal loss: 15.2449
[2023-06-24 14:57:26,015] cal percent loss: 0.0598
[2023-06-24 14:57:26,015] mass loss: 11.7819
[2023-06-24 14:57:26,015] mass percent loss: 0.0540
[2023-06-24 14:57:26,015] fat loss: 1.1133
[2023-06-24 14:57:26,015] fat percent loss: 0.0877
[2023-06-24 14:57:26,015] carb loss: 1.5347
[2023-06-24 14:57:26,015] carb percent loss: 0.0795
[2023-06-24 14:57:26,015] protein loss: 1.3414
[2023-06-24 14:57:26,015] protein percent loss: 0.0741
[2023-06-24 14:57:26,016] ingrs percent loss: 0.1868
[2023-06-24 14:57:26,016] Epoch 107/150
[2023-06-24 14:57:35,480] test loss: 1.4041
[2023-06-24 14:57:35,481] cal loss: 45.4811
[2023-06-24 14:57:35,481] cal percent loss: 0.1784
[2023-06-24 14:57:35,481] mass loss: 25.8810
[2023-06-24 14:57:35,481] mass percent loss: 0.1187
[2023-06-24 14:57:35,482] fat loss: 3.5176
[2023-06-24 14:57:35,482] fat percent loss: 0.2770
[2023-06-24 14:57:35,482] carb loss: 4.9518
[2023-06-24 14:57:35,482] carb percent loss: 0.2566
[2023-06-24 14:57:35,482] protein loss: 4.2706
[2023-06-24 14:57:35,482] protein percent loss: 0.2359
[2023-06-24 14:57:35,482] ingrs percent loss: 0.3436
[2023-06-24 14:57:35,483] Epoch 108/150
[2023-06-24 14:59:37,353] train loss: 0.5542
[2023-06-24 14:59:37,353] cal loss: 16.1270
[2023-06-24 14:59:37,353] cal percent loss: 0.0632
[2023-06-24 14:59:37,353] mass loss: 12.1362
[2023-06-24 14:59:37,354] mass percent loss: 0.0557
[2023-06-24 14:59:37,354] fat loss: 1.1623
[2023-06-24 14:59:37,354] fat percent loss: 0.0915
[2023-06-24 14:59:37,354] carb loss: 1.4943
[2023-06-24 14:59:37,354] carb percent loss: 0.0774
[2023-06-24 14:59:37,354] protein loss: 1.3499
[2023-06-24 14:59:37,354] protein percent loss: 0.0746
[2023-06-24 14:59:37,354] ingrs percent loss: 0.1862
[2023-06-24 14:59:37,354] Epoch 108/150
[2023-06-24 14:59:47,021] test loss: 1.4191
[2023-06-24 14:59:47,022] cal loss: 46.2458
[2023-06-24 14:59:47,022] cal percent loss: 0.1814
[2023-06-24 14:59:47,022] mass loss: 27.3392
[2023-06-24 14:59:47,022] mass percent loss: 0.1254
[2023-06-24 14:59:47,023] fat loss: 3.4089
[2023-06-24 14:59:47,023] fat percent loss: 0.2684
[2023-06-24 14:59:47,023] carb loss: 5.1991
[2023-06-24 14:59:47,023] carb percent loss: 0.2694
[2023-06-24 14:59:47,023] protein loss: 4.3143
[2023-06-24 14:59:47,023] protein percent loss: 0.2384
[2023-06-24 14:59:47,023] ingrs percent loss: 0.3410
[2023-06-24 14:59:47,023] Epoch 109/150
[2023-06-24 15:01:46,070] train loss: 0.5511
[2023-06-24 15:01:46,071] cal loss: 15.7662
[2023-06-24 15:01:46,071] cal percent loss: 0.0618
[2023-06-24 15:01:46,071] mass loss: 12.1053
[2023-06-24 15:01:46,071] mass percent loss: 0.0555
[2023-06-24 15:01:46,071] fat loss: 1.1512
[2023-06-24 15:01:46,071] fat percent loss: 0.0906
[2023-06-24 15:01:46,071] carb loss: 1.5443
[2023-06-24 15:01:46,071] carb percent loss: 0.0800
[2023-06-24 15:01:46,072] protein loss: 1.3513
[2023-06-24 15:01:46,072] protein percent loss: 0.0747
[2023-06-24 15:01:46,072] ingrs percent loss: 0.1835
[2023-06-24 15:01:46,072] Epoch 109/150
[2023-06-24 15:01:55,055] test loss: 1.5470
[2023-06-24 15:01:55,056] cal loss: 53.9842
[2023-06-24 15:01:55,056] cal percent loss: 0.2117
[2023-06-24 15:01:55,056] mass loss: 32.1575
[2023-06-24 15:01:55,056] mass percent loss: 0.1475
[2023-06-24 15:01:55,057] fat loss: 3.6705
[2023-06-24 15:01:55,057] fat percent loss: 0.2890
[2023-06-24 15:01:55,057] carb loss: 5.3650
[2023-06-24 15:01:55,057] carb percent loss: 0.2780
[2023-06-24 15:01:55,057] protein loss: 4.8889
[2023-06-24 15:01:55,057] protein percent loss: 0.2701
[2023-06-24 15:01:55,057] ingrs percent loss: 0.3489
[2023-06-24 15:01:55,057] Epoch 110/150
[2023-06-24 15:03:57,539] train loss: 0.5454
[2023-06-24 15:03:57,540] cal loss: 15.6457
[2023-06-24 15:03:57,540] cal percent loss: 0.0614
[2023-06-24 15:03:57,540] mass loss: 11.8957
[2023-06-24 15:03:57,540] mass percent loss: 0.0546
[2023-06-24 15:03:57,540] fat loss: 1.1290
[2023-06-24 15:03:57,540] fat percent loss: 0.0889
[2023-06-24 15:03:57,540] carb loss: 1.4879
[2023-06-24 15:03:57,540] carb percent loss: 0.0771
[2023-06-24 15:03:57,540] protein loss: 1.3506
[2023-06-24 15:03:57,540] protein percent loss: 0.0746
[2023-06-24 15:03:57,541] ingrs percent loss: 0.1838
[2023-06-24 15:03:57,541] Epoch 110/150
[2023-06-24 15:04:06,722] test loss: 1.3711
[2023-06-24 15:04:06,723] cal loss: 45.0467
[2023-06-24 15:04:06,723] cal percent loss: 0.1767
[2023-06-24 15:04:06,723] mass loss: 24.4669
[2023-06-24 15:04:06,724] mass percent loss: 0.1122
[2023-06-24 15:04:06,724] fat loss: 3.4737
[2023-06-24 15:04:06,724] fat percent loss: 0.2735
[2023-06-24 15:04:06,724] carb loss: 4.8206
[2023-06-24 15:04:06,724] carb percent loss: 0.2498
[2023-06-24 15:04:06,724] protein loss: 4.0924
[2023-06-24 15:04:06,724] protein percent loss: 0.2261
[2023-06-24 15:04:06,724] ingrs percent loss: 0.3392
[2023-06-24 15:04:06,725] Epoch 111/150
[2023-06-24 15:06:09,889] train loss: 0.5140
[2023-06-24 15:06:09,890] cal loss: 14.2948
[2023-06-24 15:06:09,890] cal percent loss: 0.0561
[2023-06-24 15:06:09,890] mass loss: 10.6165
[2023-06-24 15:06:09,890] mass percent loss: 0.0487
[2023-06-24 15:06:09,891] fat loss: 1.0313
[2023-06-24 15:06:09,891] fat percent loss: 0.0812
[2023-06-24 15:06:09,891] carb loss: 1.4091
[2023-06-24 15:06:09,891] carb percent loss: 0.0730
[2023-06-24 15:06:09,891] protein loss: 1.2648
[2023-06-24 15:06:09,891] protein percent loss: 0.0699
[2023-06-24 15:06:09,891] ingrs percent loss: 0.1815
[2023-06-24 15:06:09,891] Epoch 111/150
[2023-06-24 15:06:19,356] test loss: 1.4025
[2023-06-24 15:06:19,357] cal loss: 46.3432
[2023-06-24 15:06:19,357] cal percent loss: 0.1817
[2023-06-24 15:06:19,357] mass loss: 24.9234
[2023-06-24 15:06:19,357] mass percent loss: 0.1143
[2023-06-24 15:06:19,358] fat loss: 3.6544
[2023-06-24 15:06:19,358] fat percent loss: 0.2877
[2023-06-24 15:06:19,358] carb loss: 5.0861
[2023-06-24 15:06:19,358] carb percent loss: 0.2635
[2023-06-24 15:06:19,358] protein loss: 4.1444
[2023-06-24 15:06:19,358] protein percent loss: 0.2290
[2023-06-24 15:06:19,358] ingrs percent loss: 0.3340
[2023-06-24 15:06:19,358] Epoch 112/150
[2023-06-24 15:08:20,029] train loss: 0.5243
[2023-06-24 15:08:20,030] cal loss: 14.8354
[2023-06-24 15:08:20,030] cal percent loss: 0.0582
[2023-06-24 15:08:20,031] mass loss: 11.2179
[2023-06-24 15:08:20,031] mass percent loss: 0.0515
[2023-06-24 15:08:20,031] fat loss: 1.0460
[2023-06-24 15:08:20,031] fat percent loss: 0.0824
[2023-06-24 15:08:20,031] carb loss: 1.4352
[2023-06-24 15:08:20,031] carb percent loss: 0.0744
[2023-06-24 15:08:20,031] protein loss: 1.2807
[2023-06-24 15:08:20,031] protein percent loss: 0.0708
[2023-06-24 15:08:20,031] ingrs percent loss: 0.1826
[2023-06-24 15:08:20,031] Epoch 112/150
[2023-06-24 15:08:29,002] test loss: 1.3907
[2023-06-24 15:08:29,003] cal loss: 46.0403
[2023-06-24 15:08:29,003] cal percent loss: 0.1806
[2023-06-24 15:08:29,003] mass loss: 25.3790
[2023-06-24 15:08:29,003] mass percent loss: 0.1164
[2023-06-24 15:08:29,003] fat loss: 3.4010
[2023-06-24 15:08:29,003] fat percent loss: 0.2678
[2023-06-24 15:08:29,003] carb loss: 4.9594
[2023-06-24 15:08:29,003] carb percent loss: 0.2570
[2023-06-24 15:08:29,004] protein loss: 4.2051
[2023-06-24 15:08:29,004] protein percent loss: 0.2323
[2023-06-24 15:08:29,004] ingrs percent loss: 0.3423
[2023-06-24 15:08:29,004] Epoch 113/150
[2023-06-24 15:10:30,845] train loss: 0.5218
[2023-06-24 15:10:30,846] cal loss: 14.9500
[2023-06-24 15:10:30,846] cal percent loss: 0.0586
[2023-06-24 15:10:30,846] mass loss: 10.9143
[2023-06-24 15:10:30,846] mass percent loss: 0.0501
[2023-06-24 15:10:30,847] fat loss: 1.0427
[2023-06-24 15:10:30,847] fat percent loss: 0.0821
[2023-06-24 15:10:30,847] carb loss: 1.4011
[2023-06-24 15:10:30,847] carb percent loss: 0.0726
[2023-06-24 15:10:30,847] protein loss: 1.3144
[2023-06-24 15:10:30,847] protein percent loss: 0.0726
[2023-06-24 15:10:30,847] ingrs percent loss: 0.1815
[2023-06-24 15:10:30,847] Epoch 113/150
[2023-06-24 15:10:40,105] test loss: 1.3954
[2023-06-24 15:10:40,112] cal loss: 46.1881
[2023-06-24 15:10:40,112] cal percent loss: 0.1811
[2023-06-24 15:10:40,112] mass loss: 24.8171
[2023-06-24 15:10:40,113] mass percent loss: 0.1138
[2023-06-24 15:10:40,115] fat loss: 3.5579
[2023-06-24 15:10:40,115] fat percent loss: 0.2801
[2023-06-24 15:10:40,115] carb loss: 5.0057
[2023-06-24 15:10:40,115] carb percent loss: 0.2594
[2023-06-24 15:10:40,115] protein loss: 4.1188
[2023-06-24 15:10:40,115] protein percent loss: 0.2276
[2023-06-24 15:10:40,115] ingrs percent loss: 0.3403
[2023-06-24 15:10:40,115] Epoch 114/150
[2023-06-24 15:12:42,762] train loss: 0.5136
[2023-06-24 15:12:42,763] cal loss: 14.5735
[2023-06-24 15:12:42,763] cal percent loss: 0.0572
[2023-06-24 15:12:42,763] mass loss: 10.7004
[2023-06-24 15:12:42,763] mass percent loss: 0.0491
[2023-06-24 15:12:42,763] fat loss: 1.0566
[2023-06-24 15:12:42,763] fat percent loss: 0.0832
[2023-06-24 15:12:42,763] carb loss: 1.3429
[2023-06-24 15:12:42,763] carb percent loss: 0.0696
[2023-06-24 15:12:42,763] protein loss: 1.2510
[2023-06-24 15:12:42,764] protein percent loss: 0.0691
[2023-06-24 15:12:42,764] ingrs percent loss: 0.1810
[2023-06-24 15:12:42,764] Epoch 114/150
[2023-06-24 15:12:51,492] test loss: 1.3912
[2023-06-24 15:12:51,493] cal loss: 44.8536
[2023-06-24 15:12:51,493] cal percent loss: 0.1759
[2023-06-24 15:12:51,493] mass loss: 25.0090
[2023-06-24 15:12:51,493] mass percent loss: 0.1147
[2023-06-24 15:12:51,493] fat loss: 3.4784
[2023-06-24 15:12:51,493] fat percent loss: 0.2739
[2023-06-24 15:12:51,493] carb loss: 5.1169
[2023-06-24 15:12:51,493] carb percent loss: 0.2651
[2023-06-24 15:12:51,493] protein loss: 4.0868
[2023-06-24 15:12:51,493] protein percent loss: 0.2258
[2023-06-24 15:12:51,493] ingrs percent loss: 0.3435
[2023-06-24 15:12:51,493] Epoch 115/150
[2023-06-24 15:14:50,533] train loss: 0.5071
[2023-06-24 15:14:50,534] cal loss: 14.2296
[2023-06-24 15:14:50,534] cal percent loss: 0.0558
[2023-06-24 15:14:50,534] mass loss: 10.2941
[2023-06-24 15:14:50,534] mass percent loss: 0.0472
[2023-06-24 15:14:50,534] fat loss: 1.0243
[2023-06-24 15:14:50,534] fat percent loss: 0.0807
[2023-06-24 15:14:50,535] carb loss: 1.4176
[2023-06-24 15:14:50,535] carb percent loss: 0.0734
[2023-06-24 15:14:50,535] protein loss: 1.1844
[2023-06-24 15:14:50,535] protein percent loss: 0.0654
[2023-06-24 15:14:50,535] ingrs percent loss: 0.1809
[2023-06-24 15:14:50,535] Epoch 115/150
[2023-06-24 15:15:00,828] test loss: 1.4558
[2023-06-24 15:15:00,829] cal loss: 47.5181
[2023-06-24 15:15:00,829] cal percent loss: 0.1863
[2023-06-24 15:15:00,829] mass loss: 29.1198
[2023-06-24 15:15:00,829] mass percent loss: 0.1336
[2023-06-24 15:15:00,829] fat loss: 3.4112
[2023-06-24 15:15:00,829] fat percent loss: 0.2686
[2023-06-24 15:15:00,830] carb loss: 5.1642
[2023-06-24 15:15:00,830] carb percent loss: 0.2676
[2023-06-24 15:15:00,830] protein loss: 4.6244
[2023-06-24 15:15:00,830] protein percent loss: 0.2555
[2023-06-24 15:15:00,830] ingrs percent loss: 0.3470
[2023-06-24 15:15:00,830] Epoch 116/150
[2023-06-24 15:17:07,691] train loss: 0.5089
[2023-06-24 15:17:07,691] cal loss: 14.0822
[2023-06-24 15:17:07,691] cal percent loss: 0.0552
[2023-06-24 15:17:07,692] mass loss: 10.7951
[2023-06-24 15:17:07,692] mass percent loss: 0.0495
[2023-06-24 15:17:07,692] fat loss: 1.0380
[2023-06-24 15:17:07,692] fat percent loss: 0.0817
[2023-06-24 15:17:07,692] carb loss: 1.3809
[2023-06-24 15:17:07,692] carb percent loss: 0.0715
[2023-06-24 15:17:07,692] protein loss: 1.1872
[2023-06-24 15:17:07,692] protein percent loss: 0.0656
[2023-06-24 15:17:07,692] ingrs percent loss: 0.1808
[2023-06-24 15:17:07,692] Epoch 116/150
[2023-06-24 15:17:17,280] test loss: 1.4186
[2023-06-24 15:17:17,282] cal loss: 46.4067
[2023-06-24 15:17:17,283] cal percent loss: 0.1820
[2023-06-24 15:17:17,283] mass loss: 27.4702
[2023-06-24 15:17:17,283] mass percent loss: 0.1260
[2023-06-24 15:17:17,283] fat loss: 3.6389
[2023-06-24 15:17:17,283] fat percent loss: 0.2865
[2023-06-24 15:17:17,283] carb loss: 5.1537
[2023-06-24 15:17:17,283] carb percent loss: 0.2670
[2023-06-24 15:17:17,283] protein loss: 3.9525
[2023-06-24 15:17:17,283] protein percent loss: 0.2184
[2023-06-24 15:17:17,283] ingrs percent loss: 0.3418
[2023-06-24 15:17:17,283] Epoch 117/150
[2023-06-24 15:19:13,857] train loss: 0.5122
[2023-06-24 15:19:13,858] cal loss: 14.2890
[2023-06-24 15:19:13,858] cal percent loss: 0.0560
[2023-06-24 15:19:13,858] mass loss: 10.9558
[2023-06-24 15:19:13,858] mass percent loss: 0.0503
[2023-06-24 15:19:13,859] fat loss: 1.0164
[2023-06-24 15:19:13,859] fat percent loss: 0.0800
[2023-06-24 15:19:13,859] carb loss: 1.3618
[2023-06-24 15:19:13,859] carb percent loss: 0.0706
[2023-06-24 15:19:13,859] protein loss: 1.2531
[2023-06-24 15:19:13,859] protein percent loss: 0.0692
[2023-06-24 15:19:13,859] ingrs percent loss: 0.1814
[2023-06-24 15:19:13,859] Epoch 117/150
[2023-06-24 15:19:23,376] test loss: 1.4305
[2023-06-24 15:19:23,376] cal loss: 46.7499
[2023-06-24 15:19:23,377] cal percent loss: 0.1833
[2023-06-24 15:19:23,377] mass loss: 27.5604
[2023-06-24 15:19:23,377] mass percent loss: 0.1264
[2023-06-24 15:19:23,377] fat loss: 3.4739
[2023-06-24 15:19:23,377] fat percent loss: 0.2735
[2023-06-24 15:19:23,377] carb loss: 5.0751
[2023-06-24 15:19:23,377] carb percent loss: 0.2630
[2023-06-24 15:19:23,377] protein loss: 4.3850
[2023-06-24 15:19:23,377] protein percent loss: 0.2423
[2023-06-24 15:19:23,377] ingrs percent loss: 0.3460
[2023-06-24 15:19:23,378] Epoch 118/150
[2023-06-24 15:21:23,359] train loss: 0.4968
[2023-06-24 15:21:23,360] cal loss: 13.7017
[2023-06-24 15:21:23,360] cal percent loss: 0.0537
[2023-06-24 15:21:23,360] mass loss: 10.5100
[2023-06-24 15:21:23,360] mass percent loss: 0.0482
[2023-06-24 15:21:23,360] fat loss: 0.9756
[2023-06-24 15:21:23,360] fat percent loss: 0.0768
[2023-06-24 15:21:23,360] carb loss: 1.3388
[2023-06-24 15:21:23,360] carb percent loss: 0.0694
[2023-06-24 15:21:23,360] protein loss: 1.1687
[2023-06-24 15:21:23,361] protein percent loss: 0.0646
[2023-06-24 15:21:23,361] ingrs percent loss: 0.1796
[2023-06-24 15:21:23,361] Epoch 118/150
[2023-06-24 15:21:32,655] test loss: 1.3997
[2023-06-24 15:21:32,656] cal loss: 44.8412
[2023-06-24 15:21:32,656] cal percent loss: 0.1758
[2023-06-24 15:21:32,656] mass loss: 25.6061
[2023-06-24 15:21:32,656] mass percent loss: 0.1175
[2023-06-24 15:21:32,656] fat loss: 3.4274
[2023-06-24 15:21:32,656] fat percent loss: 0.2699
[2023-06-24 15:21:32,656] carb loss: 5.1012
[2023-06-24 15:21:32,656] carb percent loss: 0.2643
[2023-06-24 15:21:32,656] protein loss: 4.1976
[2023-06-24 15:21:32,656] protein percent loss: 0.2319
[2023-06-24 15:21:32,656] ingrs percent loss: 0.3474
[2023-06-24 15:21:32,657] Epoch 119/150
[2023-06-24 15:23:31,488] train loss: 0.4897
[2023-06-24 15:23:31,489] cal loss: 13.4573
[2023-06-24 15:23:31,489] cal percent loss: 0.0528
[2023-06-24 15:23:31,489] mass loss: 10.2367
[2023-06-24 15:23:31,489] mass percent loss: 0.0470
[2023-06-24 15:23:31,489] fat loss: 0.9642
[2023-06-24 15:23:31,490] fat percent loss: 0.0759
[2023-06-24 15:23:31,490] carb loss: 1.2787
[2023-06-24 15:23:31,490] carb percent loss: 0.0663
[2023-06-24 15:23:31,490] protein loss: 1.1636
[2023-06-24 15:23:31,490] protein percent loss: 0.0643
[2023-06-24 15:23:31,490] ingrs percent loss: 0.1791
[2023-06-24 15:23:31,490] Epoch 119/150
[2023-06-24 15:23:40,331] test loss: 1.4675
[2023-06-24 15:23:40,332] cal loss: 49.7717
[2023-06-24 15:23:40,332] cal percent loss: 0.1952
[2023-06-24 15:23:40,332] mass loss: 28.9513
[2023-06-24 15:23:40,332] mass percent loss: 0.1328
[2023-06-24 15:23:40,332] fat loss: 3.5493
[2023-06-24 15:23:40,332] fat percent loss: 0.2795
[2023-06-24 15:23:40,332] carb loss: 5.2417
[2023-06-24 15:23:40,332] carb percent loss: 0.2716
[2023-06-24 15:23:40,332] protein loss: 4.3420
[2023-06-24 15:23:40,332] protein percent loss: 0.2399
[2023-06-24 15:23:40,332] ingrs percent loss: 0.3498
[2023-06-24 15:23:40,333] Epoch 120/150
[2023-06-24 15:25:49,377] train loss: 0.4781
[2023-06-24 15:25:49,377] cal loss: 12.9879
[2023-06-24 15:25:49,377] cal percent loss: 0.0509
[2023-06-24 15:25:49,378] mass loss: 9.9219
[2023-06-24 15:25:49,378] mass percent loss: 0.0455
[2023-06-24 15:25:49,378] fat loss: 0.9471
[2023-06-24 15:25:49,378] fat percent loss: 0.0746
[2023-06-24 15:25:49,378] carb loss: 1.2337
[2023-06-24 15:25:49,378] carb percent loss: 0.0639
[2023-06-24 15:25:49,378] protein loss: 1.0846
[2023-06-24 15:25:49,378] protein percent loss: 0.0599
[2023-06-24 15:25:49,378] ingrs percent loss: 0.1788
[2023-06-24 15:25:49,378] Epoch 120/150
[2023-06-24 15:25:57,909] test loss: 1.4648
[2023-06-24 15:25:57,910] cal loss: 49.0304
[2023-06-24 15:25:57,910] cal percent loss: 0.1923
[2023-06-24 15:25:57,910] mass loss: 26.8878
[2023-06-24 15:25:57,911] mass percent loss: 0.1233
[2023-06-24 15:25:57,911] fat loss: 3.6822
[2023-06-24 15:25:57,911] fat percent loss: 0.2899
[2023-06-24 15:25:57,911] carb loss: 5.3229
[2023-06-24 15:25:57,911] carb percent loss: 0.2758
[2023-06-24 15:25:57,911] protein loss: 4.4003
[2023-06-24 15:25:57,911] protein percent loss: 0.2431
[2023-06-24 15:25:57,912] ingrs percent loss: 0.3466
[2023-06-24 15:25:57,912] Epoch 121/150
[2023-06-24 15:27:51,892] train loss: 0.4772
[2023-06-24 15:27:51,893] cal loss: 12.8932
[2023-06-24 15:27:51,893] cal percent loss: 0.0506
[2023-06-24 15:27:51,893] mass loss: 9.8408
[2023-06-24 15:27:51,893] mass percent loss: 0.0451
[2023-06-24 15:27:51,893] fat loss: 0.9229
[2023-06-24 15:27:51,894] fat percent loss: 0.0727
[2023-06-24 15:27:51,894] carb loss: 1.2374
[2023-06-24 15:27:51,894] carb percent loss: 0.0641
[2023-06-24 15:27:51,894] protein loss: 1.1061
[2023-06-24 15:27:51,894] protein percent loss: 0.0611
[2023-06-24 15:27:51,894] ingrs percent loss: 0.1794
[2023-06-24 15:27:51,894] Epoch 121/150
[2023-06-24 15:28:01,122] test loss: 1.3968
[2023-06-24 15:28:01,123] cal loss: 47.2696
[2023-06-24 15:28:01,123] cal percent loss: 0.1854
[2023-06-24 15:28:01,123] mass loss: 24.6801
[2023-06-24 15:28:01,123] mass percent loss: 0.1132
[2023-06-24 15:28:01,124] fat loss: 3.4545
[2023-06-24 15:28:01,124] fat percent loss: 0.2720
[2023-06-24 15:28:01,124] carb loss: 4.8994
[2023-06-24 15:28:01,124] carb percent loss: 0.2539
[2023-06-24 15:28:01,124] protein loss: 4.2230
[2023-06-24 15:28:01,124] protein percent loss: 0.2333
[2023-06-24 15:28:01,124] ingrs percent loss: 0.3449
[2023-06-24 15:28:01,124] Epoch 122/150
[2023-06-24 15:29:58,813] train loss: 0.4904
[2023-06-24 15:29:58,813] cal loss: 13.4422
[2023-06-24 15:29:58,814] cal percent loss: 0.0527
[2023-06-24 15:29:58,814] mass loss: 10.4770
[2023-06-24 15:29:58,814] mass percent loss: 0.0481
[2023-06-24 15:29:58,814] fat loss: 0.9470
[2023-06-24 15:29:58,814] fat percent loss: 0.0746
[2023-06-24 15:29:58,814] carb loss: 1.3380
[2023-06-24 15:29:58,814] carb percent loss: 0.0693
[2023-06-24 15:29:58,814] protein loss: 1.1212
[2023-06-24 15:29:58,814] protein percent loss: 0.0619
[2023-06-24 15:29:58,814] ingrs percent loss: 0.1791
[2023-06-24 15:29:58,815] Epoch 122/150
[2023-06-24 15:30:07,666] test loss: 1.5207
[2023-06-24 15:30:07,667] cal loss: 53.5368
[2023-06-24 15:30:07,667] cal percent loss: 0.2099
[2023-06-24 15:30:07,667] mass loss: 31.2520
[2023-06-24 15:30:07,667] mass percent loss: 0.1434
[2023-06-24 15:30:07,667] fat loss: 3.6764
[2023-06-24 15:30:07,667] fat percent loss: 0.2895
[2023-06-24 15:30:07,667] carb loss: 5.3829
[2023-06-24 15:30:07,667] carb percent loss: 0.2789
[2023-06-24 15:30:07,667] protein loss: 4.5780
[2023-06-24 15:30:07,667] protein percent loss: 0.2529
[2023-06-24 15:30:07,667] ingrs percent loss: 0.3444
[2023-06-24 15:30:07,668] Epoch 123/150
[2023-06-24 15:32:11,083] train loss: 0.4785
[2023-06-24 15:32:11,084] cal loss: 12.4895
[2023-06-24 15:32:11,084] cal percent loss: 0.0490
[2023-06-24 15:32:11,084] mass loss: 9.4121
[2023-06-24 15:32:11,084] mass percent loss: 0.0432
[2023-06-24 15:32:11,084] fat loss: 0.9514
[2023-06-24 15:32:11,084] fat percent loss: 0.0749
[2023-06-24 15:32:11,084] carb loss: 1.2895
[2023-06-24 15:32:11,085] carb percent loss: 0.0668
[2023-06-24 15:32:11,085] protein loss: 1.1468
[2023-06-24 15:32:11,085] protein percent loss: 0.0634
[2023-06-24 15:32:11,085] ingrs percent loss: 0.1786
[2023-06-24 15:32:11,085] Epoch 123/150
[2023-06-24 15:32:20,424] test loss: 1.4222
[2023-06-24 15:32:20,425] cal loss: 47.2018
[2023-06-24 15:32:20,425] cal percent loss: 0.1851
[2023-06-24 15:32:20,425] mass loss: 26.2354
[2023-06-24 15:32:20,426] mass percent loss: 0.1203
[2023-06-24 15:32:20,426] fat loss: 3.5101
[2023-06-24 15:32:20,426] fat percent loss: 0.2764
[2023-06-24 15:32:20,426] carb loss: 5.1458
[2023-06-24 15:32:20,426] carb percent loss: 0.2666
[2023-06-24 15:32:20,426] protein loss: 4.3042
[2023-06-24 15:32:20,426] protein percent loss: 0.2378
[2023-06-24 15:32:20,426] ingrs percent loss: 0.3418
[2023-06-24 15:32:20,426] Epoch 124/150
[2023-06-24 15:34:27,704] train loss: 0.4689
[2023-06-24 15:34:27,704] cal loss: 12.5390
[2023-06-24 15:34:27,705] cal percent loss: 0.0492
[2023-06-24 15:34:27,705] mass loss: 9.7436
[2023-06-24 15:34:27,705] mass percent loss: 0.0447
[2023-06-24 15:34:27,705] fat loss: 0.9054
[2023-06-24 15:34:27,705] fat percent loss: 0.0713
[2023-06-24 15:34:27,705] carb loss: 1.2155
[2023-06-24 15:34:27,705] carb percent loss: 0.0630
[2023-06-24 15:34:27,705] protein loss: 1.0674
[2023-06-24 15:34:27,705] protein percent loss: 0.0590
[2023-06-24 15:34:27,705] ingrs percent loss: 0.1775
[2023-06-24 15:34:27,706] Epoch 124/150
[2023-06-24 15:34:38,094] test loss: 1.5199
[2023-06-24 15:34:38,095] cal loss: 53.9413
[2023-06-24 15:34:38,095] cal percent loss: 0.2115
[2023-06-24 15:34:38,095] mass loss: 28.9559
[2023-06-24 15:34:38,095] mass percent loss: 0.1328
[2023-06-24 15:34:38,096] fat loss: 3.6794
[2023-06-24 15:34:38,096] fat percent loss: 0.2897
[2023-06-24 15:34:38,096] carb loss: 5.4667
[2023-06-24 15:34:38,096] carb percent loss: 0.2832
[2023-06-24 15:34:38,096] protein loss: 4.6119
[2023-06-24 15:34:38,096] protein percent loss: 0.2548
[2023-06-24 15:34:38,096] ingrs percent loss: 0.3502
[2023-06-24 15:34:38,096] Epoch 125/150
[2023-06-24 15:36:33,759] train loss: 0.4720
[2023-06-24 15:36:33,760] cal loss: 12.7804
[2023-06-24 15:36:33,760] cal percent loss: 0.0501
[2023-06-24 15:36:33,760] mass loss: 9.5702
[2023-06-24 15:36:33,760] mass percent loss: 0.0439
[2023-06-24 15:36:33,760] fat loss: 0.9144
[2023-06-24 15:36:33,760] fat percent loss: 0.0720
[2023-06-24 15:36:33,760] carb loss: 1.2123
[2023-06-24 15:36:33,760] carb percent loss: 0.0628
[2023-06-24 15:36:33,760] protein loss: 1.0769
[2023-06-24 15:36:33,760] protein percent loss: 0.0595
[2023-06-24 15:36:33,760] ingrs percent loss: 0.1796
[2023-06-24 15:36:33,760] Epoch 125/150
[2023-06-24 15:36:43,416] test loss: 1.4026
[2023-06-24 15:36:43,417] cal loss: 45.8017
[2023-06-24 15:36:43,417] cal percent loss: 0.1796
[2023-06-24 15:36:43,417] mass loss: 25.9272
[2023-06-24 15:36:43,417] mass percent loss: 0.1189
[2023-06-24 15:36:43,417] fat loss: 3.4538
[2023-06-24 15:36:43,417] fat percent loss: 0.2720
[2023-06-24 15:36:43,417] carb loss: 5.0891
[2023-06-24 15:36:43,417] carb percent loss: 0.2637
[2023-06-24 15:36:43,418] protein loss: 4.2186
[2023-06-24 15:36:43,418] protein percent loss: 0.2331
[2023-06-24 15:36:43,418] ingrs percent loss: 0.3414
[2023-06-24 15:36:43,418] Epoch 126/150
[2023-06-24 15:38:40,419] train loss: 0.4717
[2023-06-24 15:38:40,420] cal loss: 12.7936
[2023-06-24 15:38:40,420] cal percent loss: 0.0502
[2023-06-24 15:38:40,420] mass loss: 9.4977
[2023-06-24 15:38:40,420] mass percent loss: 0.0436
[2023-06-24 15:38:40,420] fat loss: 0.9130
[2023-06-24 15:38:40,421] fat percent loss: 0.0719
[2023-06-24 15:38:40,421] carb loss: 1.2315
[2023-06-24 15:38:40,421] carb percent loss: 0.0638
[2023-06-24 15:38:40,421] protein loss: 1.0882
[2023-06-24 15:38:40,421] protein percent loss: 0.0601
[2023-06-24 15:38:40,421] ingrs percent loss: 0.1783
[2023-06-24 15:38:40,421] Epoch 126/150
[2023-06-24 15:38:50,272] test loss: 1.4712
[2023-06-24 15:38:50,273] cal loss: 48.4047
[2023-06-24 15:38:50,273] cal percent loss: 0.1898
[2023-06-24 15:38:50,273] mass loss: 30.5382
[2023-06-24 15:38:50,273] mass percent loss: 0.1401
[2023-06-24 15:38:50,273] fat loss: 3.4073
[2023-06-24 15:38:50,273] fat percent loss: 0.2683
[2023-06-24 15:38:50,273] carb loss: 5.3401
[2023-06-24 15:38:50,274] carb percent loss: 0.2767
[2023-06-24 15:38:50,274] protein loss: 4.6272
[2023-06-24 15:38:50,274] protein percent loss: 0.2556
[2023-06-24 15:38:50,274] ingrs percent loss: 0.3420
[2023-06-24 15:38:50,274] Epoch 127/150
[2023-06-24 15:40:47,589] train loss: 0.4578
[2023-06-24 15:40:47,590] cal loss: 12.2051
[2023-06-24 15:40:47,590] cal percent loss: 0.0479
[2023-06-24 15:40:47,590] mass loss: 9.2242
[2023-06-24 15:40:47,590] mass percent loss: 0.0423
[2023-06-24 15:40:47,590] fat loss: 0.8867
[2023-06-24 15:40:47,590] fat percent loss: 0.0698
[2023-06-24 15:40:47,590] carb loss: 1.1609
[2023-06-24 15:40:47,590] carb percent loss: 0.0602
[2023-06-24 15:40:47,590] protein loss: 1.0151
[2023-06-24 15:40:47,590] protein percent loss: 0.0561
[2023-06-24 15:40:47,590] ingrs percent loss: 0.1775
[2023-06-24 15:40:47,590] Epoch 127/150
[2023-06-24 15:40:56,951] test loss: 1.3869
[2023-06-24 15:40:56,952] cal loss: 45.2188
[2023-06-24 15:40:56,952] cal percent loss: 0.1773
[2023-06-24 15:40:56,952] mass loss: 24.7899
[2023-06-24 15:40:56,952] mass percent loss: 0.1137
[2023-06-24 15:40:56,952] fat loss: 3.3774
[2023-06-24 15:40:56,953] fat percent loss: 0.2659
[2023-06-24 15:40:56,953] carb loss: 5.2059
[2023-06-24 15:40:56,953] carb percent loss: 0.2697
[2023-06-24 15:40:56,953] protein loss: 4.1159
[2023-06-24 15:40:56,953] protein percent loss: 0.2274
[2023-06-24 15:40:56,953] ingrs percent loss: 0.3409
[2023-06-24 15:40:56,953] Epoch 128/150
[2023-06-24 15:42:56,813] train loss: 0.4498
[2023-06-24 15:42:56,814] cal loss: 11.6005
[2023-06-24 15:42:56,814] cal percent loss: 0.0455
[2023-06-24 15:42:56,814] mass loss: 9.0701
[2023-06-24 15:42:56,814] mass percent loss: 0.0416
[2023-06-24 15:42:56,814] fat loss: 0.8474
[2023-06-24 15:42:56,814] fat percent loss: 0.0667
[2023-06-24 15:42:56,814] carb loss: 1.1866
[2023-06-24 15:42:56,814] carb percent loss: 0.0615
[2023-06-24 15:42:56,814] protein loss: 0.9736
[2023-06-24 15:42:56,814] protein percent loss: 0.0538
[2023-06-24 15:42:56,814] ingrs percent loss: 0.1771
[2023-06-24 15:42:56,815] Epoch 128/150
[2023-06-24 15:43:06,465] test loss: 1.4636
[2023-06-24 15:43:06,466] cal loss: 49.3143
[2023-06-24 15:43:06,466] cal percent loss: 0.1934
[2023-06-24 15:43:06,466] mass loss: 27.7284
[2023-06-24 15:43:06,466] mass percent loss: 0.1272
[2023-06-24 15:43:06,466] fat loss: 3.5981
[2023-06-24 15:43:06,466] fat percent loss: 0.2833
[2023-06-24 15:43:06,467] carb loss: 5.1506
[2023-06-24 15:43:06,467] carb percent loss: 0.2669
[2023-06-24 15:43:06,467] protein loss: 4.4916
[2023-06-24 15:43:06,467] protein percent loss: 0.2482
[2023-06-24 15:43:06,467] ingrs percent loss: 0.3485
[2023-06-24 15:43:06,467] Epoch 129/150
[2023-06-24 15:45:07,834] train loss: 0.4474
[2023-06-24 15:45:07,835] cal loss: 11.8431
[2023-06-24 15:45:07,835] cal percent loss: 0.0464
[2023-06-24 15:45:07,835] mass loss: 8.9896
[2023-06-24 15:45:07,835] mass percent loss: 0.0412
[2023-06-24 15:45:07,835] fat loss: 0.8216
[2023-06-24 15:45:07,835] fat percent loss: 0.0647
[2023-06-24 15:45:07,835] carb loss: 1.1677
[2023-06-24 15:45:07,835] carb percent loss: 0.0605
[2023-06-24 15:45:07,835] protein loss: 0.9783
[2023-06-24 15:45:07,835] protein percent loss: 0.0540
[2023-06-24 15:45:07,835] ingrs percent loss: 0.1766
[2023-06-24 15:45:07,835] Epoch 129/150
[2023-06-24 15:45:16,720] test loss: 1.4714
[2023-06-24 15:45:16,721] cal loss: 50.4057
[2023-06-24 15:45:16,721] cal percent loss: 0.1977
[2023-06-24 15:45:16,721] mass loss: 28.0738
[2023-06-24 15:45:16,721] mass percent loss: 0.1288
[2023-06-24 15:45:16,721] fat loss: 3.5427
[2023-06-24 15:45:16,721] fat percent loss: 0.2790
[2023-06-24 15:45:16,721] carb loss: 5.2785
[2023-06-24 15:45:16,721] carb percent loss: 0.2735
[2023-06-24 15:45:16,721] protein loss: 4.4667
[2023-06-24 15:45:16,721] protein percent loss: 0.2468
[2023-06-24 15:45:16,721] ingrs percent loss: 0.3489
[2023-06-24 15:45:16,721] Epoch 130/150
[2023-06-24 15:47:17,082] train loss: 0.4407
[2023-06-24 15:47:17,083] cal loss: 11.3597
[2023-06-24 15:47:17,083] cal percent loss: 0.0445
[2023-06-24 15:47:17,083] mass loss: 8.9025
[2023-06-24 15:47:17,083] mass percent loss: 0.0408
[2023-06-24 15:47:17,083] fat loss: 0.7954
[2023-06-24 15:47:17,083] fat percent loss: 0.0626
[2023-06-24 15:47:17,083] carb loss: 1.1327
[2023-06-24 15:47:17,083] carb percent loss: 0.0587
[2023-06-24 15:47:17,084] protein loss: 0.9723
[2023-06-24 15:47:17,084] protein percent loss: 0.0537
[2023-06-24 15:47:17,084] ingrs percent loss: 0.1764
[2023-06-24 15:47:17,084] Epoch 130/150
[2023-06-24 15:47:26,275] test loss: 1.4233
[2023-06-24 15:47:26,276] cal loss: 47.6068
[2023-06-24 15:47:26,276] cal percent loss: 0.1867
[2023-06-24 15:47:26,276] mass loss: 26.8679
[2023-06-24 15:47:26,276] mass percent loss: 0.1232
[2023-06-24 15:47:26,276] fat loss: 3.4106
[2023-06-24 15:47:26,277] fat percent loss: 0.2685
[2023-06-24 15:47:26,277] carb loss: 5.2363
[2023-06-24 15:47:26,277] carb percent loss: 0.2713
[2023-06-24 15:47:26,277] protein loss: 4.2766
[2023-06-24 15:47:26,277] protein percent loss: 0.2363
[2023-06-24 15:47:26,277] ingrs percent loss: 0.3420
[2023-06-24 15:47:26,278] Epoch 131/150
[2023-06-24 15:49:24,371] train loss: 0.4387
[2023-06-24 15:49:24,372] cal loss: 11.3224
[2023-06-24 15:49:24,372] cal percent loss: 0.0444
[2023-06-24 15:49:24,372] mass loss: 8.7204
[2023-06-24 15:49:24,372] mass percent loss: 0.0400
[2023-06-24 15:49:24,372] fat loss: 0.8237
[2023-06-24 15:49:24,372] fat percent loss: 0.0649
[2023-06-24 15:49:24,372] carb loss: 1.1083
[2023-06-24 15:49:24,373] carb percent loss: 0.0574
[2023-06-24 15:49:24,373] protein loss: 0.9351
[2023-06-24 15:49:24,373] protein percent loss: 0.0517
[2023-06-24 15:49:24,373] ingrs percent loss: 0.1765
[2023-06-24 15:49:24,373] Epoch 131/150
[2023-06-24 15:49:34,175] test loss: 1.3954
[2023-06-24 15:49:34,175] cal loss: 45.1898
[2023-06-24 15:49:34,176] cal percent loss: 0.1772
[2023-06-24 15:49:34,176] mass loss: 24.2248
[2023-06-24 15:49:34,176] mass percent loss: 0.1111
[2023-06-24 15:49:34,176] fat loss: 3.4591
[2023-06-24 15:49:34,176] fat percent loss: 0.2724
[2023-06-24 15:49:34,176] carb loss: 5.2465
[2023-06-24 15:49:34,176] carb percent loss: 0.2718
[2023-06-24 15:49:34,176] protein loss: 4.1014
[2023-06-24 15:49:34,176] protein percent loss: 0.2266
[2023-06-24 15:49:34,177] ingrs percent loss: 0.3458
[2023-06-24 15:49:34,177] Epoch 132/150
[2023-06-24 15:51:26,749] train loss: 0.4443
[2023-06-24 15:51:26,749] cal loss: 11.6912
[2023-06-24 15:51:26,750] cal percent loss: 0.0458
[2023-06-24 15:51:26,750] mass loss: 8.7158
[2023-06-24 15:51:26,750] mass percent loss: 0.0400
[2023-06-24 15:51:26,750] fat loss: 0.8474
[2023-06-24 15:51:26,750] fat percent loss: 0.0667
[2023-06-24 15:51:26,750] carb loss: 1.0966
[2023-06-24 15:51:26,750] carb percent loss: 0.0568
[2023-06-24 15:51:26,750] protein loss: 0.9897
[2023-06-24 15:51:26,750] protein percent loss: 0.0547
[2023-06-24 15:51:26,751] ingrs percent loss: 0.1765
[2023-06-24 15:51:26,751] Epoch 132/150
[2023-06-24 15:51:36,092] test loss: 1.5248
[2023-06-24 15:51:36,093] cal loss: 51.7702
[2023-06-24 15:51:36,093] cal percent loss: 0.2030
[2023-06-24 15:51:36,093] mass loss: 33.5577
[2023-06-24 15:51:36,093] mass percent loss: 0.1539
[2023-06-24 15:51:36,094] fat loss: 3.5589
[2023-06-24 15:51:36,094] fat percent loss: 0.2802
[2023-06-24 15:51:36,094] carb loss: 5.2497
[2023-06-24 15:51:36,094] carb percent loss: 0.2720
[2023-06-24 15:51:36,094] protein loss: 4.7346
[2023-06-24 15:51:36,094] protein percent loss: 0.2616
[2023-06-24 15:51:36,094] ingrs percent loss: 0.3493
[2023-06-24 15:51:36,094] Epoch 133/150
[2023-06-24 15:53:33,800] train loss: 0.4403
[2023-06-24 15:53:33,801] cal loss: 11.4492
[2023-06-24 15:53:33,801] cal percent loss: 0.0449
[2023-06-24 15:53:33,801] mass loss: 8.6439
[2023-06-24 15:53:33,801] mass percent loss: 0.0397
[2023-06-24 15:53:33,801] fat loss: 0.8193
[2023-06-24 15:53:33,802] fat percent loss: 0.0645
[2023-06-24 15:53:33,802] carb loss: 1.1118
[2023-06-24 15:53:33,802] carb percent loss: 0.0576
[2023-06-24 15:53:33,802] protein loss: 0.9675
[2023-06-24 15:53:33,802] protein percent loss: 0.0535
[2023-06-24 15:53:33,802] ingrs percent loss: 0.1766
[2023-06-24 15:53:33,802] Epoch 133/150
[2023-06-24 15:53:44,025] test loss: 1.8072
[2023-06-24 15:53:44,026] cal loss: 60.8712
[2023-06-24 15:53:44,026] cal percent loss: 0.2387
[2023-06-24 15:53:44,026] mass loss: 54.9646
[2023-06-24 15:53:44,026] mass percent loss: 0.2521
[2023-06-24 15:53:44,026] fat loss: 4.0715
[2023-06-24 15:53:44,027] fat percent loss: 0.3206
[2023-06-24 15:53:44,027] carb loss: 6.2049
[2023-06-24 15:53:44,027] carb percent loss: 0.3215
[2023-06-24 15:53:44,027] protein loss: 5.1327
[2023-06-24 15:53:44,027] protein percent loss: 0.2836
[2023-06-24 15:53:44,027] ingrs percent loss: 0.3584
[2023-06-24 15:53:44,027] Epoch 134/150
[2023-06-24 15:55:41,025] train loss: 0.4406
[2023-06-24 15:55:41,026] cal loss: 11.6397
[2023-06-24 15:55:41,026] cal percent loss: 0.0456
[2023-06-24 15:55:41,026] mass loss: 8.6143
[2023-06-24 15:55:41,026] mass percent loss: 0.0395
[2023-06-24 15:55:41,026] fat loss: 0.8398
[2023-06-24 15:55:41,026] fat percent loss: 0.0661
[2023-06-24 15:55:41,026] carb loss: 1.0798
[2023-06-24 15:55:41,026] carb percent loss: 0.0559
[2023-06-24 15:55:41,026] protein loss: 0.9674
[2023-06-24 15:55:41,027] protein percent loss: 0.0534
[2023-06-24 15:55:41,027] ingrs percent loss: 0.1761
[2023-06-24 15:55:41,027] Epoch 134/150
[2023-06-24 15:55:50,212] test loss: 1.5210
[2023-06-24 15:55:50,213] cal loss: 51.4327
[2023-06-24 15:55:50,213] cal percent loss: 0.2017
[2023-06-24 15:55:50,213] mass loss: 32.6245
[2023-06-24 15:55:50,213] mass percent loss: 0.1497
[2023-06-24 15:55:50,213] fat loss: 3.5742
[2023-06-24 15:55:50,213] fat percent loss: 0.2814
[2023-06-24 15:55:50,213] carb loss: 5.2809
[2023-06-24 15:55:50,213] carb percent loss: 0.2736
[2023-06-24 15:55:50,214] protein loss: 4.7762
[2023-06-24 15:55:50,214] protein percent loss: 0.2639
[2023-06-24 15:55:50,214] ingrs percent loss: 0.3481
[2023-06-24 15:55:50,214] Epoch 135/150
[2023-06-24 15:57:46,468] train loss: 0.4328
[2023-06-24 15:57:46,469] cal loss: 11.2302
[2023-06-24 15:57:46,469] cal percent loss: 0.0440
[2023-06-24 15:57:46,469] mass loss: 8.5214
[2023-06-24 15:57:46,469] mass percent loss: 0.0391
[2023-06-24 15:57:46,469] fat loss: 0.7854
[2023-06-24 15:57:46,469] fat percent loss: 0.0618
[2023-06-24 15:57:46,469] carb loss: 1.0883
[2023-06-24 15:57:46,469] carb percent loss: 0.0564
[2023-06-24 15:57:46,469] protein loss: 0.9298
[2023-06-24 15:57:46,469] protein percent loss: 0.0514
[2023-06-24 15:57:46,469] ingrs percent loss: 0.1763
[2023-06-24 15:57:46,469] Epoch 135/150
[2023-06-24 15:57:55,701] test loss: 1.3994
[2023-06-24 15:57:55,702] cal loss: 45.0788
[2023-06-24 15:57:55,702] cal percent loss: 0.1768
[2023-06-24 15:57:55,702] mass loss: 27.2120
[2023-06-24 15:57:55,703] mass percent loss: 0.1248
[2023-06-24 15:57:55,703] fat loss: 3.3933
[2023-06-24 15:57:55,703] fat percent loss: 0.2672
[2023-06-24 15:57:55,703] carb loss: 4.9878
[2023-06-24 15:57:55,703] carb percent loss: 0.2584
[2023-06-24 15:57:55,703] protein loss: 4.2168
[2023-06-24 15:57:55,703] protein percent loss: 0.2330
[2023-06-24 15:57:55,703] ingrs percent loss: 0.3428
[2023-06-24 15:57:55,704] Epoch 136/150
[2023-06-24 15:59:58,064] train loss: 0.4308
[2023-06-24 15:59:58,065] cal loss: 11.2802
[2023-06-24 15:59:58,065] cal percent loss: 0.0442
[2023-06-24 15:59:58,065] mass loss: 8.4392
[2023-06-24 15:59:58,065] mass percent loss: 0.0387
[2023-06-24 15:59:58,065] fat loss: 0.7976
[2023-06-24 15:59:58,065] fat percent loss: 0.0628
[2023-06-24 15:59:58,065] carb loss: 1.0714
[2023-06-24 15:59:58,066] carb percent loss: 0.0555
[2023-06-24 15:59:58,066] protein loss: 0.9042
[2023-06-24 15:59:58,066] protein percent loss: 0.0500
[2023-06-24 15:59:58,066] ingrs percent loss: 0.1757
[2023-06-24 15:59:58,066] Epoch 136/150
[2023-06-24 16:00:07,789] test loss: 1.4470
[2023-06-24 16:00:07,790] cal loss: 45.7222
[2023-06-24 16:00:07,790] cal percent loss: 0.1793
[2023-06-24 16:00:07,790] mass loss: 30.6650
[2023-06-24 16:00:07,791] mass percent loss: 0.1407
[2023-06-24 16:00:07,791] fat loss: 3.4758
[2023-06-24 16:00:07,791] fat percent loss: 0.2737
[2023-06-24 16:00:07,791] carb loss: 5.2134
[2023-06-24 16:00:07,791] carb percent loss: 0.2701
[2023-06-24 16:00:07,791] protein loss: 4.3700
[2023-06-24 16:00:07,791] protein percent loss: 0.2414
[2023-06-24 16:00:07,792] ingrs percent loss: 0.3425
[2023-06-24 16:00:07,792] Epoch 137/150
[2023-06-24 16:02:07,185] train loss: 0.4247
[2023-06-24 16:02:07,186] cal loss: 10.7939
[2023-06-24 16:02:07,186] cal percent loss: 0.0423
[2023-06-24 16:02:07,187] mass loss: 8.4130
[2023-06-24 16:02:07,187] mass percent loss: 0.0386
[2023-06-24 16:02:07,187] fat loss: 0.7665
[2023-06-24 16:02:07,187] fat percent loss: 0.0604
[2023-06-24 16:02:07,187] carb loss: 1.0538
[2023-06-24 16:02:07,187] carb percent loss: 0.0546
[2023-06-24 16:02:07,187] protein loss: 0.8991
[2023-06-24 16:02:07,187] protein percent loss: 0.0497
[2023-06-24 16:02:07,188] ingrs percent loss: 0.1752
[2023-06-24 16:02:07,188] Epoch 137/150
[2023-06-24 16:02:16,666] test loss: 1.4050
[2023-06-24 16:02:16,667] cal loss: 45.7751
[2023-06-24 16:02:16,667] cal percent loss: 0.1795
[2023-06-24 16:02:16,667] mass loss: 25.5482
[2023-06-24 16:02:16,667] mass percent loss: 0.1172
[2023-06-24 16:02:16,667] fat loss: 3.4422
[2023-06-24 16:02:16,667] fat percent loss: 0.2710
[2023-06-24 16:02:16,667] carb loss: 5.0319
[2023-06-24 16:02:16,667] carb percent loss: 0.2607
[2023-06-24 16:02:16,667] protein loss: 4.2767
[2023-06-24 16:02:16,667] protein percent loss: 0.2363
[2023-06-24 16:02:16,667] ingrs percent loss: 0.3469
[2023-06-24 16:02:16,667] Epoch 138/150
[2023-06-24 16:04:15,561] train loss: 0.4343
[2023-06-24 16:04:15,562] cal loss: 11.3186
[2023-06-24 16:04:15,562] cal percent loss: 0.0444
[2023-06-24 16:04:15,562] mass loss: 8.5984
[2023-06-24 16:04:15,562] mass percent loss: 0.0394
[2023-06-24 16:04:15,562] fat loss: 0.7945
[2023-06-24 16:04:15,562] fat percent loss: 0.0626
[2023-06-24 16:04:15,562] carb loss: 1.0791
[2023-06-24 16:04:15,562] carb percent loss: 0.0559
[2023-06-24 16:04:15,563] protein loss: 0.9482
[2023-06-24 16:04:15,563] protein percent loss: 0.0524
[2023-06-24 16:04:15,563] ingrs percent loss: 0.1757
[2023-06-24 16:04:15,563] Epoch 138/150
[2023-06-24 16:04:25,401] test loss: 1.3794
[2023-06-24 16:04:25,402] cal loss: 44.2582
[2023-06-24 16:04:25,402] cal percent loss: 0.1736
[2023-06-24 16:04:25,402] mass loss: 24.0595
[2023-06-24 16:04:25,402] mass percent loss: 0.1104
[2023-06-24 16:04:25,403] fat loss: 3.4397
[2023-06-24 16:04:25,403] fat percent loss: 0.2708
[2023-06-24 16:04:25,403] carb loss: 5.0785
[2023-06-24 16:04:25,403] carb percent loss: 0.2631
[2023-06-24 16:04:25,403] protein loss: 4.1562
[2023-06-24 16:04:25,403] protein percent loss: 0.2296
[2023-06-24 16:04:25,403] ingrs percent loss: 0.3413
[2023-06-24 16:04:25,403] Epoch 139/150
[2023-06-24 16:06:25,537] train loss: 0.4258
[2023-06-24 16:06:25,538] cal loss: 10.9000
[2023-06-24 16:06:25,538] cal percent loss: 0.0427
[2023-06-24 16:06:25,539] mass loss: 8.2847
[2023-06-24 16:06:25,539] mass percent loss: 0.0380
[2023-06-24 16:06:25,539] fat loss: 0.7671
[2023-06-24 16:06:25,539] fat percent loss: 0.0604
[2023-06-24 16:06:25,539] carb loss: 1.0690
[2023-06-24 16:06:25,539] carb percent loss: 0.0554
[2023-06-24 16:06:25,539] protein loss: 0.9087
[2023-06-24 16:06:25,539] protein percent loss: 0.0502
[2023-06-24 16:06:25,539] ingrs percent loss: 0.1754
[2023-06-24 16:06:25,540] Epoch 139/150
[2023-06-24 16:06:35,076] test loss: 1.4451
[2023-06-24 16:06:35,076] cal loss: 48.4195
[2023-06-24 16:06:35,076] cal percent loss: 0.1899
[2023-06-24 16:06:35,076] mass loss: 28.1168
[2023-06-24 16:06:35,076] mass percent loss: 0.1290
[2023-06-24 16:06:35,076] fat loss: 3.4611
[2023-06-24 16:06:35,076] fat percent loss: 0.2725
[2023-06-24 16:06:35,077] carb loss: 5.1788
[2023-06-24 16:06:35,077] carb percent loss: 0.2683
[2023-06-24 16:06:35,077] protein loss: 4.3385
[2023-06-24 16:06:35,077] protein percent loss: 0.2397
[2023-06-24 16:06:35,077] ingrs percent loss: 0.3482
[2023-06-24 16:06:35,077] Epoch 140/150
[2023-06-24 16:08:33,837] train loss: 0.4241
[2023-06-24 16:08:33,838] cal loss: 10.7145
[2023-06-24 16:08:33,838] cal percent loss: 0.0420
[2023-06-24 16:08:33,838] mass loss: 8.3696
[2023-06-24 16:08:33,838] mass percent loss: 0.0384
[2023-06-24 16:08:33,838] fat loss: 0.7847
[2023-06-24 16:08:33,838] fat percent loss: 0.0618
[2023-06-24 16:08:33,838] carb loss: 1.0410
[2023-06-24 16:08:33,838] carb percent loss: 0.0539
[2023-06-24 16:08:33,839] protein loss: 0.8897
[2023-06-24 16:08:33,839] protein percent loss: 0.0492
[2023-06-24 16:08:33,839] ingrs percent loss: 0.1750
[2023-06-24 16:08:33,839] Epoch 140/150
[2023-06-24 16:08:42,372] test loss: 1.3700
[2023-06-24 16:08:42,372] cal loss: 43.6303
[2023-06-24 16:08:42,372] cal percent loss: 0.1711
[2023-06-24 16:08:42,372] mass loss: 24.5454
[2023-06-24 16:08:42,372] mass percent loss: 0.1126
[2023-06-24 16:08:42,372] fat loss: 3.2968
[2023-06-24 16:08:42,372] fat percent loss: 0.2596
[2023-06-24 16:08:42,373] carb loss: 5.0593
[2023-06-24 16:08:42,373] carb percent loss: 0.2621
[2023-06-24 16:08:42,373] protein loss: 4.1440
[2023-06-24 16:08:42,373] protein percent loss: 0.2290
[2023-06-24 16:08:42,373] ingrs percent loss: 0.3440
[2023-06-24 16:08:42,373] Epoch 141/150
[2023-06-24 16:10:41,087] train loss: 0.4247
[2023-06-24 16:10:41,087] cal loss: 10.7315
[2023-06-24 16:10:41,088] cal percent loss: 0.0421
[2023-06-24 16:10:41,088] mass loss: 8.4130
[2023-06-24 16:10:41,088] mass percent loss: 0.0386
[2023-06-24 16:10:41,088] fat loss: 0.7668
[2023-06-24 16:10:41,088] fat percent loss: 0.0604
[2023-06-24 16:10:41,088] carb loss: 1.0425
[2023-06-24 16:10:41,088] carb percent loss: 0.0540
[2023-06-24 16:10:41,088] protein loss: 0.9212
[2023-06-24 16:10:41,088] protein percent loss: 0.0509
[2023-06-24 16:10:41,088] ingrs percent loss: 0.1749
[2023-06-24 16:10:41,088] Epoch 141/150
[2023-06-24 16:10:50,525] test loss: 1.4944
[2023-06-24 16:10:50,526] cal loss: 49.9481
[2023-06-24 16:10:50,526] cal percent loss: 0.1959
[2023-06-24 16:10:50,526] mass loss: 32.1108
[2023-06-24 16:10:50,526] mass percent loss: 0.1473
[2023-06-24 16:10:50,527] fat loss: 3.4689
[2023-06-24 16:10:50,527] fat percent loss: 0.2731
[2023-06-24 16:10:50,527] carb loss: 5.5884
[2023-06-24 16:10:50,527] carb percent loss: 0.2896
[2023-06-24 16:10:50,527] protein loss: 4.3893
[2023-06-24 16:10:50,527] protein percent loss: 0.2425
[2023-06-24 16:10:50,527] ingrs percent loss: 0.3447
[2023-06-24 16:10:50,528] Epoch 142/150
[2023-06-24 16:12:51,915] train loss: 0.4233
[2023-06-24 16:12:51,916] cal loss: 10.8769
[2023-06-24 16:12:51,916] cal percent loss: 0.0427
[2023-06-24 16:12:51,916] mass loss: 8.0383
[2023-06-24 16:12:51,916] mass percent loss: 0.0369
[2023-06-24 16:12:51,916] fat loss: 0.7861
[2023-06-24 16:12:51,916] fat percent loss: 0.0619
[2023-06-24 16:12:51,917] carb loss: 1.0188
[2023-06-24 16:12:51,917] carb percent loss: 0.0528
[2023-06-24 16:12:51,917] protein loss: 0.9122
[2023-06-24 16:12:51,917] protein percent loss: 0.0504
[2023-06-24 16:12:51,917] ingrs percent loss: 0.1753
[2023-06-24 16:12:51,917] Epoch 142/150
[2023-06-24 16:13:02,154] test loss: 1.5255
[2023-06-24 16:13:02,155] cal loss: 49.3209
[2023-06-24 16:13:02,155] cal percent loss: 0.1934
[2023-06-24 16:13:02,155] mass loss: 36.0388
[2023-06-24 16:13:02,155] mass percent loss: 0.1653
[2023-06-24 16:13:02,155] fat loss: 3.6048
[2023-06-24 16:13:02,156] fat percent loss: 0.2838
[2023-06-24 16:13:02,156] carb loss: 5.4952
[2023-06-24 16:13:02,156] carb percent loss: 0.2847
[2023-06-24 16:13:02,156] protein loss: 4.4436
[2023-06-24 16:13:02,156] protein percent loss: 0.2455
[2023-06-24 16:13:02,156] ingrs percent loss: 0.3458
[2023-06-24 16:13:02,156] Epoch 143/150
[2023-06-24 16:15:05,662] train loss: 0.4225
[2023-06-24 16:15:05,663] cal loss: 10.7773
[2023-06-24 16:15:05,663] cal percent loss: 0.0423
[2023-06-24 16:15:05,663] mass loss: 8.2603
[2023-06-24 16:15:05,663] mass percent loss: 0.0379
[2023-06-24 16:15:05,663] fat loss: 0.7516
[2023-06-24 16:15:05,663] fat percent loss: 0.0592
[2023-06-24 16:15:05,664] carb loss: 1.0390
[2023-06-24 16:15:05,664] carb percent loss: 0.0538
[2023-06-24 16:15:05,664] protein loss: 0.9106
[2023-06-24 16:15:05,664] protein percent loss: 0.0503
[2023-06-24 16:15:05,664] ingrs percent loss: 0.1753
[2023-06-24 16:15:05,664] Epoch 143/150
[2023-06-24 16:15:15,024] test loss: 1.4160
[2023-06-24 16:15:15,024] cal loss: 46.8178
[2023-06-24 16:15:15,024] cal percent loss: 0.1836
[2023-06-24 16:15:15,025] mass loss: 26.9139
[2023-06-24 16:15:15,025] mass percent loss: 0.1235
[2023-06-24 16:15:15,025] fat loss: 3.4395
[2023-06-24 16:15:15,025] fat percent loss: 0.2708
[2023-06-24 16:15:15,025] carb loss: 5.1446
[2023-06-24 16:15:15,025] carb percent loss: 0.2666
[2023-06-24 16:15:15,026] protein loss: 4.1822
[2023-06-24 16:15:15,026] protein percent loss: 0.2311
[2023-06-24 16:15:15,026] ingrs percent loss: 0.3446
[2023-06-24 16:15:15,026] Epoch 144/150
[2023-06-24 16:17:16,727] train loss: 0.4261
[2023-06-24 16:17:16,727] cal loss: 10.9616
[2023-06-24 16:17:16,727] cal percent loss: 0.0430
[2023-06-24 16:17:16,727] mass loss: 8.1870
[2023-06-24 16:17:16,728] mass percent loss: 0.0376
[2023-06-24 16:17:16,728] fat loss: 0.7674
[2023-06-24 16:17:16,728] fat percent loss: 0.0604
[2023-06-24 16:17:16,728] carb loss: 1.0705
[2023-06-24 16:17:16,728] carb percent loss: 0.0555
[2023-06-24 16:17:16,728] protein loss: 0.9132
[2023-06-24 16:17:16,728] protein percent loss: 0.0505
[2023-06-24 16:17:16,729] ingrs percent loss: 0.1758
[2023-06-24 16:17:16,729] Epoch 144/150
[2023-06-24 16:17:24,728] test loss: 1.3901
[2023-06-24 16:17:24,728] cal loss: 44.0529
[2023-06-24 16:17:24,728] cal percent loss: 0.1728
[2023-06-24 16:17:24,728] mass loss: 24.8193
[2023-06-24 16:17:24,729] mass percent loss: 0.1139
[2023-06-24 16:17:24,729] fat loss: 3.5169
[2023-06-24 16:17:24,729] fat percent loss: 0.2769
[2023-06-24 16:17:24,729] carb loss: 5.0998
[2023-06-24 16:17:24,729] carb percent loss: 0.2642
[2023-06-24 16:17:24,729] protein loss: 4.1548
[2023-06-24 16:17:24,729] protein percent loss: 0.2295
[2023-06-24 16:17:24,729] ingrs percent loss: 0.3416
[2023-06-24 16:17:24,729] Epoch 145/150
[2023-06-24 16:19:22,836] train loss: 0.4181
[2023-06-24 16:19:22,837] cal loss: 10.5660
[2023-06-24 16:19:22,837] cal percent loss: 0.0414
[2023-06-24 16:19:22,837] mass loss: 8.0053
[2023-06-24 16:19:22,837] mass percent loss: 0.0367
[2023-06-24 16:19:22,838] fat loss: 0.7533
[2023-06-24 16:19:22,838] fat percent loss: 0.0593
[2023-06-24 16:19:22,838] carb loss: 1.0182
[2023-06-24 16:19:22,838] carb percent loss: 0.0528
[2023-06-24 16:19:22,838] protein loss: 0.8881
[2023-06-24 16:19:22,838] protein percent loss: 0.0491
[2023-06-24 16:19:22,838] ingrs percent loss: 0.1753
[2023-06-24 16:19:22,838] Epoch 145/150
[2023-06-24 16:19:31,933] test loss: 1.5796
[2023-06-24 16:19:31,933] cal loss: 54.8903
[2023-06-24 16:19:31,933] cal percent loss: 0.2153
[2023-06-24 16:19:31,934] mass loss: 35.7680
[2023-06-24 16:19:31,934] mass percent loss: 0.1641
[2023-06-24 16:19:31,934] fat loss: 3.6982
[2023-06-24 16:19:31,934] fat percent loss: 0.2912
[2023-06-24 16:19:31,934] carb loss: 5.4919
[2023-06-24 16:19:31,934] carb percent loss: 0.2846
[2023-06-24 16:19:31,934] protein loss: 4.8186
[2023-06-24 16:19:31,934] protein percent loss: 0.2662
[2023-06-24 16:19:31,934] ingrs percent loss: 0.3510
[2023-06-24 16:19:31,934] Epoch 146/150
[2023-06-24 16:21:39,379] train loss: 0.4167
[2023-06-24 16:21:39,380] cal loss: 10.4872
[2023-06-24 16:21:39,380] cal percent loss: 0.0411
[2023-06-24 16:21:39,380] mass loss: 8.0440
[2023-06-24 16:21:39,380] mass percent loss: 0.0369
[2023-06-24 16:21:39,380] fat loss: 0.7475
[2023-06-24 16:21:39,381] fat percent loss: 0.0589
[2023-06-24 16:21:39,381] carb loss: 1.0145
[2023-06-24 16:21:39,381] carb percent loss: 0.0526
[2023-06-24 16:21:39,381] protein loss: 0.8838
[2023-06-24 16:21:39,381] protein percent loss: 0.0488
[2023-06-24 16:21:39,381] ingrs percent loss: 0.1748
[2023-06-24 16:21:39,381] Epoch 146/150
[2023-06-24 16:21:48,604] test loss: 1.4302
[2023-06-24 16:21:48,605] cal loss: 46.5507
[2023-06-24 16:21:48,605] cal percent loss: 0.1826
[2023-06-24 16:21:48,605] mass loss: 27.4399
[2023-06-24 16:21:48,606] mass percent loss: 0.1259
[2023-06-24 16:21:48,606] fat loss: 3.4588
[2023-06-24 16:21:48,606] fat percent loss: 0.2723
[2023-06-24 16:21:48,606] carb loss: 5.1482
[2023-06-24 16:21:48,606] carb percent loss: 0.2667
[2023-06-24 16:21:48,606] protein loss: 4.3153
[2023-06-24 16:21:48,606] protein percent loss: 0.2384
[2023-06-24 16:21:48,606] ingrs percent loss: 0.3486
[2023-06-24 16:21:48,607] Epoch 147/150
[2023-06-24 16:23:46,995] train loss: 0.4174
[2023-06-24 16:23:46,995] cal loss: 10.5979
[2023-06-24 16:23:46,995] cal percent loss: 0.0416
[2023-06-24 16:23:46,996] mass loss: 7.8626
[2023-06-24 16:23:46,996] mass percent loss: 0.0361
[2023-06-24 16:23:46,996] fat loss: 0.7507
[2023-06-24 16:23:46,996] fat percent loss: 0.0591
[2023-06-24 16:23:46,996] carb loss: 1.0163
[2023-06-24 16:23:46,996] carb percent loss: 0.0527
[2023-06-24 16:23:46,996] protein loss: 0.8934
[2023-06-24 16:23:46,996] protein percent loss: 0.0494
[2023-06-24 16:23:46,997] ingrs percent loss: 0.1753
[2023-06-24 16:23:46,997] Epoch 147/150
[2023-06-24 16:23:56,706] test loss: 1.3871
[2023-06-24 16:23:56,707] cal loss: 45.8446
[2023-06-24 16:23:56,707] cal percent loss: 0.1798
[2023-06-24 16:23:56,707] mass loss: 25.3313
[2023-06-24 16:23:56,708] mass percent loss: 0.1162
[2023-06-24 16:23:56,708] fat loss: 3.3918
[2023-06-24 16:23:56,708] fat percent loss: 0.2671
[2023-06-24 16:23:56,708] carb loss: 4.9679
[2023-06-24 16:23:56,708] carb percent loss: 0.2574
[2023-06-24 16:23:56,708] protein loss: 4.2250
[2023-06-24 16:23:56,708] protein percent loss: 0.2334
[2023-06-24 16:23:56,708] ingrs percent loss: 0.3392
[2023-06-24 16:23:56,709] Epoch 148/150
[2023-06-24 16:26:01,217] train loss: 0.4198
[2023-06-24 16:26:01,217] cal loss: 10.4530
[2023-06-24 16:26:01,217] cal percent loss: 0.0410
[2023-06-24 16:26:01,218] mass loss: 8.3766
[2023-06-24 16:26:01,218] mass percent loss: 0.0384
[2023-06-24 16:26:01,218] fat loss: 0.7480
[2023-06-24 16:26:01,218] fat percent loss: 0.0589
[2023-06-24 16:26:01,218] carb loss: 1.0170
[2023-06-24 16:26:01,218] carb percent loss: 0.0527
[2023-06-24 16:26:01,218] protein loss: 0.8997
[2023-06-24 16:26:01,218] protein percent loss: 0.0497
[2023-06-24 16:26:01,218] ingrs percent loss: 0.1752
[2023-06-24 16:26:01,218] Epoch 148/150
[2023-06-24 16:26:11,433] test loss: 1.4643
[2023-06-24 16:26:11,433] cal loss: 47.5339
[2023-06-24 16:26:11,434] cal percent loss: 0.1864
[2023-06-24 16:26:11,434] mass loss: 31.2059
[2023-06-24 16:26:11,434] mass percent loss: 0.1431
[2023-06-24 16:26:11,434] fat loss: 3.6384
[2023-06-24 16:26:11,434] fat percent loss: 0.2865
[2023-06-24 16:26:11,434] carb loss: 5.2135
[2023-06-24 16:26:11,434] carb percent loss: 0.2701
[2023-06-24 16:26:11,434] protein loss: 4.2567
[2023-06-24 16:26:11,435] protein percent loss: 0.2352
[2023-06-24 16:26:11,435] ingrs percent loss: 0.3417
[2023-06-24 16:26:11,435] Epoch 149/150
[2023-06-24 16:28:11,979] train loss: 0.4181
[2023-06-24 16:28:11,980] cal loss: 10.5887
[2023-06-24 16:28:11,980] cal percent loss: 0.0415
[2023-06-24 16:28:11,980] mass loss: 8.1431
[2023-06-24 16:28:11,980] mass percent loss: 0.0374
[2023-06-24 16:28:11,980] fat loss: 0.7517
[2023-06-24 16:28:11,980] fat percent loss: 0.0592
[2023-06-24 16:28:11,980] carb loss: 0.9840
[2023-06-24 16:28:11,980] carb percent loss: 0.0510
[2023-06-24 16:28:11,980] protein loss: 0.9083
[2023-06-24 16:28:11,980] protein percent loss: 0.0502
[2023-06-24 16:28:11,980] ingrs percent loss: 0.1750
[2023-06-24 16:28:11,980] Epoch 149/150
[2023-06-24 16:28:21,644] test loss: 1.5511
[2023-06-24 16:28:21,644] cal loss: 52.0444
[2023-06-24 16:28:21,644] cal percent loss: 0.2041
[2023-06-24 16:28:21,645] mass loss: 35.5085
[2023-06-24 16:28:21,645] mass percent loss: 0.1629
[2023-06-24 16:28:21,645] fat loss: 3.6026
[2023-06-24 16:28:21,645] fat percent loss: 0.2837
[2023-06-24 16:28:21,645] carb loss: 5.3340
[2023-06-24 16:28:21,645] carb percent loss: 0.2764
[2023-06-24 16:28:21,645] protein loss: 4.8929
[2023-06-24 16:28:21,645] protein percent loss: 0.2703
[2023-06-24 16:28:21,646] ingrs percent loss: 0.3475
[2023-06-24 16:28:21,646] Epoch 150/150
[2023-06-24 16:30:25,198] train loss: 0.4132
[2023-06-24 16:30:25,199] cal loss: 10.3005
[2023-06-24 16:30:25,199] cal percent loss: 0.0404
[2023-06-24 16:30:25,199] mass loss: 7.9577
[2023-06-24 16:30:25,199] mass percent loss: 0.0365
[2023-06-24 16:30:25,199] fat loss: 0.7336
[2023-06-24 16:30:25,199] fat percent loss: 0.0578
[2023-06-24 16:30:25,199] carb loss: 1.0205
[2023-06-24 16:30:25,200] carb percent loss: 0.0529
[2023-06-24 16:30:25,200] protein loss: 0.8578
[2023-06-24 16:30:25,200] protein percent loss: 0.0474
[2023-06-24 16:30:25,200] ingrs percent loss: 0.1748
[2023-06-24 16:30:25,200] Epoch 150/150
[2023-06-24 16:30:35,055] test loss: 1.3970
[2023-06-24 16:30:35,056] cal loss: 45.5741
[2023-06-24 16:30:35,056] cal percent loss: 0.1787
[2023-06-24 16:30:35,056] mass loss: 26.4481
[2023-06-24 16:30:35,056] mass percent loss: 0.1213
[2023-06-24 16:30:35,056] fat loss: 3.2846
[2023-06-24 16:30:35,056] fat percent loss: 0.2586
[2023-06-24 16:30:35,056] carb loss: 5.1437
[2023-06-24 16:30:35,057] carb percent loss: 0.2665
[2023-06-24 16:30:35,057] protein loss: 4.2262
[2023-06-24 16:30:35,057] protein percent loss: 0.2335
[2023-06-24 16:30:35,057] ingrs percent loss: 0.3435
[2023-06-25 02:07:34,631] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpn_mltingrs_resnet101_wrot_fc3_nodrop_attninit_warmup_smaller_150ep_mltscl.pt
TITLE:
- fpn multi ingrs with aug+rot fc 3 no dropout smaller new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 02:07:37,524] Epoch 1/150
[2023-06-25 02:07:39,640] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 02:07:41,263] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,266] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,266] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,273] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,273] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,280] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,280] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,282] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,282] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,288] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,288] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,294] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,294] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,296] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,296] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,305] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,305] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,311] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,312] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,313] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,313] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,320] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,320] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,326] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,326] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,328] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,328] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,334] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,334] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,340] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,341] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,342] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,342] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,349] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,349] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,355] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,355] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,357] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,357] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,363] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,363] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,369] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,369] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,371] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,371] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,377] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,377] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,384] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,384] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,385] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,386] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,392] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,392] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,398] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,398] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,400] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,400] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,406] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,406] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,412] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,412] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,414] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,414] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,420] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,421] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,427] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,427] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,429] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,429] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,435] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:41,435] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:41,441] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,103] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,104] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,104] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,105] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:07:42,105] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,105] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,105] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,105] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,106] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,107] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,108] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,109] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:07:42,109] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,109] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:07:42,109] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,110] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:07:42,111] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,111] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,111] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,111] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:42,111] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,111] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:42,111] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,111] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,111] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,111] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:42,111] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:07:42,111] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,111] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,111] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,112] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,113] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,114] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,118] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,119] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,120] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:07:42,121] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,122] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,125] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,126] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,127] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,128] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,129] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,130] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:42,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,145] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,146] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,147] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,147] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:42,147] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:42,147] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:07:42,147] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:07:42,147] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:07:45,703] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,706] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,706] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,712] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,712] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,718] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,718] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,720] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,720] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,726] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,726] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,733] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,733] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,734] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,734] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,741] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,741] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,747] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,747] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,748] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,749] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,755] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,755] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,761] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,761] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,763] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,763] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,769] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,769] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,775] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,775] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,777] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,777] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,783] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,783] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,789] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,789] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,791] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,791] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,797] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,797] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,803] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,803] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,805] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,805] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,811] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,811] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,818] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,818] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,819] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,820] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,826] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,826] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,832] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,832] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,834] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,834] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,840] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,840] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,846] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,846] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,848] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,848] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,854] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,854] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,861] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,861] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,862] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,862] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,868] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:45,869] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:07:45,875] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:07:46,510] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:07:46,511] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:07:46,511] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:07:46,511] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,511] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,511] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,512] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:07:46,512] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,512] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:07:46,513] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,514] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,515] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,516] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,517] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,518] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,519] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,520] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,521] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:07:46,521] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,521] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:07:46,521] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:07:46,521] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:07:46,521] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:07:46,522] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,523] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,523] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,523] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:07:46,523] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,523] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:07:46,523] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,523] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,524] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,524] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,524] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:07:46,524] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,524] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,525] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,526] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,527] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,528] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,529] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,530] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,531] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,532] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,533] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,534] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,535] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,536] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,537] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,538] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,539] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,540] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,541] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,542] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,543] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,544] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,545] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,546] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,547] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,548] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,549] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,550] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,551] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,552] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,553] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,554] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,555] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,556] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:07:46,557] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:07:46,557] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:07:46,558] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:07:46,558] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:10:00,833] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpn_mltingrs_resnet101_wrot_fc3_nodrop_attninit_warmup_smaller_150ep_mltscl.pt
TITLE:
- fpn multi ingrs with aug+rot fc 3 no dropout smaller new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 02:10:03,711] Epoch 1/150
[2023-06-25 02:10:05,677] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 02:10:06,894] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,897] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,897] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,906] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,906] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,912] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,912] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,914] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,914] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,920] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,920] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,926] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,926] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,928] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,928] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,934] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,934] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,939] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,940] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,941] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,941] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,947] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,947] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,953] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,953] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,955] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,955] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,961] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,961] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,967] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,967] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,968] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,968] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,974] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,974] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,980] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,980] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,982] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,982] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,988] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,988] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,994] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,994] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:06,996] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:06,996] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,002] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,002] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,007] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,008] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,009] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,009] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,015] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,015] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,021] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,021] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,023] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,023] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,029] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,029] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,036] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,036] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,038] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,038] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,044] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,044] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,050] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,050] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,051] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,051] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,057] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,057] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:07,063] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,695] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,696] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:10:07,696] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:10:07,697] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,698] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,699] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,700] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,701] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,701] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,701] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,701] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,701] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:10:07,702] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,702] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,702] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,702] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:07,702] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,702] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:07,702] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,702] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,702] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,702] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:07,702] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,702] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,703] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,704] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,705] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,706] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,707] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,708] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,709] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,710] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,711] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:07,712] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,713] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,714] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,715] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,716] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,717] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,718] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,719] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,720] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,721] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,722] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,723] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,724] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,725] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,726] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,727] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,728] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,729] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,730] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:07,731] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,732] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,733] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,734] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:07,735] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:07,735] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:10:07,735] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:10:07,735] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:10:11,648] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,651] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,651] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,659] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,659] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,665] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,666] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,667] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,667] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,673] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,674] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,679] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,680] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,681] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,681] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,687] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,687] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,694] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,694] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,695] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,695] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,701] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,702] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,708] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,708] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,709] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,709] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,715] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,716] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,722] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,722] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,723] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,723] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,729] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,730] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,735] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,735] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,737] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,737] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,743] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,743] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,749] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,749] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,751] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,751] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,757] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,757] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,763] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,763] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,764] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,764] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,770] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,770] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,776] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,776] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,778] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,778] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,784] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,784] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,790] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,790] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,792] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,792] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,798] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,798] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,803] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,804] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,805] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,805] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,811] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:11,811] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:10:11,817] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:10:12,459] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,460] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,461] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,461] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,462] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,462] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,463] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,464] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,465] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:10:12,465] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,466] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,467] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,467] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,467] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,467] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:10:12,467] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,467] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:10:12,467] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,467] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,467] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,467] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,467] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:10:12,467] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,467] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,468] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,469] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,470] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,471] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,472] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,473] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,474] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,475] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,476] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,477] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,478] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,479] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,480] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,481] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,482] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,483] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,484] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,485] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,486] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,487] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:10:12,488] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,489] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,490] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,491] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,492] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,493] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,494] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,495] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,496] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,497] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,498] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,498] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:10:12,498] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:10:12,498] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:10:12,498] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:10:12,498] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:32,166] DATA:
  IMGS_DIR: /srv/datasets2/nutrition5k_dataset/imagery/realsense_overhead
  METADATAS_PATH: /srv/datasets2/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv
  SPLITS_TEST_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_test_ids.txt
  SPLITS_TRAIN_PATH: /srv/datasets2/nutrition5k_dataset/dish_ids/splits/depth_train_ids.txt
EVAL: {}
MODEL:
  MASK_WEIGHT: 0.5
  NAME: openseed
  PRETRAINED: ''
SAVE_PATH: models/fixed/fpn_mltingrs_resnet101_wrot_fc3_nodrop_attninit_warmup_smaller_150ep_mltscl.pt
TITLE:
- fpn multi ingrs with aug+rot fc 3 no dropout smaller new attn initialize with warmup
  150ep multi scale
TRAIN:
  BATCH_SIZE: 32
  CKPT: null
  FINETUNE: false
  LAYERS: 1
  LOSS: multi
  LR: 0.0001
  NUM_EPOCHS: 150
  SEED: 12345
  WEIGHT_DECAY: 0.0001

[2023-06-25 02:14:35,003] Epoch 1/150
[2023-06-25 02:14:36,996] URL https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth cached in /home/parinayok/.torch/iopath_cache/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
[2023-06-25 02:14:38,442] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,444] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,445] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,453] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,453] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,459] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,459] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,461] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,461] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,467] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,467] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,473] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,473] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,475] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,475] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,481] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,481] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,487] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,487] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,488] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,488] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,494] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,494] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,500] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,500] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,502] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,502] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,508] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,508] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,514] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,514] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,516] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,516] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,522] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,522] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,528] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,528] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,529] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,529] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,535] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,535] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,541] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,541] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,543] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,543] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,549] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,549] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,555] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,555] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,557] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,557] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,563] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,563] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,569] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,569] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,570] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,570] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,576] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,576] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,582] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,583] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,584] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,584] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,590] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,590] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,596] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,596] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,598] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,598] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,604] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:38,604] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:38,610] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,248] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,249] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,251] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,252] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,252] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,253] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,253] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,254] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,255] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,256] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:39,256] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,257] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,257] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,257] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,257] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:39,257] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,257] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:39,258] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,258] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,258] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,258] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,258] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:39,258] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,258] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,259] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,260] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,261] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,262] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,263] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,264] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,265] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,266] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,267] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,268] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,269] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,270] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,271] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,272] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,273] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,274] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,275] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,276] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,277] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:39,278] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,279] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,280] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,281] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,282] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,283] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,284] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,285] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,286] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:39,287] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:39,287] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:39,288] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:39,288] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:43,279] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,281] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,281] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,287] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,287] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,293] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,293] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,295] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,295] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,301] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,301] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,307] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,307] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,309] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,309] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,315] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,315] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,321] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,321] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,322] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,322] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,328] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,328] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,334] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,334] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,336] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,336] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,342] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,342] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,348] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,348] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,350] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,350] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,356] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,356] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,362] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,362] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,363] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,364] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,370] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,370] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,375] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,376] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,377] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,377] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,383] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,383] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,389] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,389] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,391] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,391] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,397] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,397] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,403] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,403] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,405] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,405] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,411] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,411] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,417] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,417] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,418] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,418] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,424] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,424] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,430] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,431] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,432] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,432] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,438] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:43,438] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:43,444] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:44,099] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:44,100] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,100] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:44,100] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:44,101] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,102] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,103] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,103] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,104] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,105] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,106] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,107] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,108] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,109] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,110] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,111] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,111] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,111] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,111] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,111] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:44,112] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,113] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,113] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,113] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,114] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,114] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:44,114] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,114] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:44,114] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,114] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,114] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,114] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,114] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:44,114] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,114] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,115] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,116] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,117] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,118] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,119] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,120] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,121] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,122] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,123] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,124] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,125] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,126] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,127] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,128] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,129] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,130] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,131] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,132] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,133] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,134] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,135] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,136] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,137] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,138] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,139] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,140] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,141] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,142] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,143] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:44,144] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:44,145] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:44,145] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:44,145] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:44,145] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:47,381] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,383] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,384] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,390] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,390] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,396] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,396] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,398] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,398] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,404] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,404] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,410] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,410] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,411] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,412] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,417] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,418] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,424] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,424] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,425] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,426] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,431] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,431] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,437] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,438] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,439] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,439] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,445] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,445] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,451] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,452] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,453] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,453] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,459] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,459] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,465] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,466] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,467] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,467] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,474] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,474] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,480] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,480] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,482] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,482] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,488] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,488] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,494] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,494] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,496] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,496] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,502] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,502] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,508] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,508] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,510] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,510] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,516] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,516] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,522] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,522] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,524] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,524] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,530] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,530] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,536] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,536] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,537] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,537] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,543] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:47,543] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:47,549] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,221] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,222] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,222] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:48,223] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,223] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,223] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,223] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,223] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,224] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,225] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,227] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,228] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:48,228] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,228] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:48,228] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:48,228] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:48,228] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,229] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,229] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,229] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,229] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:48,229] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,229] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:48,230] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,230] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,230] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,230] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,230] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:48,230] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:48,230] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,231] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,232] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,233] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,234] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,235] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,236] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,237] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,238] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,239] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,240] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,241] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,242] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,243] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,244] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,245] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,246] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,247] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,248] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,249] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,250] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,251] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,252] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,253] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,254] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,255] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,256] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,257] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:48,258] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:48,259] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:48,260] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:48,260] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:48,260] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:50,351] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,354] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,354] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,360] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,360] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,366] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,366] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,367] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,367] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,374] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,374] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,381] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,381] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,382] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,382] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,388] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,388] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,394] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,394] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,396] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,396] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,402] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,402] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,408] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,408] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,410] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,410] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,416] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,416] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,422] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,422] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,424] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,424] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,430] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,430] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,436] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,436] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,438] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,438] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,444] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,444] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,450] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,450] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,452] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,452] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,461] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,461] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,468] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,468] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,470] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,470] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,477] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,477] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,483] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,483] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,485] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,486] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,492] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,492] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,499] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,499] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,500] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,501] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,507] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,507] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,514] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,514] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,515] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,516] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,522] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:50,522] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:50,529] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:51,127] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,127] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,128] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,129] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,129] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,129] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,129] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,129] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:51,129] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,130] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,130] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,131] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,132] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,133] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:51,133] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,134] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,134] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,134] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:51,134] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,134] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:51,134] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,134] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,134] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,134] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:51,134] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:51,134] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,135] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,136] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,137] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,138] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,139] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,140] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,141] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,142] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,143] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,144] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,145] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:51,146] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,147] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,148] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,149] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,150] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,151] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,152] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,153] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,154] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,155] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,156] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,157] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,158] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,159] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,160] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,161] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,162] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,163] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,164] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,165] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,166] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,167] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,168] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,169] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,170] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,171] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:51,172] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:51,173] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:51,173] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:51,173] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:51,173] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:53,779] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,781] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,781] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,790] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,790] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,796] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,796] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,797] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,798] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,804] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,804] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,809] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,810] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,811] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,811] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,817] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,817] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,823] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,823] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,825] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,825] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,831] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,831] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,837] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,837] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,839] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,839] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,844] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,845] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,850] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,850] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,852] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,852] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,858] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,858] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,864] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,864] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,866] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,866] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,872] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,872] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,878] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,878] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,879] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,880] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,886] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,886] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,892] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,892] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,893] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,893] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,899] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,899] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,905] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,905] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,907] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,907] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,913] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,913] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,919] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,919] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,921] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,921] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,927] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,927] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,940] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,941] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,942] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,942] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,950] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:53,950] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:53,958] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,673] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:54,674] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:54,675] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,676] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,676] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,677] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,678] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,679] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,679] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,679] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,679] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,679] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,679] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:54,680] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,680] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,680] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,680] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:54,680] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,680] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:54,680] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,680] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,680] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,680] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:54,680] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,680] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,681] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,682] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,683] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,684] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,685] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,686] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,687] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,688] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,689] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,690] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,691] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,692] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,693] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,694] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,695] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,696] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,697] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,698] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,699] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,700] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,701] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,702] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,703] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,704] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,705] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,706] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:54,707] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:54,708] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:54,709] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:54,709] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:54,709] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:56,862] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,865] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,865] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,871] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,871] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,877] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,877] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,879] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,879] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,885] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,885] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,891] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,891] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,893] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,893] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,899] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,899] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,905] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,905] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,907] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,907] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,913] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,913] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,919] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,919] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,920] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,921] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,926] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,927] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,932] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,933] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,934] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,934] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,940] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,940] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,946] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,946] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,948] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,948] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,954] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,954] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,960] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,960] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,961] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,962] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,967] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,968] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,973] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,974] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,975] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,975] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,982] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,982] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,988] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,988] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,990] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,990] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:56,996] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:56,996] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,002] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,002] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,003] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,004] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,009] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,010] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,015] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,016] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,017] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,017] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,023] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,023] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:14:57,029] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:14:57,596] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,596] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,597] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,598] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,598] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,599] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,599] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,600] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,601] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,602] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,603] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,603] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,604] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,604] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,604] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:14:57,604] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,604] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:14:57,604] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,604] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,604] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,605] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:14:57,605] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,605] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,606] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,607] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,608] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,609] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,610] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,611] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,612] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,613] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,614] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,615] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,616] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,617] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,618] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,619] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,620] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,621] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,622] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,623] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,624] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,625] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,626] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,627] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,628] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,629] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,630] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,631] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,632] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,633] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:14:57,634] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:14:57,635] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:14:57,635] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:14:57,635] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:14:57,635] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:00,161] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,163] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,163] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,170] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,170] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,176] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,176] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,178] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,178] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,184] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,184] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,190] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,190] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,191] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,192] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,197] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,198] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,203] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,204] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,205] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,205] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,211] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,211] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,217] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,217] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,219] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,219] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,225] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,225] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,231] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,231] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,232] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,232] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,238] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,238] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,244] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,244] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,246] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,246] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,252] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,252] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,258] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,258] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,259] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,260] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,265] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,266] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,271] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,271] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,273] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,273] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,279] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,279] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,285] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,285] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,287] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,287] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,293] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,293] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,299] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,299] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,300] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,300] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,306] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,306] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,312] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,312] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,314] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,314] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,320] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,320] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:00,326] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,886] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,887] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,887] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,888] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,888] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,889] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,890] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:00,891] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,892] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,892] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,892] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:00,892] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,892] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:00,892] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,892] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,892] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,893] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:00,893] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,893] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,894] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,895] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,896] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,897] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,898] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,899] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,900] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,901] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,902] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,903] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,904] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,905] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,906] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,907] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,908] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,909] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,910] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,911] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,912] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,913] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,914] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,915] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,916] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,917] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,918] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,919] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,920] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:00,921] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:00,922] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:00,922] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:15:00,922] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:00,922] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:03,319] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,322] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,322] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,329] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,329] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,335] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,335] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,337] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,337] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,343] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,343] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,349] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,349] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,351] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,351] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,357] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,357] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,363] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,363] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,365] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,365] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,371] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,371] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,377] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,377] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,378] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,379] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,384] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,384] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,390] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,391] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,392] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,392] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,398] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,398] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,404] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,404] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,406] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,406] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,412] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,412] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,418] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,418] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,419] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,420] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,425] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,426] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,431] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,432] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,433] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,433] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,439] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,439] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,445] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,445] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,447] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,447] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,453] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,453] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,459] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,459] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,461] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,461] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,467] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,467] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,473] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,473] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,474] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,474] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,480] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:03,480] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:03,486] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,044] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,045] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:15:04,045] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,045] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:04,045] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:04,045] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:04,045] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:04,046] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,047] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,048] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,048] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,049] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,050] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,051] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,052] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,053] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:04,054] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,055] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:04,055] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,056] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,057] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,058] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,058] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,058] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,058] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:04,058] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,058] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:04,058] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,058] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,058] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,058] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,058] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:04,058] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:15:04,059] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,060] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,061] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,062] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,063] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,064] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,065] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,066] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,067] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,068] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,069] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,070] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,071] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,072] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,073] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,074] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,075] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,076] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,077] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,078] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,079] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,080] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,081] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,082] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,083] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,084] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:04,085] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,086] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,087] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,088] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,089] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,090] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,091] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,092] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,093] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:04,094] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:04,094] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:15:04,095] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:04,095] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:06,603] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,606] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,606] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,613] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,613] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,619] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,619] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,621] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,621] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,627] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,627] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,633] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,633] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,634] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,635] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,640] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,640] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,646] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,646] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,648] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,648] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,654] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,654] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,660] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,660] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,662] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,662] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,668] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,668] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,674] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,674] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,675] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,675] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,681] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,681] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,687] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,687] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,689] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,689] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,695] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,695] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,701] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,701] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,702] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,702] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,708] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,708] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,714] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,714] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,716] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,716] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,722] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,722] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,728] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,728] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,730] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,730] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,735] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,736] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,741] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,742] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,743] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,743] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,749] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,749] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,755] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,755] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,757] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,757] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,763] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:06,763] => init weight of Linear/Conv2d from trunc norm
[2023-06-25 02:15:06,769] => init bias of Linear/Conv2d to zeros
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,315] Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.qkv.bias, Model Shape: torch.Size([288]) <-> Ckpt Shape: torch.Size([288])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.qkv.weight, Model Shape: torch.Size([288, 96]) <-> Ckpt Shape: torch.Size([288, 96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 3]) <-> Ckpt Shape: torch.Size([169, 3])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.0.downsample.reduction.weight, Model Shape: torch.Size([192, 384]) <-> Ckpt Shape: torch.Size([192, 384])
[2023-06-25 02:15:07,316] Loaded backbone.layers.1.blocks.0.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,316] Loaded backbone.layers.1.blocks.0.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.qkv.bias, Model Shape: torch.Size([576]) <-> Ckpt Shape: torch.Size([576])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.qkv.weight, Model Shape: torch.Size([576, 192]) <-> Ckpt Shape: torch.Size([576, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 6]) <-> Ckpt Shape: torch.Size([169, 6])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,317] Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,318] Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,318] Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,318] Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,318] Loaded backbone.layers.1.downsample.reduction.weight, Model Shape: torch.Size([384, 768]) <-> Ckpt Shape: torch.Size([384, 768])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,318] Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,319] Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.qkv.bias, Model Shape: torch.Size([1152]) <-> Ckpt Shape: torch.Size([1152])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.qkv.weight, Model Shape: torch.Size([1152, 384]) <-> Ckpt Shape: torch.Size([1152, 384])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.relative_position_bias_table, Model Shape: torch.Size([169, 12]) <-> Ckpt Shape: torch.Size([169, 12])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,320] Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,321] Loaded backbone.layers.2.downsample.reduction.weight, Model Shape: torch.Size([768, 1536]) <-> Ckpt Shape: torch.Size([768, 1536])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.qkv.bias, Model Shape: torch.Size([2304]) <-> Ckpt Shape: torch.Size([2304])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.qkv.weight, Model Shape: torch.Size([2304, 768]) <-> Ckpt Shape: torch.Size([2304, 768])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.relative_position_bias_table, Model Shape: torch.Size([169, 24]) <-> Ckpt Shape: torch.Size([169, 24])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.attn.relative_position_index, Model Shape: torch.Size([49, 49]) <-> Ckpt Shape: torch.Size([49, 49])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])
[2023-06-25 02:15:07,321] Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,322] Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,322] Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,322] Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])
[2023-06-25 02:15:07,322] Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,322] Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])
[2023-06-25 02:15:07,322] Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,322] Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,322] Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,322] Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])
[2023-06-25 02:15:07,322] Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 4, 4]) <-> Ckpt Shape: torch.Size([96, 3, 4, 4])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.adapter_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.adapter_1.weight, Model Shape: torch.Size([256, 96, 1, 1]) <-> Ckpt Shape: torch.Size([256, 96, 1, 1])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.input_proj.0.0.weight, Model Shape: torch.Size([256, 192, 1, 1]) <-> Ckpt Shape: torch.Size([256, 192, 1, 1])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.input_proj.0.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,322] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.1.0.weight, Model Shape: torch.Size([256, 384, 1, 1]) <-> Ckpt Shape: torch.Size([256, 384, 1, 1])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.1.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.2.0.weight, Model Shape: torch.Size([256, 768, 1, 1]) <-> Ckpt Shape: torch.Size([256, 768, 1, 1])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.2.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.3.0.weight, Model Shape: torch.Size([256, 768, 3, 3]) <-> Ckpt Shape: torch.Size([256, 768, 3, 3])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.input_proj.3.1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.layer_1.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.layer_1.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.layer_1.weight, Model Shape: torch.Size([256, 256, 3, 3]) <-> Ckpt Shape: torch.Size([256, 256, 3, 3])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.mask_features.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.mask_features.weight, Model Shape: torch.Size([256, 256, 1, 1]) <-> Ckpt Shape: torch.Size([256, 256, 1, 1])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,323] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,324] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,325] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,326] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,327] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.pixel_decoder.transformer.level_embed, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor._bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,328] Loaded sem_seg_head.predictor.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,329] Loaded sem_seg_head.predictor.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,330] Loaded sem_seg_head.predictor.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.class_embed, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,331] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,332] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,333] Loaded sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.weight, Model Shape: torch.Size([4, 256]) <-> Ckpt Shape: torch.Size([4, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,334] Loaded sem_seg_head.predictor.decoder.layers.0.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,335] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,336] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,337] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,338] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,339] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,340] Loaded sem_seg_head.predictor.decoder.layers.5.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,341] Loaded sem_seg_head.predictor.decoder.layers.6.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.6.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,342] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.7.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.bias, Model Shape: torch.Size([128]) <-> Ckpt Shape: torch.Size([128])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.weight, Model Shape: torch.Size([128, 256]) <-> Ckpt Shape: torch.Size([128, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,343] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.linear1.weight, Model Shape: torch.Size([2048, 256]) <-> Ckpt Shape: torch.Size([2048, 256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.linear2.weight, Model Shape: torch.Size([256, 2048]) <-> Ckpt Shape: torch.Size([256, 2048])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm1.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm2.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.norm3.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.in_proj_weight, Model Shape: torch.Size([768, 256]) <-> Ckpt Shape: torch.Size([768, 256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.layers.8.self_attn.out_proj.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,344] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.0.weight, Model Shape: torch.Size([256, 512]) <-> Ckpt Shape: torch.Size([256, 512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.decoder.ref_point_head.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.decoder_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.decoder_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.enc_output.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.enc_output.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.enc_output_norm.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.enc_output_norm.weight, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,345] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,346] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,347] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,348] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,349] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,350] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,351] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,352] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Model Shape: torch.Size([49408, 512]) <-> Ckpt Shape: torch.Size([49408, 512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.lang_proj, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_encoder.logit_scale, Model Shape: torch.Size([]) <-> Ckpt Shape: torch.Size([])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.lang_mapper, Model Shape: torch.Size([512, 256]) <-> Ckpt Shape: torch.Size([512, 256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.0.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.0.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.1.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.1.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.2.bias, Model Shape: torch.Size([256]) <-> Ckpt Shape: torch.Size([256])
[2023-06-25 02:15:07,353] Loaded sem_seg_head.predictor.mask_embed.layers.2.weight, Model Shape: torch.Size([256, 256]) <-> Ckpt Shape: torch.Size([256, 256])
[2023-06-25 02:15:07,353] $UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])
[2023-06-25 02:15:07,353] $UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([18, 512])
[2023-06-25 02:15:07,353] *UNMATCHED* sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Model Shape: torch.Size([77, 512]) <-> Ckpt Shape: torch.Size([18, 512])
